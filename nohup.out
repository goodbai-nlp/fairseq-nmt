Start training...
2021-03-10 20:46:19 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'tpu': False, 'distributed_num_procs': 1}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4096, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4096, 'batch_size_valid': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 200, 'max_update': 200000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/home/amax/Data/flstm/iwslt/multifeatgen_baseline_new', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': 50, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'model_parallel_size': 1, 'distributed_rank': 0}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='multifeatgen', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='multifeatgen', attention_dropout=0.1, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, conv_kernel_size=3, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/iwslt14_deen_s8000t6000', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_glu=True, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, empty_cache_freq=0, encoder_attention_heads=8, encoder_conv_dim=512, encoder_conv_type='lightweight', encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_glu=True, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=False, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', heartbeat_timeout=-1, ignore_prefix_size=0, input_dropout=0.1, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=200, max_source_positions=1024, max_target_positions=1024, max_tokens=4096, max_tokens_valid=4096, max_update=200000, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_reccurrent_enc=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=50, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/home/amax/Data/flstm/iwslt/multifeatgen_baseline_new', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, simul_type=None, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[1], upsample_primary=-1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, weight_dropout=0.1, weight_softmax=True, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin/iwslt14_deen_s8000t6000', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'simul_type': None}
2021-03-10 20:46:19 | INFO | fairseq.tasks.translation | [de] dictionary: 8856 types
2021-03-10 20:46:19 | INFO | fairseq.tasks.translation | [en] dictionary: 6632 types
2021-03-10 20:46:19 | INFO | fairseq.data.data_utils | loaded 7,282 examples from: data-bin/iwslt14_deen_s8000t6000/valid.de-en.de
2021-03-10 20:46:19 | INFO | fairseq.data.data_utils | loaded 7,282 examples from: data-bin/iwslt14_deen_s8000t6000/valid.de-en.en
2021-03-10 20:46:19 | INFO | fairseq.tasks.translation | data-bin/iwslt14_deen_s8000t6000 valid de-en 7282 examples
No module named 'lightconv_cuda'
2021-03-10 20:46:19 | INFO | fairseq_cli.train | FeatLstmModel(
  (encoder): FeatLstmEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(8856, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layer): MultiFeatsGenEncoderLayer(
      (feat0): LightConvEncoderLayer(
        dropout=0.3, relu_dropout=0.0, input_dropout=0.1, normalize_before=False
        (linear1): Linear(in_features=512, out_features=1024, bias=True)
        (act): GLU(dim=-1)
        (conv): LightweightConv1dTBC(
          512, kernel_size=3, padding_l=1, num_heads=8, weight_softmax=True, bias=False, weight_dropout=0.1
          (weight_dropout_module): FairseqDropout()
        )
        (linear2): Linear(in_features=512, out_features=512, bias=True)
        (dropout_module): FairseqDropout()
        (relu_dropout_module): FairseqDropout()
        (input_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (layer_norms): ModuleList(
          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
      (feat1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (fusion_net): LSTMCell(1024, 512)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(6632, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=6632, bias=False)
  )
)
2021-03-10 20:46:19 | INFO | fairseq_cli.train | task: TranslationTask
2021-03-10 20:46:19 | INFO | fairseq_cli.train | model: FeatLstmModel
2021-03-10 20:46:19 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2021-03-10 20:46:19 | INFO | fairseq_cli.train | num. model params: 33,949,208 (num. trained: 33,949,208)
2021-03-10 20:46:20 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2021-03-10 20:46:20 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2021-03-10 20:46:20 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = GeForce RTX 2080 Ti                     
2021-03-10 20:46:20 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2021-03-10 20:46:20 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2021-03-10 20:46:20 | INFO | fairseq_cli.train | max tokens per GPU = 4096 and batch size per GPU = None
2021-03-10 20:46:20 | INFO | fairseq.trainer | Preparing to load checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-10 20:46:20 | INFO | fairseq.trainer | No existing checkpoint found /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-10 20:46:20 | INFO | fairseq.trainer | loading train data for epoch 1
2021-03-10 20:46:20 | INFO | fairseq.data.data_utils | loaded 160,215 examples from: data-bin/iwslt14_deen_s8000t6000/train.de-en.de
2021-03-10 20:46:20 | INFO | fairseq.data.data_utils | loaded 160,215 examples from: data-bin/iwslt14_deen_s8000t6000/train.de-en.en
2021-03-10 20:46:20 | INFO | fairseq.tasks.translation | data-bin/iwslt14_deen_s8000t6000 train de-en 160215 examples
Start training...
2021-03-10 20:46:25 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'tpu': False, 'distributed_num_procs': 1}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4096, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4096, 'batch_size_valid': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 200, 'max_update': 200000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/home/amax/Data/flstm/iwslt/multifeatgen_baseline_new', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': 50, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'model_parallel_size': 1, 'distributed_rank': 0}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='multifeatgen', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='multifeatgen', attention_dropout=0.1, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, conv_kernel_size=3, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/iwslt14_deen_s8000t6000', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_glu=True, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, empty_cache_freq=0, encoder_attention_heads=8, encoder_conv_dim=512, encoder_conv_type='lightweight', encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_glu=True, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=False, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', heartbeat_timeout=-1, ignore_prefix_size=0, input_dropout=0.1, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=200, max_source_positions=1024, max_target_positions=1024, max_tokens=4096, max_tokens_valid=4096, max_update=200000, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_reccurrent_enc=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=50, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/home/amax/Data/flstm/iwslt/multifeatgen_baseline_new', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, simul_type=None, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[1], upsample_primary=-1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, weight_dropout=0.1, weight_softmax=True, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin/iwslt14_deen_s8000t6000', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'simul_type': None}
2021-03-10 20:46:25 | INFO | fairseq.tasks.translation | [de] dictionary: 8856 types
2021-03-10 20:46:25 | INFO | fairseq.tasks.translation | [en] dictionary: 6632 types
2021-03-10 20:46:25 | INFO | fairseq.data.data_utils | loaded 7,282 examples from: data-bin/iwslt14_deen_s8000t6000/valid.de-en.de
2021-03-10 20:46:25 | INFO | fairseq.data.data_utils | loaded 7,282 examples from: data-bin/iwslt14_deen_s8000t6000/valid.de-en.en
2021-03-10 20:46:25 | INFO | fairseq.tasks.translation | data-bin/iwslt14_deen_s8000t6000 valid de-en 7282 examples
No module named 'lightconv_cuda'
2021-03-10 20:46:25 | INFO | fairseq_cli.train | FeatLstmModel(
  (encoder): FeatLstmEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(8856, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layer): MultiFeatsGenEncoderLayer(
      (feat0): LightConvEncoderLayer(
        dropout=0.3, relu_dropout=0.0, input_dropout=0.1, normalize_before=False
        (linear1): Linear(in_features=512, out_features=1024, bias=True)
        (act): GLU(dim=-1)
        (conv): LightweightConv1dTBC(
          512, kernel_size=3, padding_l=1, num_heads=8, weight_softmax=True, bias=False, weight_dropout=0.1
          (weight_dropout_module): FairseqDropout()
        )
        (linear2): Linear(in_features=512, out_features=512, bias=True)
        (dropout_module): FairseqDropout()
        (relu_dropout_module): FairseqDropout()
        (input_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (layer_norms): ModuleList(
          (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
      (feat1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (fusion_net): LSTMCell(1024, 512)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(6632, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=6632, bias=False)
  )
)
2021-03-10 20:46:25 | INFO | fairseq_cli.train | task: TranslationTask
2021-03-10 20:46:25 | INFO | fairseq_cli.train | model: FeatLstmModel
2021-03-10 20:46:25 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2021-03-10 20:46:25 | INFO | fairseq_cli.train | num. model params: 33,949,208 (num. trained: 33,949,208)
2021-03-10 20:46:27 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2021-03-10 20:46:27 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2021-03-10 20:46:27 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = GeForce RTX 2080 Ti                     
2021-03-10 20:46:27 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2021-03-10 20:46:27 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2021-03-10 20:46:27 | INFO | fairseq_cli.train | max tokens per GPU = 4096 and batch size per GPU = None
2021-03-10 20:46:27 | INFO | fairseq.trainer | Preparing to load checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-10 20:46:27 | INFO | fairseq.trainer | No existing checkpoint found /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-10 20:46:27 | INFO | fairseq.trainer | loading train data for epoch 1
2021-03-10 20:46:27 | INFO | fairseq.data.data_utils | loaded 160,215 examples from: data-bin/iwslt14_deen_s8000t6000/train.de-en.de
2021-03-10 20:46:27 | INFO | fairseq.data.data_utils | loaded 160,215 examples from: data-bin/iwslt14_deen_s8000t6000/train.de-en.en
2021-03-10 20:46:27 | INFO | fairseq.tasks.translation | data-bin/iwslt14_deen_s8000t6000 train de-en 160215 examples
2021-03-10 20:46:27 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16
2021-03-10 20:46:27 | INFO | fairseq.trainer | begin training epoch 1
2021-03-10 20:46:27 | INFO | fairseq_cli.train | Start iterating over samples
/home/amax/Codes/flstm-nmt/fairseq/utils.py:344: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2021-03-10 20:46:49 | INFO | train_inner | epoch 001:    100 / 1103 loss=12.27, nll_loss=12.133, ppl=4491.5, wps=16601.4, ups=4.71, wpb=3515.6, bsz=121.8, num_updates=100, lr=1.25e-05, gnorm=3.112, train_wall=21, gb_free=7, wall=22
2021-03-10 20:47:11 | INFO | train_inner | epoch 001:    200 / 1103 loss=10.66, nll_loss=10.334, ppl=1290.92, wps=15977.3, ups=4.5, wpb=3550.5, bsz=141.4, num_updates=200, lr=2.5e-05, gnorm=1.387, train_wall=22, gb_free=7, wall=44
2021-03-10 20:47:33 | INFO | train_inner | epoch 001:    300 / 1103 loss=10.025, nll_loss=9.607, ppl=779.84, wps=15801.4, ups=4.45, wpb=3551.7, bsz=133.6, num_updates=300, lr=3.75e-05, gnorm=1.408, train_wall=22, gb_free=6.8, wall=66
2021-03-10 20:47:56 | INFO | train_inner | epoch 001:    400 / 1103 loss=9.557, nll_loss=9.042, ppl=527.21, wps=16235, ups=4.45, wpb=3651.2, bsz=158.2, num_updates=400, lr=5e-05, gnorm=1.4, train_wall=22, gb_free=7, wall=89
2021-03-10 20:48:18 | INFO | train_inner | epoch 001:    500 / 1103 loss=9.442, nll_loss=8.896, ppl=476.24, wps=16039.7, ups=4.4, wpb=3646.7, bsz=152.6, num_updates=500, lr=6.25e-05, gnorm=1.421, train_wall=23, gb_free=7, wall=112
2021-03-10 20:48:41 | INFO | train_inner | epoch 001:    600 / 1103 loss=9.192, nll_loss=8.609, ppl=390.48, wps=15943.3, ups=4.44, wpb=3591, bsz=156, num_updates=600, lr=7.5e-05, gnorm=1.402, train_wall=22, gb_free=7.4, wall=134
2021-03-10 20:49:03 | INFO | train_inner | epoch 001:    700 / 1103 loss=8.953, nll_loss=8.333, ppl=322.49, wps=15919.9, ups=4.47, wpb=3562, bsz=163, num_updates=700, lr=8.75e-05, gnorm=1.529, train_wall=22, gb_free=6.9, wall=157
2021-03-10 20:49:26 | INFO | train_inner | epoch 001:    800 / 1103 loss=8.832, nll_loss=8.194, ppl=292.78, wps=15964.2, ups=4.42, wpb=3613.3, bsz=138.2, num_updates=800, lr=0.0001, gnorm=1.199, train_wall=23, gb_free=7.5, wall=179
2021-03-10 20:49:48 | INFO | train_inner | epoch 001:    900 / 1103 loss=8.665, nll_loss=7.998, ppl=255.66, wps=15902.5, ups=4.5, wpb=3532.1, bsz=139.5, num_updates=900, lr=0.0001125, gnorm=1.366, train_wall=22, gb_free=6.7, wall=201
2021-03-10 20:50:11 | INFO | train_inner | epoch 001:   1000 / 1103 loss=8.463, nll_loss=7.764, ppl=217.31, wps=15815.9, ups=4.41, wpb=3583.6, bsz=152.7, num_updates=1000, lr=0.000125, gnorm=1.364, train_wall=23, gb_free=7, wall=224
2021-03-10 20:50:33 | INFO | train_inner | epoch 001:   1100 / 1103 loss=8.409, nll_loss=7.697, ppl=207.46, wps=15858, ups=4.47, wpb=3549.9, bsz=140.7, num_updates=1100, lr=0.0001375, gnorm=1.453, train_wall=22, gb_free=6.9, wall=246
2021-03-10 20:50:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-10 20:50:38 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 8.122 | nll_loss 7.325 | ppl 160.31 | wps 48197.2 | wpb 2873.1 | bsz 115.6 | num_updates 1103
2021-03-10 20:50:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 1103 updates
2021-03-10 20:50:38 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt
2021-03-10 20:50:38 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt
2021-03-10 20:50:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt (epoch 1 @ 1103 updates, score 8.122) (writing took 0.5291342586278915 seconds)
2021-03-10 20:50:38 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2021-03-10 20:50:38 | INFO | train | epoch 001 | loss 9.489 | nll_loss 8.955 | ppl 496.13 | wps 15725.2 | ups 4.39 | wpb 3577.8 | bsz 145.3 | num_updates 1103 | lr 0.000137875 | gnorm 1.548 | train_wall 246 | gb_free 7 | wall 251
2021-03-10 20:50:38 | INFO | fairseq.trainer | begin training epoch 2
2021-03-10 20:50:38 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-10 20:51:00 | INFO | train_inner | epoch 002:     97 / 1103 loss=8.092, nll_loss=7.334, ppl=161.34, wps=13292.3, ups=3.67, wpb=3617.3, bsz=161.5, num_updates=1200, lr=0.00015, gnorm=1.281, train_wall=23, gb_free=6.9, wall=274
2021-03-10 20:51:23 | INFO | train_inner | epoch 002:    197 / 1103 loss=8.05, nll_loss=7.284, ppl=155.84, wps=15903.1, ups=4.43, wpb=3592.6, bsz=144.8, num_updates=1300, lr=0.0001625, gnorm=1.244, train_wall=22, gb_free=7, wall=296
2021-03-10 20:51:46 | INFO | train_inner | epoch 002:    297 / 1103 loss=7.884, nll_loss=7.091, ppl=136.38, wps=15686.1, ups=4.41, wpb=3555.7, bsz=157.4, num_updates=1400, lr=0.000175, gnorm=1.349, train_wall=23, gb_free=7.1, wall=319
2021-03-10 20:52:08 | INFO | train_inner | epoch 002:    397 / 1103 loss=7.882, nll_loss=7.087, ppl=135.92, wps=15836.8, ups=4.45, wpb=3560.8, bsz=132.4, num_updates=1500, lr=0.0001875, gnorm=1.228, train_wall=22, gb_free=7.1, wall=341
2021-03-10 20:52:31 | INFO | train_inner | epoch 002:    497 / 1103 loss=7.732, nll_loss=6.913, ppl=120.49, wps=16043.6, ups=4.45, wpb=3607.3, bsz=142.7, num_updates=1600, lr=0.0002, gnorm=1.284, train_wall=22, gb_free=7, wall=364
2021-03-10 20:52:53 | INFO | train_inner | epoch 002:    597 / 1103 loss=7.627, nll_loss=6.792, ppl=110.84, wps=15895.8, ups=4.43, wpb=3588.9, bsz=147, num_updates=1700, lr=0.0002125, gnorm=1.26, train_wall=22, gb_free=7, wall=386
2021-03-10 20:53:16 | INFO | train_inner | epoch 002:    697 / 1103 loss=7.438, nll_loss=6.576, ppl=95.41, wps=15800, ups=4.44, wpb=3555.9, bsz=151.4, num_updates=1800, lr=0.000225, gnorm=1.171, train_wall=22, gb_free=7, wall=409
2021-03-10 20:53:38 | INFO | train_inner | epoch 002:    797 / 1103 loss=7.378, nll_loss=6.505, ppl=90.8, wps=15906.6, ups=4.44, wpb=3585, bsz=146.2, num_updates=1900, lr=0.0002375, gnorm=1.233, train_wall=22, gb_free=6.8, wall=431
2021-03-10 20:54:01 | INFO | train_inner | epoch 002:    897 / 1103 loss=7.317, nll_loss=6.434, ppl=86.44, wps=16021.9, ups=4.46, wpb=3593.9, bsz=135.4, num_updates=2000, lr=0.00025, gnorm=1.16, train_wall=22, gb_free=7, wall=454
2021-03-10 20:54:23 | INFO | train_inner | epoch 002:    997 / 1103 loss=7.144, nll_loss=6.236, ppl=75.39, wps=15666.9, ups=4.47, wpb=3503.2, bsz=142.8, num_updates=2100, lr=0.0002625, gnorm=1.157, train_wall=22, gb_free=7.4, wall=476
2021-03-10 20:54:45 | INFO | train_inner | epoch 002:   1097 / 1103 loss=7.124, nll_loss=6.211, ppl=74.07, wps=16216.4, ups=4.5, wpb=3607.4, bsz=139.8, num_updates=2200, lr=0.000275, gnorm=1.221, train_wall=22, gb_free=6.8, wall=499
2021-03-10 20:54:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-10 20:54:51 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 6.698 | nll_loss 5.664 | ppl 50.72 | wps 48199.2 | wpb 2873.1 | bsz 115.6 | num_updates 2206 | best_loss 6.698
2021-03-10 20:54:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 2206 updates
2021-03-10 20:54:51 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt
2021-03-10 20:54:53 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt
2021-03-10 20:54:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt (epoch 2 @ 2206 updates, score 6.698) (writing took 4.509477291256189 seconds)
2021-03-10 20:54:55 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2021-03-10 20:54:55 | INFO | train | epoch 002 | loss 7.604 | nll_loss 6.767 | ppl 108.91 | wps 15373.5 | ups 4.3 | wpb 3577.8 | bsz 145.3 | num_updates 2206 | lr 0.00027575 | gnorm 1.236 | train_wall 247 | gb_free 6.6 | wall 508
2021-03-10 20:54:55 | INFO | fairseq.trainer | begin training epoch 3
2021-03-10 20:54:55 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-10 20:55:16 | INFO | train_inner | epoch 003:     94 / 1103 loss=6.908, nll_loss=5.963, ppl=62.39, wps=11620.6, ups=3.24, wpb=3584.9, bsz=140.2, num_updates=2300, lr=0.0002875, gnorm=1.121, train_wall=22, gb_free=7.3, wall=529
2021-03-10 20:55:39 | INFO | train_inner | epoch 003:    194 / 1103 loss=6.806, nll_loss=5.845, ppl=57.46, wps=15792, ups=4.45, wpb=3547.5, bsz=138.9, num_updates=2400, lr=0.0003, gnorm=1.193, train_wall=22, gb_free=7, wall=552
2021-03-10 20:56:01 | INFO | train_inner | epoch 003:    294 / 1103 loss=6.648, nll_loss=5.663, ppl=50.68, wps=15866.9, ups=4.45, wpb=3566, bsz=143.4, num_updates=2500, lr=0.0003125, gnorm=1.152, train_wall=22, gb_free=6.7, wall=574
2021-03-10 20:56:23 | INFO | train_inner | epoch 003:    394 / 1103 loss=6.524, nll_loss=5.517, ppl=45.79, wps=16144.7, ups=4.48, wpb=3605, bsz=143.4, num_updates=2600, lr=0.000325, gnorm=1.143, train_wall=22, gb_free=7.1, wall=597
2021-03-10 20:56:46 | INFO | train_inner | epoch 003:    494 / 1103 loss=6.478, nll_loss=5.462, ppl=44.09, wps=16096.7, ups=4.5, wpb=3577.6, bsz=135.7, num_updates=2700, lr=0.0003375, gnorm=1.143, train_wall=22, gb_free=7.2, wall=619
2021-03-10 20:57:08 | INFO | train_inner | epoch 003:    594 / 1103 loss=6.239, nll_loss=5.185, ppl=36.39, wps=15752.9, ups=4.43, wpb=3557.8, bsz=152.4, num_updates=2800, lr=0.00035, gnorm=1.128, train_wall=22, gb_free=7, wall=641
2021-03-10 20:57:31 | INFO | train_inner | epoch 003:    694 / 1103 loss=6.151, nll_loss=5.083, ppl=33.89, wps=15934.5, ups=4.4, wpb=3623.5, bsz=157.7, num_updates=2900, lr=0.0003625, gnorm=1.132, train_wall=23, gb_free=6.8, wall=664
2021-03-10 20:57:54 | INFO | train_inner | epoch 003:    794 / 1103 loss=6.041, nll_loss=4.953, ppl=30.98, wps=15922.3, ups=4.45, wpb=3581, bsz=153, num_updates=3000, lr=0.000375, gnorm=1.129, train_wall=22, gb_free=6.9, wall=687
2021-03-10 20:58:16 | INFO | train_inner | epoch 003:    894 / 1103 loss=6.092, nll_loss=5.009, ppl=32.19, wps=15974.9, ups=4.44, wpb=3595.6, bsz=122.1, num_updates=3100, lr=0.0003875, gnorm=1.11, train_wall=22, gb_free=7.2, wall=709
2021-03-10 20:58:38 | INFO | train_inner | epoch 003:    994 / 1103 loss=5.916, nll_loss=4.805, ppl=27.96, wps=15995.7, ups=4.5, wpb=3557.8, bsz=149.6, num_updates=3200, lr=0.0004, gnorm=1.104, train_wall=22, gb_free=6.9, wall=731
2021-03-10 20:59:01 | INFO | train_inner | epoch 003:   1094 / 1103 loss=5.783, nll_loss=4.65, ppl=25.1, wps=15889.6, ups=4.46, wpb=3560.4, bsz=158.1, num_updates=3300, lr=0.0004125, gnorm=1.13, train_wall=22, gb_free=7.1, wall=754
2021-03-10 20:59:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-10 20:59:06 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 5.548 | nll_loss 4.286 | ppl 19.5 | wps 48239.9 | wpb 2873.1 | bsz 115.6 | num_updates 3309 | best_loss 5.548
2021-03-10 20:59:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 3309 updates
2021-03-10 20:59:06 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt
2021-03-10 20:59:09 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt
2021-03-10 20:59:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt (epoch 3 @ 3309 updates, score 5.548) (writing took 4.470445849001408 seconds)
2021-03-10 20:59:11 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2021-03-10 20:59:11 | INFO | train | epoch 003 | loss 6.316 | nll_loss 5.274 | ppl 38.68 | wps 15419.3 | ups 4.31 | wpb 3577.8 | bsz 145.3 | num_updates 3309 | lr 0.000413625 | gnorm 1.134 | train_wall 246 | gb_free 6.9 | wall 764
2021-03-10 20:59:11 | INFO | fairseq.trainer | begin training epoch 4
2021-03-10 20:59:11 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-10 20:59:32 | INFO | train_inner | epoch 004:     91 / 1103 loss=5.647, nll_loss=4.493, ppl=22.51, wps=11558.1, ups=3.24, wpb=3565.6, bsz=151.6, num_updates=3400, lr=0.000425, gnorm=1.066, train_wall=22, gb_free=6.5, wall=785
2021-03-10 20:59:54 | INFO | train_inner | epoch 004:    191 / 1103 loss=5.659, nll_loss=4.502, ppl=22.66, wps=15923.8, ups=4.49, wpb=3543.4, bsz=136.6, num_updates=3500, lr=0.0004375, gnorm=1.084, train_wall=22, gb_free=6.6, wall=807
2021-03-10 21:00:16 | INFO | train_inner | epoch 004:    291 / 1103 loss=5.573, nll_loss=4.401, ppl=21.12, wps=16177.7, ups=4.47, wpb=3621.9, bsz=132.6, num_updates=3600, lr=0.00045, gnorm=1.052, train_wall=22, gb_free=7, wall=829
2021-03-10 21:00:38 | INFO | train_inner | epoch 004:    391 / 1103 loss=5.618, nll_loss=4.451, ppl=21.88, wps=15895.9, ups=4.52, wpb=3516.7, bsz=134.6, num_updates=3700, lr=0.0004625, gnorm=1.094, train_wall=22, gb_free=7, wall=851
2021-03-10 21:01:01 | INFO | train_inner | epoch 004:    491 / 1103 loss=5.451, nll_loss=4.258, ppl=19.13, wps=16016.3, ups=4.44, wpb=3611.1, bsz=140.3, num_updates=3800, lr=0.000475, gnorm=1.013, train_wall=22, gb_free=7, wall=874
2021-03-10 21:01:23 | INFO | train_inner | epoch 004:    591 / 1103 loss=5.447, nll_loss=4.252, ppl=19.06, wps=15986.5, ups=4.44, wpb=3596.9, bsz=139.8, num_updates=3900, lr=0.0004875, gnorm=1.054, train_wall=22, gb_free=7.3, wall=896
2021-03-10 21:01:46 | INFO | train_inner | epoch 004:    691 / 1103 loss=5.363, nll_loss=4.156, ppl=17.82, wps=15886.5, ups=4.41, wpb=3598.3, bsz=145.3, num_updates=4000, lr=0.0005, gnorm=1.038, train_wall=23, gb_free=6.8, wall=919
2021-03-10 21:02:08 | INFO | train_inner | epoch 004:    791 / 1103 loss=5.291, nll_loss=4.072, ppl=16.82, wps=15732.3, ups=4.47, wpb=3521.2, bsz=162.6, num_updates=4100, lr=0.000493865, gnorm=1.075, train_wall=22, gb_free=6.9, wall=942
2021-03-10 21:02:31 | INFO | train_inner | epoch 004:    891 / 1103 loss=5.277, nll_loss=4.055, ppl=16.62, wps=15917.2, ups=4.46, wpb=3571.6, bsz=151.5, num_updates=4200, lr=0.00048795, gnorm=1.026, train_wall=22, gb_free=7, wall=964
2021-03-10 21:02:53 | INFO | train_inner | epoch 004:    991 / 1103 loss=5.207, nll_loss=3.975, ppl=15.72, wps=16249.8, ups=4.46, wpb=3640, bsz=145, num_updates=4300, lr=0.000482243, gnorm=0.959, train_wall=22, gb_free=6.8, wall=986
2021-03-10 21:03:16 | INFO | train_inner | epoch 004:   1091 / 1103 loss=5.12, nll_loss=3.876, ppl=14.69, wps=15918.3, ups=4.46, wpb=3572.9, bsz=157.1, num_updates=4400, lr=0.000476731, gnorm=0.961, train_wall=22, gb_free=7.2, wall=1009
2021-03-10 21:03:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-10 21:03:22 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 4.961 | nll_loss 3.572 | ppl 11.89 | wps 48243.5 | wpb 2873.1 | bsz 115.6 | num_updates 4412 | best_loss 4.961
2021-03-10 21:03:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 4412 updates
2021-03-10 21:03:22 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt
2021-03-10 21:03:24 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt
2021-03-10 21:03:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt (epoch 4 @ 4412 updates, score 4.961) (writing took 4.435573291033506 seconds)
2021-03-10 21:03:27 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2021-03-10 21:03:27 | INFO | train | epoch 004 | loss 5.417 | nll_loss 4.22 | ppl 18.63 | wps 15438 | ups 4.31 | wpb 3577.8 | bsz 145.3 | num_updates 4412 | lr 0.000476083 | gnorm 1.037 | train_wall 246 | gb_free 7.2 | wall 1020
2021-03-10 21:03:27 | INFO | fairseq.trainer | begin training epoch 5
2021-03-10 21:03:27 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-10 21:03:46 | INFO | train_inner | epoch 005:     88 / 1103 loss=5.043, nll_loss=3.788, ppl=13.81, wps=11533.9, ups=3.25, wpb=3545.8, bsz=155.8, num_updates=4500, lr=0.000471405, gnorm=0.974, train_wall=22, gb_free=7, wall=1040
2021-03-10 21:04:09 | INFO | train_inner | epoch 005:    188 / 1103 loss=4.97, nll_loss=3.702, ppl=13.02, wps=16087.5, ups=4.44, wpb=3626.9, bsz=152.2, num_updates=4600, lr=0.000466252, gnorm=0.927, train_wall=22, gb_free=7, wall=1062
2021-03-10 21:04:31 | INFO | train_inner | epoch 005:    288 / 1103 loss=5.032, nll_loss=3.773, ppl=13.67, wps=15907.8, ups=4.47, wpb=3561.3, bsz=141.7, num_updates=4700, lr=0.000461266, gnorm=0.959, train_wall=22, gb_free=7.6, wall=1084
2021-03-10 21:04:54 | INFO | train_inner | epoch 005:    388 / 1103 loss=4.958, nll_loss=3.689, ppl=12.9, wps=16025.1, ups=4.47, wpb=3583.8, bsz=140.7, num_updates=4800, lr=0.000456435, gnorm=0.909, train_wall=22, gb_free=7, wall=1107
2021-03-10 21:05:16 | INFO | train_inner | epoch 005:    488 / 1103 loss=4.962, nll_loss=3.692, ppl=12.93, wps=15629.1, ups=4.43, wpb=3527.9, bsz=129, num_updates=4900, lr=0.000451754, gnorm=0.934, train_wall=22, gb_free=6.8, wall=1129
2021-03-10 21:05:39 | INFO | train_inner | epoch 005:    588 / 1103 loss=4.908, nll_loss=3.63, ppl=12.38, wps=15812.6, ups=4.45, wpb=3554.2, bsz=137.5, num_updates=5000, lr=0.000447214, gnorm=0.916, train_wall=22, gb_free=6.9, wall=1152
2021-03-10 21:06:01 | INFO | train_inner | epoch 005:    688 / 1103 loss=4.756, nll_loss=3.457, ppl=10.99, wps=16126.9, ups=4.42, wpb=3646, bsz=162.2, num_updates=5100, lr=0.000442807, gnorm=0.877, train_wall=22, gb_free=7.2, wall=1175
2021-03-10 21:06:24 | INFO | train_inner | epoch 005:    788 / 1103 loss=4.874, nll_loss=3.594, ppl=12.07, wps=15798.2, ups=4.47, wpb=3532.7, bsz=136.1, num_updates=5200, lr=0.000438529, gnorm=0.919, train_wall=22, gb_free=6.9, wall=1197
2021-03-10 21:06:46 | INFO | train_inner | epoch 005:    888 / 1103 loss=4.766, nll_loss=3.47, ppl=11.08, wps=15912.9, ups=4.45, wpb=3572.4, bsz=158.9, num_updates=5300, lr=0.000434372, gnorm=0.941, train_wall=22, gb_free=7, wall=1219
2021-03-10 21:07:09 | INFO | train_inner | epoch 005:    988 / 1103 loss=4.787, nll_loss=3.494, ppl=11.27, wps=15886.7, ups=4.46, wpb=3562.5, bsz=139, num_updates=5400, lr=0.000430331, gnorm=0.892, train_wall=22, gb_free=6.9, wall=1242
2021-03-10 21:07:31 | INFO | train_inner | epoch 005:   1088 / 1103 loss=4.765, nll_loss=3.47, ppl=11.08, wps=15994.4, ups=4.41, wpb=3629.4, bsz=144.1, num_updates=5500, lr=0.000426401, gnorm=0.899, train_wall=23, gb_free=6.6, wall=1264
2021-03-10 21:07:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-10 21:07:38 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 4.599 | nll_loss 3.157 | ppl 8.92 | wps 48285.5 | wpb 2873.1 | bsz 115.6 | num_updates 5515 | best_loss 4.599
2021-03-10 21:07:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 5515 updates
2021-03-10 21:07:38 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt
2021-03-10 21:07:41 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt
2021-03-10 21:07:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt (epoch 5 @ 5515 updates, score 4.599) (writing took 4.789154198020697 seconds)
2021-03-10 21:07:43 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2021-03-10 21:07:43 | INFO | train | epoch 005 | loss 4.886 | nll_loss 3.607 | ppl 12.19 | wps 15375.2 | ups 4.3 | wpb 3577.8 | bsz 145.3 | num_updates 5515 | lr 0.000425821 | gnorm 0.922 | train_wall 247 | gb_free 7.2 | wall 1276
2021-03-10 21:07:43 | INFO | fairseq.trainer | begin training epoch 6
2021-03-10 21:07:43 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-10 21:08:02 | INFO | train_inner | epoch 006:     85 / 1103 loss=4.68, nll_loss=3.372, ppl=10.36, wps=11542.7, ups=3.26, wpb=3544.4, bsz=144.4, num_updates=5600, lr=0.000422577, gnorm=0.923, train_wall=22, gb_free=7.2, wall=1295
2021-03-10 21:08:24 | INFO | train_inner | epoch 006:    185 / 1103 loss=4.618, nll_loss=3.3, ppl=9.85, wps=15905.8, ups=4.49, wpb=3545.7, bsz=155.5, num_updates=5700, lr=0.000418854, gnorm=0.908, train_wall=22, gb_free=7.1, wall=1317
2021-03-10 21:08:47 | INFO | train_inner | epoch 006:    285 / 1103 loss=4.612, nll_loss=3.292, ppl=9.8, wps=15576.4, ups=4.45, wpb=3498.8, bsz=137.2, num_updates=5800, lr=0.000415227, gnorm=0.892, train_wall=22, gb_free=7.3, wall=1340
2021-03-10 21:09:10 | INFO | train_inner | epoch 006:    385 / 1103 loss=4.557, nll_loss=3.231, ppl=9.39, wps=15898.1, ups=4.38, wpb=3627.9, bsz=146.6, num_updates=5900, lr=0.000411693, gnorm=0.847, train_wall=23, gb_free=6.8, wall=1363
2021-03-10 21:09:32 | INFO | train_inner | epoch 006:    485 / 1103 loss=4.602, nll_loss=3.281, ppl=9.72, wps=16081.5, ups=4.43, wpb=3629.9, bsz=143.4, num_updates=6000, lr=0.000408248, gnorm=0.876, train_wall=22, gb_free=7.1, wall=1385
2021-03-10 21:09:54 | INFO | train_inner | epoch 006:    585 / 1103 loss=4.637, nll_loss=3.323, ppl=10.01, wps=15949.2, ups=4.49, wpb=3552.5, bsz=138.1, num_updates=6100, lr=0.000404888, gnorm=0.899, train_wall=22, gb_free=7.4, wall=1408
2021-03-10 21:10:17 | INFO | train_inner | epoch 006:    685 / 1103 loss=4.534, nll_loss=3.206, ppl=9.23, wps=15826.3, ups=4.48, wpb=3535.5, bsz=157.8, num_updates=6200, lr=0.00040161, gnorm=0.889, train_wall=22, gb_free=7.2, wall=1430
2021-03-10 21:10:40 | INFO | train_inner | epoch 006:    785 / 1103 loss=4.489, nll_loss=3.155, ppl=8.91, wps=16158.7, ups=4.4, wpb=3675.8, bsz=159.6, num_updates=6300, lr=0.00039841, gnorm=0.842, train_wall=23, gb_free=7.3, wall=1453
2021-03-10 21:11:02 | INFO | train_inner | epoch 006:    885 / 1103 loss=4.617, nll_loss=3.302, ppl=9.86, wps=15961.4, ups=4.48, wpb=3563.8, bsz=137.9, num_updates=6400, lr=0.000395285, gnorm=0.9, train_wall=22, gb_free=7, wall=1475
2021-03-10 21:11:24 | INFO | train_inner | epoch 006:    985 / 1103 loss=4.608, nll_loss=3.292, ppl=9.79, wps=15847, ups=4.44, wpb=3566.2, bsz=130.9, num_updates=6500, lr=0.000392232, gnorm=0.87, train_wall=22, gb_free=7, wall=1497
2021-03-10 21:11:47 | INFO | train_inner | epoch 006:   1085 / 1103 loss=4.499, nll_loss=3.167, ppl=8.98, wps=16194.5, ups=4.49, wpb=3610.4, bsz=150.6, num_updates=6600, lr=0.000389249, gnorm=0.864, train_wall=22, gb_free=7.3, wall=1520
2021-03-10 21:11:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-10 21:11:55 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 4.471 | nll_loss 3.006 | ppl 8.03 | wps 48329.7 | wpb 2873.1 | bsz 115.6 | num_updates 6618 | best_loss 4.471
2021-03-10 21:11:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 6618 updates
2021-03-10 21:11:55 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt
2021-03-10 21:11:57 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt
2021-03-10 21:11:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt (epoch 6 @ 6618 updates, score 4.471) (writing took 4.44807855039835 seconds)
2021-03-10 21:11:59 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2021-03-10 21:11:59 | INFO | train | epoch 006 | loss 4.584 | nll_loss 3.263 | ppl 9.6 | wps 15432.5 | ups 4.31 | wpb 3577.8 | bsz 145.3 | num_updates 6618 | lr 0.00038872 | gnorm 0.883 | train_wall 246 | gb_free 7 | wall 1532
2021-03-10 21:11:59 | INFO | fairseq.trainer | begin training epoch 7
2021-03-10 21:11:59 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-10 21:12:18 | INFO | train_inner | epoch 007:     82 / 1103 loss=4.389, nll_loss=3.04, ppl=8.23, wps=11596, ups=3.23, wpb=3592.4, bsz=146.5, num_updates=6700, lr=0.000386334, gnorm=0.84, train_wall=22, gb_free=7.4, wall=1551
2021-03-10 21:12:40 | INFO | train_inner | epoch 007:    182 / 1103 loss=4.317, nll_loss=2.958, ppl=7.77, wps=15948.6, ups=4.41, wpb=3618.3, bsz=151, num_updates=6800, lr=0.000383482, gnorm=0.841, train_wall=23, gb_free=7.1, wall=1573
2021-03-10 21:13:03 | INFO | train_inner | epoch 007:    282 / 1103 loss=4.432, nll_loss=3.09, ppl=8.51, wps=16207.3, ups=4.5, wpb=3602.7, bsz=151.6, num_updates=6900, lr=0.000380693, gnorm=0.856, train_wall=22, gb_free=7.6, wall=1596
2021-03-10 21:13:25 | INFO | train_inner | epoch 007:    382 / 1103 loss=4.398, nll_loss=3.051, ppl=8.29, wps=16214.3, ups=4.45, wpb=3644.2, bsz=145.9, num_updates=7000, lr=0.000377964, gnorm=0.83, train_wall=22, gb_free=6.8, wall=1618
2021-03-10 21:13:47 | INFO | train_inner | epoch 007:    482 / 1103 loss=4.459, nll_loss=3.121, ppl=8.7, wps=15631.9, ups=4.45, wpb=3512.6, bsz=133.4, num_updates=7100, lr=0.000375293, gnorm=0.884, train_wall=22, gb_free=6.8, wall=1641
2021-03-10 21:14:10 | INFO | train_inner | epoch 007:    582 / 1103 loss=4.418, nll_loss=3.074, ppl=8.42, wps=16107.1, ups=4.45, wpb=3616.3, bsz=144.3, num_updates=7200, lr=0.000372678, gnorm=0.859, train_wall=22, gb_free=6.9, wall=1663
2021-03-10 21:14:32 | INFO | train_inner | epoch 007:    682 / 1103 loss=4.44, nll_loss=3.099, ppl=8.57, wps=15750.1, ups=4.51, wpb=3495.7, bsz=139.5, num_updates=7300, lr=0.000370117, gnorm=0.913, train_wall=22, gb_free=7, wall=1685
2021-03-10 21:14:55 | INFO | train_inner | epoch 007:    782 / 1103 loss=4.335, nll_loss=2.979, ppl=7.89, wps=16064.6, ups=4.43, wpb=3623.4, bsz=148.9, num_updates=7400, lr=0.000367607, gnorm=0.828, train_wall=22, gb_free=7.1, wall=1708
2021-03-10 21:15:17 | INFO | train_inner | epoch 007:    882 / 1103 loss=4.375, nll_loss=3.027, ppl=8.15, wps=15735.5, ups=4.47, wpb=3524, bsz=152.2, num_updates=7500, lr=0.000365148, gnorm=0.85, train_wall=22, gb_free=6.6, wall=1730
2021-03-10 21:15:39 | INFO | train_inner | epoch 007:    982 / 1103 loss=4.38, nll_loss=3.032, ppl=8.18, wps=15968.5, ups=4.47, wpb=3571.5, bsz=143.2, num_updates=7600, lr=0.000362738, gnorm=0.87, train_wall=22, gb_free=7.2, wall=1753
2021-03-10 21:16:02 | INFO | train_inner | epoch 007:   1082 / 1103 loss=4.381, nll_loss=3.034, ppl=8.19, wps=15998.9, ups=4.49, wpb=3562.3, bsz=136.4, num_updates=7700, lr=0.000360375, gnorm=0.838, train_wall=22, gb_free=7.3, wall=1775
2021-03-10 21:16:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-10 21:16:10 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 4.338 | nll_loss 2.855 | ppl 7.24 | wps 48320.7 | wpb 2873.1 | bsz 115.6 | num_updates 7721 | best_loss 4.338
2021-03-10 21:16:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 7721 updates
2021-03-10 21:16:10 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt
2021-03-10 21:16:12 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt
2021-03-10 21:16:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt (epoch 7 @ 7721 updates, score 4.338) (writing took 4.402955695986748 seconds)
2021-03-10 21:16:15 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2021-03-10 21:16:15 | INFO | train | epoch 007 | loss 4.389 | nll_loss 3.041 | ppl 8.23 | wps 15437 | ups 4.31 | wpb 3577.8 | bsz 145.3 | num_updates 7721 | lr 0.000359885 | gnorm 0.854 | train_wall 246 | gb_free 7 | wall 1788
2021-03-10 21:16:15 | INFO | fairseq.trainer | begin training epoch 8
2021-03-10 21:16:15 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-10 21:16:33 | INFO | train_inner | epoch 008:     79 / 1103 loss=4.283, nll_loss=2.921, ppl=7.57, wps=11640.5, ups=3.25, wpb=3586.8, bsz=136.5, num_updates=7800, lr=0.000358057, gnorm=0.839, train_wall=22, gb_free=7.1, wall=1806
2021-03-10 21:16:55 | INFO | train_inner | epoch 008:    179 / 1103 loss=4.173, nll_loss=2.796, ppl=6.95, wps=15906.5, ups=4.42, wpb=3597.8, bsz=166.2, num_updates=7900, lr=0.000355784, gnorm=0.82, train_wall=23, gb_free=6.9, wall=1828
2021-03-10 21:17:18 | INFO | train_inner | epoch 008:    279 / 1103 loss=4.195, nll_loss=2.819, ppl=7.05, wps=15713.1, ups=4.44, wpb=3538.8, bsz=145.7, num_updates=8000, lr=0.000353553, gnorm=0.839, train_wall=22, gb_free=7, wall=1851
2021-03-10 21:17:39 | INFO | train_inner | epoch 008:    379 / 1103 loss=4.287, nll_loss=2.926, ppl=7.6, wps=16215.7, ups=4.58, wpb=3538.3, bsz=143.4, num_updates=8100, lr=0.000351364, gnorm=0.853, train_wall=22, gb_free=7.1, wall=1873
2021-03-10 21:18:00 | INFO | train_inner | epoch 008:    479 / 1103 loss=4.263, nll_loss=2.899, ppl=7.46, wps=17668.3, ups=4.9, wpb=3604.5, bsz=152, num_updates=8200, lr=0.000349215, gnorm=0.871, train_wall=20, gb_free=6.9, wall=1893
2021-03-10 21:18:20 | INFO | train_inner | epoch 008:    579 / 1103 loss=4.254, nll_loss=2.887, ppl=7.4, wps=17583.1, ups=4.91, wpb=3582.9, bsz=143.2, num_updates=8300, lr=0.000347105, gnorm=0.827, train_wall=20, gb_free=7, wall=1913
2021-03-10 21:18:41 | INFO | train_inner | epoch 008:    679 / 1103 loss=4.238, nll_loss=2.871, ppl=7.31, wps=17421.8, ups=4.87, wpb=3579.5, bsz=151.8, num_updates=8400, lr=0.000345033, gnorm=0.815, train_wall=20, gb_free=6.9, wall=1934
2021-03-10 21:19:01 | INFO | train_inner | epoch 008:    779 / 1103 loss=4.284, nll_loss=2.922, ppl=7.58, wps=17361.2, ups=4.92, wpb=3526.1, bsz=136.4, num_updates=8500, lr=0.000342997, gnorm=0.854, train_wall=20, gb_free=6.8, wall=1954
2021-03-10 21:19:22 | INFO | train_inner | epoch 008:    879 / 1103 loss=4.289, nll_loss=2.928, ppl=7.61, wps=17324.2, ups=4.86, wpb=3561.1, bsz=135, num_updates=8600, lr=0.000340997, gnorm=0.849, train_wall=20, gb_free=6.9, wall=1975
2021-03-10 21:19:42 | INFO | train_inner | epoch 008:    979 / 1103 loss=4.24, nll_loss=2.873, ppl=7.33, wps=17679.2, ups=4.86, wpb=3639.5, bsz=148.7, num_updates=8700, lr=0.000339032, gnorm=0.818, train_wall=20, gb_free=7.1, wall=1995
2021-03-10 21:20:04 | INFO | train_inner | epoch 008:   1079 / 1103 loss=4.252, nll_loss=2.888, ppl=7.4, wps=16567.1, ups=4.61, wpb=3595.6, bsz=143.3, num_updates=8800, lr=0.0003371, gnorm=0.828, train_wall=22, gb_free=7, wall=2017
2021-03-10 21:20:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-10 21:20:13 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 4.26 | nll_loss 2.76 | ppl 6.77 | wps 48311.7 | wpb 2873.1 | bsz 115.6 | num_updates 8824 | best_loss 4.26
2021-03-10 21:20:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 8824 updates
2021-03-10 21:20:13 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt
2021-03-10 21:20:15 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt
2021-03-10 21:20:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt (epoch 8 @ 8824 updates, score 4.26) (writing took 4.499916851520538 seconds)
2021-03-10 21:20:18 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2021-03-10 21:20:18 | INFO | train | epoch 008 | loss 4.249 | nll_loss 2.883 | ppl 7.38 | wps 16236.1 | ups 4.54 | wpb 3577.8 | bsz 145.3 | num_updates 8824 | lr 0.000336641 | gnorm 0.838 | train_wall 233 | gb_free 7.2 | wall 2031
2021-03-10 21:20:18 | INFO | fairseq.trainer | begin training epoch 9
2021-03-10 21:20:18 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-10 21:20:35 | INFO | train_inner | epoch 009:     76 / 1103 loss=4.077, nll_loss=2.686, ppl=6.44, wps=11826.6, ups=3.21, wpb=3678.9, bsz=160.2, num_updates=8900, lr=0.000335201, gnorm=0.79, train_wall=23, gb_free=7.4, wall=2048
2021-03-10 21:20:58 | INFO | train_inner | epoch 009:    176 / 1103 loss=4.166, nll_loss=2.786, ppl=6.9, wps=15973.6, ups=4.43, wpb=3603.1, bsz=129.5, num_updates=9000, lr=0.000333333, gnorm=0.822, train_wall=22, gb_free=7, wall=2071
2021-03-10 21:21:20 | INFO | train_inner | epoch 009:    276 / 1103 loss=4.156, nll_loss=2.776, ppl=6.85, wps=15859.8, ups=4.46, wpb=3555.6, bsz=138.2, num_updates=9100, lr=0.000331497, gnorm=0.856, train_wall=22, gb_free=6.6, wall=2093
2021-03-10 21:21:43 | INFO | train_inner | epoch 009:    376 / 1103 loss=4.154, nll_loss=2.774, ppl=6.84, wps=15824.8, ups=4.44, wpb=3566.8, bsz=139.9, num_updates=9200, lr=0.00032969, gnorm=0.855, train_wall=22, gb_free=6.8, wall=2116
2021-03-10 21:22:05 | INFO | train_inner | epoch 009:    476 / 1103 loss=4.141, nll_loss=2.758, ppl=6.77, wps=16001.5, ups=4.45, wpb=3596.1, bsz=141.5, num_updates=9300, lr=0.000327913, gnorm=0.809, train_wall=22, gb_free=7.2, wall=2138
2021-03-10 21:22:27 | INFO | train_inner | epoch 009:    576 / 1103 loss=4.11, nll_loss=2.725, ppl=6.61, wps=15970.1, ups=4.5, wpb=3545.7, bsz=157.8, num_updates=9400, lr=0.000326164, gnorm=0.849, train_wall=22, gb_free=7.5, wall=2160
2021-03-10 21:22:50 | INFO | train_inner | epoch 009:    676 / 1103 loss=4.194, nll_loss=2.821, ppl=7.07, wps=15877.3, ups=4.49, wpb=3539.8, bsz=134.3, num_updates=9500, lr=0.000324443, gnorm=0.849, train_wall=22, gb_free=7, wall=2183
2021-03-10 21:23:12 | INFO | train_inner | epoch 009:    776 / 1103 loss=4.164, nll_loss=2.787, ppl=6.9, wps=15962.9, ups=4.51, wpb=3541.4, bsz=145.1, num_updates=9600, lr=0.000322749, gnorm=0.835, train_wall=22, gb_free=7, wall=2205
2021-03-10 21:23:34 | INFO | train_inner | epoch 009:    876 / 1103 loss=4.129, nll_loss=2.747, ppl=6.71, wps=16011, ups=4.48, wpb=3574.1, bsz=149.2, num_updates=9700, lr=0.000321081, gnorm=0.83, train_wall=22, gb_free=7.3, wall=2227
2021-03-10 21:23:57 | INFO | train_inner | epoch 009:    976 / 1103 loss=4.14, nll_loss=2.76, ppl=6.78, wps=15985.1, ups=4.42, wpb=3612.7, bsz=151.2, num_updates=9800, lr=0.000319438, gnorm=0.822, train_wall=22, gb_free=6.9, wall=2250
2021-03-10 21:24:19 | INFO | train_inner | epoch 009:   1076 / 1103 loss=4.144, nll_loss=2.766, ppl=6.8, wps=15870.8, ups=4.45, wpb=3566.9, bsz=145.8, num_updates=9900, lr=0.000317821, gnorm=0.828, train_wall=22, gb_free=7.2, wall=2272
2021-03-10 21:24:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-10 21:24:29 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 4.178 | nll_loss 2.664 | ppl 6.34 | wps 48233.9 | wpb 2873.1 | bsz 115.6 | num_updates 9927 | best_loss 4.178
2021-03-10 21:24:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 9927 updates
2021-03-10 21:24:29 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt
2021-03-10 21:24:31 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt
2021-03-10 21:24:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt (epoch 9 @ 9927 updates, score 4.178) (writing took 4.822915319353342 seconds)
2021-03-10 21:24:34 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2021-03-10 21:24:34 | INFO | train | epoch 009 | loss 4.141 | nll_loss 2.761 | ppl 6.78 | wps 15414.9 | ups 4.31 | wpb 3577.8 | bsz 145.3 | num_updates 9927 | lr 0.000317388 | gnorm 0.831 | train_wall 246 | gb_free 7 | wall 2287
2021-03-10 21:24:34 | INFO | fairseq.trainer | begin training epoch 10
2021-03-10 21:24:34 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-10 21:24:50 | INFO | train_inner | epoch 010:     73 / 1103 loss=4.06, nll_loss=2.669, ppl=6.36, wps=11366.7, ups=3.23, wpb=3517.5, bsz=146.3, num_updates=10000, lr=0.000316228, gnorm=0.822, train_wall=22, gb_free=7, wall=2303
2021-03-10 21:25:12 | INFO | train_inner | epoch 010:    173 / 1103 loss=4.066, nll_loss=2.674, ppl=6.38, wps=16083.9, ups=4.5, wpb=3576.1, bsz=139, num_updates=10100, lr=0.000314658, gnorm=0.813, train_wall=22, gb_free=7, wall=2325
2021-03-10 21:25:35 | INFO | train_inner | epoch 010:    273 / 1103 loss=4.001, nll_loss=2.599, ppl=6.06, wps=16025.7, ups=4.45, wpb=3603.1, bsz=150.5, num_updates=10200, lr=0.000313112, gnorm=0.802, train_wall=22, gb_free=7, wall=2348
2021-03-10 21:25:57 | INFO | train_inner | epoch 010:    373 / 1103 loss=4.047, nll_loss=2.653, ppl=6.29, wps=16021.8, ups=4.46, wpb=3591, bsz=146.4, num_updates=10300, lr=0.000311588, gnorm=0.822, train_wall=22, gb_free=7, wall=2370
2021-03-10 21:26:20 | INFO | train_inner | epoch 010:    473 / 1103 loss=4.085, nll_loss=2.695, ppl=6.48, wps=15856.5, ups=4.48, wpb=3539.6, bsz=134.9, num_updates=10400, lr=0.000310087, gnorm=0.864, train_wall=22, gb_free=6.9, wall=2393
2021-03-10 21:26:42 | INFO | train_inner | epoch 010:    573 / 1103 loss=4.029, nll_loss=2.633, ppl=6.2, wps=16187.4, ups=4.45, wpb=3634.8, bsz=150.2, num_updates=10500, lr=0.000308607, gnorm=0.799, train_wall=22, gb_free=7.4, wall=2415
2021-03-10 21:27:04 | INFO | train_inner | epoch 010:    673 / 1103 loss=4.063, nll_loss=2.672, ppl=6.37, wps=15881.6, ups=4.49, wpb=3539.7, bsz=146.3, num_updates=10600, lr=0.000307148, gnorm=0.842, train_wall=22, gb_free=7.1, wall=2437
2021-03-10 21:27:26 | INFO | train_inner | epoch 010:    773 / 1103 loss=4.09, nll_loss=2.702, ppl=6.51, wps=16366, ups=4.58, wpb=3569.5, bsz=141, num_updates=10700, lr=0.000305709, gnorm=0.809, train_wall=22, gb_free=7, wall=2459
2021-03-10 21:27:48 | INFO | train_inner | epoch 010:    873 / 1103 loss=4.088, nll_loss=2.7, ppl=6.5, wps=16008.1, ups=4.48, wpb=3572.1, bsz=133.9, num_updates=10800, lr=0.00030429, gnorm=0.832, train_wall=22, gb_free=6.8, wall=2482
2021-03-10 21:28:11 | INFO | train_inner | epoch 010:    973 / 1103 loss=4.073, nll_loss=2.684, ppl=6.43, wps=16171.6, ups=4.52, wpb=3580, bsz=153.5, num_updates=10900, lr=0.000302891, gnorm=0.861, train_wall=22, gb_free=7, wall=2504
2021-03-10 21:28:33 | INFO | train_inner | epoch 010:   1073 / 1103 loss=4.029, nll_loss=2.634, ppl=6.21, wps=16162.4, ups=4.43, wpb=3647.9, bsz=161.3, num_updates=11000, lr=0.000301511, gnorm=0.832, train_wall=22, gb_free=6.9, wall=2526
2021-03-10 21:28:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-10 21:28:44 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 4.157 | nll_loss 2.638 | ppl 6.22 | wps 48315.1 | wpb 2873.1 | bsz 115.6 | num_updates 11030 | best_loss 4.157
2021-03-10 21:28:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 11030 updates
2021-03-10 21:28:44 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt
2021-03-10 21:28:46 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt
2021-03-10 21:28:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt (epoch 10 @ 11030 updates, score 4.157) (writing took 4.487572491168976 seconds)
2021-03-10 21:28:48 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2021-03-10 21:28:48 | INFO | train | epoch 010 | loss 4.056 | nll_loss 2.664 | ppl 6.34 | wps 15513.7 | ups 4.34 | wpb 3577.8 | bsz 145.3 | num_updates 11030 | lr 0.000301101 | gnorm 0.829 | train_wall 245 | gb_free 7.3 | wall 2541
2021-03-10 21:28:48 | INFO | fairseq.trainer | begin training epoch 11
2021-03-10 21:28:48 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-10 21:29:04 | INFO | train_inner | epoch 011:     70 / 1103 loss=4.001, nll_loss=2.602, ppl=6.07, wps=11600.8, ups=3.26, wpb=3557.4, bsz=143.8, num_updates=11100, lr=0.00030015, gnorm=0.837, train_wall=22, gb_free=6.7, wall=2557
2021-03-10 21:29:26 | INFO | train_inner | epoch 011:    170 / 1103 loss=3.98, nll_loss=2.575, ppl=5.96, wps=15760.9, ups=4.47, wpb=3526.9, bsz=135, num_updates=11200, lr=0.000298807, gnorm=0.817, train_wall=22, gb_free=7, wall=2579
2021-03-10 21:29:49 | INFO | train_inner | epoch 011:    270 / 1103 loss=3.956, nll_loss=2.548, ppl=5.85, wps=16153.8, ups=4.4, wpb=3672.5, bsz=139, num_updates=11300, lr=0.000297482, gnorm=0.783, train_wall=23, gb_free=6.6, wall=2602
2021-03-10 21:30:11 | INFO | train_inner | epoch 011:    370 / 1103 loss=3.935, nll_loss=2.526, ppl=5.76, wps=15993.1, ups=4.47, wpb=3579.1, bsz=161.4, num_updates=11400, lr=0.000296174, gnorm=0.809, train_wall=22, gb_free=7, wall=2624
2021-03-10 21:30:34 | INFO | train_inner | epoch 011:    470 / 1103 loss=3.934, nll_loss=2.525, ppl=5.76, wps=15759.7, ups=4.42, wpb=3568, bsz=160.2, num_updates=11500, lr=0.000294884, gnorm=0.832, train_wall=23, gb_free=6.8, wall=2647
2021-03-10 21:30:56 | INFO | train_inner | epoch 011:    570 / 1103 loss=3.946, nll_loss=2.54, ppl=5.81, wps=16367.1, ups=4.44, wpb=3685.7, bsz=161, num_updates=11600, lr=0.00029361, gnorm=0.776, train_wall=22, gb_free=7, wall=2670
2021-03-10 21:31:19 | INFO | train_inner | epoch 011:    670 / 1103 loss=4, nll_loss=2.6, ppl=6.06, wps=15712.2, ups=4.51, wpb=3482.1, bsz=144.8, num_updates=11700, lr=0.000292353, gnorm=0.843, train_wall=22, gb_free=7.2, wall=2692
2021-03-10 21:31:41 | INFO | train_inner | epoch 011:    770 / 1103 loss=4.009, nll_loss=2.611, ppl=6.11, wps=16015.1, ups=4.49, wpb=3566.6, bsz=143.9, num_updates=11800, lr=0.000291111, gnorm=0.823, train_wall=22, gb_free=7.4, wall=2714
2021-03-10 21:32:03 | INFO | train_inner | epoch 011:    870 / 1103 loss=4.001, nll_loss=2.602, ppl=6.07, wps=16045.6, ups=4.43, wpb=3619, bsz=144.1, num_updates=11900, lr=0.000289886, gnorm=0.802, train_wall=22, gb_free=7.1, wall=2737
2021-03-10 21:32:26 | INFO | train_inner | epoch 011:    970 / 1103 loss=4.043, nll_loss=2.649, ppl=6.27, wps=15811, ups=4.46, wpb=3545.8, bsz=124.2, num_updates=12000, lr=0.000288675, gnorm=0.834, train_wall=22, gb_free=7, wall=2759
2021-03-10 21:32:48 | INFO | train_inner | epoch 011:   1070 / 1103 loss=4.026, nll_loss=2.631, ppl=6.2, wps=15686.3, ups=4.47, wpb=3511.1, bsz=138.9, num_updates=12100, lr=0.00028748, gnorm=0.871, train_wall=22, gb_free=6.9, wall=2781
2021-03-10 21:32:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-10 21:32:59 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 4.094 | nll_loss 2.576 | ppl 5.96 | wps 48256.6 | wpb 2873.1 | bsz 115.6 | num_updates 12133 | best_loss 4.094
2021-03-10 21:32:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 12133 updates
2021-03-10 21:32:59 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt
2021-03-10 21:33:01 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt
2021-03-10 21:33:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt (epoch 11 @ 12133 updates, score 4.094) (writing took 4.508799973875284 seconds)
2021-03-10 21:33:04 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2021-03-10 21:33:04 | INFO | train | epoch 011 | loss 3.981 | nll_loss 2.579 | ppl 5.97 | wps 15427.2 | ups 4.31 | wpb 3577.8 | bsz 145.3 | num_updates 12133 | lr 0.000287089 | gnorm 0.818 | train_wall 246 | gb_free 7.5 | wall 2797
2021-03-10 21:33:04 | INFO | fairseq.trainer | begin training epoch 12
2021-03-10 21:33:04 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-10 21:33:19 | INFO | train_inner | epoch 012:     67 / 1103 loss=3.947, nll_loss=2.539, ppl=5.81, wps=11557.8, ups=3.26, wpb=3543.3, bsz=131, num_updates=12200, lr=0.000286299, gnorm=0.823, train_wall=22, gb_free=6.8, wall=2812
2021-03-10 21:33:42 | INFO | train_inner | epoch 012:    167 / 1103 loss=3.884, nll_loss=2.467, ppl=5.53, wps=15996.3, ups=4.42, wpb=3617.3, bsz=153, num_updates=12300, lr=0.000285133, gnorm=0.843, train_wall=22, gb_free=7, wall=2835
2021-03-10 21:34:04 | INFO | train_inner | epoch 012:    267 / 1103 loss=3.85, nll_loss=2.43, ppl=5.39, wps=15595.8, ups=4.44, wpb=3515.2, bsz=161.3, num_updates=12400, lr=0.000283981, gnorm=0.805, train_wall=22, gb_free=7.1, wall=2857
2021-03-10 21:34:27 | INFO | train_inner | epoch 012:    367 / 1103 loss=3.922, nll_loss=2.51, ppl=5.7, wps=16134.4, ups=4.44, wpb=3630.9, bsz=145.8, num_updates=12500, lr=0.000282843, gnorm=0.81, train_wall=22, gb_free=6.8, wall=2880
2021-03-10 21:34:49 | INFO | train_inner | epoch 012:    467 / 1103 loss=3.945, nll_loss=2.536, ppl=5.8, wps=15966.4, ups=4.45, wpb=3587, bsz=134.7, num_updates=12600, lr=0.000281718, gnorm=0.803, train_wall=22, gb_free=7.1, wall=2902
2021-03-10 21:35:11 | INFO | train_inner | epoch 012:    567 / 1103 loss=3.932, nll_loss=2.522, ppl=5.74, wps=15906.7, ups=4.45, wpb=3573.5, bsz=142.3, num_updates=12700, lr=0.000280607, gnorm=0.829, train_wall=22, gb_free=6.7, wall=2925
2021-03-10 21:35:34 | INFO | train_inner | epoch 012:    667 / 1103 loss=3.97, nll_loss=2.566, ppl=5.92, wps=15948, ups=4.54, wpb=3515, bsz=142.4, num_updates=12800, lr=0.000279508, gnorm=0.829, train_wall=22, gb_free=7.6, wall=2947
2021-03-10 21:35:56 | INFO | train_inner | epoch 012:    767 / 1103 loss=3.966, nll_loss=2.561, ppl=5.9, wps=15966.6, ups=4.48, wpb=3566, bsz=135.1, num_updates=12900, lr=0.000278423, gnorm=0.828, train_wall=22, gb_free=7, wall=2969
2021-03-10 21:36:19 | INFO | train_inner | epoch 012:    867 / 1103 loss=3.878, nll_loss=2.462, ppl=5.51, wps=16174.5, ups=4.4, wpb=3674.8, bsz=160.6, num_updates=13000, lr=0.00027735, gnorm=0.791, train_wall=23, gb_free=7.3, wall=2992
2021-03-10 21:36:41 | INFO | train_inner | epoch 012:    967 / 1103 loss=3.891, nll_loss=2.478, ppl=5.57, wps=16085, ups=4.41, wpb=3644.8, bsz=154.8, num_updates=13100, lr=0.000276289, gnorm=0.781, train_wall=23, gb_free=6.8, wall=3014
2021-03-10 21:37:03 | INFO | train_inner | epoch 012:   1067 / 1103 loss=3.976, nll_loss=2.573, ppl=5.95, wps=15712.6, ups=4.51, wpb=3487.3, bsz=130.6, num_updates=13200, lr=0.000275241, gnorm=0.852, train_wall=22, gb_free=7.2, wall=3037
2021-03-10 21:37:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-10 21:37:15 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 4.057 | nll_loss 2.536 | ppl 5.8 | wps 48357.8 | wpb 2873.1 | bsz 115.6 | num_updates 13236 | best_loss 4.057
2021-03-10 21:37:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 13236 updates
2021-03-10 21:37:15 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt
2021-03-10 21:37:18 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt
2021-03-10 21:37:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt (epoch 12 @ 13236 updates, score 4.057) (writing took 4.941672507673502 seconds)
2021-03-10 21:37:20 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2021-03-10 21:37:20 | INFO | train | epoch 012 | loss 3.92 | nll_loss 2.509 | ppl 5.69 | wps 15395.3 | ups 4.3 | wpb 3577.8 | bsz 145.3 | num_updates 13236 | lr 0.000274866 | gnorm 0.818 | train_wall 246 | gb_free 7.1 | wall 3053
2021-03-10 21:37:20 | INFO | fairseq.trainer | begin training epoch 13
2021-03-10 21:37:20 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-10 21:37:35 | INFO | train_inner | epoch 013:     64 / 1103 loss=3.839, nll_loss=2.417, ppl=5.34, wps=11470.2, ups=3.19, wpb=3597.8, bsz=151.1, num_updates=13300, lr=0.000274204, gnorm=0.796, train_wall=22, gb_free=7, wall=3068
2021-03-10 21:37:57 | INFO | train_inner | epoch 013:    164 / 1103 loss=3.817, nll_loss=2.392, ppl=5.25, wps=16160.9, ups=4.47, wpb=3612, bsz=156.2, num_updates=13400, lr=0.000273179, gnorm=0.789, train_wall=22, gb_free=6.9, wall=3090
2021-03-10 21:38:19 | INFO | train_inner | epoch 013:    264 / 1103 loss=3.879, nll_loss=2.461, ppl=5.51, wps=15756.4, ups=4.49, wpb=3511.8, bsz=131, num_updates=13500, lr=0.000272166, gnorm=0.827, train_wall=22, gb_free=7.2, wall=3113
2021-03-10 21:38:42 | INFO | train_inner | epoch 013:    364 / 1103 loss=3.872, nll_loss=2.453, ppl=5.47, wps=15647.2, ups=4.47, wpb=3499.7, bsz=139.8, num_updates=13600, lr=0.000271163, gnorm=0.855, train_wall=22, gb_free=7.1, wall=3135
2021-03-10 21:39:04 | INFO | train_inner | epoch 013:    464 / 1103 loss=3.819, nll_loss=2.394, ppl=5.25, wps=16054.6, ups=4.41, wpb=3642.4, bsz=153.4, num_updates=13700, lr=0.000270172, gnorm=0.796, train_wall=23, gb_free=7.2, wall=3158
2021-03-10 21:39:27 | INFO | train_inner | epoch 013:    564 / 1103 loss=3.872, nll_loss=2.454, ppl=5.48, wps=15881.7, ups=4.43, wpb=3583.6, bsz=145, num_updates=13800, lr=0.000269191, gnorm=0.814, train_wall=22, gb_free=7.2, wall=3180
2021-03-10 21:39:49 | INFO | train_inner | epoch 013:    664 / 1103 loss=3.89, nll_loss=2.475, ppl=5.56, wps=16202.3, ups=4.47, wpb=3625.7, bsz=151.7, num_updates=13900, lr=0.000268221, gnorm=0.826, train_wall=22, gb_free=6.9, wall=3203
2021-03-10 21:40:12 | INFO | train_inner | epoch 013:    764 / 1103 loss=3.876, nll_loss=2.459, ppl=5.5, wps=15894.5, ups=4.45, wpb=3571.6, bsz=140.2, num_updates=14000, lr=0.000267261, gnorm=0.834, train_wall=22, gb_free=7.1, wall=3225
2021-03-10 21:40:34 | INFO | train_inner | epoch 013:    864 / 1103 loss=3.885, nll_loss=2.47, ppl=5.54, wps=15782, ups=4.48, wpb=3526.7, bsz=140.4, num_updates=14100, lr=0.000266312, gnorm=0.803, train_wall=22, gb_free=6.9, wall=3247
2021-03-10 21:40:57 | INFO | train_inner | epoch 013:    964 / 1103 loss=3.915, nll_loss=2.503, ppl=5.67, wps=15901.4, ups=4.46, wpb=3566.4, bsz=140.3, num_updates=14200, lr=0.000265372, gnorm=0.852, train_wall=22, gb_free=7, wall=3270
2021-03-10 21:41:19 | INFO | train_inner | epoch 013:   1064 / 1103 loss=3.884, nll_loss=2.47, ppl=5.54, wps=16179.3, ups=4.49, wpb=3601.1, bsz=148.5, num_updates=14300, lr=0.000264443, gnorm=0.804, train_wall=22, gb_free=6.9, wall=3292
2021-03-10 21:41:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-10 21:41:31 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 4.051 | nll_loss 2.522 | ppl 5.74 | wps 48265.9 | wpb 2873.1 | bsz 115.6 | num_updates 14339 | best_loss 4.051
2021-03-10 21:41:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 14339 updates
2021-03-10 21:41:31 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt
2021-03-10 21:41:34 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt
2021-03-10 21:41:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt (epoch 13 @ 14339 updates, score 4.051) (writing took 4.76478186249733 seconds)
2021-03-10 21:41:36 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2021-03-10 21:41:36 | INFO | train | epoch 013 | loss 3.865 | nll_loss 2.446 | ppl 5.45 | wps 15414 | ups 4.31 | wpb 3577.8 | bsz 145.3 | num_updates 14339 | lr 0.000264083 | gnorm 0.817 | train_wall 246 | gb_free 6.8 | wall 3309
2021-03-10 21:41:36 | INFO | fairseq.trainer | begin training epoch 14
2021-03-10 21:41:36 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-10 21:41:50 | INFO | train_inner | epoch 014:     61 / 1103 loss=3.808, nll_loss=2.382, ppl=5.21, wps=11466, ups=3.23, wpb=3555, bsz=147.1, num_updates=14400, lr=0.000263523, gnorm=0.825, train_wall=22, gb_free=7.2, wall=3323
2021-03-10 21:42:12 | INFO | train_inner | epoch 014:    161 / 1103 loss=3.807, nll_loss=2.379, ppl=5.2, wps=15799.8, ups=4.47, wpb=3535.4, bsz=135.8, num_updates=14500, lr=0.000262613, gnorm=0.807, train_wall=22, gb_free=6.8, wall=3345
2021-03-10 21:42:35 | INFO | train_inner | epoch 014:    261 / 1103 loss=3.762, nll_loss=2.329, ppl=5.02, wps=15737.2, ups=4.45, wpb=3533.9, bsz=158.9, num_updates=14600, lr=0.000261712, gnorm=0.825, train_wall=22, gb_free=7.2, wall=3368
2021-03-10 21:42:55 | INFO | train_inner | epoch 014:    361 / 1103 loss=3.836, nll_loss=2.411, ppl=5.32, wps=17253.9, ups=4.84, wpb=3566.4, bsz=132.4, num_updates=14700, lr=0.00026082, gnorm=0.842, train_wall=21, gb_free=6.7, wall=3389
2021-03-10 21:43:16 | INFO | train_inner | epoch 014:    461 / 1103 loss=3.817, nll_loss=2.391, ppl=5.25, wps=17265.3, ups=4.84, wpb=3567.7, bsz=144.4, num_updates=14800, lr=0.000259938, gnorm=0.83, train_wall=21, gb_free=7.5, wall=3409
2021-03-10 21:43:37 | INFO | train_inner | epoch 014:    561 / 1103 loss=3.838, nll_loss=2.414, ppl=5.33, wps=17273.7, ups=4.82, wpb=3584.4, bsz=137, num_updates=14900, lr=0.000259064, gnorm=0.83, train_wall=21, gb_free=6.6, wall=3430
2021-03-10 21:43:59 | INFO | train_inner | epoch 014:    661 / 1103 loss=3.789, nll_loss=2.361, ppl=5.14, wps=16338.1, ups=4.49, wpb=3638.5, bsz=158.9, num_updates=15000, lr=0.000258199, gnorm=0.785, train_wall=22, gb_free=6.9, wall=3452
2021-03-10 21:44:21 | INFO | train_inner | epoch 014:    761 / 1103 loss=3.837, nll_loss=2.415, ppl=5.33, wps=16391.9, ups=4.48, wpb=3656.4, bsz=145, num_updates=15100, lr=0.000257343, gnorm=0.789, train_wall=22, gb_free=7, wall=3475
2021-03-10 21:44:44 | INFO | train_inner | epoch 014:    861 / 1103 loss=3.798, nll_loss=2.371, ppl=5.17, wps=16026, ups=4.44, wpb=3611.2, bsz=156.5, num_updates=15200, lr=0.000256495, gnorm=0.799, train_wall=22, gb_free=6.8, wall=3497
2021-03-10 21:45:06 | INFO | train_inner | epoch 014:    961 / 1103 loss=3.872, nll_loss=2.455, ppl=5.48, wps=16088.9, ups=4.49, wpb=3579.7, bsz=133.7, num_updates=15300, lr=0.000255655, gnorm=0.843, train_wall=22, gb_free=6.9, wall=3519
2021-03-10 21:45:29 | INFO | train_inner | epoch 014:   1061 / 1103 loss=3.86, nll_loss=2.442, ppl=5.44, wps=16000.8, ups=4.48, wpb=3570.4, bsz=144.6, num_updates=15400, lr=0.000254824, gnorm=0.817, train_wall=22, gb_free=7.1, wall=3542
2021-03-10 21:45:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-10 21:45:42 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 4.016 | nll_loss 2.481 | ppl 5.58 | wps 48271.2 | wpb 2873.1 | bsz 115.6 | num_updates 15442 | best_loss 4.016
2021-03-10 21:45:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 15442 updates
2021-03-10 21:45:42 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt
2021-03-10 21:45:45 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt
2021-03-10 21:45:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt (epoch 14 @ 15442 updates, score 4.016) (writing took 4.650046944618225 seconds)
2021-03-10 21:45:46 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2021-03-10 21:45:46 | INFO | train | epoch 014 | loss 3.818 | nll_loss 2.393 | ppl 5.25 | wps 15778.6 | ups 4.41 | wpb 3577.8 | bsz 145.3 | num_updates 15442 | lr 0.000254477 | gnorm 0.818 | train_wall 240 | gb_free 7.2 | wall 3559
2021-03-10 21:45:46 | INFO | fairseq.trainer | begin training epoch 15
2021-03-10 21:45:46 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-10 21:45:59 | INFO | train_inner | epoch 015:     58 / 1103 loss=3.761, nll_loss=2.328, ppl=5.02, wps=11372.2, ups=3.25, wpb=3504.3, bsz=145.4, num_updates=15500, lr=0.000254, gnorm=0.804, train_wall=22, gb_free=7.4, wall=3572
2021-03-10 21:46:22 | INFO | train_inner | epoch 015:    158 / 1103 loss=3.768, nll_loss=2.334, ppl=5.04, wps=15868.2, ups=4.49, wpb=3537.3, bsz=139.4, num_updates=15600, lr=0.000253185, gnorm=0.808, train_wall=22, gb_free=6.9, wall=3595
2021-03-10 21:46:44 | INFO | train_inner | epoch 015:    258 / 1103 loss=3.753, nll_loss=2.318, ppl=4.99, wps=15906.5, ups=4.42, wpb=3601.2, bsz=142, num_updates=15700, lr=0.000252377, gnorm=0.794, train_wall=23, gb_free=6.8, wall=3617
2021-03-10 21:47:07 | INFO | train_inner | epoch 015:    358 / 1103 loss=3.762, nll_loss=2.328, ppl=5.02, wps=16113.3, ups=4.45, wpb=3624.2, bsz=145.8, num_updates=15800, lr=0.000251577, gnorm=0.805, train_wall=22, gb_free=7, wall=3640
2021-03-10 21:47:29 | INFO | train_inner | epoch 015:    458 / 1103 loss=3.751, nll_loss=2.317, ppl=4.98, wps=15896.3, ups=4.49, wpb=3541, bsz=161.6, num_updates=15900, lr=0.000250785, gnorm=0.832, train_wall=22, gb_free=6.6, wall=3662
2021-03-10 21:47:51 | INFO | train_inner | epoch 015:    558 / 1103 loss=3.803, nll_loss=2.374, ppl=5.18, wps=16097.1, ups=4.49, wpb=3583.3, bsz=137, num_updates=16000, lr=0.00025, gnorm=0.813, train_wall=22, gb_free=7.3, wall=3684
2021-03-10 21:48:14 | INFO | train_inner | epoch 015:    658 / 1103 loss=3.76, nll_loss=2.327, ppl=5.02, wps=16011.6, ups=4.48, wpb=3576.7, bsz=150.7, num_updates=16100, lr=0.000249222, gnorm=0.808, train_wall=22, gb_free=7.2, wall=3707
2021-03-10 21:48:36 | INFO | train_inner | epoch 015:    758 / 1103 loss=3.805, nll_loss=2.377, ppl=5.19, wps=16284.5, ups=4.45, wpb=3660.3, bsz=137.4, num_updates=16200, lr=0.000248452, gnorm=0.798, train_wall=22, gb_free=7.1, wall=3729
2021-03-10 21:48:59 | INFO | train_inner | epoch 015:    858 / 1103 loss=3.775, nll_loss=2.344, ppl=5.08, wps=15686.1, ups=4.44, wpb=3529.2, bsz=140.9, num_updates=16300, lr=0.000247689, gnorm=0.828, train_wall=22, gb_free=6.8, wall=3752
2021-03-10 21:49:21 | INFO | train_inner | epoch 015:    958 / 1103 loss=3.771, nll_loss=2.34, ppl=5.06, wps=15772.3, ups=4.46, wpb=3538.2, bsz=159.3, num_updates=16400, lr=0.000246932, gnorm=0.831, train_wall=22, gb_free=6.8, wall=3774
2021-03-10 21:49:44 | INFO | train_inner | epoch 015:   1058 / 1103 loss=3.777, nll_loss=2.346, ppl=5.08, wps=16119.8, ups=4.42, wpb=3645.8, bsz=146.9, num_updates=16500, lr=0.000246183, gnorm=0.81, train_wall=23, gb_free=7, wall=3797
2021-03-10 21:49:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-10 21:49:57 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 3.988 | nll_loss 2.453 | ppl 5.48 | wps 48241.8 | wpb 2873.1 | bsz 115.6 | num_updates 16545 | best_loss 3.988
2021-03-10 21:49:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 16545 updates
2021-03-10 21:49:57 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt
2021-03-10 21:49:59 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt
2021-03-10 21:50:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt (epoch 15 @ 16545 updates, score 3.988) (writing took 4.396377939730883 seconds)
2021-03-10 21:50:02 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2021-03-10 21:50:02 | INFO | train | epoch 015 | loss 3.773 | nll_loss 2.341 | ppl 5.07 | wps 15448.2 | ups 4.32 | wpb 3577.8 | bsz 145.3 | num_updates 16545 | lr 0.000245848 | gnorm 0.813 | train_wall 246 | gb_free 6.9 | wall 3815
2021-03-10 21:50:02 | INFO | fairseq.trainer | begin training epoch 16
2021-03-10 21:50:02 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-10 21:50:14 | INFO | train_inner | epoch 016:     55 / 1103 loss=3.744, nll_loss=2.309, ppl=4.96, wps=11673.1, ups=3.28, wpb=3562.8, bsz=139.8, num_updates=16600, lr=0.00024544, gnorm=0.822, train_wall=22, gb_free=7, wall=3827
2021-03-10 21:50:36 | INFO | train_inner | epoch 016:    155 / 1103 loss=3.732, nll_loss=2.294, ppl=4.9, wps=16085.7, ups=4.51, wpb=3567.5, bsz=140.3, num_updates=16700, lr=0.000244704, gnorm=0.825, train_wall=22, gb_free=7, wall=3850
2021-03-10 21:50:59 | INFO | train_inner | epoch 016:    255 / 1103 loss=3.714, nll_loss=2.274, ppl=4.84, wps=15927.5, ups=4.44, wpb=3589.9, bsz=145, num_updates=16800, lr=0.000243975, gnorm=0.828, train_wall=22, gb_free=6.6, wall=3872
2021-03-10 21:51:21 | INFO | train_inner | epoch 016:    355 / 1103 loss=3.732, nll_loss=2.293, ppl=4.9, wps=15777.9, ups=4.5, wpb=3505.2, bsz=137, num_updates=16900, lr=0.000243252, gnorm=0.847, train_wall=22, gb_free=7.1, wall=3894
2021-03-10 21:51:44 | INFO | train_inner | epoch 016:    455 / 1103 loss=3.746, nll_loss=2.308, ppl=4.95, wps=15906.4, ups=4.46, wpb=3564, bsz=133.8, num_updates=17000, lr=0.000242536, gnorm=0.821, train_wall=22, gb_free=7.1, wall=3917
2021-03-10 21:52:06 | INFO | train_inner | epoch 016:    555 / 1103 loss=3.685, nll_loss=2.242, ppl=4.73, wps=16184.9, ups=4.42, wpb=3662.9, bsz=160.4, num_updates=17100, lr=0.000241825, gnorm=0.789, train_wall=23, gb_free=7, wall=3939
2021-03-10 21:52:29 | INFO | train_inner | epoch 016:    655 / 1103 loss=3.744, nll_loss=2.308, ppl=4.95, wps=15944.4, ups=4.46, wpb=3574.4, bsz=150, num_updates=17200, lr=0.000241121, gnorm=0.839, train_wall=22, gb_free=7.2, wall=3962
2021-03-10 21:52:51 | INFO | train_inner | epoch 016:    755 / 1103 loss=3.745, nll_loss=2.309, ppl=4.96, wps=16022.5, ups=4.44, wpb=3607.9, bsz=145.8, num_updates=17300, lr=0.000240424, gnorm=0.809, train_wall=22, gb_free=7.3, wall=3984
2021-03-10 21:53:14 | INFO | train_inner | epoch 016:    855 / 1103 loss=3.814, nll_loss=2.388, ppl=5.23, wps=15806, ups=4.46, wpb=3546.3, bsz=132.1, num_updates=17400, lr=0.000239732, gnorm=0.859, train_wall=22, gb_free=7.4, wall=4007
2021-03-10 21:53:36 | INFO | train_inner | epoch 016:    955 / 1103 loss=3.716, nll_loss=2.277, ppl=4.85, wps=15924.6, ups=4.43, wpb=3591, bsz=163.3, num_updates=17500, lr=0.000239046, gnorm=0.82, train_wall=22, gb_free=6.9, wall=4029
2021-03-10 21:53:59 | INFO | train_inner | epoch 016:   1055 / 1103 loss=3.724, nll_loss=2.287, ppl=4.88, wps=16106.8, ups=4.44, wpb=3628.8, bsz=159, num_updates=17600, lr=0.000238366, gnorm=0.788, train_wall=22, gb_free=7, wall=4052
2021-03-10 21:54:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-10 21:54:13 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 3.986 | nll_loss 2.446 | ppl 5.45 | wps 48258.4 | wpb 2873.1 | bsz 115.6 | num_updates 17648 | best_loss 3.986
2021-03-10 21:54:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 17648 updates
2021-03-10 21:54:13 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt
2021-03-10 21:54:15 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt
2021-03-10 21:54:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt (epoch 16 @ 17648 updates, score 3.986) (writing took 4.75147071108222 seconds)
2021-03-10 21:54:18 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2021-03-10 21:54:18 | INFO | train | epoch 016 | loss 3.736 | nll_loss 2.299 | ppl 4.92 | wps 15404.6 | ups 4.31 | wpb 3577.8 | bsz 145.3 | num_updates 17648 | lr 0.000238041 | gnorm 0.823 | train_wall 246 | gb_free 7.1 | wall 4071
2021-03-10 21:54:18 | INFO | fairseq.trainer | begin training epoch 17
2021-03-10 21:54:18 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-10 21:54:30 | INFO | train_inner | epoch 017:     52 / 1103 loss=3.718, nll_loss=2.276, ppl=4.84, wps=11268, ups=3.21, wpb=3513.5, bsz=131.4, num_updates=17700, lr=0.000237691, gnorm=0.824, train_wall=22, gb_free=7.1, wall=4083
2021-03-10 21:54:52 | INFO | train_inner | epoch 017:    152 / 1103 loss=3.696, nll_loss=2.252, ppl=4.76, wps=16025, ups=4.46, wpb=3595.6, bsz=140.9, num_updates=17800, lr=0.000237023, gnorm=0.804, train_wall=22, gb_free=7, wall=4105
2021-03-10 21:55:15 | INFO | train_inner | epoch 017:    252 / 1103 loss=3.646, nll_loss=2.195, ppl=4.58, wps=15689.5, ups=4.46, wpb=3518.5, bsz=150.3, num_updates=17900, lr=0.00023636, gnorm=0.803, train_wall=22, gb_free=7.1, wall=4128
2021-03-10 21:55:37 | INFO | train_inner | epoch 017:    352 / 1103 loss=3.656, nll_loss=2.207, ppl=4.62, wps=15986.2, ups=4.43, wpb=3606.9, bsz=156.2, num_updates=18000, lr=0.000235702, gnorm=0.808, train_wall=22, gb_free=6.7, wall=4150
2021-03-10 21:56:00 | INFO | train_inner | epoch 017:    452 / 1103 loss=3.664, nll_loss=2.217, ppl=4.65, wps=16055.9, ups=4.43, wpb=3622.6, bsz=150.4, num_updates=18100, lr=0.00023505, gnorm=0.797, train_wall=22, gb_free=6.9, wall=4173
2021-03-10 21:56:22 | INFO | train_inner | epoch 017:    552 / 1103 loss=3.689, nll_loss=2.244, ppl=4.74, wps=16073.7, ups=4.45, wpb=3613.3, bsz=142.2, num_updates=18200, lr=0.000234404, gnorm=0.803, train_wall=22, gb_free=7.4, wall=4195
2021-03-10 21:56:45 | INFO | train_inner | epoch 017:    652 / 1103 loss=3.692, nll_loss=2.249, ppl=4.75, wps=15972.5, ups=4.41, wpb=3621.3, bsz=152.6, num_updates=18300, lr=0.000233762, gnorm=0.813, train_wall=23, gb_free=6.8, wall=4218
2021-03-10 21:57:07 | INFO | train_inner | epoch 017:    752 / 1103 loss=3.709, nll_loss=2.269, ppl=4.82, wps=15790.1, ups=4.44, wpb=3553.9, bsz=147.8, num_updates=18400, lr=0.000233126, gnorm=0.826, train_wall=22, gb_free=7.2, wall=4241
2021-03-10 21:57:30 | INFO | train_inner | epoch 017:    852 / 1103 loss=3.715, nll_loss=2.277, ppl=4.85, wps=15957.8, ups=4.48, wpb=3563.8, bsz=155.4, num_updates=18500, lr=0.000232495, gnorm=0.827, train_wall=22, gb_free=7.3, wall=4263
2021-03-10 21:57:52 | INFO | train_inner | epoch 017:    952 / 1103 loss=3.775, nll_loss=2.342, ppl=5.07, wps=15938.1, ups=4.47, wpb=3567, bsz=125.4, num_updates=18600, lr=0.000231869, gnorm=0.833, train_wall=22, gb_free=7.1, wall=4285
2021-03-10 21:58:14 | INFO | train_inner | epoch 017:   1052 / 1103 loss=3.715, nll_loss=2.276, ppl=4.84, wps=16193.1, ups=4.51, wpb=3592.5, bsz=153.6, num_updates=18700, lr=0.000231249, gnorm=0.828, train_wall=22, gb_free=7.1, wall=4307
2021-03-10 21:58:25 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-10 21:58:29 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 3.984 | nll_loss 2.446 | ppl 5.45 | wps 48233.4 | wpb 2873.1 | bsz 115.6 | num_updates 18751 | best_loss 3.984
2021-03-10 21:58:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 18751 updates
2021-03-10 21:58:29 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt
2021-03-10 21:58:31 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt
2021-03-10 21:58:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt (epoch 17 @ 18751 updates, score 3.984) (writing took 4.591665800660849 seconds)
2021-03-10 21:58:34 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2021-03-10 21:58:34 | INFO | train | epoch 017 | loss 3.699 | nll_loss 2.257 | ppl 4.78 | wps 15416.4 | ups 4.31 | wpb 3577.8 | bsz 145.3 | num_updates 18751 | lr 0.000230934 | gnorm 0.818 | train_wall 246 | gb_free 6.9 | wall 4327
2021-03-10 21:58:34 | INFO | fairseq.trainer | begin training epoch 18
2021-03-10 21:58:34 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-10 21:58:45 | INFO | train_inner | epoch 018:     49 / 1103 loss=3.737, nll_loss=2.298, ppl=4.92, wps=11404.5, ups=3.26, wpb=3498.3, bsz=117.5, num_updates=18800, lr=0.000230633, gnorm=0.859, train_wall=22, gb_free=6.9, wall=4338
2021-03-10 21:59:07 | INFO | train_inner | epoch 018:    149 / 1103 loss=3.685, nll_loss=2.238, ppl=4.72, wps=16078.5, ups=4.5, wpb=3575.4, bsz=127.5, num_updates=18900, lr=0.000230022, gnorm=0.831, train_wall=22, gb_free=7, wall=4360
2021-03-10 21:59:30 | INFO | train_inner | epoch 018:    249 / 1103 loss=3.661, nll_loss=2.211, ppl=4.63, wps=15776.3, ups=4.44, wpb=3553.3, bsz=134.2, num_updates=19000, lr=0.000229416, gnorm=0.816, train_wall=22, gb_free=7, wall=4383
2021-03-10 21:59:52 | INFO | train_inner | epoch 018:    349 / 1103 loss=3.634, nll_loss=2.181, ppl=4.54, wps=16092.3, ups=4.45, wpb=3614.2, bsz=153.4, num_updates=19100, lr=0.000228814, gnorm=0.816, train_wall=22, gb_free=7.1, wall=4405
2021-03-10 22:00:15 | INFO | train_inner | epoch 018:    449 / 1103 loss=3.681, nll_loss=2.235, ppl=4.71, wps=15722.9, ups=4.48, wpb=3513.4, bsz=138.2, num_updates=19200, lr=0.000228218, gnorm=0.843, train_wall=22, gb_free=7.1, wall=4428
2021-03-10 22:00:37 | INFO | train_inner | epoch 018:    549 / 1103 loss=3.621, nll_loss=2.167, ppl=4.49, wps=15771.5, ups=4.42, wpb=3568.1, bsz=150.7, num_updates=19300, lr=0.000227626, gnorm=0.801, train_wall=23, gb_free=7, wall=4450
2021-03-10 22:01:00 | INFO | train_inner | epoch 018:    649 / 1103 loss=3.655, nll_loss=2.207, ppl=4.62, wps=16002.4, ups=4.46, wpb=3589, bsz=155.4, num_updates=19400, lr=0.000227038, gnorm=0.807, train_wall=22, gb_free=6.8, wall=4473
2021-03-10 22:01:22 | INFO | train_inner | epoch 018:    749 / 1103 loss=3.615, nll_loss=2.163, ppl=4.48, wps=16086.9, ups=4.45, wpb=3617.4, bsz=170.9, num_updates=19500, lr=0.000226455, gnorm=0.797, train_wall=22, gb_free=6.9, wall=4495
2021-03-10 22:01:45 | INFO | train_inner | epoch 018:    849 / 1103 loss=3.682, nll_loss=2.238, ppl=4.72, wps=16081.2, ups=4.46, wpb=3605.5, bsz=147.5, num_updates=19600, lr=0.000225877, gnorm=0.815, train_wall=22, gb_free=7.2, wall=4518
2021-03-10 22:02:07 | INFO | train_inner | epoch 018:    949 / 1103 loss=3.702, nll_loss=2.261, ppl=4.79, wps=15832.5, ups=4.43, wpb=3575.8, bsz=144.7, num_updates=19700, lr=0.000225303, gnorm=0.86, train_wall=22, gb_free=6.9, wall=4540
2021-03-10 22:02:29 | INFO | train_inner | epoch 018:   1049 / 1103 loss=3.709, nll_loss=2.27, ppl=4.82, wps=16092.5, ups=4.48, wpb=3591.6, bsz=147.4, num_updates=19800, lr=0.000224733, gnorm=0.845, train_wall=22, gb_free=6.9, wall=4563
2021-03-10 22:02:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-10 22:02:45 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 3.972 | nll_loss 2.431 | ppl 5.39 | wps 48218.3 | wpb 2873.1 | bsz 115.6 | num_updates 19854 | best_loss 3.972
2021-03-10 22:02:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 19854 updates
2021-03-10 22:02:45 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt
2021-03-10 22:02:47 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt
2021-03-10 22:02:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt (epoch 18 @ 19854 updates, score 3.972) (writing took 4.400252193212509 seconds)
2021-03-10 22:02:50 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2021-03-10 22:02:50 | INFO | train | epoch 018 | loss 3.667 | nll_loss 2.22 | ppl 4.66 | wps 15427.2 | ups 4.31 | wpb 3577.8 | bsz 145.3 | num_updates 19854 | lr 0.000224427 | gnorm 0.823 | train_wall 246 | gb_free 7.2 | wall 4583
2021-03-10 22:02:50 | INFO | fairseq.trainer | begin training epoch 19
2021-03-10 22:02:50 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-10 22:03:00 | INFO | train_inner | epoch 019:     46 / 1103 loss=3.661, nll_loss=2.213, ppl=4.64, wps=11570.9, ups=3.26, wpb=3553.7, bsz=135.5, num_updates=19900, lr=0.000224168, gnorm=0.816, train_wall=22, gb_free=6.9, wall=4593
2021-03-10 22:03:23 | INFO | train_inner | epoch 019:    146 / 1103 loss=3.587, nll_loss=2.128, ppl=4.37, wps=15995.8, ups=4.44, wpb=3602.7, bsz=147.4, num_updates=20000, lr=0.000223607, gnorm=0.799, train_wall=22, gb_free=7.2, wall=4616
2021-03-10 22:03:45 | INFO | train_inner | epoch 019:    246 / 1103 loss=3.63, nll_loss=2.175, ppl=4.52, wps=15889.4, ups=4.42, wpb=3595.2, bsz=131.7, num_updates=20100, lr=0.00022305, gnorm=0.82, train_wall=23, gb_free=7, wall=4638
2021-03-10 22:04:08 | INFO | train_inner | epoch 019:    346 / 1103 loss=3.614, nll_loss=2.158, ppl=4.46, wps=15812.6, ups=4.49, wpb=3525.2, bsz=147.4, num_updates=20200, lr=0.000222497, gnorm=0.828, train_wall=22, gb_free=7.5, wall=4661
2021-03-10 22:04:30 | INFO | train_inner | epoch 019:    446 / 1103 loss=3.63, nll_loss=2.177, ppl=4.52, wps=15853.8, ups=4.49, wpb=3531.7, bsz=145.1, num_updates=20300, lr=0.000221948, gnorm=0.829, train_wall=22, gb_free=6.9, wall=4683
2021-03-10 22:04:52 | INFO | train_inner | epoch 019:    546 / 1103 loss=3.668, nll_loss=2.221, ppl=4.66, wps=16001, ups=4.57, wpb=3503, bsz=138.2, num_updates=20400, lr=0.000221404, gnorm=0.83, train_wall=22, gb_free=7, wall=4705
2021-03-10 22:05:14 | INFO | train_inner | epoch 019:    646 / 1103 loss=3.641, nll_loss=2.191, ppl=4.57, wps=16291.6, ups=4.42, wpb=3681.9, bsz=155.8, num_updates=20500, lr=0.000220863, gnorm=0.81, train_wall=22, gb_free=6.9, wall=4728
2021-03-10 22:05:37 | INFO | train_inner | epoch 019:    746 / 1103 loss=3.679, nll_loss=2.232, ppl=4.7, wps=16040.3, ups=4.51, wpb=3558.2, bsz=135.8, num_updates=20600, lr=0.000220326, gnorm=0.85, train_wall=22, gb_free=6.9, wall=4750
2021-03-10 22:05:59 | INFO | train_inner | epoch 019:    846 / 1103 loss=3.637, nll_loss=2.186, ppl=4.55, wps=15884.3, ups=4.42, wpb=3595.4, bsz=140.2, num_updates=20700, lr=0.000219793, gnorm=0.83, train_wall=23, gb_free=6.9, wall=4772
2021-03-10 22:06:22 | INFO | train_inner | epoch 019:    946 / 1103 loss=3.65, nll_loss=2.203, ppl=4.6, wps=16130.3, ups=4.44, wpb=3632.5, bsz=158.2, num_updates=20800, lr=0.000219265, gnorm=0.806, train_wall=22, gb_free=7.4, wall=4795
2021-03-10 22:06:44 | INFO | train_inner | epoch 019:   1046 / 1103 loss=3.616, nll_loss=2.163, ppl=4.48, wps=15768.8, ups=4.44, wpb=3554.5, bsz=156.7, num_updates=20900, lr=0.000218739, gnorm=0.815, train_wall=22, gb_free=7.1, wall=4817
2021-03-10 22:06:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-10 22:07:01 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 3.964 | nll_loss 2.422 | ppl 5.36 | wps 48250.1 | wpb 2873.1 | bsz 115.6 | num_updates 20957 | best_loss 3.964
2021-03-10 22:07:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 20957 updates
2021-03-10 22:07:01 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt
2021-03-10 22:07:03 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt
2021-03-10 22:07:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt (epoch 19 @ 20957 updates, score 3.964) (writing took 4.639871787279844 seconds)
2021-03-10 22:07:06 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2021-03-10 22:07:06 | INFO | train | epoch 019 | loss 3.635 | nll_loss 2.183 | ppl 4.54 | wps 15424.4 | ups 4.31 | wpb 3577.8 | bsz 145.3 | num_updates 20957 | lr 0.000218442 | gnorm 0.823 | train_wall 246 | gb_free 7.1 | wall 4839
2021-03-10 22:07:06 | INFO | fairseq.trainer | begin training epoch 20
2021-03-10 22:07:06 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-10 22:07:15 | INFO | train_inner | epoch 020:     43 / 1103 loss=3.67, nll_loss=2.222, ppl=4.67, wps=11617.5, ups=3.22, wpb=3608.8, bsz=130.6, num_updates=21000, lr=0.000218218, gnorm=0.854, train_wall=22, gb_free=7, wall=4848
2021-03-10 22:07:38 | INFO | train_inner | epoch 020:    143 / 1103 loss=3.562, nll_loss=2.097, ppl=4.28, wps=15708.2, ups=4.44, wpb=3536.6, bsz=138.6, num_updates=21100, lr=0.0002177, gnorm=0.821, train_wall=22, gb_free=7, wall=4871
2021-03-10 22:08:00 | INFO | train_inner | epoch 020:    243 / 1103 loss=3.583, nll_loss=2.122, ppl=4.35, wps=16007.8, ups=4.42, wpb=3622.5, bsz=139.2, num_updates=21200, lr=0.000217186, gnorm=0.808, train_wall=23, gb_free=6.9, wall=4894
2021-03-10 22:08:23 | INFO | train_inner | epoch 020:    343 / 1103 loss=3.574, nll_loss=2.114, ppl=4.33, wps=16179.1, ups=4.42, wpb=3664.5, bsz=156.2, num_updates=21300, lr=0.000216676, gnorm=0.788, train_wall=23, gb_free=6.7, wall=4916
2021-03-10 22:08:46 | INFO | train_inner | epoch 020:    443 / 1103 loss=3.603, nll_loss=2.146, ppl=4.42, wps=16078, ups=4.4, wpb=3653.4, bsz=145.6, num_updates=21400, lr=0.000216169, gnorm=0.821, train_wall=23, gb_free=7, wall=4939
2021-03-10 22:09:08 | INFO | train_inner | epoch 020:    543 / 1103 loss=3.571, nll_loss=2.111, ppl=4.32, wps=15897.9, ups=4.45, wpb=3571.7, bsz=165, num_updates=21500, lr=0.000215666, gnorm=0.822, train_wall=22, gb_free=7.6, wall=4961
2021-03-10 22:09:31 | INFO | train_inner | epoch 020:    643 / 1103 loss=3.616, nll_loss=2.161, ppl=4.47, wps=15764.2, ups=4.48, wpb=3522.5, bsz=143.3, num_updates=21600, lr=0.000215166, gnorm=0.844, train_wall=22, gb_free=7.1, wall=4984
2021-03-10 22:09:53 | INFO | train_inner | epoch 020:    743 / 1103 loss=3.637, nll_loss=2.184, ppl=4.55, wps=15661.3, ups=4.49, wpb=3488.8, bsz=140.4, num_updates=21700, lr=0.000214669, gnorm=0.858, train_wall=22, gb_free=7.2, wall=5006
2021-03-10 22:10:15 | INFO | train_inner | epoch 020:    843 / 1103 loss=3.656, nll_loss=2.206, ppl=4.61, wps=15889.2, ups=4.48, wpb=3547.4, bsz=131.8, num_updates=21800, lr=0.000214176, gnorm=0.861, train_wall=22, gb_free=7.6, wall=5028
2021-03-10 22:10:38 | INFO | train_inner | epoch 020:    943 / 1103 loss=3.608, nll_loss=2.152, ppl=4.44, wps=15772.6, ups=4.41, wpb=3575.4, bsz=147, num_updates=21900, lr=0.000213687, gnorm=0.816, train_wall=23, gb_free=7.7, wall=5051
2021-03-10 22:11:00 | INFO | train_inner | epoch 020:   1043 / 1103 loss=3.623, nll_loss=2.172, ppl=4.51, wps=15998.4, ups=4.5, wpb=3555.5, bsz=163.6, num_updates=22000, lr=0.000213201, gnorm=0.83, train_wall=22, gb_free=7.3, wall=5073
2021-03-10 22:11:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-10 22:11:17 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 3.947 | nll_loss 2.405 | ppl 5.3 | wps 48183.1 | wpb 2873.1 | bsz 115.6 | num_updates 22060 | best_loss 3.947
2021-03-10 22:11:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 22060 updates
2021-03-10 22:11:17 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt
2021-03-10 22:11:20 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt
2021-03-10 22:11:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt (epoch 20 @ 22060 updates, score 3.947) (writing took 4.949876539409161 seconds)
2021-03-10 22:11:22 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2021-03-10 22:11:22 | INFO | train | epoch 020 | loss 3.609 | nll_loss 2.153 | ppl 4.45 | wps 15369.5 | ups 4.3 | wpb 3577.8 | bsz 145.3 | num_updates 22060 | lr 0.000212911 | gnorm 0.828 | train_wall 247 | gb_free 7 | wall 5095
2021-03-10 22:11:22 | INFO | fairseq.trainer | begin training epoch 21
2021-03-10 22:11:22 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-10 22:11:32 | INFO | train_inner | epoch 021:     40 / 1103 loss=3.585, nll_loss=2.126, ppl=4.36, wps=11529.6, ups=3.19, wpb=3616.1, bsz=146.4, num_updates=22100, lr=0.000212718, gnorm=0.811, train_wall=22, gb_free=7, wall=5105
2021-03-10 22:11:54 | INFO | train_inner | epoch 021:    140 / 1103 loss=3.564, nll_loss=2.102, ppl=4.29, wps=15990.3, ups=4.46, wpb=3588.6, bsz=143.4, num_updates=22200, lr=0.000212238, gnorm=0.813, train_wall=22, gb_free=6.9, wall=5127
2021-03-10 22:12:16 | INFO | train_inner | epoch 021:    240 / 1103 loss=3.56, nll_loss=2.097, ppl=4.28, wps=15818.2, ups=4.5, wpb=3513.7, bsz=151.8, num_updates=22300, lr=0.000211762, gnorm=0.818, train_wall=22, gb_free=7, wall=5149
2021-03-10 22:12:39 | INFO | train_inner | epoch 021:    340 / 1103 loss=3.57, nll_loss=2.107, ppl=4.31, wps=15950.7, ups=4.46, wpb=3579.7, bsz=136.1, num_updates=22400, lr=0.000211289, gnorm=0.844, train_wall=22, gb_free=6.9, wall=5172
2021-03-10 22:13:01 | INFO | train_inner | epoch 021:    440 / 1103 loss=3.549, nll_loss=2.084, ppl=4.24, wps=15864.8, ups=4.43, wpb=3577.2, bsz=146.7, num_updates=22500, lr=0.000210819, gnorm=0.804, train_wall=22, gb_free=7.2, wall=5194
2021-03-10 22:13:24 | INFO | train_inner | epoch 021:    540 / 1103 loss=3.571, nll_loss=2.109, ppl=4.31, wps=15960.5, ups=4.41, wpb=3619.8, bsz=148.1, num_updates=22600, lr=0.000210352, gnorm=0.849, train_wall=23, gb_free=7.3, wall=5217
2021-03-10 22:13:46 | INFO | train_inner | epoch 021:    640 / 1103 loss=3.603, nll_loss=2.146, ppl=4.42, wps=15804.6, ups=4.47, wpb=3534.4, bsz=141.2, num_updates=22700, lr=0.000209888, gnorm=0.832, train_wall=22, gb_free=7, wall=5239
2021-03-10 22:14:09 | INFO | train_inner | epoch 021:    740 / 1103 loss=3.588, nll_loss=2.129, ppl=4.37, wps=15792.1, ups=4.45, wpb=3551.2, bsz=144.4, num_updates=22800, lr=0.000209427, gnorm=0.832, train_wall=22, gb_free=7.5, wall=5262
2021-03-10 22:14:31 | INFO | train_inner | epoch 021:    840 / 1103 loss=3.572, nll_loss=2.112, ppl=4.32, wps=16097, ups=4.44, wpb=3628.2, bsz=155.4, num_updates=22900, lr=0.000208969, gnorm=0.808, train_wall=22, gb_free=7.2, wall=5284
2021-03-10 22:14:54 | INFO | train_inner | epoch 021:    940 / 1103 loss=3.614, nll_loss=2.158, ppl=4.46, wps=15870, ups=4.44, wpb=3575.8, bsz=141.3, num_updates=23000, lr=0.000208514, gnorm=0.828, train_wall=22, gb_free=7.4, wall=5307
2021-03-10 22:15:16 | INFO | train_inner | epoch 021:   1040 / 1103 loss=3.577, nll_loss=2.119, ppl=4.35, wps=16038.2, ups=4.46, wpb=3596.7, bsz=162.2, num_updates=23100, lr=0.000208063, gnorm=0.825, train_wall=22, gb_free=7.4, wall=5329
2021-03-10 22:15:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-10 22:15:34 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 3.933 | nll_loss 2.389 | ppl 5.24 | wps 48279.7 | wpb 2873.1 | bsz 115.6 | num_updates 23163 | best_loss 3.933
2021-03-10 22:15:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 23163 updates
2021-03-10 22:15:34 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt
2021-03-10 22:15:36 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt
2021-03-10 22:15:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt (epoch 21 @ 23163 updates, score 3.933) (writing took 4.594738505780697 seconds)
2021-03-10 22:15:39 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2021-03-10 22:15:39 | INFO | train | epoch 021 | loss 3.581 | nll_loss 2.121 | ppl 4.35 | wps 15399.5 | ups 4.3 | wpb 3577.8 | bsz 145.3 | num_updates 23163 | lr 0.000207779 | gnorm 0.826 | train_wall 246 | gb_free 6.7 | wall 5352
2021-03-10 22:15:39 | INFO | fairseq.trainer | begin training epoch 22
2021-03-10 22:15:39 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-10 22:15:47 | INFO | train_inner | epoch 022:     37 / 1103 loss=3.64, nll_loss=2.187, ppl=4.55, wps=11613.8, ups=3.23, wpb=3591.9, bsz=121.4, num_updates=23200, lr=0.000207614, gnorm=0.839, train_wall=22, gb_free=6.9, wall=5360
2021-03-10 22:16:10 | INFO | train_inner | epoch 022:    137 / 1103 loss=3.51, nll_loss=2.038, ppl=4.11, wps=16057.8, ups=4.44, wpb=3614.5, bsz=144.6, num_updates=23300, lr=0.000207168, gnorm=0.835, train_wall=22, gb_free=7.1, wall=5383
2021-03-10 22:16:32 | INFO | train_inner | epoch 022:    237 / 1103 loss=3.556, nll_loss=2.091, ppl=4.26, wps=16174.3, ups=4.46, wpb=3624.1, bsz=140.4, num_updates=23400, lr=0.000206725, gnorm=0.812, train_wall=22, gb_free=7, wall=5405
2021-03-10 22:16:54 | INFO | train_inner | epoch 022:    337 / 1103 loss=3.5, nll_loss=2.029, ppl=4.08, wps=15619.9, ups=4.48, wpb=3484.8, bsz=161.4, num_updates=23500, lr=0.000206284, gnorm=0.826, train_wall=22, gb_free=7, wall=5427
2021-03-10 22:17:17 | INFO | train_inner | epoch 022:    437 / 1103 loss=3.585, nll_loss=2.125, ppl=4.36, wps=16162.4, ups=4.5, wpb=3590.1, bsz=147.4, num_updates=23600, lr=0.000205847, gnorm=0.827, train_wall=22, gb_free=7, wall=5450
2021-03-10 22:17:39 | INFO | train_inner | epoch 022:    537 / 1103 loss=3.569, nll_loss=2.106, ppl=4.3, wps=15866.6, ups=4.48, wpb=3542.7, bsz=138.7, num_updates=23700, lr=0.000205412, gnorm=0.838, train_wall=22, gb_free=7, wall=5472
2021-03-10 22:18:01 | INFO | train_inner | epoch 022:    637 / 1103 loss=3.594, nll_loss=2.135, ppl=4.39, wps=15884.4, ups=4.49, wpb=3536.4, bsz=133.5, num_updates=23800, lr=0.00020498, gnorm=0.845, train_wall=22, gb_free=7.2, wall=5494
2021-03-10 22:18:24 | INFO | train_inner | epoch 022:    737 / 1103 loss=3.512, nll_loss=2.043, ppl=4.12, wps=15974.3, ups=4.4, wpb=3633.9, bsz=158.4, num_updates=23900, lr=0.000204551, gnorm=0.794, train_wall=23, gb_free=6.9, wall=5517
2021-03-10 22:18:46 | INFO | train_inner | epoch 022:    837 / 1103 loss=3.597, nll_loss=2.139, ppl=4.41, wps=15975.1, ups=4.47, wpb=3575.3, bsz=142.6, num_updates=24000, lr=0.000204124, gnorm=0.864, train_wall=22, gb_free=7.5, wall=5539
2021-03-10 22:19:09 | INFO | train_inner | epoch 022:    937 / 1103 loss=3.612, nll_loss=2.154, ppl=4.45, wps=15732.5, ups=4.44, wpb=3544.2, bsz=125.1, num_updates=24100, lr=0.0002037, gnorm=0.853, train_wall=22, gb_free=7.2, wall=5562
2021-03-10 22:19:31 | INFO | train_inner | epoch 022:   1037 / 1103 loss=3.561, nll_loss=2.098, ppl=4.28, wps=15859.3, ups=4.41, wpb=3595.1, bsz=149.9, num_updates=24200, lr=0.000203279, gnorm=0.85, train_wall=23, gb_free=7.2, wall=5585
2021-03-10 22:19:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-10 22:19:50 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 3.951 | nll_loss 2.401 | ppl 5.28 | wps 48156.4 | wpb 2873.1 | bsz 115.6 | num_updates 24266 | best_loss 3.933
2021-03-10 22:19:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 24266 updates
2021-03-10 22:19:50 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-10 22:19:52 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-10 22:19:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt (epoch 22 @ 24266 updates, score 3.951) (writing took 2.12720188125968 seconds)
2021-03-10 22:19:52 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2021-03-10 22:19:52 | INFO | train | epoch 022 | loss 3.557 | nll_loss 2.093 | ppl 4.27 | wps 15549.9 | ups 4.35 | wpb 3577.8 | bsz 145.3 | num_updates 24266 | lr 0.000203002 | gnorm 0.834 | train_wall 246 | gb_free 6.8 | wall 5606
2021-03-10 22:19:52 | INFO | fairseq.trainer | begin training epoch 23
2021-03-10 22:19:52 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-10 22:20:00 | INFO | train_inner | epoch 023:     34 / 1103 loss=3.522, nll_loss=2.055, ppl=4.15, wps=12553.6, ups=3.48, wpb=3612.2, bsz=158.6, num_updates=24300, lr=0.00020286, gnorm=0.827, train_wall=23, gb_free=7.2, wall=5613
2021-03-10 22:20:23 | INFO | train_inner | epoch 023:    134 / 1103 loss=3.515, nll_loss=2.043, ppl=4.12, wps=15938.6, ups=4.47, wpb=3562.5, bsz=139.1, num_updates=24400, lr=0.000202444, gnorm=0.825, train_wall=22, gb_free=7, wall=5636
2021-03-10 22:20:45 | INFO | train_inner | epoch 023:    234 / 1103 loss=3.484, nll_loss=2.008, ppl=4.02, wps=15897.3, ups=4.42, wpb=3597.2, bsz=146.2, num_updates=24500, lr=0.000202031, gnorm=0.814, train_wall=23, gb_free=7, wall=5658
2021-03-10 22:21:07 | INFO | train_inner | epoch 023:    334 / 1103 loss=3.531, nll_loss=2.063, ppl=4.18, wps=16477.4, ups=4.54, wpb=3630.6, bsz=142.7, num_updates=24600, lr=0.000201619, gnorm=0.834, train_wall=22, gb_free=7.1, wall=5680
2021-03-10 22:21:28 | INFO | train_inner | epoch 023:    434 / 1103 loss=3.504, nll_loss=2.034, ppl=4.1, wps=17694.7, ups=4.86, wpb=3642.9, bsz=161, num_updates=24700, lr=0.000201211, gnorm=0.81, train_wall=20, gb_free=6.9, wall=5701
2021-03-10 22:21:48 | INFO | train_inner | epoch 023:    534 / 1103 loss=3.566, nll_loss=2.101, ppl=4.29, wps=17204.3, ups=4.89, wpb=3517.7, bsz=131.9, num_updates=24800, lr=0.000200805, gnorm=0.868, train_wall=20, gb_free=6.8, wall=5721
2021-03-10 22:22:09 | INFO | train_inner | epoch 023:    634 / 1103 loss=3.57, nll_loss=2.106, ppl=4.3, wps=16929.4, ups=4.86, wpb=3484.3, bsz=124.5, num_updates=24900, lr=0.000200401, gnorm=0.869, train_wall=20, gb_free=7, wall=5742
2021-03-10 22:22:29 | INFO | train_inner | epoch 023:    734 / 1103 loss=3.556, nll_loss=2.091, ppl=4.26, wps=17534.3, ups=4.87, wpb=3600.1, bsz=150.1, num_updates=25000, lr=0.0002, gnorm=0.827, train_wall=20, gb_free=7, wall=5763
2021-03-10 22:22:50 | INFO | train_inner | epoch 023:    834 / 1103 loss=3.581, nll_loss=2.12, ppl=4.35, wps=17199.2, ups=4.82, wpb=3567.8, bsz=137.8, num_updates=25100, lr=0.000199601, gnorm=0.85, train_wall=21, gb_free=7.2, wall=5783
2021-03-10 22:23:11 | INFO | train_inner | epoch 023:    934 / 1103 loss=3.534, nll_loss=2.068, ppl=4.19, wps=17420.6, ups=4.89, wpb=3560.3, bsz=153.9, num_updates=25200, lr=0.000199205, gnorm=0.839, train_wall=20, gb_free=6.8, wall=5804
2021-03-10 22:23:31 | INFO | train_inner | epoch 023:   1034 / 1103 loss=3.53, nll_loss=2.064, ppl=4.18, wps=17421.4, ups=4.83, wpb=3603.6, bsz=158.6, num_updates=25300, lr=0.000198811, gnorm=0.837, train_wall=21, gb_free=7.2, wall=5824
2021-03-10 22:23:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-10 22:23:49 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 3.933 | nll_loss 2.379 | ppl 5.2 | wps 48138 | wpb 2873.1 | bsz 115.6 | num_updates 25369 | best_loss 3.933
2021-03-10 22:23:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 25369 updates
2021-03-10 22:23:49 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt
2021-03-10 22:23:51 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt
2021-03-10 22:23:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt (epoch 23 @ 25369 updates, score 3.933) (writing took 4.501278501003981 seconds)
2021-03-10 22:23:54 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2021-03-10 22:23:54 | INFO | train | epoch 023 | loss 3.534 | nll_loss 2.067 | ppl 4.19 | wps 16338.3 | ups 4.57 | wpb 3577.8 | bsz 145.3 | num_updates 25369 | lr 0.00019854 | gnorm 0.835 | train_wall 232 | gb_free 7 | wall 5847
2021-03-10 22:23:54 | INFO | fairseq.trainer | begin training epoch 24
2021-03-10 22:23:54 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-10 22:24:01 | INFO | train_inner | epoch 024:     31 / 1103 loss=3.514, nll_loss=2.045, ppl=4.13, wps=11997, ups=3.36, wpb=3568.2, bsz=150, num_updates=25400, lr=0.000198419, gnorm=0.833, train_wall=21, gb_free=6.9, wall=5854
2021-03-10 22:24:24 | INFO | train_inner | epoch 024:    131 / 1103 loss=3.464, nll_loss=1.986, ppl=3.96, wps=15846.1, ups=4.43, wpb=3573.6, bsz=147.8, num_updates=25500, lr=0.00019803, gnorm=0.832, train_wall=22, gb_free=7, wall=5877
2021-03-10 22:24:46 | INFO | train_inner | epoch 024:    231 / 1103 loss=3.492, nll_loss=2.016, ppl=4.04, wps=15855.8, ups=4.42, wpb=3585.5, bsz=137.4, num_updates=25600, lr=0.000197642, gnorm=0.847, train_wall=22, gb_free=6.8, wall=5899
2021-03-10 22:25:09 | INFO | train_inner | epoch 024:    331 / 1103 loss=3.516, nll_loss=2.044, ppl=4.13, wps=16016, ups=4.46, wpb=3592.3, bsz=142.4, num_updates=25700, lr=0.000197257, gnorm=0.839, train_wall=22, gb_free=7.1, wall=5922
2021-03-10 22:25:31 | INFO | train_inner | epoch 024:    431 / 1103 loss=3.537, nll_loss=2.069, ppl=4.19, wps=15928.7, ups=4.45, wpb=3581.7, bsz=136.8, num_updates=25800, lr=0.000196875, gnorm=0.856, train_wall=22, gb_free=6.9, wall=5944
2021-03-10 22:25:54 | INFO | train_inner | epoch 024:    531 / 1103 loss=3.477, nll_loss=2.002, ppl=4, wps=15654.7, ups=4.46, wpb=3513, bsz=156.4, num_updates=25900, lr=0.000196494, gnorm=0.838, train_wall=22, gb_free=7, wall=5967
2021-03-10 22:26:16 | INFO | train_inner | epoch 024:    631 / 1103 loss=3.542, nll_loss=2.074, ppl=4.21, wps=16009.7, ups=4.42, wpb=3620.9, bsz=132.3, num_updates=26000, lr=0.000196116, gnorm=0.817, train_wall=23, gb_free=6.9, wall=5989
2021-03-10 22:26:39 | INFO | train_inner | epoch 024:    731 / 1103 loss=3.505, nll_loss=2.034, ppl=4.09, wps=15919.7, ups=4.47, wpb=3558.8, bsz=153.4, num_updates=26100, lr=0.00019574, gnorm=0.84, train_wall=22, gb_free=7, wall=6012
2021-03-10 22:27:01 | INFO | train_inner | epoch 024:    831 / 1103 loss=3.529, nll_loss=2.062, ppl=4.17, wps=15764.3, ups=4.45, wpb=3545.5, bsz=147.4, num_updates=26200, lr=0.000195366, gnorm=0.858, train_wall=22, gb_free=7, wall=6034
2021-03-10 22:27:23 | INFO | train_inner | epoch 024:    931 / 1103 loss=3.529, nll_loss=2.06, ppl=4.17, wps=15965.3, ups=4.45, wpb=3585.4, bsz=144.1, num_updates=26300, lr=0.000194994, gnorm=0.848, train_wall=22, gb_free=6.9, wall=6057
2021-03-10 22:27:46 | INFO | train_inner | epoch 024:   1031 / 1103 loss=3.506, nll_loss=2.036, ppl=4.1, wps=15926, ups=4.46, wpb=3569.3, bsz=158.1, num_updates=26400, lr=0.000194625, gnorm=0.824, train_wall=22, gb_free=7, wall=6079
2021-03-10 22:28:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-10 22:28:06 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 3.926 | nll_loss 2.379 | ppl 5.2 | wps 48235.1 | wpb 2873.1 | bsz 115.6 | num_updates 26472 | best_loss 3.926
2021-03-10 22:28:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 26472 updates
2021-03-10 22:28:06 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt
2021-03-10 22:28:08 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt
2021-03-10 22:28:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt (epoch 24 @ 26472 updates, score 3.926) (writing took 5.120054736733437 seconds)
2021-03-10 22:28:11 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2021-03-10 22:28:11 | INFO | train | epoch 024 | loss 3.513 | nll_loss 2.042 | ppl 4.12 | wps 15362.6 | ups 4.29 | wpb 3577.8 | bsz 145.3 | num_updates 26472 | lr 0.00019436 | gnorm 0.839 | train_wall 247 | gb_free 7 | wall 6104
2021-03-10 22:28:11 | INFO | fairseq.trainer | begin training epoch 25
2021-03-10 22:28:11 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-10 22:28:17 | INFO | train_inner | epoch 025:     28 / 1103 loss=3.525, nll_loss=2.056, ppl=4.16, wps=11506, ups=3.18, wpb=3613.2, bsz=139.6, num_updates=26500, lr=0.000194257, gnorm=0.835, train_wall=22, gb_free=6.9, wall=6110
2021-03-10 22:28:40 | INFO | train_inner | epoch 025:    128 / 1103 loss=3.452, nll_loss=1.97, ppl=3.92, wps=16001.1, ups=4.46, wpb=3586.5, bsz=139.1, num_updates=26600, lr=0.000193892, gnorm=0.828, train_wall=22, gb_free=7.3, wall=6133
2021-03-10 22:29:02 | INFO | train_inner | epoch 025:    228 / 1103 loss=3.474, nll_loss=1.997, ppl=3.99, wps=16104.9, ups=4.45, wpb=3616, bsz=144.2, num_updates=26700, lr=0.000193528, gnorm=0.869, train_wall=22, gb_free=6.8, wall=6155
2021-03-10 22:29:25 | INFO | train_inner | epoch 025:    328 / 1103 loss=3.451, nll_loss=1.973, ppl=3.93, wps=15987.9, ups=4.44, wpb=3597.8, bsz=157.3, num_updates=26800, lr=0.000193167, gnorm=0.851, train_wall=22, gb_free=7.1, wall=6178
2021-03-10 22:29:47 | INFO | train_inner | epoch 025:    428 / 1103 loss=3.498, nll_loss=2.024, ppl=4.07, wps=15823.3, ups=4.44, wpb=3565.7, bsz=136.1, num_updates=26900, lr=0.000192807, gnorm=0.833, train_wall=22, gb_free=7.3, wall=6200
2021-03-10 22:30:10 | INFO | train_inner | epoch 025:    528 / 1103 loss=3.525, nll_loss=2.055, ppl=4.15, wps=16066.8, ups=4.45, wpb=3610.1, bsz=137.4, num_updates=27000, lr=0.00019245, gnorm=0.847, train_wall=22, gb_free=7.3, wall=6223
2021-03-10 22:30:32 | INFO | train_inner | epoch 025:    628 / 1103 loss=3.497, nll_loss=2.023, ppl=4.06, wps=15771.5, ups=4.47, wpb=3526.9, bsz=142.6, num_updates=27100, lr=0.000192095, gnorm=0.869, train_wall=22, gb_free=7.2, wall=6245
2021-03-10 22:30:54 | INFO | train_inner | epoch 025:    728 / 1103 loss=3.556, nll_loss=2.089, ppl=4.26, wps=16191.7, ups=4.48, wpb=3617.2, bsz=130.1, num_updates=27200, lr=0.000191741, gnorm=0.848, train_wall=22, gb_free=7.3, wall=6267
2021-03-10 22:31:17 | INFO | train_inner | epoch 025:    828 / 1103 loss=3.517, nll_loss=2.046, ppl=4.13, wps=15681.4, ups=4.47, wpb=3511.8, bsz=136.2, num_updates=27300, lr=0.00019139, gnorm=0.86, train_wall=22, gb_free=7.4, wall=6290
2021-03-10 22:31:39 | INFO | train_inner | epoch 025:    928 / 1103 loss=3.482, nll_loss=2.008, ppl=4.02, wps=16265.5, ups=4.42, wpb=3681.4, bsz=163.3, num_updates=27400, lr=0.00019104, gnorm=0.806, train_wall=23, gb_free=6.9, wall=6313
2021-03-10 22:32:02 | INFO | train_inner | epoch 025:   1028 / 1103 loss=3.479, nll_loss=2.007, ppl=4.02, wps=15719.2, ups=4.46, wpb=3526, bsz=170.4, num_updates=27500, lr=0.000190693, gnorm=0.845, train_wall=22, gb_free=7.2, wall=6335
2021-03-10 22:32:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-10 22:32:22 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 3.921 | nll_loss 2.373 | ppl 5.18 | wps 48288.7 | wpb 2873.1 | bsz 115.6 | num_updates 27575 | best_loss 3.921
2021-03-10 22:32:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 27575 updates
2021-03-10 22:32:22 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt
2021-03-10 22:32:24 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt
2021-03-10 22:32:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt (epoch 25 @ 27575 updates, score 3.921) (writing took 4.592916831374168 seconds)
2021-03-10 22:32:27 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2021-03-10 22:32:27 | INFO | train | epoch 025 | loss 3.492 | nll_loss 2.018 | ppl 4.05 | wps 15416.3 | ups 4.31 | wpb 3577.8 | bsz 145.3 | num_updates 27575 | lr 0.000190433 | gnorm 0.846 | train_wall 246 | gb_free 6.8 | wall 6360
2021-03-10 22:32:27 | INFO | fairseq.trainer | begin training epoch 26
2021-03-10 22:32:27 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-10 22:32:33 | INFO | train_inner | epoch 026:     25 / 1103 loss=3.479, nll_loss=2.005, ppl=4.01, wps=11597.5, ups=3.25, wpb=3570.8, bsz=153.5, num_updates=27600, lr=0.000190347, gnorm=0.838, train_wall=22, gb_free=6.8, wall=6366
2021-03-10 22:32:55 | INFO | train_inner | epoch 026:    125 / 1103 loss=3.424, nll_loss=1.94, ppl=3.84, wps=16250.5, ups=4.47, wpb=3638.7, bsz=151.9, num_updates=27700, lr=0.000190003, gnorm=0.807, train_wall=22, gb_free=6.9, wall=6388
2021-03-10 22:33:17 | INFO | train_inner | epoch 026:    225 / 1103 loss=3.435, nll_loss=1.952, ppl=3.87, wps=15655.5, ups=4.46, wpb=3513.4, bsz=147.1, num_updates=27800, lr=0.000189661, gnorm=0.885, train_wall=22, gb_free=6.9, wall=6411
2021-03-10 22:33:40 | INFO | train_inner | epoch 026:    325 / 1103 loss=3.472, nll_loss=1.994, ppl=3.98, wps=16108.9, ups=4.45, wpb=3622.7, bsz=135.6, num_updates=27900, lr=0.000189321, gnorm=0.836, train_wall=22, gb_free=6.9, wall=6433
2021-03-10 22:34:03 | INFO | train_inner | epoch 026:    425 / 1103 loss=3.472, nll_loss=1.994, ppl=3.98, wps=15966.1, ups=4.42, wpb=3612.3, bsz=140.9, num_updates=28000, lr=0.000188982, gnorm=0.836, train_wall=23, gb_free=7, wall=6456
2021-03-10 22:34:25 | INFO | train_inner | epoch 026:    525 / 1103 loss=3.499, nll_loss=2.025, ppl=4.07, wps=15955.5, ups=4.47, wpb=3570.6, bsz=132.6, num_updates=28100, lr=0.000188646, gnorm=0.879, train_wall=22, gb_free=7, wall=6478
2021-03-10 22:34:47 | INFO | train_inner | epoch 026:    625 / 1103 loss=3.492, nll_loss=2.017, ppl=4.05, wps=15849.3, ups=4.46, wpb=3551.4, bsz=145.5, num_updates=28200, lr=0.000188311, gnorm=0.85, train_wall=22, gb_free=6.4, wall=6500
2021-03-10 22:35:10 | INFO | train_inner | epoch 026:    725 / 1103 loss=3.491, nll_loss=2.016, ppl=4.04, wps=15795.1, ups=4.43, wpb=3562.6, bsz=133.1, num_updates=28300, lr=0.000187978, gnorm=0.844, train_wall=22, gb_free=6.8, wall=6523
2021-03-10 22:35:32 | INFO | train_inner | epoch 026:    825 / 1103 loss=3.478, nll_loss=2.001, ppl=4, wps=15971.2, ups=4.45, wpb=3585.2, bsz=146.8, num_updates=28400, lr=0.000187647, gnorm=0.84, train_wall=22, gb_free=6.9, wall=6545
2021-03-10 22:35:55 | INFO | train_inner | epoch 026:    925 / 1103 loss=3.453, nll_loss=1.976, ppl=3.94, wps=15770.4, ups=4.49, wpb=3515.6, bsz=169.8, num_updates=28500, lr=0.000187317, gnorm=0.845, train_wall=22, gb_free=7.1, wall=6568
2021-03-10 22:36:17 | INFO | train_inner | epoch 026:   1025 / 1103 loss=3.484, nll_loss=2.01, ppl=4.03, wps=16062.9, ups=4.43, wpb=3625.3, bsz=153.4, num_updates=28600, lr=0.000186989, gnorm=0.822, train_wall=22, gb_free=6.6, wall=6590
2021-03-10 22:36:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-10 22:36:38 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 3.921 | nll_loss 2.369 | ppl 5.17 | wps 48294.6 | wpb 2873.1 | bsz 115.6 | num_updates 28678 | best_loss 3.921
2021-03-10 22:36:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 28678 updates
2021-03-10 22:36:38 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt
2021-03-10 22:36:40 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt
2021-03-10 22:36:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt (epoch 26 @ 28678 updates, score 3.921) (writing took 4.500081427395344 seconds)
2021-03-10 22:36:43 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2021-03-10 22:36:43 | INFO | train | epoch 026 | loss 3.473 | nll_loss 1.996 | ppl 3.99 | wps 15416.3 | ups 4.31 | wpb 3577.8 | bsz 145.3 | num_updates 28678 | lr 0.000186735 | gnorm 0.846 | train_wall 246 | gb_free 6.4 | wall 6616
2021-03-10 22:36:43 | INFO | fairseq.trainer | begin training epoch 27
2021-03-10 22:36:43 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-10 22:36:48 | INFO | train_inner | epoch 027:     22 / 1103 loss=3.518, nll_loss=2.046, ppl=4.13, wps=11534.2, ups=3.26, wpb=3537.9, bsz=127, num_updates=28700, lr=0.000186663, gnorm=0.87, train_wall=22, gb_free=6.9, wall=6621
2021-03-10 22:37:10 | INFO | train_inner | epoch 027:    122 / 1103 loss=3.418, nll_loss=1.932, ppl=3.82, wps=15975.5, ups=4.46, wpb=3585, bsz=146.1, num_updates=28800, lr=0.000186339, gnorm=0.834, train_wall=22, gb_free=7, wall=6643
2021-03-10 22:37:33 | INFO | train_inner | epoch 027:    222 / 1103 loss=3.441, nll_loss=1.96, ppl=3.89, wps=15940.8, ups=4.48, wpb=3558.9, bsz=149.4, num_updates=28900, lr=0.000186016, gnorm=0.833, train_wall=22, gb_free=7.3, wall=6666
2021-03-10 22:37:55 | INFO | train_inner | epoch 027:    322 / 1103 loss=3.428, nll_loss=1.943, ppl=3.85, wps=15855.5, ups=4.47, wpb=3549.8, bsz=146.6, num_updates=29000, lr=0.000185695, gnorm=0.855, train_wall=22, gb_free=6.7, wall=6688
2021-03-10 22:38:18 | INFO | train_inner | epoch 027:    422 / 1103 loss=3.436, nll_loss=1.954, ppl=3.88, wps=16013.6, ups=4.43, wpb=3610.9, bsz=146.1, num_updates=29100, lr=0.000185376, gnorm=0.839, train_wall=22, gb_free=7, wall=6711
2021-03-10 22:38:40 | INFO | train_inner | epoch 027:    522 / 1103 loss=3.419, nll_loss=1.936, ppl=3.83, wps=16087.2, ups=4.46, wpb=3605.1, bsz=164.5, num_updates=29200, lr=0.000185058, gnorm=0.843, train_wall=22, gb_free=6.8, wall=6733
2021-03-10 22:39:02 | INFO | train_inner | epoch 027:    622 / 1103 loss=3.463, nll_loss=1.984, ppl=3.95, wps=15924.1, ups=4.46, wpb=3572.8, bsz=139.3, num_updates=29300, lr=0.000184742, gnorm=0.877, train_wall=22, gb_free=7.1, wall=6756
2021-03-10 22:39:25 | INFO | train_inner | epoch 027:    722 / 1103 loss=3.482, nll_loss=2.006, ppl=4.02, wps=15949.7, ups=4.44, wpb=3593.2, bsz=137.5, num_updates=29400, lr=0.000184428, gnorm=0.842, train_wall=22, gb_free=7.1, wall=6778
2021-03-10 22:39:48 | INFO | train_inner | epoch 027:    822 / 1103 loss=3.453, nll_loss=1.973, ppl=3.93, wps=15837.5, ups=4.43, wpb=3576.8, bsz=144.4, num_updates=29500, lr=0.000184115, gnorm=0.842, train_wall=22, gb_free=6.8, wall=6801
2021-03-10 22:40:10 | INFO | train_inner | epoch 027:    922 / 1103 loss=3.493, nll_loss=2.018, ppl=4.05, wps=15891.6, ups=4.46, wpb=3559.2, bsz=132.9, num_updates=29600, lr=0.000183804, gnorm=0.859, train_wall=22, gb_free=6.5, wall=6823
2021-03-10 22:40:32 | INFO | train_inner | epoch 027:   1022 / 1103 loss=3.478, nll_loss=2.003, ppl=4.01, wps=15755.2, ups=4.44, wpb=3549.2, bsz=151.9, num_updates=29700, lr=0.000183494, gnorm=0.856, train_wall=22, gb_free=7, wall=6846
2021-03-10 22:40:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-10 22:40:54 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 3.925 | nll_loss 2.373 | ppl 5.18 | wps 48250.1 | wpb 2873.1 | bsz 115.6 | num_updates 29781 | best_loss 3.921
2021-03-10 22:40:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 29781 updates
2021-03-10 22:40:54 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-10 22:40:57 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-10 22:40:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt (epoch 27 @ 29781 updates, score 3.925) (writing took 2.144493907690048 seconds)
2021-03-10 22:40:57 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2021-03-10 22:40:57 | INFO | train | epoch 027 | loss 3.454 | nll_loss 1.974 | ppl 3.93 | wps 15550.1 | ups 4.35 | wpb 3577.8 | bsz 145.3 | num_updates 29781 | lr 0.000183244 | gnorm 0.848 | train_wall 246 | gb_free 7.1 | wall 6870
2021-03-10 22:40:57 | INFO | fairseq.trainer | begin training epoch 28
2021-03-10 22:40:57 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-10 22:41:01 | INFO | train_inner | epoch 028:     19 / 1103 loss=3.476, nll_loss=2, ppl=4, wps=12591.3, ups=3.51, wpb=3591.8, bsz=141.4, num_updates=29800, lr=0.000183186, gnorm=0.853, train_wall=22, gb_free=6.6, wall=6874
2021-03-10 22:41:24 | INFO | train_inner | epoch 028:    119 / 1103 loss=3.394, nll_loss=1.905, ppl=3.74, wps=15987.2, ups=4.43, wpb=3605.8, bsz=146.4, num_updates=29900, lr=0.000182879, gnorm=0.829, train_wall=22, gb_free=6.9, wall=6897
2021-03-10 22:41:46 | INFO | train_inner | epoch 028:    219 / 1103 loss=3.429, nll_loss=1.945, ppl=3.85, wps=16279.8, ups=4.43, wpb=3675.1, bsz=144.9, num_updates=30000, lr=0.000182574, gnorm=0.816, train_wall=22, gb_free=7, wall=6919
2021-03-10 22:42:08 | INFO | train_inner | epoch 028:    319 / 1103 loss=3.421, nll_loss=1.936, ppl=3.83, wps=16074.5, ups=4.49, wpb=3581.3, bsz=151.3, num_updates=30100, lr=0.000182271, gnorm=0.852, train_wall=22, gb_free=7.2, wall=6942
2021-03-10 22:42:31 | INFO | train_inner | epoch 028:    419 / 1103 loss=3.45, nll_loss=1.967, ppl=3.91, wps=15835.5, ups=4.5, wpb=3517.9, bsz=124.2, num_updates=30200, lr=0.000181969, gnorm=0.897, train_wall=22, gb_free=6.9, wall=6964
2021-03-10 22:42:53 | INFO | train_inner | epoch 028:    519 / 1103 loss=3.444, nll_loss=1.961, ppl=3.89, wps=15737.8, ups=4.47, wpb=3517.8, bsz=136.2, num_updates=30300, lr=0.000181668, gnorm=0.864, train_wall=22, gb_free=7, wall=6986
2021-03-10 22:43:15 | INFO | train_inner | epoch 028:    619 / 1103 loss=3.429, nll_loss=1.946, ppl=3.85, wps=15662.6, ups=4.5, wpb=3481.6, bsz=146.6, num_updates=30400, lr=0.000181369, gnorm=0.864, train_wall=22, gb_free=6.9, wall=7008
2021-03-10 22:43:38 | INFO | train_inner | epoch 028:    719 / 1103 loss=3.43, nll_loss=1.947, ppl=3.86, wps=15856.3, ups=4.43, wpb=3581.9, bsz=155.5, num_updates=30500, lr=0.000181071, gnorm=0.834, train_wall=22, gb_free=7.4, wall=7031
2021-03-10 22:44:00 | INFO | train_inner | epoch 028:    819 / 1103 loss=3.45, nll_loss=1.969, ppl=3.92, wps=15875.8, ups=4.42, wpb=3588.1, bsz=141.7, num_updates=30600, lr=0.000180775, gnorm=0.837, train_wall=22, gb_free=7.2, wall=7054
2021-03-10 22:44:23 | INFO | train_inner | epoch 028:    919 / 1103 loss=3.451, nll_loss=1.971, ppl=3.92, wps=16040.9, ups=4.44, wpb=3613.4, bsz=146.5, num_updates=30700, lr=0.000180481, gnorm=0.835, train_wall=22, gb_free=7.1, wall=7076
2021-03-10 22:44:46 | INFO | train_inner | epoch 028:   1019 / 1103 loss=3.424, nll_loss=1.941, ppl=3.84, wps=15909.7, ups=4.41, wpb=3607.3, bsz=158.5, num_updates=30800, lr=0.000180187, gnorm=0.83, train_wall=23, gb_free=7.1, wall=7099
2021-03-10 22:45:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-10 22:45:08 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 3.944 | nll_loss 2.385 | ppl 5.22 | wps 48167.9 | wpb 2873.1 | bsz 115.6 | num_updates 30884 | best_loss 3.921
2021-03-10 22:45:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 30884 updates
2021-03-10 22:45:08 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-10 22:45:10 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-10 22:45:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt (epoch 28 @ 30884 updates, score 3.944) (writing took 2.1298291869461536 seconds)
2021-03-10 22:45:10 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2021-03-10 22:45:10 | INFO | train | epoch 028 | loss 3.435 | nll_loss 1.952 | ppl 3.87 | wps 15544.3 | ups 4.34 | wpb 3577.8 | bsz 145.3 | num_updates 30884 | lr 0.000179942 | gnorm 0.848 | train_wall 247 | gb_free 7.2 | wall 7124
2021-03-10 22:45:10 | INFO | fairseq.trainer | begin training epoch 29
2021-03-10 22:45:10 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-10 22:45:14 | INFO | train_inner | epoch 029:     16 / 1103 loss=3.466, nll_loss=1.987, ppl=3.97, wps=12548.8, ups=3.5, wpb=3586.8, bsz=142.8, num_updates=30900, lr=0.000179896, gnorm=0.87, train_wall=22, gb_free=6.8, wall=7127
2021-03-10 22:45:37 | INFO | train_inner | epoch 029:    116 / 1103 loss=3.365, nll_loss=1.872, ppl=3.66, wps=15776.7, ups=4.44, wpb=3550.7, bsz=147.2, num_updates=31000, lr=0.000179605, gnorm=0.828, train_wall=22, gb_free=7.4, wall=7150
2021-03-10 22:45:59 | INFO | train_inner | epoch 029:    216 / 1103 loss=3.4, nll_loss=1.911, ppl=3.76, wps=15986.3, ups=4.44, wpb=3603.5, bsz=138.6, num_updates=31100, lr=0.000179316, gnorm=0.845, train_wall=22, gb_free=6.9, wall=7172
2021-03-10 22:46:22 | INFO | train_inner | epoch 029:    316 / 1103 loss=3.398, nll_loss=1.909, ppl=3.76, wps=15957.9, ups=4.46, wpb=3578.2, bsz=149.1, num_updates=31200, lr=0.000179029, gnorm=0.846, train_wall=22, gb_free=7.3, wall=7195
2021-03-10 22:46:44 | INFO | train_inner | epoch 029:    416 / 1103 loss=3.43, nll_loss=1.945, ppl=3.85, wps=16091.5, ups=4.44, wpb=3622.9, bsz=142.2, num_updates=31300, lr=0.000178743, gnorm=0.857, train_wall=22, gb_free=7.1, wall=7217
2021-03-10 22:47:07 | INFO | train_inner | epoch 029:    516 / 1103 loss=3.37, nll_loss=1.878, ppl=3.68, wps=15779.8, ups=4.44, wpb=3556.6, bsz=160.1, num_updates=31400, lr=0.000178458, gnorm=0.84, train_wall=22, gb_free=7.4, wall=7240
2021-03-10 22:47:29 | INFO | train_inner | epoch 029:    616 / 1103 loss=3.421, nll_loss=1.937, ppl=3.83, wps=16187.8, ups=4.45, wpb=3633.8, bsz=155.2, num_updates=31500, lr=0.000178174, gnorm=0.837, train_wall=22, gb_free=7, wall=7262
2021-03-10 22:47:52 | INFO | train_inner | epoch 029:    716 / 1103 loss=3.47, nll_loss=1.991, ppl=3.98, wps=16084.4, ups=4.46, wpb=3606.6, bsz=137.8, num_updates=31600, lr=0.000177892, gnorm=0.879, train_wall=22, gb_free=7.9, wall=7285
2021-03-10 22:48:14 | INFO | train_inner | epoch 029:    816 / 1103 loss=3.456, nll_loss=1.974, ppl=3.93, wps=15694, ups=4.49, wpb=3491.5, bsz=130.8, num_updates=31700, lr=0.000177611, gnorm=0.897, train_wall=22, gb_free=7.1, wall=7307
2021-03-10 22:48:36 | INFO | train_inner | epoch 029:    916 / 1103 loss=3.427, nll_loss=1.943, ppl=3.85, wps=15926.4, ups=4.45, wpb=3582.6, bsz=152.5, num_updates=31800, lr=0.000177332, gnorm=0.849, train_wall=22, gb_free=7, wall=7329
2021-03-10 22:48:59 | INFO | train_inner | epoch 029:   1016 / 1103 loss=3.42, nll_loss=1.937, ppl=3.83, wps=15904.6, ups=4.43, wpb=3587.6, bsz=155, num_updates=31900, lr=0.000177054, gnorm=0.851, train_wall=22, gb_free=7, wall=7352
2021-03-10 22:49:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-10 22:49:22 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 3.917 | nll_loss 2.369 | ppl 5.16 | wps 48175.2 | wpb 2873.1 | bsz 115.6 | num_updates 31987 | best_loss 3.917
2021-03-10 22:49:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 31987 updates
2021-03-10 22:49:22 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt
2021-03-10 22:49:24 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt
2021-03-10 22:49:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt (epoch 29 @ 31987 updates, score 3.917) (writing took 4.64466156065464 seconds)
2021-03-10 22:49:27 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2021-03-10 22:49:27 | INFO | train | epoch 029 | loss 3.419 | nll_loss 1.933 | ppl 3.82 | wps 15389.7 | ups 4.3 | wpb 3577.8 | bsz 145.3 | num_updates 31987 | lr 0.000176813 | gnorm 0.854 | train_wall 247 | gb_free 6.9 | wall 7380
2021-03-10 22:49:27 | INFO | fairseq.trainer | begin training epoch 30
2021-03-10 22:49:27 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-10 22:49:30 | INFO | train_inner | epoch 030:     13 / 1103 loss=3.442, nll_loss=1.959, ppl=3.89, wps=11372.9, ups=3.22, wpb=3535.5, bsz=132.2, num_updates=32000, lr=0.000176777, gnorm=0.871, train_wall=22, gb_free=7.1, wall=7383
2021-03-10 22:49:53 | INFO | train_inner | epoch 030:    113 / 1103 loss=3.353, nll_loss=1.856, ppl=3.62, wps=15906.3, ups=4.42, wpb=3594.8, bsz=144.1, num_updates=32100, lr=0.000176501, gnorm=0.83, train_wall=22, gb_free=6.5, wall=7406
2021-03-10 22:50:15 | INFO | train_inner | epoch 030:    213 / 1103 loss=3.43, nll_loss=1.944, ppl=3.85, wps=16168.6, ups=4.49, wpb=3604.9, bsz=125.2, num_updates=32200, lr=0.000176227, gnorm=0.845, train_wall=22, gb_free=7.2, wall=7428
2021-03-10 22:50:37 | INFO | train_inner | epoch 030:    313 / 1103 loss=3.33, nll_loss=1.833, ppl=3.56, wps=15818.1, ups=4.45, wpb=3553, bsz=172.3, num_updates=32300, lr=0.000175954, gnorm=0.831, train_wall=22, gb_free=7, wall=7450
2021-03-10 22:51:00 | INFO | train_inner | epoch 030:    413 / 1103 loss=3.402, nll_loss=1.914, ppl=3.77, wps=16086.7, ups=4.44, wpb=3625.1, bsz=152.1, num_updates=32400, lr=0.000175682, gnorm=0.86, train_wall=22, gb_free=6.9, wall=7473
2021-03-10 22:51:22 | INFO | train_inner | epoch 030:    513 / 1103 loss=3.383, nll_loss=1.891, ppl=3.71, wps=15643.2, ups=4.45, wpb=3512.1, bsz=145.2, num_updates=32500, lr=0.000175412, gnorm=0.861, train_wall=22, gb_free=7, wall=7495
2021-03-10 22:51:45 | INFO | train_inner | epoch 030:    613 / 1103 loss=3.398, nll_loss=1.908, ppl=3.75, wps=15824.4, ups=4.45, wpb=3559, bsz=142.4, num_updates=32600, lr=0.000175142, gnorm=0.875, train_wall=22, gb_free=7, wall=7518
2021-03-10 22:52:07 | INFO | train_inner | epoch 030:    713 / 1103 loss=3.435, nll_loss=1.949, ppl=3.86, wps=15666.8, ups=4.44, wpb=3526.4, bsz=126.8, num_updates=32700, lr=0.000174874, gnorm=0.899, train_wall=22, gb_free=7.1, wall=7540
2021-03-10 22:52:30 | INFO | train_inner | epoch 030:    813 / 1103 loss=3.409, nll_loss=1.924, ppl=3.79, wps=16142, ups=4.46, wpb=3623, bsz=158.4, num_updates=32800, lr=0.000174608, gnorm=0.837, train_wall=22, gb_free=6.8, wall=7563
2021-03-10 22:52:52 | INFO | train_inner | epoch 030:    913 / 1103 loss=3.416, nll_loss=1.929, ppl=3.81, wps=15926.6, ups=4.45, wpb=3582.9, bsz=139.4, num_updates=32900, lr=0.000174342, gnorm=0.857, train_wall=22, gb_free=7.6, wall=7585
2021-03-10 22:53:15 | INFO | train_inner | epoch 030:   1013 / 1103 loss=3.426, nll_loss=1.943, ppl=3.84, wps=16289.2, ups=4.41, wpb=3690.2, bsz=152.3, num_updates=33000, lr=0.000174078, gnorm=0.825, train_wall=23, gb_free=7.7, wall=7608
2021-03-10 22:53:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-10 22:53:39 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 3.935 | nll_loss 2.382 | ppl 5.21 | wps 48182.3 | wpb 2873.1 | bsz 115.6 | num_updates 33090 | best_loss 3.917
2021-03-10 22:53:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 33090 updates
2021-03-10 22:53:39 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-10 22:53:41 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-10 22:53:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt (epoch 30 @ 33090 updates, score 3.935) (writing took 2.337150029838085 seconds)
2021-03-10 22:53:41 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2021-03-10 22:53:41 | INFO | train | epoch 030 | loss 3.402 | nll_loss 1.914 | ppl 3.77 | wps 15534.2 | ups 4.34 | wpb 3577.8 | bsz 145.3 | num_updates 33090 | lr 0.000173841 | gnorm 0.856 | train_wall 246 | gb_free 6.8 | wall 7634
2021-03-10 22:53:41 | INFO | fairseq.trainer | begin training epoch 31
2021-03-10 22:53:41 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-10 22:53:43 | INFO | train_inner | epoch 031:     10 / 1103 loss=3.438, nll_loss=1.955, ppl=3.88, wps=12273.2, ups=3.52, wpb=3484.5, bsz=141, num_updates=33100, lr=0.000173814, gnorm=0.898, train_wall=22, gb_free=7.4, wall=7636
2021-03-10 22:54:06 | INFO | train_inner | epoch 031:    110 / 1103 loss=3.33, nll_loss=1.831, ppl=3.56, wps=15921.6, ups=4.46, wpb=3572.6, bsz=149.4, num_updates=33200, lr=0.000173553, gnorm=0.843, train_wall=22, gb_free=6.9, wall=7659
2021-03-10 22:54:28 | INFO | train_inner | epoch 031:    210 / 1103 loss=3.346, nll_loss=1.85, ppl=3.6, wps=16199.7, ups=4.42, wpb=3661.4, bsz=154.8, num_updates=33300, lr=0.000173292, gnorm=0.832, train_wall=22, gb_free=7, wall=7681
2021-03-10 22:54:51 | INFO | train_inner | epoch 031:    310 / 1103 loss=3.354, nll_loss=1.858, ppl=3.62, wps=15949.4, ups=4.45, wpb=3585.4, bsz=145.8, num_updates=33400, lr=0.000173032, gnorm=0.845, train_wall=22, gb_free=6.7, wall=7704
2021-03-10 22:55:13 | INFO | train_inner | epoch 031:    410 / 1103 loss=3.419, nll_loss=1.93, ppl=3.81, wps=15843.1, ups=4.48, wpb=3535.2, bsz=126.2, num_updates=33500, lr=0.000172774, gnorm=0.867, train_wall=22, gb_free=7, wall=7726
2021-03-10 22:55:36 | INFO | train_inner | epoch 031:    510 / 1103 loss=3.416, nll_loss=1.927, ppl=3.8, wps=15914.6, ups=4.45, wpb=3574.3, bsz=132.4, num_updates=33600, lr=0.000172516, gnorm=0.867, train_wall=22, gb_free=7.1, wall=7749
2021-03-10 22:55:58 | INFO | train_inner | epoch 031:    610 / 1103 loss=3.36, nll_loss=1.866, ppl=3.65, wps=15815.8, ups=4.42, wpb=3574.5, bsz=158.1, num_updates=33700, lr=0.00017226, gnorm=0.852, train_wall=22, gb_free=7.1, wall=7771
2021-03-10 22:56:20 | INFO | train_inner | epoch 031:    710 / 1103 loss=3.398, nll_loss=1.909, ppl=3.76, wps=15965.4, ups=4.49, wpb=3559.6, bsz=146.1, num_updates=33800, lr=0.000172005, gnorm=0.881, train_wall=22, gb_free=7.1, wall=7794
2021-03-10 22:56:43 | INFO | train_inner | epoch 031:    810 / 1103 loss=3.399, nll_loss=1.91, ppl=3.76, wps=15738.5, ups=4.45, wpb=3536.3, bsz=145.7, num_updates=33900, lr=0.000171751, gnorm=0.879, train_wall=22, gb_free=7, wall=7816
2021-03-10 22:57:05 | INFO | train_inner | epoch 031:    910 / 1103 loss=3.447, nll_loss=1.965, ppl=3.9, wps=15938.5, ups=4.45, wpb=3578.4, bsz=134.4, num_updates=34000, lr=0.000171499, gnorm=0.875, train_wall=22, gb_free=6.9, wall=7839
2021-03-10 22:57:28 | INFO | train_inner | epoch 031:   1010 / 1103 loss=3.394, nll_loss=1.906, ppl=3.75, wps=15932.3, ups=4.49, wpb=3545.4, bsz=150.8, num_updates=34100, lr=0.000171247, gnorm=0.858, train_wall=22, gb_free=7.1, wall=7861
2021-03-10 22:57:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-10 22:57:52 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 3.919 | nll_loss 2.366 | ppl 5.15 | wps 48222 | wpb 2873.1 | bsz 115.6 | num_updates 34193 | best_loss 3.917
2021-03-10 22:57:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 34193 updates
2021-03-10 22:57:52 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-10 22:57:55 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-10 22:57:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt (epoch 31 @ 34193 updates, score 3.919) (writing took 2.397384572774172 seconds)
2021-03-10 22:57:55 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2021-03-10 22:57:55 | INFO | train | epoch 031 | loss 3.386 | nll_loss 1.895 | ppl 3.72 | wps 15541.5 | ups 4.34 | wpb 3577.8 | bsz 145.3 | num_updates 34193 | lr 0.000171014 | gnorm 0.86 | train_wall 246 | gb_free 7.2 | wall 7888
2021-03-10 22:57:55 | INFO | fairseq.trainer | begin training epoch 32
2021-03-10 22:57:55 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-10 22:57:57 | INFO | train_inner | epoch 032:      7 / 1103 loss=3.393, nll_loss=1.905, ppl=3.75, wps=12598.8, ups=3.46, wpb=3637.6, bsz=154.6, num_updates=34200, lr=0.000170996, gnorm=0.862, train_wall=22, gb_free=7.3, wall=7890
2021-03-10 22:58:19 | INFO | train_inner | epoch 032:    107 / 1103 loss=3.324, nll_loss=1.823, ppl=3.54, wps=15966.9, ups=4.44, wpb=3597.3, bsz=139.6, num_updates=34300, lr=0.000170747, gnorm=0.855, train_wall=22, gb_free=7.7, wall=7912
2021-03-10 22:58:41 | INFO | train_inner | epoch 032:    207 / 1103 loss=3.345, nll_loss=1.845, ppl=3.59, wps=16112.9, ups=4.5, wpb=3580.2, bsz=134.9, num_updates=34400, lr=0.000170499, gnorm=0.849, train_wall=22, gb_free=6.6, wall=7934
2021-03-10 22:59:04 | INFO | train_inner | epoch 032:    307 / 1103 loss=3.348, nll_loss=1.852, ppl=3.61, wps=16068.2, ups=4.47, wpb=3592.4, bsz=149.3, num_updates=34500, lr=0.000170251, gnorm=0.86, train_wall=22, gb_free=7.1, wall=7957
2021-03-10 22:59:26 | INFO | train_inner | epoch 032:    407 / 1103 loss=3.342, nll_loss=1.846, ppl=3.59, wps=15954, ups=4.46, wpb=3577.8, bsz=158.6, num_updates=34600, lr=0.000170005, gnorm=0.853, train_wall=22, gb_free=6.9, wall=7979
2021-03-10 22:59:48 | INFO | train_inner | epoch 032:    507 / 1103 loss=3.375, nll_loss=1.882, ppl=3.68, wps=15883.2, ups=4.49, wpb=3539.3, bsz=137.4, num_updates=34700, lr=0.00016976, gnorm=0.882, train_wall=22, gb_free=7.1, wall=8001
2021-03-10 23:00:11 | INFO | train_inner | epoch 032:    607 / 1103 loss=3.408, nll_loss=1.916, ppl=3.77, wps=15838.4, ups=4.45, wpb=3561.1, bsz=120.1, num_updates=34800, lr=0.000169516, gnorm=0.883, train_wall=22, gb_free=6.8, wall=8024
2021-03-10 23:00:33 | INFO | train_inner | epoch 032:    707 / 1103 loss=3.367, nll_loss=1.874, ppl=3.67, wps=15809.2, ups=4.48, wpb=3530.9, bsz=153.5, num_updates=34900, lr=0.000169273, gnorm=0.855, train_wall=22, gb_free=7.2, wall=8046
2021-03-10 23:00:56 | INFO | train_inner | epoch 032:    807 / 1103 loss=3.399, nll_loss=1.908, ppl=3.75, wps=15723.9, ups=4.43, wpb=3549.9, bsz=130, num_updates=35000, lr=0.000169031, gnorm=0.886, train_wall=22, gb_free=7.1, wall=8069
2021-03-10 23:01:18 | INFO | train_inner | epoch 032:    907 / 1103 loss=3.376, nll_loss=1.885, ppl=3.69, wps=15927.9, ups=4.44, wpb=3585.3, bsz=149.5, num_updates=35100, lr=0.00016879, gnorm=0.869, train_wall=22, gb_free=7.1, wall=8091
2021-03-10 23:01:41 | INFO | train_inner | epoch 032:   1007 / 1103 loss=3.401, nll_loss=1.914, ppl=3.77, wps=16164, ups=4.48, wpb=3608.2, bsz=160.4, num_updates=35200, lr=0.00016855, gnorm=0.856, train_wall=22, gb_free=7.2, wall=8114
2021-03-10 23:02:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-10 23:02:06 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 3.914 | nll_loss 2.36 | ppl 5.14 | wps 48282.3 | wpb 2873.1 | bsz 115.6 | num_updates 35296 | best_loss 3.914
2021-03-10 23:02:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 35296 updates
2021-03-10 23:02:06 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt
2021-03-10 23:02:08 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt
2021-03-10 23:02:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt (epoch 32 @ 35296 updates, score 3.914) (writing took 4.695395294576883 seconds)
2021-03-10 23:02:10 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2021-03-10 23:02:10 | INFO | train | epoch 032 | loss 3.371 | nll_loss 1.877 | ppl 3.67 | wps 15435.7 | ups 4.31 | wpb 3577.8 | bsz 145.3 | num_updates 35296 | lr 0.000168321 | gnorm 0.863 | train_wall 246 | gb_free 7.5 | wall 8144
2021-03-10 23:02:11 | INFO | fairseq.trainer | begin training epoch 33
2021-03-10 23:02:11 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-10 23:02:12 | INFO | train_inner | epoch 033:      4 / 1103 loss=3.392, nll_loss=1.905, ppl=3.75, wps=11681.8, ups=3.23, wpb=3617.1, bsz=162.2, num_updates=35300, lr=0.000168311, gnorm=0.843, train_wall=22, gb_free=6.7, wall=8145
2021-03-10 23:02:34 | INFO | train_inner | epoch 033:    104 / 1103 loss=3.292, nll_loss=1.787, ppl=3.45, wps=16071.3, ups=4.48, wpb=3586.2, bsz=150.3, num_updates=35400, lr=0.000168073, gnorm=0.843, train_wall=22, gb_free=6.9, wall=8167
2021-03-10 23:02:56 | INFO | train_inner | epoch 033:    204 / 1103 loss=3.364, nll_loss=1.869, ppl=3.65, wps=16005.6, ups=4.52, wpb=3540.4, bsz=141.8, num_updates=35500, lr=0.000167836, gnorm=0.866, train_wall=22, gb_free=7.2, wall=8189
2021-03-10 23:03:19 | INFO | train_inner | epoch 033:    304 / 1103 loss=3.375, nll_loss=1.88, ppl=3.68, wps=15972.1, ups=4.39, wpb=3639.7, bsz=127.8, num_updates=35600, lr=0.0001676, gnorm=0.858, train_wall=23, gb_free=6.9, wall=8212
2021-03-10 23:03:41 | INFO | train_inner | epoch 033:    404 / 1103 loss=3.32, nll_loss=1.819, ppl=3.53, wps=16024.7, ups=4.43, wpb=3619.9, bsz=153.6, num_updates=35700, lr=0.000167365, gnorm=0.857, train_wall=22, gb_free=7, wall=8234
2021-03-10 23:04:04 | INFO | train_inner | epoch 033:    504 / 1103 loss=3.364, nll_loss=1.869, ppl=3.65, wps=15930, ups=4.42, wpb=3605.6, bsz=137.5, num_updates=35800, lr=0.000167132, gnorm=0.877, train_wall=23, gb_free=6.9, wall=8257
2021-03-10 23:04:26 | INFO | train_inner | epoch 033:    604 / 1103 loss=3.34, nll_loss=1.843, ppl=3.59, wps=15729.5, ups=4.45, wpb=3534.7, bsz=156.6, num_updates=35900, lr=0.000166899, gnorm=0.878, train_wall=22, gb_free=7.2, wall=8280
2021-03-10 23:04:49 | INFO | train_inner | epoch 033:    704 / 1103 loss=3.383, nll_loss=1.89, ppl=3.71, wps=16101.8, ups=4.47, wpb=3600.3, bsz=143.4, num_updates=36000, lr=0.000166667, gnorm=0.87, train_wall=22, gb_free=7.1, wall=8302
2021-03-10 23:05:11 | INFO | train_inner | epoch 033:    804 / 1103 loss=3.35, nll_loss=1.854, ppl=3.61, wps=15992.7, ups=4.43, wpb=3607.7, bsz=153.8, num_updates=36100, lr=0.000166436, gnorm=0.855, train_wall=22, gb_free=7.1, wall=8325
2021-03-10 23:05:33 | INFO | train_inner | epoch 033:    904 / 1103 loss=3.403, nll_loss=1.913, ppl=3.77, wps=15511.5, ups=4.54, wpb=3419.6, bsz=134.2, num_updates=36200, lr=0.000166206, gnorm=0.921, train_wall=22, gb_free=7.2, wall=8347
2021-03-10 23:05:56 | INFO | train_inner | epoch 033:   1004 / 1103 loss=3.401, nll_loss=1.911, ppl=3.76, wps=15927, ups=4.48, wpb=3553.5, bsz=137, num_updates=36300, lr=0.000165977, gnorm=0.889, train_wall=22, gb_free=6.8, wall=8369
2021-03-10 23:06:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-10 23:06:22 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 3.91 | nll_loss 2.359 | ppl 5.13 | wps 48261.2 | wpb 2873.1 | bsz 115.6 | num_updates 36399 | best_loss 3.91
2021-03-10 23:06:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 36399 updates
2021-03-10 23:06:22 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt
2021-03-10 23:06:24 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt
2021-03-10 23:06:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_best.pt (epoch 33 @ 36399 updates, score 3.91) (writing took 4.509799540042877 seconds)
2021-03-10 23:06:26 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2021-03-10 23:06:26 | INFO | train | epoch 033 | loss 3.358 | nll_loss 1.862 | ppl 3.63 | wps 15420.4 | ups 4.31 | wpb 3577.8 | bsz 145.3 | num_updates 36399 | lr 0.000165751 | gnorm 0.867 | train_wall 246 | gb_free 6.9 | wall 8400
2021-03-10 23:06:26 | INFO | fairseq.trainer | begin training epoch 34
2021-03-10 23:06:26 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-10 23:06:27 | INFO | train_inner | epoch 034:      1 / 1103 loss=3.341, nll_loss=1.846, ppl=3.59, wps=11780.1, ups=3.22, wpb=3660.6, bsz=163.4, num_updates=36400, lr=0.000165748, gnorm=0.825, train_wall=22, gb_free=7.1, wall=8400
2021-03-10 23:06:49 | INFO | train_inner | epoch 034:    101 / 1103 loss=3.286, nll_loss=1.781, ppl=3.44, wps=16030, ups=4.47, wpb=3589.9, bsz=162.9, num_updates=36500, lr=0.000165521, gnorm=0.845, train_wall=22, gb_free=7.3, wall=8422
2021-03-10 23:07:12 | INFO | train_inner | epoch 034:    201 / 1103 loss=3.302, nll_loss=1.798, ppl=3.48, wps=16094, ups=4.45, wpb=3618.7, bsz=155, num_updates=36600, lr=0.000165295, gnorm=0.857, train_wall=22, gb_free=7.3, wall=8445
2021-03-10 23:07:34 | INFO | train_inner | epoch 034:    301 / 1103 loss=3.338, nll_loss=1.839, ppl=3.58, wps=15999.3, ups=4.48, wpb=3571.1, bsz=146.2, num_updates=36700, lr=0.00016507, gnorm=0.881, train_wall=22, gb_free=7.4, wall=8467
2021-03-10 23:07:56 | INFO | train_inner | epoch 034:    401 / 1103 loss=3.359, nll_loss=1.861, ppl=3.63, wps=15670.5, ups=4.46, wpb=3511.3, bsz=124.6, num_updates=36800, lr=0.000164845, gnorm=0.893, train_wall=22, gb_free=7.3, wall=8490
2021-03-10 23:08:19 | INFO | train_inner | epoch 034:    501 / 1103 loss=3.387, nll_loss=1.893, ppl=3.71, wps=16122.4, ups=4.47, wpb=3609.3, bsz=124.5, num_updates=36900, lr=0.000164622, gnorm=0.883, train_wall=22, gb_free=6.9, wall=8512
2021-03-10 23:08:41 | INFO | train_inner | epoch 034:    601 / 1103 loss=3.318, nll_loss=1.819, ppl=3.53, wps=16117.5, ups=4.45, wpb=3624.7, bsz=169.4, num_updates=37000, lr=0.000164399, gnorm=0.844, train_wall=22, gb_free=6.7, wall=8534
2021-03-10 23:09:04 | INFO | train_inner | epoch 034:    701 / 1103 loss=3.344, nll_loss=1.848, ppl=3.6, wps=16007.6, ups=4.47, wpb=3579.8, bsz=152.7, num_updates=37100, lr=0.000164177, gnorm=0.866, train_wall=22, gb_free=6.9, wall=8557
2021-03-10 23:09:26 | INFO | train_inner | epoch 034:    801 / 1103 loss=3.318, nll_loss=1.818, ppl=3.53, wps=15697.4, ups=4.44, wpb=3539.3, bsz=153, num_updates=37200, lr=0.000163956, gnorm=0.873, train_wall=22, gb_free=7.2, wall=8579
2021-03-10 23:09:49 | INFO | train_inner | epoch 034:    901 / 1103 loss=3.35, nll_loss=1.852, ppl=3.61, wps=15710.9, ups=4.48, wpb=3505.9, bsz=140.9, num_updates=37300, lr=0.000163737, gnorm=0.888, train_wall=22, gb_free=6.7, wall=8602
2021-03-10 23:10:11 | INFO | train_inner | epoch 034:   1001 / 1103 loss=3.371, nll_loss=1.876, ppl=3.67, wps=15983.6, ups=4.44, wpb=3597.9, bsz=137.8, num_updates=37400, lr=0.000163517, gnorm=0.868, train_wall=22, gb_free=7, wall=8624
2021-03-10 23:10:33 | INFO | train_inner | epoch 034:   1101 / 1103 loss=3.407, nll_loss=1.918, ppl=3.78, wps=16074, ups=4.46, wpb=3607.1, bsz=132.6, num_updates=37500, lr=0.000163299, gnorm=0.887, train_wall=22, gb_free=6.6, wall=8647
2021-03-10 23:10:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-10 23:10:38 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 3.923 | nll_loss 2.369 | ppl 5.17 | wps 48235.2 | wpb 2873.1 | bsz 115.6 | num_updates 37502 | best_loss 3.91
2021-03-10 23:10:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 37502 updates
2021-03-10 23:10:38 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-10 23:10:40 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-10 23:10:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt (epoch 34 @ 37502 updates, score 3.923) (writing took 2.0616847053170204 seconds)
2021-03-10 23:10:40 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2021-03-10 23:10:40 | INFO | train | epoch 034 | loss 3.344 | nll_loss 1.846 | ppl 3.6 | wps 15573.2 | ups 4.35 | wpb 3577.8 | bsz 145.3 | num_updates 37502 | lr 0.000163295 | gnorm 0.872 | train_wall 246 | gb_free 6.7 | wall 8653
2021-03-10 23:10:40 | INFO | fairseq.trainer | begin training epoch 35
2021-03-10 23:10:40 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-10 23:11:02 | INFO | train_inner | epoch 035:     98 / 1103 loss=3.296, nll_loss=1.79, ppl=3.46, wps=12702.8, ups=3.5, wpb=3625.4, bsz=143.4, num_updates=37600, lr=0.000163082, gnorm=0.846, train_wall=22, gb_free=7.2, wall=8675
2021-03-10 23:11:24 | INFO | train_inner | epoch 035:    198 / 1103 loss=3.3, nll_loss=1.793, ppl=3.47, wps=15808.9, ups=4.45, wpb=3549.4, bsz=136.7, num_updates=37700, lr=0.000162866, gnorm=0.874, train_wall=22, gb_free=7.1, wall=8698
2021-03-10 23:11:47 | INFO | train_inner | epoch 035:    298 / 1103 loss=3.3, nll_loss=1.795, ppl=3.47, wps=15910.6, ups=4.44, wpb=3583.1, bsz=148.9, num_updates=37800, lr=0.00016265, gnorm=0.874, train_wall=22, gb_free=7.2, wall=8720
2021-03-10 23:12:09 | INFO | train_inner | epoch 035:    398 / 1103 loss=3.323, nll_loss=1.82, ppl=3.53, wps=15862.6, ups=4.46, wpb=3560.2, bsz=138.6, num_updates=37900, lr=0.000162435, gnorm=0.882, train_wall=22, gb_free=7.3, wall=8743
2021-03-10 23:12:32 | INFO | train_inner | epoch 035:    498 / 1103 loss=3.332, nll_loss=1.83, ppl=3.56, wps=15961.1, ups=4.49, wpb=3553.3, bsz=137, num_updates=38000, lr=0.000162221, gnorm=0.873, train_wall=22, gb_free=6.9, wall=8765
2021-03-10 23:12:54 | INFO | train_inner | epoch 035:    598 / 1103 loss=3.331, nll_loss=1.832, ppl=3.56, wps=15902.2, ups=4.46, wpb=3567.3, bsz=149.6, num_updates=38100, lr=0.000162008, gnorm=0.866, train_wall=22, gb_free=7.2, wall=8787
2021-03-10 23:13:17 | INFO | train_inner | epoch 035:    698 / 1103 loss=3.343, nll_loss=1.847, ppl=3.6, wps=16058.4, ups=4.46, wpb=3601.8, bsz=159.7, num_updates=38200, lr=0.000161796, gnorm=0.862, train_wall=22, gb_free=7.8, wall=8810
2021-03-10 23:13:39 | INFO | train_inner | epoch 035:    798 / 1103 loss=3.32, nll_loss=1.821, ppl=3.53, wps=16023.3, ups=4.44, wpb=3607.8, bsz=161.1, num_updates=38300, lr=0.000161585, gnorm=0.863, train_wall=22, gb_free=7.3, wall=8832
2021-03-10 23:14:02 | INFO | train_inner | epoch 035:    898 / 1103 loss=3.384, nll_loss=1.891, ppl=3.71, wps=16075.2, ups=4.43, wpb=3631.3, bsz=133.4, num_updates=38400, lr=0.000161374, gnorm=0.886, train_wall=22, gb_free=7.1, wall=8855
2021-03-10 23:14:24 | INFO | train_inner | epoch 035:    998 / 1103 loss=3.338, nll_loss=1.839, ppl=3.58, wps=15693, ups=4.44, wpb=3536.5, bsz=147.4, num_updates=38500, lr=0.000161165, gnorm=0.886, train_wall=22, gb_free=6.9, wall=8877
2021-03-10 23:14:47 | INFO | train_inner | epoch 035:   1098 / 1103 loss=3.354, nll_loss=1.859, ppl=3.63, wps=15915, ups=4.48, wpb=3553.6, bsz=143.6, num_updates=38600, lr=0.000160956, gnorm=0.887, train_wall=22, gb_free=7.4, wall=8900
2021-03-10 23:14:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-10 23:14:51 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 3.921 | nll_loss 2.367 | ppl 5.16 | wps 48202.3 | wpb 2873.1 | bsz 115.6 | num_updates 38605 | best_loss 3.91
2021-03-10 23:14:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 38605 updates
2021-03-10 23:14:51 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-10 23:14:53 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-10 23:14:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt (epoch 35 @ 38605 updates, score 3.921) (writing took 2.04384508356452 seconds)
2021-03-10 23:14:53 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2021-03-10 23:14:53 | INFO | train | epoch 035 | loss 3.33 | nll_loss 1.829 | ppl 3.55 | wps 15558 | ups 4.35 | wpb 3577.8 | bsz 145.3 | num_updates 38605 | lr 0.000160945 | gnorm 0.873 | train_wall 246 | gb_free 7.2 | wall 8907
2021-03-10 23:14:54 | INFO | fairseq.trainer | begin training epoch 36
2021-03-10 23:14:54 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-10 23:15:15 | INFO | train_inner | epoch 036:     95 / 1103 loss=3.27, nll_loss=1.76, ppl=3.39, wps=12482.9, ups=3.52, wpb=3548.5, bsz=140.5, num_updates=38700, lr=0.000160748, gnorm=0.865, train_wall=22, gb_free=6.9, wall=8928
2021-03-10 23:15:37 | INFO | train_inner | epoch 036:    195 / 1103 loss=3.303, nll_loss=1.798, ppl=3.48, wps=15850.7, ups=4.47, wpb=3542.6, bsz=147.7, num_updates=38800, lr=0.00016054, gnorm=0.902, train_wall=22, gb_free=6.7, wall=8950
2021-03-10 23:16:00 | INFO | train_inner | epoch 036:    295 / 1103 loss=3.294, nll_loss=1.789, ppl=3.46, wps=15912.7, ups=4.45, wpb=3574.8, bsz=156.6, num_updates=38900, lr=0.000160334, gnorm=0.876, train_wall=22, gb_free=7.1, wall=8973
2021-03-10 23:16:22 | INFO | train_inner | epoch 036:    395 / 1103 loss=3.31, nll_loss=1.807, ppl=3.5, wps=15896.3, ups=4.47, wpb=3555.9, bsz=148.2, num_updates=39000, lr=0.000160128, gnorm=0.889, train_wall=22, gb_free=7.1, wall=8995
2021-03-10 23:16:45 | INFO | train_inner | epoch 036:    495 / 1103 loss=3.321, nll_loss=1.816, ppl=3.52, wps=15786.7, ups=4.45, wpb=3548.7, bsz=131, num_updates=39100, lr=0.000159923, gnorm=0.883, train_wall=22, gb_free=6.8, wall=9018
2021-03-10 23:17:07 | INFO | train_inner | epoch 036:    595 / 1103 loss=3.323, nll_loss=1.822, ppl=3.54, wps=16074.7, ups=4.49, wpb=3579.1, bsz=147.3, num_updates=39200, lr=0.000159719, gnorm=0.889, train_wall=22, gb_free=7, wall=9040
2021-03-10 23:17:29 | INFO | train_inner | epoch 036:    695 / 1103 loss=3.348, nll_loss=1.851, ppl=3.61, wps=16097.7, ups=4.47, wpb=3603.7, bsz=146.4, num_updates=39300, lr=0.000159516, gnorm=0.866, train_wall=22, gb_free=7.1, wall=9062
2021-03-10 23:17:52 | INFO | train_inner | epoch 036:    795 / 1103 loss=3.324, nll_loss=1.823, ppl=3.54, wps=15862.4, ups=4.46, wpb=3553.6, bsz=142.5, num_updates=39400, lr=0.000159313, gnorm=0.896, train_wall=22, gb_free=7.1, wall=9085
2021-03-10 23:18:14 | INFO | train_inner | epoch 036:    895 / 1103 loss=3.311, nll_loss=1.809, ppl=3.5, wps=15933.9, ups=4.42, wpb=3608.2, bsz=147.4, num_updates=39500, lr=0.000159111, gnorm=0.863, train_wall=23, gb_free=7.1, wall=9107
2021-03-10 23:18:37 | INFO | train_inner | epoch 036:    995 / 1103 loss=3.346, nll_loss=1.849, ppl=3.6, wps=16078.4, ups=4.44, wpb=3619.8, bsz=146.6, num_updates=39600, lr=0.00015891, gnorm=0.877, train_wall=22, gb_free=7.5, wall=9130
2021-03-10 23:18:59 | INFO | train_inner | epoch 036:   1095 / 1103 loss=3.354, nll_loss=1.857, ppl=3.62, wps=15970.9, ups=4.45, wpb=3590.2, bsz=139.2, num_updates=39700, lr=0.00015871, gnorm=0.887, train_wall=22, gb_free=6.9, wall=9152
2021-03-10 23:19:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-10 23:19:05 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 3.919 | nll_loss 2.364 | ppl 5.15 | wps 48199.1 | wpb 2873.1 | bsz 115.6 | num_updates 39708 | best_loss 3.91
2021-03-10 23:19:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 39708 updates
2021-03-10 23:19:05 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-10 23:19:07 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-10 23:19:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt (epoch 36 @ 39708 updates, score 3.919) (writing took 2.1807570084929466 seconds)
2021-03-10 23:19:07 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2021-03-10 23:19:07 | INFO | train | epoch 036 | loss 3.318 | nll_loss 1.816 | ppl 3.52 | wps 15560.5 | ups 4.35 | wpb 3577.8 | bsz 145.3 | num_updates 39708 | lr 0.000158694 | gnorm 0.881 | train_wall 246 | gb_free 7 | wall 9160
2021-03-10 23:19:07 | INFO | fairseq.trainer | begin training epoch 37
2021-03-10 23:19:07 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-10 23:19:28 | INFO | train_inner | epoch 037:     92 / 1103 loss=3.269, nll_loss=1.759, ppl=3.39, wps=12664.4, ups=3.46, wpb=3655.7, bsz=145, num_updates=39800, lr=0.000158511, gnorm=0.859, train_wall=23, gb_free=7, wall=9181
2021-03-10 23:19:51 | INFO | train_inner | epoch 037:    192 / 1103 loss=3.273, nll_loss=1.766, ppl=3.4, wps=16278.6, ups=4.46, wpb=3650.7, bsz=166, num_updates=39900, lr=0.000158312, gnorm=0.839, train_wall=22, gb_free=7.1, wall=9204
2021-03-10 23:20:13 | INFO | train_inner | epoch 037:    292 / 1103 loss=3.272, nll_loss=1.762, ppl=3.39, wps=15658.6, ups=4.45, wpb=3519.3, bsz=147.7, num_updates=40000, lr=0.000158114, gnorm=0.883, train_wall=22, gb_free=7, wall=9226
2021-03-10 23:20:35 | INFO | train_inner | epoch 037:    392 / 1103 loss=3.286, nll_loss=1.778, ppl=3.43, wps=15689.1, ups=4.47, wpb=3506.2, bsz=143.2, num_updates=40100, lr=0.000157917, gnorm=0.887, train_wall=22, gb_free=7.4, wall=9249
2021-03-10 23:20:58 | INFO | train_inner | epoch 037:    492 / 1103 loss=3.285, nll_loss=1.777, ppl=3.43, wps=16026.7, ups=4.39, wpb=3647.5, bsz=144.9, num_updates=40200, lr=0.00015772, gnorm=0.849, train_wall=23, gb_free=7, wall=9271
2021-03-10 23:21:21 | INFO | train_inner | epoch 037:    592 / 1103 loss=3.326, nll_loss=1.824, ppl=3.54, wps=15865.1, ups=4.46, wpb=3557.2, bsz=135.7, num_updates=40300, lr=0.000157524, gnorm=0.9, train_wall=22, gb_free=7.6, wall=9294
2021-03-10 23:21:43 | INFO | train_inner | epoch 037:    692 / 1103 loss=3.314, nll_loss=1.81, ppl=3.51, wps=15793.1, ups=4.47, wpb=3532, bsz=143.9, num_updates=40400, lr=0.000157329, gnorm=0.893, train_wall=22, gb_free=7.1, wall=9316
2021-03-10 23:22:05 | INFO | train_inner | epoch 037:    792 / 1103 loss=3.296, nll_loss=1.791, ppl=3.46, wps=15740.4, ups=4.46, wpb=3526.2, bsz=149.8, num_updates=40500, lr=0.000157135, gnorm=0.886, train_wall=22, gb_free=7, wall=9338
2021-03-10 23:22:28 | INFO | train_inner | epoch 037:    892 / 1103 loss=3.338, nll_loss=1.839, ppl=3.58, wps=15941, ups=4.49, wpb=3553.3, bsz=138.9, num_updates=40600, lr=0.000156941, gnorm=0.909, train_wall=22, gb_free=7, wall=9361
2021-03-10 23:22:50 | INFO | train_inner | epoch 037:    992 / 1103 loss=3.339, nll_loss=1.84, ppl=3.58, wps=15976.2, ups=4.41, wpb=3619.3, bsz=139.4, num_updates=40700, lr=0.000156748, gnorm=0.879, train_wall=23, gb_free=7, wall=9383
2021-03-10 23:23:13 | INFO | train_inner | epoch 037:   1092 / 1103 loss=3.349, nll_loss=1.851, ppl=3.61, wps=16012.5, ups=4.46, wpb=3588.1, bsz=143, num_updates=40800, lr=0.000156556, gnorm=0.898, train_wall=22, gb_free=6.7, wall=9406
2021-03-10 23:23:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-10 23:23:19 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 3.911 | nll_loss 2.359 | ppl 5.13 | wps 48196.2 | wpb 2873.1 | bsz 115.6 | num_updates 40811 | best_loss 3.91
2021-03-10 23:23:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 40811 updates
2021-03-10 23:23:19 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-10 23:23:21 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-10 23:23:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt (epoch 37 @ 40811 updates, score 3.911) (writing took 2.109595786780119 seconds)
2021-03-10 23:23:21 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2021-03-10 23:23:21 | INFO | train | epoch 037 | loss 3.304 | nll_loss 1.8 | ppl 3.48 | wps 15541 | ups 4.34 | wpb 3577.8 | bsz 145.3 | num_updates 40811 | lr 0.000156535 | gnorm 0.88 | train_wall 247 | gb_free 7.6 | wall 9414
2021-03-10 23:23:21 | INFO | fairseq.trainer | begin training epoch 38
2021-03-10 23:23:21 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-10 23:23:41 | INFO | train_inner | epoch 038:     89 / 1103 loss=3.252, nll_loss=1.742, ppl=3.34, wps=12627.5, ups=3.54, wpb=3566.1, bsz=158.2, num_updates=40900, lr=0.000156365, gnorm=0.857, train_wall=22, gb_free=7.2, wall=9434
2021-03-10 23:24:03 | INFO | train_inner | epoch 038:    189 / 1103 loss=3.245, nll_loss=1.732, ppl=3.32, wps=16048.4, ups=4.45, wpb=3609.7, bsz=151.5, num_updates=41000, lr=0.000156174, gnorm=0.852, train_wall=22, gb_free=7, wall=9457
2021-03-10 23:24:26 | INFO | train_inner | epoch 038:    289 / 1103 loss=3.287, nll_loss=1.778, ppl=3.43, wps=15996.9, ups=4.49, wpb=3560.6, bsz=136.6, num_updates=41100, lr=0.000155984, gnorm=0.89, train_wall=22, gb_free=6.7, wall=9479
2021-03-10 23:24:48 | INFO | train_inner | epoch 038:    389 / 1103 loss=3.279, nll_loss=1.771, ppl=3.41, wps=16297, ups=4.44, wpb=3671, bsz=152.3, num_updates=41200, lr=0.000155794, gnorm=0.859, train_wall=22, gb_free=7.3, wall=9501
2021-03-10 23:25:11 | INFO | train_inner | epoch 038:    489 / 1103 loss=3.323, nll_loss=1.82, ppl=3.53, wps=15968.2, ups=4.48, wpb=3568.1, bsz=136.6, num_updates=41300, lr=0.000155606, gnorm=0.894, train_wall=22, gb_free=7, wall=9524
2021-03-10 23:25:33 | INFO | train_inner | epoch 038:    589 / 1103 loss=3.276, nll_loss=1.766, ppl=3.4, wps=15609.2, ups=4.44, wpb=3513.4, bsz=145.5, num_updates=41400, lr=0.000155417, gnorm=0.894, train_wall=22, gb_free=7.4, wall=9546
2021-03-10 23:25:56 | INFO | train_inner | epoch 038:    689 / 1103 loss=3.321, nll_loss=1.818, ppl=3.53, wps=15961.3, ups=4.46, wpb=3578.5, bsz=136.2, num_updates=41500, lr=0.00015523, gnorm=0.894, train_wall=22, gb_free=7.1, wall=9569
2021-03-10 23:26:18 | INFO | train_inner | epoch 038:    789 / 1103 loss=3.285, nll_loss=1.779, ppl=3.43, wps=16109, ups=4.44, wpb=3631.7, bsz=157.9, num_updates=41600, lr=0.000155043, gnorm=0.877, train_wall=22, gb_free=6.8, wall=9591
2021-03-10 23:26:41 | INFO | train_inner | epoch 038:    889 / 1103 loss=3.32, nll_loss=1.818, ppl=3.53, wps=15826.7, ups=4.43, wpb=3574.3, bsz=141.8, num_updates=41700, lr=0.000154857, gnorm=0.885, train_wall=22, gb_free=7, wall=9614
2021-03-10 23:27:03 | INFO | train_inner | epoch 038:    989 / 1103 loss=3.336, nll_loss=1.836, ppl=3.57, wps=15811.7, ups=4.46, wpb=3548.9, bsz=137.1, num_updates=41800, lr=0.000154672, gnorm=0.924, train_wall=22, gb_free=7, wall=9636
2021-03-10 23:27:26 | INFO | train_inner | epoch 038:   1089 / 1103 loss=3.287, nll_loss=1.78, ppl=3.44, wps=15792.3, ups=4.45, wpb=3551.7, bsz=146.6, num_updates=41900, lr=0.000154487, gnorm=0.887, train_wall=22, gb_free=6.9, wall=9659
2021-03-10 23:27:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-10 23:27:32 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 3.925 | nll_loss 2.373 | ppl 5.18 | wps 48225.7 | wpb 2873.1 | bsz 115.6 | num_updates 41914 | best_loss 3.91
2021-03-10 23:27:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 41914 updates
2021-03-10 23:27:32 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-10 23:27:34 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-10 23:27:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt (epoch 38 @ 41914 updates, score 3.925) (writing took 2.0347891561686993 seconds)
2021-03-10 23:27:34 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2021-03-10 23:27:34 | INFO | train | epoch 038 | loss 3.292 | nll_loss 1.785 | ppl 3.45 | wps 15573.4 | ups 4.35 | wpb 3577.8 | bsz 145.3 | num_updates 41914 | lr 0.000154462 | gnorm 0.884 | train_wall 246 | gb_free 7.1 | wall 9668
2021-03-10 23:27:34 | INFO | fairseq.trainer | begin training epoch 39
2021-03-10 23:27:34 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-10 23:27:54 | INFO | train_inner | epoch 039:     86 / 1103 loss=3.238, nll_loss=1.723, ppl=3.3, wps=12437.5, ups=3.56, wpb=3496.9, bsz=149.4, num_updates=42000, lr=0.000154303, gnorm=0.88, train_wall=22, gb_free=7.6, wall=9687
2021-03-10 23:28:16 | INFO | train_inner | epoch 039:    186 / 1103 loss=3.247, nll_loss=1.733, ppl=3.32, wps=16005.2, ups=4.47, wpb=3583.5, bsz=145.1, num_updates=42100, lr=0.00015412, gnorm=0.87, train_wall=22, gb_free=7, wall=9709
2021-03-10 23:28:39 | INFO | train_inner | epoch 039:    286 / 1103 loss=3.257, nll_loss=1.744, ppl=3.35, wps=15873.7, ups=4.44, wpb=3576.4, bsz=137.2, num_updates=42200, lr=0.000153937, gnorm=0.885, train_wall=22, gb_free=7, wall=9732
2021-03-10 23:29:01 | INFO | train_inner | epoch 039:    386 / 1103 loss=3.218, nll_loss=1.702, ppl=3.25, wps=15681.8, ups=4.42, wpb=3545.6, bsz=162.2, num_updates=42300, lr=0.000153755, gnorm=0.862, train_wall=22, gb_free=7, wall=9754
2021-03-10 23:29:24 | INFO | train_inner | epoch 039:    486 / 1103 loss=3.271, nll_loss=1.76, ppl=3.39, wps=15895.7, ups=4.42, wpb=3593.9, bsz=144, num_updates=42400, lr=0.000153574, gnorm=0.875, train_wall=22, gb_free=7, wall=9777
2021-03-10 23:29:46 | INFO | train_inner | epoch 039:    586 / 1103 loss=3.28, nll_loss=1.774, ppl=3.42, wps=16471.6, ups=4.47, wpb=3682.1, bsz=164.7, num_updates=42500, lr=0.000153393, gnorm=0.858, train_wall=22, gb_free=7.2, wall=9799
2021-03-10 23:30:09 | INFO | train_inner | epoch 039:    686 / 1103 loss=3.285, nll_loss=1.777, ppl=3.43, wps=16108.5, ups=4.44, wpb=3630.6, bsz=139.1, num_updates=42600, lr=0.000153213, gnorm=0.879, train_wall=22, gb_free=7.1, wall=9822
2021-03-10 23:30:31 | INFO | train_inner | epoch 039:    786 / 1103 loss=3.314, nll_loss=1.812, ppl=3.51, wps=16340.5, ups=4.49, wpb=3638.8, bsz=152.8, num_updates=42700, lr=0.000153033, gnorm=0.889, train_wall=22, gb_free=6.4, wall=9844
2021-03-10 23:30:53 | INFO | train_inner | epoch 039:    886 / 1103 loss=3.331, nll_loss=1.828, ppl=3.55, wps=15927.9, ups=4.48, wpb=3559.2, bsz=132.3, num_updates=42800, lr=0.000152854, gnorm=0.908, train_wall=22, gb_free=7.1, wall=9866
2021-03-10 23:31:16 | INFO | train_inner | epoch 039:    986 / 1103 loss=3.348, nll_loss=1.848, ppl=3.6, wps=15855.5, ups=4.5, wpb=3519.5, bsz=125.4, num_updates=42900, lr=0.000152676, gnorm=0.94, train_wall=22, gb_free=7.1, wall=9889
2021-03-10 23:31:38 | INFO | train_inner | epoch 039:   1086 / 1103 loss=3.311, nll_loss=1.806, ppl=3.5, wps=15783.2, ups=4.43, wpb=3565.4, bsz=141.8, num_updates=43000, lr=0.000152499, gnorm=0.897, train_wall=22, gb_free=7.1, wall=9911
2021-03-10 23:31:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-10 23:31:46 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 3.943 | nll_loss 2.385 | ppl 5.22 | wps 48193.8 | wpb 2873.1 | bsz 115.6 | num_updates 43017 | best_loss 3.91
2021-03-10 23:31:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 43017 updates
2021-03-10 23:31:46 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-10 23:31:48 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-10 23:31:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt (epoch 39 @ 43017 updates, score 3.943) (writing took 2.0528496094048023 seconds)
2021-03-10 23:31:48 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2021-03-10 23:31:48 | INFO | train | epoch 039 | loss 3.281 | nll_loss 1.772 | ppl 3.42 | wps 15583.2 | ups 4.36 | wpb 3577.8 | bsz 145.3 | num_updates 43017 | lr 0.000152468 | gnorm 0.886 | train_wall 246 | gb_free 7 | wall 9921
2021-03-10 23:31:48 | INFO | fairseq.trainer | begin training epoch 40
2021-03-10 23:31:48 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-10 23:32:06 | INFO | train_inner | epoch 040:     83 / 1103 loss=3.235, nll_loss=1.718, ppl=3.29, wps=12356.5, ups=3.53, wpb=3496.8, bsz=138.3, num_updates=43100, lr=0.000152322, gnorm=0.888, train_wall=22, gb_free=6.9, wall=9940
2021-03-10 23:32:29 | INFO | train_inner | epoch 040:    183 / 1103 loss=3.228, nll_loss=1.71, ppl=3.27, wps=15774.2, ups=4.45, wpb=3545.1, bsz=135.8, num_updates=43200, lr=0.000152145, gnorm=0.88, train_wall=22, gb_free=7.5, wall=9962
2021-03-10 23:32:51 | INFO | train_inner | epoch 040:    283 / 1103 loss=3.27, nll_loss=1.759, ppl=3.38, wps=16172.6, ups=4.47, wpb=3621, bsz=138.2, num_updates=43300, lr=0.000151969, gnorm=0.873, train_wall=22, gb_free=7, wall=9984
2021-03-10 23:33:14 | INFO | train_inner | epoch 040:    383 / 1103 loss=3.255, nll_loss=1.74, ppl=3.34, wps=15698.4, ups=4.44, wpb=3535.6, bsz=137.8, num_updates=43400, lr=0.000151794, gnorm=0.899, train_wall=22, gb_free=6.9, wall=10007
2021-03-10 23:33:36 | INFO | train_inner | epoch 040:    483 / 1103 loss=3.254, nll_loss=1.741, ppl=3.34, wps=15837.3, ups=4.46, wpb=3550.3, bsz=145.2, num_updates=43500, lr=0.00015162, gnorm=0.892, train_wall=22, gb_free=7.1, wall=10029
2021-03-10 23:33:59 | INFO | train_inner | epoch 040:    583 / 1103 loss=3.261, nll_loss=1.749, ppl=3.36, wps=15790, ups=4.48, wpb=3522.8, bsz=145.1, num_updates=43600, lr=0.000151446, gnorm=0.927, train_wall=22, gb_free=7.2, wall=10052
2021-03-10 23:34:21 | INFO | train_inner | epoch 040:    683 / 1103 loss=3.284, nll_loss=1.775, ppl=3.42, wps=16050.5, ups=4.44, wpb=3617.8, bsz=143.6, num_updates=43700, lr=0.000151272, gnorm=0.892, train_wall=22, gb_free=7.6, wall=10074
2021-03-10 23:34:44 | INFO | train_inner | epoch 040:    783 / 1103 loss=3.283, nll_loss=1.776, ppl=3.42, wps=16032.1, ups=4.44, wpb=3610.5, bsz=152.4, num_updates=43800, lr=0.000151099, gnorm=0.891, train_wall=22, gb_free=6.9, wall=10097
2021-03-10 23:35:06 | INFO | train_inner | epoch 040:    883 / 1103 loss=3.314, nll_loss=1.811, ppl=3.51, wps=16047.4, ups=4.48, wpb=3582.9, bsz=142.6, num_updates=43900, lr=0.000150927, gnorm=0.901, train_wall=22, gb_free=7.2, wall=10119
2021-03-10 23:35:28 | INFO | train_inner | epoch 040:    983 / 1103 loss=3.277, nll_loss=1.772, ppl=3.41, wps=16117.8, ups=4.44, wpb=3630, bsz=170.6, num_updates=44000, lr=0.000150756, gnorm=0.866, train_wall=22, gb_free=6.9, wall=10142
2021-03-10 23:35:51 | INFO | train_inner | epoch 040:   1083 / 1103 loss=3.28, nll_loss=1.772, ppl=3.42, wps=15828.5, ups=4.44, wpb=3565.3, bsz=152.3, num_updates=44100, lr=0.000150585, gnorm=0.881, train_wall=22, gb_free=7, wall=10164
2021-03-10 23:35:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-10 23:35:59 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 3.92 | nll_loss 2.364 | ppl 5.15 | wps 48206.5 | wpb 2873.1 | bsz 115.6 | num_updates 44120 | best_loss 3.91
2021-03-10 23:35:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 44120 updates
2021-03-10 23:35:59 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-10 23:36:01 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-10 23:36:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt (epoch 40 @ 44120 updates, score 3.92) (writing took 2.043198984116316 seconds)
2021-03-10 23:36:01 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2021-03-10 23:36:01 | INFO | train | epoch 040 | loss 3.269 | nll_loss 1.759 | ppl 3.38 | wps 15559.5 | ups 4.35 | wpb 3577.8 | bsz 145.3 | num_updates 44120 | lr 0.000150551 | gnorm 0.889 | train_wall 246 | gb_free 6.8 | wall 10174
2021-03-10 23:36:01 | INFO | fairseq.trainer | begin training epoch 41
2021-03-10 23:36:01 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-10 23:36:19 | INFO | train_inner | epoch 041:     80 / 1103 loss=3.261, nll_loss=1.749, ppl=3.36, wps=12836.9, ups=3.51, wpb=3662.4, bsz=143.3, num_updates=44200, lr=0.000150414, gnorm=0.87, train_wall=22, gb_free=6.6, wall=10193
2021-03-10 23:36:42 | INFO | train_inner | epoch 041:    180 / 1103 loss=3.243, nll_loss=1.728, ppl=3.31, wps=15987, ups=4.48, wpb=3566.9, bsz=145.6, num_updates=44300, lr=0.000150244, gnorm=0.887, train_wall=22, gb_free=6.9, wall=10215
2021-03-10 23:37:04 | INFO | train_inner | epoch 041:    280 / 1103 loss=3.217, nll_loss=1.699, ppl=3.25, wps=15811.9, ups=4.46, wpb=3548.3, bsz=154.2, num_updates=44400, lr=0.000150075, gnorm=0.877, train_wall=22, gb_free=6.9, wall=10237
2021-03-10 23:37:27 | INFO | train_inner | epoch 041:    380 / 1103 loss=3.265, nll_loss=1.755, ppl=3.37, wps=16208.4, ups=4.48, wpb=3618.4, bsz=149.6, num_updates=44500, lr=0.000149906, gnorm=0.866, train_wall=22, gb_free=7.1, wall=10260
2021-03-10 23:37:49 | INFO | train_inner | epoch 041:    480 / 1103 loss=3.248, nll_loss=1.733, ppl=3.33, wps=15568, ups=4.5, wpb=3463.2, bsz=140.2, num_updates=44600, lr=0.000149738, gnorm=0.919, train_wall=22, gb_free=7.2, wall=10282
2021-03-10 23:38:11 | INFO | train_inner | epoch 041:    580 / 1103 loss=3.264, nll_loss=1.753, ppl=3.37, wps=16256, ups=4.42, wpb=3677.4, bsz=150, num_updates=44700, lr=0.000149571, gnorm=0.878, train_wall=23, gb_free=7, wall=10305
2021-03-10 23:38:34 | INFO | train_inner | epoch 041:    680 / 1103 loss=3.247, nll_loss=1.734, ppl=3.33, wps=15972, ups=4.43, wpb=3602.3, bsz=155.1, num_updates=44800, lr=0.000149404, gnorm=0.883, train_wall=22, gb_free=7.2, wall=10327
2021-03-10 23:38:56 | INFO | train_inner | epoch 041:    780 / 1103 loss=3.261, nll_loss=1.749, ppl=3.36, wps=15799.9, ups=4.46, wpb=3543.7, bsz=145.2, num_updates=44900, lr=0.000149237, gnorm=0.912, train_wall=22, gb_free=7.2, wall=10350
2021-03-10 23:39:19 | INFO | train_inner | epoch 041:    880 / 1103 loss=3.28, nll_loss=1.77, ppl=3.41, wps=15951.2, ups=4.46, wpb=3575.8, bsz=136.5, num_updates=45000, lr=0.000149071, gnorm=0.908, train_wall=22, gb_free=7.5, wall=10372
2021-03-10 23:39:41 | INFO | train_inner | epoch 041:    980 / 1103 loss=3.3, nll_loss=1.793, ppl=3.47, wps=15869.7, ups=4.44, wpb=3575.3, bsz=126.3, num_updates=45100, lr=0.000148906, gnorm=0.908, train_wall=22, gb_free=6.8, wall=10395
2021-03-10 23:40:04 | INFO | train_inner | epoch 041:   1080 / 1103 loss=3.272, nll_loss=1.762, ppl=3.39, wps=15837.6, ups=4.46, wpb=3550.8, bsz=149.8, num_updates=45200, lr=0.000148741, gnorm=0.91, train_wall=22, gb_free=6.9, wall=10417
2021-03-10 23:40:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-10 23:40:13 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 3.933 | nll_loss 2.375 | ppl 5.19 | wps 48195.9 | wpb 2873.1 | bsz 115.6 | num_updates 45223 | best_loss 3.91
2021-03-10 23:40:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 45223 updates
2021-03-10 23:40:13 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-10 23:40:15 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-10 23:40:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt (epoch 41 @ 45223 updates, score 3.933) (writing took 2.0460567511618137 seconds)
2021-03-10 23:40:15 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2021-03-10 23:40:15 | INFO | train | epoch 041 | loss 3.259 | nll_loss 1.747 | ppl 3.36 | wps 15569.3 | ups 4.35 | wpb 3577.8 | bsz 145.3 | num_updates 45223 | lr 0.000148703 | gnorm 0.893 | train_wall 246 | gb_free 7.1 | wall 10428
2021-03-10 23:40:15 | INFO | fairseq.trainer | begin training epoch 42
2021-03-10 23:40:15 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-10 23:40:32 | INFO | train_inner | epoch 042:     77 / 1103 loss=3.232, nll_loss=1.716, ppl=3.28, wps=12796, ups=3.53, wpb=3625.1, bsz=146.5, num_updates=45300, lr=0.000148577, gnorm=0.89, train_wall=22, gb_free=6.9, wall=10445
2021-03-10 23:40:55 | INFO | train_inner | epoch 042:    177 / 1103 loss=3.243, nll_loss=1.727, ppl=3.31, wps=16024.1, ups=4.45, wpb=3603.7, bsz=139.2, num_updates=45400, lr=0.000148413, gnorm=0.878, train_wall=22, gb_free=6.9, wall=10468
2021-03-10 23:41:17 | INFO | train_inner | epoch 042:    277 / 1103 loss=3.201, nll_loss=1.679, ppl=3.2, wps=15814.8, ups=4.45, wpb=3553.1, bsz=144.5, num_updates=45500, lr=0.00014825, gnorm=0.892, train_wall=22, gb_free=6.9, wall=10490
2021-03-10 23:41:39 | INFO | train_inner | epoch 042:    377 / 1103 loss=3.262, nll_loss=1.749, ppl=3.36, wps=15972.3, ups=4.47, wpb=3570.6, bsz=131.7, num_updates=45600, lr=0.000148087, gnorm=0.896, train_wall=22, gb_free=7.2, wall=10513
2021-03-10 23:42:02 | INFO | train_inner | epoch 042:    477 / 1103 loss=3.254, nll_loss=1.741, ppl=3.34, wps=16006.3, ups=4.48, wpb=3570.6, bsz=145.9, num_updates=45700, lr=0.000147925, gnorm=0.901, train_wall=22, gb_free=7, wall=10535
2021-03-10 23:42:24 | INFO | train_inner | epoch 042:    577 / 1103 loss=3.264, nll_loss=1.751, ppl=3.37, wps=15862.8, ups=4.48, wpb=3540.5, bsz=135.1, num_updates=45800, lr=0.000147764, gnorm=0.905, train_wall=22, gb_free=7.1, wall=10557
2021-03-10 23:42:47 | INFO | train_inner | epoch 042:    677 / 1103 loss=3.242, nll_loss=1.729, ppl=3.31, wps=15996.4, ups=4.44, wpb=3600.3, bsz=156.6, num_updates=45900, lr=0.000147602, gnorm=0.881, train_wall=22, gb_free=6.9, wall=10580
2021-03-10 23:43:09 | INFO | train_inner | epoch 042:    777 / 1103 loss=3.245, nll_loss=1.731, ppl=3.32, wps=15935.8, ups=4.42, wpb=3604, bsz=147, num_updates=46000, lr=0.000147442, gnorm=0.89, train_wall=23, gb_free=6.9, wall=10602
2021-03-10 23:43:32 | INFO | train_inner | epoch 042:    877 / 1103 loss=3.25, nll_loss=1.738, ppl=3.34, wps=15676.4, ups=4.46, wpb=3512.3, bsz=155.8, num_updates=46100, lr=0.000147282, gnorm=0.911, train_wall=22, gb_free=7.8, wall=10625
2021-03-10 23:43:54 | INFO | train_inner | epoch 042:    977 / 1103 loss=3.265, nll_loss=1.755, ppl=3.38, wps=15872.6, ups=4.49, wpb=3536.3, bsz=148.8, num_updates=46200, lr=0.000147122, gnorm=0.917, train_wall=22, gb_free=7.7, wall=10647
2021-03-10 23:44:16 | INFO | train_inner | epoch 042:   1077 / 1103 loss=3.279, nll_loss=1.77, ppl=3.41, wps=16025.3, ups=4.42, wpb=3625.7, bsz=140.3, num_updates=46300, lr=0.000146964, gnorm=0.907, train_wall=23, gb_free=7.1, wall=10670
2021-03-10 23:44:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-10 23:44:26 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 3.93 | nll_loss 2.374 | ppl 5.18 | wps 48232 | wpb 2873.1 | bsz 115.6 | num_updates 46326 | best_loss 3.91
2021-03-10 23:44:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 46326 updates
2021-03-10 23:44:26 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-10 23:44:28 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-10 23:44:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt (epoch 42 @ 46326 updates, score 3.93) (writing took 2.134742960333824 seconds)
2021-03-10 23:44:28 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2021-03-10 23:44:28 | INFO | train | epoch 042 | loss 3.248 | nll_loss 1.734 | ppl 3.33 | wps 15561.6 | ups 4.35 | wpb 3577.8 | bsz 145.3 | num_updates 46326 | lr 0.000146922 | gnorm 0.896 | train_wall 246 | gb_free 7.1 | wall 10681
2021-03-10 23:44:28 | INFO | fairseq.trainer | begin training epoch 43
2021-03-10 23:44:28 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-10 23:44:44 | INFO | train_inner | epoch 043:     74 / 1103 loss=3.209, nll_loss=1.692, ppl=3.23, wps=13500.2, ups=3.68, wpb=3666.3, bsz=163.1, num_updates=46400, lr=0.000146805, gnorm=0.864, train_wall=21, gb_free=7.2, wall=10697
2021-03-10 23:45:04 | INFO | train_inner | epoch 043:    174 / 1103 loss=3.198, nll_loss=1.678, ppl=3.2, wps=17377.9, ups=4.93, wpb=3527.7, bsz=164.4, num_updates=46500, lr=0.000146647, gnorm=0.884, train_wall=20, gb_free=7.1, wall=10717
2021-03-10 23:45:24 | INFO | train_inner | epoch 043:    274 / 1103 loss=3.238, nll_loss=1.721, ppl=3.3, wps=17521.7, ups=4.87, wpb=3597.2, bsz=131.4, num_updates=46600, lr=0.00014649, gnorm=0.903, train_wall=20, gb_free=7.1, wall=10738
2021-03-10 23:45:45 | INFO | train_inner | epoch 043:    374 / 1103 loss=3.249, nll_loss=1.732, ppl=3.32, wps=17431, ups=4.85, wpb=3592.6, bsz=129.9, num_updates=46700, lr=0.000146333, gnorm=0.915, train_wall=21, gb_free=6.5, wall=10758
2021-03-10 23:46:06 | INFO | train_inner | epoch 043:    474 / 1103 loss=3.243, nll_loss=1.727, ppl=3.31, wps=17286.8, ups=4.88, wpb=3542.2, bsz=134.3, num_updates=46800, lr=0.000146176, gnorm=0.91, train_wall=20, gb_free=7.4, wall=10779
2021-03-10 23:46:26 | INFO | train_inner | epoch 043:    574 / 1103 loss=3.211, nll_loss=1.693, ppl=3.23, wps=17505.8, ups=4.83, wpb=3624.9, bsz=156.8, num_updates=46900, lr=0.00014602, gnorm=0.877, train_wall=21, gb_free=7.1, wall=10799
2021-03-10 23:46:47 | INFO | train_inner | epoch 043:    674 / 1103 loss=3.244, nll_loss=1.728, ppl=3.31, wps=17126.2, ups=4.86, wpb=3522.8, bsz=142.2, num_updates=47000, lr=0.000145865, gnorm=0.921, train_wall=20, gb_free=7, wall=10820
2021-03-10 23:47:08 | INFO | train_inner | epoch 043:    774 / 1103 loss=3.233, nll_loss=1.718, ppl=3.29, wps=16832.4, ups=4.65, wpb=3619.6, bsz=155.6, num_updates=47100, lr=0.00014571, gnorm=0.889, train_wall=21, gb_free=7.1, wall=10842
2021-03-10 23:47:31 | INFO | train_inner | epoch 043:    874 / 1103 loss=3.248, nll_loss=1.735, ppl=3.33, wps=15977.1, ups=4.43, wpb=3609.6, bsz=143.6, num_updates=47200, lr=0.000145556, gnorm=0.886, train_wall=22, gb_free=7.7, wall=10864
2021-03-10 23:47:53 | INFO | train_inner | epoch 043:    974 / 1103 loss=3.271, nll_loss=1.76, ppl=3.39, wps=15884.5, ups=4.47, wpb=3557.6, bsz=141.4, num_updates=47300, lr=0.000145402, gnorm=0.921, train_wall=22, gb_free=7, wall=10886
2021-03-10 23:48:16 | INFO | train_inner | epoch 043:   1074 / 1103 loss=3.253, nll_loss=1.74, ppl=3.34, wps=15808.5, ups=4.44, wpb=3557, bsz=145.3, num_updates=47400, lr=0.000145248, gnorm=0.9, train_wall=22, gb_free=7.2, wall=10909
2021-03-10 23:48:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-10 23:48:26 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 3.943 | nll_loss 2.387 | ppl 5.23 | wps 48222.1 | wpb 2873.1 | bsz 115.6 | num_updates 47429 | best_loss 3.91
2021-03-10 23:48:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 47429 updates
2021-03-10 23:48:26 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-10 23:48:28 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-10 23:48:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt (epoch 43 @ 47429 updates, score 3.943) (writing took 2.394577607512474 seconds)
2021-03-10 23:48:28 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2021-03-10 23:48:28 | INFO | train | epoch 043 | loss 3.237 | nll_loss 1.721 | ppl 3.3 | wps 16436.3 | ups 4.59 | wpb 3577.8 | bsz 145.3 | num_updates 47429 | lr 0.000145204 | gnorm 0.899 | train_wall 233 | gb_free 6.9 | wall 10922
2021-03-10 23:48:28 | INFO | fairseq.trainer | begin training epoch 44
2021-03-10 23:48:28 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-10 23:48:45 | INFO | train_inner | epoch 044:     71 / 1103 loss=3.204, nll_loss=1.683, ppl=3.21, wps=12382.2, ups=3.46, wpb=3576.8, bsz=143.8, num_updates=47500, lr=0.000145095, gnorm=0.89, train_wall=22, gb_free=7.1, wall=10938
2021-03-10 23:49:07 | INFO | train_inner | epoch 044:    171 / 1103 loss=3.215, nll_loss=1.693, ppl=3.23, wps=15959, ups=4.48, wpb=3566.2, bsz=132, num_updates=47600, lr=0.000144943, gnorm=0.906, train_wall=22, gb_free=6.9, wall=10960
2021-03-10 23:49:29 | INFO | train_inner | epoch 044:    271 / 1103 loss=3.21, nll_loss=1.688, ppl=3.22, wps=15960.2, ups=4.49, wpb=3558.2, bsz=138.5, num_updates=47700, lr=0.000144791, gnorm=0.916, train_wall=22, gb_free=6.8, wall=10983
2021-03-10 23:49:52 | INFO | train_inner | epoch 044:    371 / 1103 loss=3.147, nll_loss=1.622, ppl=3.08, wps=15978.7, ups=4.41, wpb=3622.3, bsz=187.9, num_updates=47800, lr=0.000144639, gnorm=0.869, train_wall=23, gb_free=7.1, wall=11005
2021-03-10 23:50:15 | INFO | train_inner | epoch 044:    471 / 1103 loss=3.226, nll_loss=1.708, ppl=3.27, wps=16082.9, ups=4.43, wpb=3632.9, bsz=140, num_updates=47900, lr=0.000144488, gnorm=0.887, train_wall=22, gb_free=6.9, wall=11028
2021-03-10 23:50:37 | INFO | train_inner | epoch 044:    571 / 1103 loss=3.232, nll_loss=1.717, ppl=3.29, wps=16046.5, ups=4.5, wpb=3562.6, bsz=151.1, num_updates=48000, lr=0.000144338, gnorm=0.903, train_wall=22, gb_free=7.7, wall=11050
2021-03-10 23:50:59 | INFO | train_inner | epoch 044:    671 / 1103 loss=3.267, nll_loss=1.756, ppl=3.38, wps=16255.4, ups=4.46, wpb=3642.5, bsz=146.6, num_updates=48100, lr=0.000144187, gnorm=0.892, train_wall=22, gb_free=7.4, wall=11072
2021-03-10 23:51:22 | INFO | train_inner | epoch 044:    771 / 1103 loss=3.245, nll_loss=1.729, ppl=3.31, wps=16011.1, ups=4.47, wpb=3584.9, bsz=136.5, num_updates=48200, lr=0.000144038, gnorm=0.902, train_wall=22, gb_free=6.9, wall=11095
2021-03-10 23:51:44 | INFO | train_inner | epoch 044:    871 / 1103 loss=3.222, nll_loss=1.705, ppl=3.26, wps=15779.5, ups=4.5, wpb=3510.1, bsz=147.3, num_updates=48300, lr=0.000143889, gnorm=0.918, train_wall=22, gb_free=7.1, wall=11117
2021-03-10 23:52:07 | INFO | train_inner | epoch 044:    971 / 1103 loss=3.256, nll_loss=1.742, ppl=3.34, wps=15873.6, ups=4.41, wpb=3596.8, bsz=137.4, num_updates=48400, lr=0.00014374, gnorm=0.908, train_wall=23, gb_free=7.1, wall=11140
2021-03-10 23:52:29 | INFO | train_inner | epoch 044:   1071 / 1103 loss=3.29, nll_loss=1.779, ppl=3.43, wps=15651.9, ups=4.53, wpb=3458.6, bsz=125.2, num_updates=48500, lr=0.000143592, gnorm=0.963, train_wall=22, gb_free=7.1, wall=11162
2021-03-10 23:52:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-10 23:52:40 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 3.944 | nll_loss 2.388 | ppl 5.24 | wps 48223.5 | wpb 2873.1 | bsz 115.6 | num_updates 48532 | best_loss 3.91
2021-03-10 23:52:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 48532 updates
2021-03-10 23:52:40 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-10 23:52:42 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-10 23:52:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt (epoch 44 @ 48532 updates, score 3.944) (writing took 2.215151432901621 seconds)
2021-03-10 23:52:42 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2021-03-10 23:52:42 | INFO | train | epoch 044 | loss 3.227 | nll_loss 1.71 | ppl 3.27 | wps 15568.8 | ups 4.35 | wpb 3577.8 | bsz 145.3 | num_updates 48532 | lr 0.000143544 | gnorm 0.904 | train_wall 246 | gb_free 6.9 | wall 11175
2021-03-10 23:52:42 | INFO | fairseq.trainer | begin training epoch 45
2021-03-10 23:52:42 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-10 23:52:57 | INFO | train_inner | epoch 045:     68 / 1103 loss=3.19, nll_loss=1.669, ppl=3.18, wps=12650.7, ups=3.47, wpb=3640.8, bsz=161.8, num_updates=48600, lr=0.000143444, gnorm=0.868, train_wall=22, gb_free=7, wall=11191
2021-03-10 23:53:20 | INFO | train_inner | epoch 045:    168 / 1103 loss=3.203, nll_loss=1.682, ppl=3.21, wps=16028, ups=4.48, wpb=3581.5, bsz=144.6, num_updates=48700, lr=0.000143296, gnorm=0.915, train_wall=22, gb_free=7.1, wall=11213
2021-03-10 23:53:42 | INFO | train_inner | epoch 045:    268 / 1103 loss=3.179, nll_loss=1.655, ppl=3.15, wps=15981.1, ups=4.42, wpb=3611.6, bsz=159.2, num_updates=48800, lr=0.00014315, gnorm=0.899, train_wall=22, gb_free=7, wall=11236
2021-03-10 23:54:04 | INFO | train_inner | epoch 045:    368 / 1103 loss=3.202, nll_loss=1.678, ppl=3.2, wps=15630.8, ups=4.54, wpb=3440, bsz=135.4, num_updates=48900, lr=0.000143003, gnorm=0.944, train_wall=22, gb_free=7.3, wall=11258
2021-03-10 23:54:27 | INFO | train_inner | epoch 045:    468 / 1103 loss=3.199, nll_loss=1.677, ppl=3.2, wps=16105.8, ups=4.47, wpb=3602.7, bsz=152.5, num_updates=49000, lr=0.000142857, gnorm=0.886, train_wall=22, gb_free=7.1, wall=11280
2021-03-10 23:54:49 | INFO | train_inner | epoch 045:    568 / 1103 loss=3.205, nll_loss=1.685, ppl=3.22, wps=16019.2, ups=4.43, wpb=3619.3, bsz=152.1, num_updates=49100, lr=0.000142712, gnorm=0.902, train_wall=22, gb_free=7, wall=11302
2021-03-10 23:55:12 | INFO | train_inner | epoch 045:    668 / 1103 loss=3.237, nll_loss=1.722, ppl=3.3, wps=16291.7, ups=4.49, wpb=3630.8, bsz=150.3, num_updates=49200, lr=0.000142566, gnorm=0.894, train_wall=22, gb_free=7.1, wall=11325
2021-03-10 23:55:34 | INFO | train_inner | epoch 045:    768 / 1103 loss=3.223, nll_loss=1.704, ppl=3.26, wps=15897.2, ups=4.44, wpb=3578.5, bsz=147, num_updates=49300, lr=0.000142422, gnorm=0.904, train_wall=22, gb_free=7.2, wall=11347
2021-03-10 23:55:57 | INFO | train_inner | epoch 045:    868 / 1103 loss=3.273, nll_loss=1.761, ppl=3.39, wps=16010.1, ups=4.47, wpb=3585.4, bsz=128.3, num_updates=49400, lr=0.000142278, gnorm=0.927, train_wall=22, gb_free=7.4, wall=11370
2021-03-10 23:56:19 | INFO | train_inner | epoch 045:    968 / 1103 loss=3.247, nll_loss=1.732, ppl=3.32, wps=15831.9, ups=4.48, wpb=3537.5, bsz=138.6, num_updates=49500, lr=0.000142134, gnorm=0.928, train_wall=22, gb_free=6.5, wall=11392
2021-03-10 23:56:42 | INFO | train_inner | epoch 045:   1068 / 1103 loss=3.237, nll_loss=1.721, ppl=3.3, wps=15951, ups=4.42, wpb=3609.2, bsz=144.6, num_updates=49600, lr=0.00014199, gnorm=0.9, train_wall=23, gb_free=7.1, wall=11415
2021-03-10 23:56:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-10 23:56:53 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 3.936 | nll_loss 2.378 | ppl 5.2 | wps 48204.5 | wpb 2873.1 | bsz 115.6 | num_updates 49635 | best_loss 3.91
2021-03-10 23:56:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 49635 updates
2021-03-10 23:56:53 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-10 23:56:55 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-10 23:56:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt (epoch 45 @ 49635 updates, score 3.936) (writing took 2.081395745277405 seconds)
2021-03-10 23:56:55 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2021-03-10 23:56:55 | INFO | train | epoch 045 | loss 3.219 | nll_loss 1.7 | ppl 3.25 | wps 15590.4 | ups 4.36 | wpb 3577.8 | bsz 145.3 | num_updates 49635 | lr 0.00014194 | gnorm 0.909 | train_wall 246 | gb_free 7.4 | wall 11428
2021-03-10 23:56:55 | INFO | fairseq.trainer | begin training epoch 46
2021-03-10 23:56:55 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-10 23:57:10 | INFO | train_inner | epoch 046:     65 / 1103 loss=3.177, nll_loss=1.651, ppl=3.14, wps=12401, ups=3.52, wpb=3524.2, bsz=144.9, num_updates=49700, lr=0.000141848, gnorm=0.905, train_wall=22, gb_free=7.1, wall=11443
2021-03-10 23:57:32 | INFO | train_inner | epoch 046:    165 / 1103 loss=3.175, nll_loss=1.647, ppl=3.13, wps=15553.9, ups=4.54, wpb=3428.9, bsz=135.4, num_updates=49800, lr=0.000141705, gnorm=0.939, train_wall=22, gb_free=6.9, wall=11465
2021-03-10 23:57:54 | INFO | train_inner | epoch 046:    265 / 1103 loss=3.192, nll_loss=1.667, ppl=3.18, wps=15762, ups=4.45, wpb=3539.7, bsz=137.8, num_updates=49900, lr=0.000141563, gnorm=0.908, train_wall=22, gb_free=6.8, wall=11488
2021-03-10 23:58:17 | INFO | train_inner | epoch 046:    365 / 1103 loss=3.21, nll_loss=1.688, ppl=3.22, wps=15653, ups=4.46, wpb=3511, bsz=133.8, num_updates=50000, lr=0.000141421, gnorm=0.938, train_wall=22, gb_free=7.2, wall=11510
2021-03-10 23:58:39 | INFO | train_inner | epoch 046:    465 / 1103 loss=3.2, nll_loss=1.678, ppl=3.2, wps=16056.8, ups=4.42, wpb=3633.6, bsz=141.3, num_updates=50100, lr=0.00014128, gnorm=0.897, train_wall=23, gb_free=7, wall=11533
2021-03-10 23:59:02 | INFO | train_inner | epoch 046:    565 / 1103 loss=3.229, nll_loss=1.712, ppl=3.28, wps=16112.3, ups=4.46, wpb=3610.6, bsz=143.3, num_updates=50200, lr=0.000141139, gnorm=0.9, train_wall=22, gb_free=7.2, wall=11555
2021-03-10 23:59:25 | INFO | train_inner | epoch 046:    665 / 1103 loss=3.189, nll_loss=1.667, ppl=3.17, wps=16029.1, ups=4.4, wpb=3639.4, bsz=153, num_updates=50300, lr=0.000140999, gnorm=0.898, train_wall=23, gb_free=6.9, wall=11578
2021-03-10 23:59:47 | INFO | train_inner | epoch 046:    765 / 1103 loss=3.227, nll_loss=1.711, ppl=3.27, wps=16008.6, ups=4.46, wpb=3587.7, bsz=145, num_updates=50400, lr=0.000140859, gnorm=0.903, train_wall=22, gb_free=6.9, wall=11600
2021-03-11 00:00:09 | INFO | train_inner | epoch 046:    865 / 1103 loss=3.185, nll_loss=1.664, ppl=3.17, wps=15897.4, ups=4.46, wpb=3566.9, bsz=172.6, num_updates=50500, lr=0.00014072, gnorm=0.905, train_wall=22, gb_free=7.4, wall=11623
2021-03-11 00:00:32 | INFO | train_inner | epoch 046:    965 / 1103 loss=3.216, nll_loss=1.698, ppl=3.24, wps=16197.7, ups=4.41, wpb=3672.1, bsz=151.6, num_updates=50600, lr=0.00014058, gnorm=0.894, train_wall=23, gb_free=7.2, wall=11645
2021-03-11 00:00:55 | INFO | train_inner | epoch 046:   1065 / 1103 loss=3.269, nll_loss=1.757, ppl=3.38, wps=15928.7, ups=4.47, wpb=3567.2, bsz=135.8, num_updates=50700, lr=0.000140442, gnorm=0.937, train_wall=22, gb_free=7.2, wall=11668
2021-03-11 00:01:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-11 00:01:07 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 3.931 | nll_loss 2.377 | ppl 5.2 | wps 48195.7 | wpb 2873.1 | bsz 115.6 | num_updates 50738 | best_loss 3.91
2021-03-11 00:01:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 50738 updates
2021-03-11 00:01:07 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 00:01:09 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 00:01:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt (epoch 46 @ 50738 updates, score 3.931) (writing took 2.0852617993950844 seconds)
2021-03-11 00:01:09 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2021-03-11 00:01:09 | INFO | train | epoch 046 | loss 3.208 | nll_loss 1.687 | ppl 3.22 | wps 15551.1 | ups 4.35 | wpb 3577.8 | bsz 145.3 | num_updates 50738 | lr 0.000140389 | gnorm 0.91 | train_wall 246 | gb_free 6.9 | wall 11682
2021-03-11 00:01:09 | INFO | fairseq.trainer | begin training epoch 47
2021-03-11 00:01:09 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-11 00:01:23 | INFO | train_inner | epoch 047:     62 / 1103 loss=3.209, nll_loss=1.687, ppl=3.22, wps=12651.1, ups=3.53, wpb=3580.2, bsz=141.9, num_updates=50800, lr=0.000140303, gnorm=0.915, train_wall=22, gb_free=6.6, wall=11696
2021-03-11 00:01:45 | INFO | train_inner | epoch 047:    162 / 1103 loss=3.192, nll_loss=1.666, ppl=3.17, wps=15942.2, ups=4.56, wpb=3498.3, bsz=133.3, num_updates=50900, lr=0.000140165, gnorm=0.937, train_wall=22, gb_free=6.9, wall=11718
2021-03-11 00:02:07 | INFO | train_inner | epoch 047:    262 / 1103 loss=3.197, nll_loss=1.674, ppl=3.19, wps=15981.8, ups=4.45, wpb=3591.4, bsz=146.6, num_updates=51000, lr=0.000140028, gnorm=0.907, train_wall=22, gb_free=7.3, wall=11740
2021-03-11 00:02:30 | INFO | train_inner | epoch 047:    362 / 1103 loss=3.174, nll_loss=1.648, ppl=3.13, wps=16123.5, ups=4.41, wpb=3653.9, bsz=151.7, num_updates=51100, lr=0.000139891, gnorm=0.898, train_wall=23, gb_free=7.2, wall=11763
2021-03-11 00:02:53 | INFO | train_inner | epoch 047:    462 / 1103 loss=3.156, nll_loss=1.627, ppl=3.09, wps=15764.5, ups=4.42, wpb=3566.8, bsz=153.9, num_updates=51200, lr=0.000139754, gnorm=0.894, train_wall=23, gb_free=7.4, wall=11786
2021-03-11 00:03:15 | INFO | train_inner | epoch 047:    562 / 1103 loss=3.226, nll_loss=1.707, ppl=3.26, wps=15802.3, ups=4.46, wpb=3544.5, bsz=138.1, num_updates=51300, lr=0.000139618, gnorm=0.93, train_wall=22, gb_free=6.9, wall=11808
2021-03-11 00:03:37 | INFO | train_inner | epoch 047:    662 / 1103 loss=3.2, nll_loss=1.679, ppl=3.2, wps=16232.4, ups=4.51, wpb=3597.7, bsz=153, num_updates=51400, lr=0.000139482, gnorm=0.905, train_wall=22, gb_free=6.8, wall=11830
2021-03-11 00:04:00 | INFO | train_inner | epoch 047:    762 / 1103 loss=3.202, nll_loss=1.68, ppl=3.2, wps=16008.1, ups=4.44, wpb=3605.8, bsz=141.8, num_updates=51500, lr=0.000139347, gnorm=0.903, train_wall=22, gb_free=6.9, wall=11853
2021-03-11 00:04:22 | INFO | train_inner | epoch 047:    862 / 1103 loss=3.209, nll_loss=1.689, ppl=3.22, wps=15777.3, ups=4.48, wpb=3523.5, bsz=144.2, num_updates=51600, lr=0.000139212, gnorm=0.929, train_wall=22, gb_free=7, wall=11875
2021-03-11 00:04:44 | INFO | train_inner | epoch 047:    962 / 1103 loss=3.205, nll_loss=1.685, ppl=3.22, wps=15979.6, ups=4.48, wpb=3564.5, bsz=151, num_updates=51700, lr=0.000139077, gnorm=0.915, train_wall=22, gb_free=7.1, wall=11897
2021-03-11 00:05:07 | INFO | train_inner | epoch 047:   1062 / 1103 loss=3.226, nll_loss=1.708, ppl=3.27, wps=16025.9, ups=4.48, wpb=3577.3, bsz=134.4, num_updates=51800, lr=0.000138943, gnorm=0.921, train_wall=22, gb_free=7, wall=11920
2021-03-11 00:05:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-11 00:05:20 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 3.932 | nll_loss 2.378 | ppl 5.2 | wps 48189.4 | wpb 2873.1 | bsz 115.6 | num_updates 51841 | best_loss 3.91
2021-03-11 00:05:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 51841 updates
2021-03-11 00:05:20 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 00:05:22 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 00:05:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt (epoch 47 @ 51841 updates, score 3.932) (writing took 2.1811452992260456 seconds)
2021-03-11 00:05:22 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2021-03-11 00:05:22 | INFO | train | epoch 047 | loss 3.199 | nll_loss 1.677 | ppl 3.2 | wps 15599.3 | ups 4.36 | wpb 3577.8 | bsz 145.3 | num_updates 51841 | lr 0.000138888 | gnorm 0.912 | train_wall 246 | gb_free 7.2 | wall 11935
2021-03-11 00:05:22 | INFO | fairseq.trainer | begin training epoch 48
2021-03-11 00:05:22 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-11 00:05:35 | INFO | train_inner | epoch 048:     59 / 1103 loss=3.193, nll_loss=1.671, ppl=3.18, wps=12678.4, ups=3.51, wpb=3615.6, bsz=145.1, num_updates=51900, lr=0.000138809, gnorm=0.89, train_wall=22, gb_free=7, wall=11948
2021-03-11 00:05:58 | INFO | train_inner | epoch 048:    159 / 1103 loss=3.18, nll_loss=1.654, ppl=3.15, wps=16237.2, ups=4.47, wpb=3635.6, bsz=151.1, num_updates=52000, lr=0.000138675, gnorm=0.918, train_wall=22, gb_free=6.9, wall=11971
2021-03-11 00:06:20 | INFO | train_inner | epoch 048:    259 / 1103 loss=3.162, nll_loss=1.632, ppl=3.1, wps=15861.9, ups=4.43, wpb=3583.7, bsz=139.2, num_updates=52100, lr=0.000138542, gnorm=0.913, train_wall=22, gb_free=6.9, wall=11993
2021-03-11 00:06:43 | INFO | train_inner | epoch 048:    359 / 1103 loss=3.156, nll_loss=1.626, ppl=3.09, wps=15668.5, ups=4.44, wpb=3530.6, bsz=135.7, num_updates=52200, lr=0.000138409, gnorm=0.918, train_wall=22, gb_free=6.6, wall=12016
2021-03-11 00:07:05 | INFO | train_inner | epoch 048:    459 / 1103 loss=3.202, nll_loss=1.679, ppl=3.2, wps=15872, ups=4.43, wpb=3580.8, bsz=134, num_updates=52300, lr=0.000138277, gnorm=0.921, train_wall=22, gb_free=6.8, wall=12038
2021-03-11 00:07:28 | INFO | train_inner | epoch 048:    559 / 1103 loss=3.181, nll_loss=1.657, ppl=3.15, wps=16063.1, ups=4.41, wpb=3640.6, bsz=151.5, num_updates=52400, lr=0.000138145, gnorm=0.895, train_wall=23, gb_free=6.7, wall=12061
2021-03-11 00:07:50 | INFO | train_inner | epoch 048:    659 / 1103 loss=3.204, nll_loss=1.683, ppl=3.21, wps=16115.1, ups=4.45, wpb=3624.7, bsz=148.5, num_updates=52500, lr=0.000138013, gnorm=0.907, train_wall=22, gb_free=7, wall=12083
2021-03-11 00:08:13 | INFO | train_inner | epoch 048:    759 / 1103 loss=3.223, nll_loss=1.702, ppl=3.25, wps=15737.1, ups=4.47, wpb=3524.2, bsz=128.7, num_updates=52600, lr=0.000137882, gnorm=0.941, train_wall=22, gb_free=7.1, wall=12106
2021-03-11 00:08:35 | INFO | train_inner | epoch 048:    859 / 1103 loss=3.201, nll_loss=1.678, ppl=3.2, wps=15687.1, ups=4.48, wpb=3499.4, bsz=144.9, num_updates=52700, lr=0.000137751, gnorm=0.968, train_wall=22, gb_free=6.8, wall=12128
2021-03-11 00:08:57 | INFO | train_inner | epoch 048:    959 / 1103 loss=3.2, nll_loss=1.68, ppl=3.2, wps=16010.1, ups=4.48, wpb=3571.8, bsz=156.7, num_updates=52800, lr=0.00013762, gnorm=0.909, train_wall=22, gb_free=7, wall=12151
2021-03-11 00:09:20 | INFO | train_inner | epoch 048:   1059 / 1103 loss=3.197, nll_loss=1.676, ppl=3.2, wps=15921.3, ups=4.42, wpb=3605.5, bsz=162.2, num_updates=52900, lr=0.00013749, gnorm=0.907, train_wall=23, gb_free=6.8, wall=12173
2021-03-11 00:09:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-11 00:09:34 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 3.941 | nll_loss 2.382 | ppl 5.21 | wps 48176.8 | wpb 2873.1 | bsz 115.6 | num_updates 52944 | best_loss 3.91
2021-03-11 00:09:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 52944 updates
2021-03-11 00:09:34 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 00:09:36 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 00:09:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt (epoch 48 @ 52944 updates, score 3.941) (writing took 2.0426352694630623 seconds)
2021-03-11 00:09:36 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2021-03-11 00:09:36 | INFO | train | epoch 048 | loss 3.189 | nll_loss 1.666 | ppl 3.17 | wps 15537.3 | ups 4.34 | wpb 3577.8 | bsz 145.3 | num_updates 52944 | lr 0.000137433 | gnorm 0.918 | train_wall 247 | gb_free 7 | wall 12189
2021-03-11 00:09:36 | INFO | fairseq.trainer | begin training epoch 49
2021-03-11 00:09:36 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-11 00:09:49 | INFO | train_inner | epoch 049:     56 / 1103 loss=3.167, nll_loss=1.642, ppl=3.12, wps=12683, ups=3.5, wpb=3627.3, bsz=157, num_updates=53000, lr=0.000137361, gnorm=0.884, train_wall=22, gb_free=6.9, wall=12202
2021-03-11 00:10:11 | INFO | train_inner | epoch 049:    156 / 1103 loss=3.156, nll_loss=1.626, ppl=3.09, wps=16090.4, ups=4.43, wpb=3634.8, bsz=139, num_updates=53100, lr=0.000137231, gnorm=0.897, train_wall=22, gb_free=6.9, wall=12224
2021-03-11 00:10:34 | INFO | train_inner | epoch 049:    256 / 1103 loss=3.159, nll_loss=1.63, ppl=3.1, wps=15923.7, ups=4.45, wpb=3575.2, bsz=146.5, num_updates=53200, lr=0.000137102, gnorm=0.909, train_wall=22, gb_free=7.2, wall=12247
2021-03-11 00:10:56 | INFO | train_inner | epoch 049:    356 / 1103 loss=3.137, nll_loss=1.605, ppl=3.04, wps=15683.9, ups=4.44, wpb=3530.6, bsz=150.3, num_updates=53300, lr=0.000136973, gnorm=0.91, train_wall=22, gb_free=7, wall=12269
2021-03-11 00:11:19 | INFO | train_inner | epoch 049:    456 / 1103 loss=3.198, nll_loss=1.673, ppl=3.19, wps=15891.5, ups=4.42, wpb=3597.4, bsz=137.6, num_updates=53400, lr=0.000136845, gnorm=0.922, train_wall=23, gb_free=6.9, wall=12292
2021-03-11 00:11:41 | INFO | train_inner | epoch 049:    556 / 1103 loss=3.159, nll_loss=1.631, ppl=3.1, wps=15839.5, ups=4.47, wpb=3546.4, bsz=147.5, num_updates=53500, lr=0.000136717, gnorm=0.909, train_wall=22, gb_free=6.9, wall=12314
2021-03-11 00:12:02 | INFO | train_inner | epoch 049:    656 / 1103 loss=3.158, nll_loss=1.63, ppl=3.09, wps=16772.5, ups=4.77, wpb=3519.3, bsz=152.6, num_updates=53600, lr=0.00013659, gnorm=0.934, train_wall=21, gb_free=6.9, wall=12335
2021-03-11 00:12:23 | INFO | train_inner | epoch 049:    756 / 1103 loss=3.218, nll_loss=1.697, ppl=3.24, wps=17288.6, ups=4.86, wpb=3558.8, bsz=129.8, num_updates=53700, lr=0.000136462, gnorm=0.953, train_wall=20, gb_free=6.9, wall=12356
2021-03-11 00:12:43 | INFO | train_inner | epoch 049:    856 / 1103 loss=3.207, nll_loss=1.686, ppl=3.22, wps=17430.7, ups=4.83, wpb=3608.1, bsz=145.5, num_updates=53800, lr=0.000136335, gnorm=0.917, train_wall=21, gb_free=7.9, wall=12377
2021-03-11 00:13:04 | INFO | train_inner | epoch 049:    956 / 1103 loss=3.221, nll_loss=1.702, ppl=3.25, wps=17347.6, ups=4.86, wpb=3571.6, bsz=140.9, num_updates=53900, lr=0.000136209, gnorm=0.938, train_wall=20, gb_free=7, wall=12397
2021-03-11 00:13:24 | INFO | train_inner | epoch 049:   1056 / 1103 loss=3.22, nll_loss=1.7, ppl=3.25, wps=17383.2, ups=4.9, wpb=3546, bsz=138.5, num_updates=54000, lr=0.000136083, gnorm=0.953, train_wall=20, gb_free=6.9, wall=12418
2021-03-11 00:13:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-11 00:13:38 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 3.934 | nll_loss 2.378 | ppl 5.2 | wps 48055.6 | wpb 2873.1 | bsz 115.6 | num_updates 54047 | best_loss 3.91
2021-03-11 00:13:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 54047 updates
2021-03-11 00:13:38 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 00:13:40 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 00:13:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt (epoch 49 @ 54047 updates, score 3.934) (writing took 2.134369295090437 seconds)
2021-03-11 00:13:40 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2021-03-11 00:13:40 | INFO | train | epoch 049 | loss 3.182 | nll_loss 1.657 | ppl 3.15 | wps 16150.3 | ups 4.51 | wpb 3577.8 | bsz 145.3 | num_updates 54047 | lr 0.000136024 | gnorm 0.922 | train_wall 237 | gb_free 7.2 | wall 12433
2021-03-11 00:13:40 | INFO | fairseq.trainer | begin training epoch 50
2021-03-11 00:13:40 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-11 00:13:51 | INFO | train_inner | epoch 050:     53 / 1103 loss=3.168, nll_loss=1.643, ppl=3.12, wps=13399.5, ups=3.74, wpb=3586.7, bsz=159, num_updates=54100, lr=0.000135957, gnorm=0.931, train_wall=21, gb_free=6.9, wall=12444
2021-03-11 00:14:12 | INFO | train_inner | epoch 050:    153 / 1103 loss=3.139, nll_loss=1.607, ppl=3.05, wps=17478.9, ups=4.81, wpb=3636.2, bsz=147.4, num_updates=54200, lr=0.000135831, gnorm=0.889, train_wall=21, gb_free=7.1, wall=12465
2021-03-11 00:14:33 | INFO | train_inner | epoch 050:    253 / 1103 loss=3.145, nll_loss=1.616, ppl=3.07, wps=17464.3, ups=4.85, wpb=3602.3, bsz=162.8, num_updates=54300, lr=0.000135706, gnorm=0.906, train_wall=21, gb_free=7.5, wall=12486
2021-03-11 00:14:53 | INFO | train_inner | epoch 050:    353 / 1103 loss=3.183, nll_loss=1.654, ppl=3.15, wps=17145.4, ups=4.95, wpb=3461.3, bsz=118.6, num_updates=54400, lr=0.000135582, gnorm=0.988, train_wall=20, gb_free=7.2, wall=12506
2021-03-11 00:15:13 | INFO | train_inner | epoch 050:    453 / 1103 loss=3.198, nll_loss=1.674, ppl=3.19, wps=17685.8, ups=4.84, wpb=3652, bsz=136.9, num_updates=54500, lr=0.000135457, gnorm=0.908, train_wall=21, gb_free=7, wall=12527
2021-03-11 00:15:34 | INFO | train_inner | epoch 050:    553 / 1103 loss=3.168, nll_loss=1.64, ppl=3.12, wps=17276.7, ups=4.8, wpb=3598.2, bsz=142.6, num_updates=54600, lr=0.000135333, gnorm=0.918, train_wall=21, gb_free=6.6, wall=12547
2021-03-11 00:15:55 | INFO | train_inner | epoch 050:    653 / 1103 loss=3.166, nll_loss=1.639, ppl=3.11, wps=17352, ups=4.84, wpb=3585, bsz=152.5, num_updates=54700, lr=0.000135209, gnorm=0.92, train_wall=21, gb_free=6.9, wall=12568
2021-03-11 00:16:16 | INFO | train_inner | epoch 050:    753 / 1103 loss=3.176, nll_loss=1.651, ppl=3.14, wps=17327.6, ups=4.86, wpb=3566.7, bsz=155.9, num_updates=54800, lr=0.000135086, gnorm=0.918, train_wall=20, gb_free=7, wall=12589
2021-03-11 00:16:36 | INFO | train_inner | epoch 050:    853 / 1103 loss=3.182, nll_loss=1.658, ppl=3.16, wps=17385.8, ups=4.84, wpb=3590.8, bsz=149.4, num_updates=54900, lr=0.000134963, gnorm=0.916, train_wall=21, gb_free=6.9, wall=12609
2021-03-11 00:16:57 | INFO | train_inner | epoch 050:    953 / 1103 loss=3.185, nll_loss=1.663, ppl=3.17, wps=17561.5, ups=4.83, wpb=3634, bsz=161.8, num_updates=55000, lr=0.00013484, gnorm=0.916, train_wall=21, gb_free=6.8, wall=12630
2021-03-11 00:17:18 | INFO | train_inner | epoch 050:   1053 / 1103 loss=3.206, nll_loss=1.683, ppl=3.21, wps=16816.3, ups=4.82, wpb=3489.9, bsz=133.8, num_updates=55100, lr=0.000134718, gnorm=0.949, train_wall=21, gb_free=7.2, wall=12651
2021-03-11 00:17:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-11 00:17:33 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 3.95 | nll_loss 2.395 | ppl 5.26 | wps 48118.1 | wpb 2873.1 | bsz 115.6 | num_updates 55150 | best_loss 3.91
2021-03-11 00:17:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 55150 updates
2021-03-11 00:17:33 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 00:17:35 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 00:17:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt (epoch 50 @ 55150 updates, score 3.95) (writing took 2.1663844250142574 seconds)
2021-03-11 00:17:35 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2021-03-11 00:17:35 | INFO | train | epoch 050 | loss 3.173 | nll_loss 1.647 | ppl 3.13 | wps 16812.6 | ups 4.7 | wpb 3577.8 | bsz 145.3 | num_updates 55150 | lr 0.000134656 | gnorm 0.923 | train_wall 227 | gb_free 6.9 | wall 12668
2021-03-11 00:17:35 | INFO | fairseq.trainer | begin training epoch 51
2021-03-11 00:17:35 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-11 00:17:46 | INFO | train_inner | epoch 051:     50 / 1103 loss=3.168, nll_loss=1.641, ppl=3.12, wps=12552.4, ups=3.51, wpb=3580.2, bsz=145, num_updates=55200, lr=0.000134595, gnorm=0.919, train_wall=22, gb_free=7, wall=12679
2021-03-11 00:18:09 | INFO | train_inner | epoch 051:    150 / 1103 loss=3.109, nll_loss=1.572, ppl=2.97, wps=15811.7, ups=4.47, wpb=3535.6, bsz=152.2, num_updates=55300, lr=0.000134474, gnorm=0.898, train_wall=22, gb_free=6.8, wall=12702
2021-03-11 00:18:31 | INFO | train_inner | epoch 051:    250 / 1103 loss=3.118, nll_loss=1.583, ppl=3, wps=15876.3, ups=4.47, wpb=3554.4, bsz=150.6, num_updates=55400, lr=0.000134352, gnorm=0.918, train_wall=22, gb_free=7.1, wall=12724
2021-03-11 00:18:53 | INFO | train_inner | epoch 051:    350 / 1103 loss=3.162, nll_loss=1.634, ppl=3.1, wps=16161.6, ups=4.47, wpb=3617.3, bsz=149, num_updates=55500, lr=0.000134231, gnorm=0.912, train_wall=22, gb_free=6.9, wall=12746
2021-03-11 00:19:16 | INFO | train_inner | epoch 051:    450 / 1103 loss=3.184, nll_loss=1.658, ppl=3.16, wps=16041, ups=4.45, wpb=3604.7, bsz=134.3, num_updates=55600, lr=0.00013411, gnorm=0.934, train_wall=22, gb_free=6.9, wall=12769
2021-03-11 00:19:38 | INFO | train_inner | epoch 051:    550 / 1103 loss=3.155, nll_loss=1.625, ppl=3.08, wps=15712.6, ups=4.45, wpb=3534.5, bsz=142.3, num_updates=55700, lr=0.00013399, gnorm=0.92, train_wall=22, gb_free=7, wall=12791
2021-03-11 00:20:01 | INFO | train_inner | epoch 051:    650 / 1103 loss=3.198, nll_loss=1.676, ppl=3.2, wps=15982.4, ups=4.48, wpb=3566.3, bsz=150.9, num_updates=55800, lr=0.00013387, gnorm=0.945, train_wall=22, gb_free=7, wall=12814
2021-03-11 00:20:23 | INFO | train_inner | epoch 051:    750 / 1103 loss=3.166, nll_loss=1.636, ppl=3.11, wps=15864.8, ups=4.41, wpb=3601.5, bsz=136.4, num_updates=55900, lr=0.00013375, gnorm=0.924, train_wall=23, gb_free=7, wall=12836
2021-03-11 00:20:46 | INFO | train_inner | epoch 051:    850 / 1103 loss=3.194, nll_loss=1.671, ppl=3.19, wps=15962.4, ups=4.46, wpb=3581.7, bsz=143.1, num_updates=56000, lr=0.000133631, gnorm=0.942, train_wall=22, gb_free=6.9, wall=12859
2021-03-11 00:21:08 | INFO | train_inner | epoch 051:    950 / 1103 loss=3.195, nll_loss=1.672, ppl=3.19, wps=15922.4, ups=4.45, wpb=3578.5, bsz=145.8, num_updates=56100, lr=0.000133511, gnorm=0.935, train_wall=22, gb_free=7.1, wall=12881
2021-03-11 00:21:31 | INFO | train_inner | epoch 051:   1050 / 1103 loss=3.164, nll_loss=1.637, ppl=3.11, wps=15838.9, ups=4.41, wpb=3589.1, bsz=147, num_updates=56200, lr=0.000133393, gnorm=0.919, train_wall=23, gb_free=6.8, wall=12904
2021-03-11 00:21:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-11 00:21:47 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 3.954 | nll_loss 2.397 | ppl 5.27 | wps 48211.3 | wpb 2873.1 | bsz 115.6 | num_updates 56253 | best_loss 3.91
2021-03-11 00:21:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 56253 updates
2021-03-11 00:21:47 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 00:21:49 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 00:21:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt (epoch 51 @ 56253 updates, score 3.954) (writing took 2.3085732460021973 seconds)
2021-03-11 00:21:49 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2021-03-11 00:21:49 | INFO | train | epoch 051 | loss 3.164 | nll_loss 1.636 | ppl 3.11 | wps 15528.4 | ups 4.34 | wpb 3577.8 | bsz 145.3 | num_updates 56253 | lr 0.00013333 | gnorm 0.924 | train_wall 247 | gb_free 6.9 | wall 12922
2021-03-11 00:21:49 | INFO | fairseq.trainer | begin training epoch 52
2021-03-11 00:21:49 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-11 00:22:00 | INFO | train_inner | epoch 052:     47 / 1103 loss=3.155, nll_loss=1.624, ppl=3.08, wps=12518.6, ups=3.47, wpb=3610.6, bsz=140.6, num_updates=56300, lr=0.000133274, gnorm=0.904, train_wall=22, gb_free=7, wall=12933
2021-03-11 00:22:22 | INFO | train_inner | epoch 052:    147 / 1103 loss=3.119, nll_loss=1.583, ppl=3, wps=15785.7, ups=4.44, wpb=3559, bsz=142.1, num_updates=56400, lr=0.000133156, gnorm=0.931, train_wall=22, gb_free=7.1, wall=12955
2021-03-11 00:22:45 | INFO | train_inner | epoch 052:    247 / 1103 loss=3.125, nll_loss=1.59, ppl=3.01, wps=15862.4, ups=4.47, wpb=3546.4, bsz=141.4, num_updates=56500, lr=0.000133038, gnorm=0.918, train_wall=22, gb_free=6.9, wall=12978
2021-03-11 00:23:07 | INFO | train_inner | epoch 052:    347 / 1103 loss=3.14, nll_loss=1.608, ppl=3.05, wps=16047, ups=4.47, wpb=3593.7, bsz=146.6, num_updates=56600, lr=0.00013292, gnorm=0.917, train_wall=22, gb_free=7, wall=13000
2021-03-11 00:23:29 | INFO | train_inner | epoch 052:    447 / 1103 loss=3.138, nll_loss=1.606, ppl=3.04, wps=15958.2, ups=4.45, wpb=3586.7, bsz=149.4, num_updates=56700, lr=0.000132803, gnorm=0.917, train_wall=22, gb_free=6.9, wall=13023
2021-03-11 00:23:52 | INFO | train_inner | epoch 052:    547 / 1103 loss=3.169, nll_loss=1.639, ppl=3.11, wps=15806, ups=4.49, wpb=3516.5, bsz=124.4, num_updates=56800, lr=0.000132686, gnorm=0.964, train_wall=22, gb_free=7, wall=13045
2021-03-11 00:24:14 | INFO | train_inner | epoch 052:    647 / 1103 loss=3.164, nll_loss=1.638, ppl=3.11, wps=15985.6, ups=4.4, wpb=3634.2, bsz=151.4, num_updates=56900, lr=0.00013257, gnorm=0.914, train_wall=23, gb_free=6.9, wall=13068
2021-03-11 00:24:37 | INFO | train_inner | epoch 052:    747 / 1103 loss=3.211, nll_loss=1.689, ppl=3.22, wps=15948.6, ups=4.47, wpb=3571.5, bsz=134.3, num_updates=57000, lr=0.000132453, gnorm=0.957, train_wall=22, gb_free=6.9, wall=13090
2021-03-11 00:24:59 | INFO | train_inner | epoch 052:    847 / 1103 loss=3.156, nll_loss=1.628, ppl=3.09, wps=15895.4, ups=4.49, wpb=3541.9, bsz=152.2, num_updates=57100, lr=0.000132337, gnorm=0.934, train_wall=22, gb_free=7.2, wall=13112
2021-03-11 00:25:22 | INFO | train_inner | epoch 052:    947 / 1103 loss=3.162, nll_loss=1.635, ppl=3.11, wps=15854.1, ups=4.45, wpb=3562.5, bsz=158.5, num_updates=57200, lr=0.000132221, gnorm=0.935, train_wall=22, gb_free=7.4, wall=13135
2021-03-11 00:25:44 | INFO | train_inner | epoch 052:   1047 / 1103 loss=3.177, nll_loss=1.652, ppl=3.14, wps=15900.8, ups=4.41, wpb=3603.8, bsz=147.5, num_updates=57300, lr=0.000132106, gnorm=0.918, train_wall=23, gb_free=6.9, wall=13157
2021-03-11 00:25:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-11 00:26:01 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 3.95 | nll_loss 2.394 | ppl 5.26 | wps 48191.8 | wpb 2873.1 | bsz 115.6 | num_updates 57356 | best_loss 3.91
2021-03-11 00:26:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 57356 updates
2021-03-11 00:26:01 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 00:26:03 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 00:26:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt (epoch 52 @ 57356 updates, score 3.95) (writing took 2.1354785561561584 seconds)
2021-03-11 00:26:03 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2021-03-11 00:26:03 | INFO | train | epoch 052 | loss 3.156 | nll_loss 1.626 | ppl 3.09 | wps 15551.7 | ups 4.35 | wpb 3577.8 | bsz 145.3 | num_updates 57356 | lr 0.000132042 | gnorm 0.927 | train_wall 246 | gb_free 6.9 | wall 13176
2021-03-11 00:26:03 | INFO | fairseq.trainer | begin training epoch 53
2021-03-11 00:26:03 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-11 00:26:13 | INFO | train_inner | epoch 053:     44 / 1103 loss=3.154, nll_loss=1.625, ppl=3.08, wps=12655.9, ups=3.51, wpb=3606.3, bsz=147.2, num_updates=57400, lr=0.000131991, gnorm=0.913, train_wall=22, gb_free=6.9, wall=13186
2021-03-11 00:26:36 | INFO | train_inner | epoch 053:    144 / 1103 loss=3.131, nll_loss=1.597, ppl=3.03, wps=16168.1, ups=4.4, wpb=3676.9, bsz=144.5, num_updates=57500, lr=0.000131876, gnorm=0.9, train_wall=23, gb_free=7, wall=13209
2021-03-11 00:26:58 | INFO | train_inner | epoch 053:    244 / 1103 loss=3.125, nll_loss=1.592, ppl=3.01, wps=16294.9, ups=4.44, wpb=3666.8, bsz=154.4, num_updates=57600, lr=0.000131762, gnorm=0.908, train_wall=22, gb_free=7.3, wall=13231
2021-03-11 00:27:20 | INFO | train_inner | epoch 053:    344 / 1103 loss=3.161, nll_loss=1.631, ppl=3.1, wps=15929.8, ups=4.48, wpb=3559.3, bsz=131.4, num_updates=57700, lr=0.000131647, gnorm=0.944, train_wall=22, gb_free=6.5, wall=13253
2021-03-11 00:27:43 | INFO | train_inner | epoch 053:    444 / 1103 loss=3.131, nll_loss=1.597, ppl=3.03, wps=15655.4, ups=4.46, wpb=3507.5, bsz=146.8, num_updates=57800, lr=0.000131533, gnorm=0.937, train_wall=22, gb_free=7.3, wall=13276
2021-03-11 00:28:05 | INFO | train_inner | epoch 053:    544 / 1103 loss=3.157, nll_loss=1.627, ppl=3.09, wps=15999.7, ups=4.48, wpb=3571.2, bsz=139.8, num_updates=57900, lr=0.00013142, gnorm=0.938, train_wall=22, gb_free=6.9, wall=13298
2021-03-11 00:28:28 | INFO | train_inner | epoch 053:    644 / 1103 loss=3.131, nll_loss=1.597, ppl=3.03, wps=15694.8, ups=4.45, wpb=3525.8, bsz=150, num_updates=58000, lr=0.000131306, gnorm=0.929, train_wall=22, gb_free=7, wall=13321
2021-03-11 00:28:50 | INFO | train_inner | epoch 053:    744 / 1103 loss=3.167, nll_loss=1.64, ppl=3.12, wps=15978.7, ups=4.44, wpb=3597.9, bsz=153, num_updates=58100, lr=0.000131193, gnorm=0.936, train_wall=22, gb_free=6.9, wall=13343
2021-03-11 00:29:12 | INFO | train_inner | epoch 053:    844 / 1103 loss=3.161, nll_loss=1.631, ppl=3.1, wps=16071.7, ups=4.46, wpb=3602.5, bsz=138.2, num_updates=58200, lr=0.000131081, gnorm=0.936, train_wall=22, gb_free=6.9, wall=13366
2021-03-11 00:29:35 | INFO | train_inner | epoch 053:    944 / 1103 loss=3.155, nll_loss=1.625, ppl=3.08, wps=15963.4, ups=4.45, wpb=3590.8, bsz=145.8, num_updates=58300, lr=0.000130968, gnorm=0.933, train_wall=22, gb_free=6.9, wall=13388
2021-03-11 00:29:57 | INFO | train_inner | epoch 053:   1044 / 1103 loss=3.171, nll_loss=1.645, ppl=3.13, wps=15864.7, ups=4.52, wpb=3512.2, bsz=146.2, num_updates=58400, lr=0.000130856, gnorm=0.968, train_wall=22, gb_free=7.2, wall=13410
2021-03-11 00:30:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-11 00:30:14 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 3.954 | nll_loss 2.396 | ppl 5.26 | wps 48183.4 | wpb 2873.1 | bsz 115.6 | num_updates 58459 | best_loss 3.91
2021-03-11 00:30:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 58459 updates
2021-03-11 00:30:14 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 00:30:16 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 00:30:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt (epoch 53 @ 58459 updates, score 3.954) (writing took 2.014250200241804 seconds)
2021-03-11 00:30:16 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2021-03-11 00:30:16 | INFO | train | epoch 053 | loss 3.149 | nll_loss 1.618 | ppl 3.07 | wps 15584.8 | ups 4.36 | wpb 3577.8 | bsz 145.3 | num_updates 58459 | lr 0.00013079 | gnorm 0.933 | train_wall 246 | gb_free 6.8 | wall 13429
2021-03-11 00:30:16 | INFO | fairseq.trainer | begin training epoch 54
2021-03-11 00:30:16 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-11 00:30:25 | INFO | train_inner | epoch 054:     41 / 1103 loss=3.152, nll_loss=1.62, ppl=3.07, wps=12459.3, ups=3.55, wpb=3510.7, bsz=134.2, num_updates=58500, lr=0.000130744, gnorm=0.943, train_wall=22, gb_free=7, wall=13438
2021-03-11 00:30:48 | INFO | train_inner | epoch 054:    141 / 1103 loss=3.088, nll_loss=1.546, ppl=2.92, wps=15657.8, ups=4.47, wpb=3502, bsz=140, num_updates=58600, lr=0.000130632, gnorm=0.92, train_wall=22, gb_free=6.9, wall=13461
2021-03-11 00:31:10 | INFO | train_inner | epoch 054:    241 / 1103 loss=3.1, nll_loss=1.564, ppl=2.96, wps=16134.4, ups=4.42, wpb=3650.8, bsz=165, num_updates=58700, lr=0.000130521, gnorm=0.912, train_wall=23, gb_free=6.9, wall=13483
2021-03-11 00:31:33 | INFO | train_inner | epoch 054:    341 / 1103 loss=3.119, nll_loss=1.585, ppl=3, wps=16105.9, ups=4.4, wpb=3661.6, bsz=155.4, num_updates=58800, lr=0.00013041, gnorm=0.923, train_wall=23, gb_free=6.7, wall=13506
2021-03-11 00:31:56 | INFO | train_inner | epoch 054:    441 / 1103 loss=3.117, nll_loss=1.581, ppl=2.99, wps=15806.5, ups=4.45, wpb=3553.9, bsz=150.3, num_updates=58900, lr=0.000130299, gnorm=0.929, train_wall=22, gb_free=7.3, wall=13529
2021-03-11 00:32:18 | INFO | train_inner | epoch 054:    541 / 1103 loss=3.177, nll_loss=1.649, ppl=3.14, wps=15945.2, ups=4.44, wpb=3589.8, bsz=131.8, num_updates=59000, lr=0.000130189, gnorm=0.948, train_wall=22, gb_free=7, wall=13551
2021-03-11 00:32:40 | INFO | train_inner | epoch 054:    641 / 1103 loss=3.139, nll_loss=1.607, ppl=3.05, wps=16045.1, ups=4.45, wpb=3604.9, bsz=151, num_updates=59100, lr=0.000130079, gnorm=0.921, train_wall=22, gb_free=6.9, wall=13574
2021-03-11 00:33:03 | INFO | train_inner | epoch 054:    741 / 1103 loss=3.138, nll_loss=1.606, ppl=3.04, wps=16110.4, ups=4.46, wpb=3612.2, bsz=154.1, num_updates=59200, lr=0.000129969, gnorm=0.927, train_wall=22, gb_free=7.5, wall=13596
2021-03-11 00:33:25 | INFO | train_inner | epoch 054:    841 / 1103 loss=3.187, nll_loss=1.66, ppl=3.16, wps=15921.4, ups=4.5, wpb=3538.6, bsz=126, num_updates=59300, lr=0.000129859, gnorm=0.957, train_wall=22, gb_free=6.4, wall=13618
2021-03-11 00:33:47 | INFO | train_inner | epoch 054:    941 / 1103 loss=3.177, nll_loss=1.65, ppl=3.14, wps=15848.3, ups=4.47, wpb=3544.7, bsz=135.9, num_updates=59400, lr=0.00012975, gnorm=0.96, train_wall=22, gb_free=7.5, wall=13641
2021-03-11 00:34:10 | INFO | train_inner | epoch 054:   1041 / 1103 loss=3.157, nll_loss=1.629, ppl=3.09, wps=16082.7, ups=4.44, wpb=3624.6, bsz=160.6, num_updates=59500, lr=0.000129641, gnorm=0.926, train_wall=22, gb_free=7.1, wall=13663
2021-03-11 00:34:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-11 00:34:28 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 3.965 | nll_loss 2.405 | ppl 5.3 | wps 48198.3 | wpb 2873.1 | bsz 115.6 | num_updates 59562 | best_loss 3.91
2021-03-11 00:34:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 59562 updates
2021-03-11 00:34:28 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 00:34:30 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 00:34:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt (epoch 54 @ 59562 updates, score 3.965) (writing took 2.0704017244279385 seconds)
2021-03-11 00:34:30 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2021-03-11 00:34:30 | INFO | train | epoch 054 | loss 3.14 | nll_loss 1.608 | ppl 3.05 | wps 15557.8 | ups 4.35 | wpb 3577.8 | bsz 145.3 | num_updates 59562 | lr 0.000129573 | gnorm 0.934 | train_wall 246 | gb_free 7 | wall 13683
2021-03-11 00:34:30 | INFO | fairseq.trainer | begin training epoch 55
2021-03-11 00:34:30 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-11 00:34:38 | INFO | train_inner | epoch 055:     38 / 1103 loss=3.127, nll_loss=1.592, ppl=3.02, wps=12386.1, ups=3.53, wpb=3508.9, bsz=146.2, num_updates=59600, lr=0.000129532, gnorm=0.944, train_wall=22, gb_free=7.2, wall=13692
2021-03-11 00:35:01 | INFO | train_inner | epoch 055:    138 / 1103 loss=3.086, nll_loss=1.545, ppl=2.92, wps=16127.6, ups=4.43, wpb=3641.7, bsz=154.6, num_updates=59700, lr=0.000129423, gnorm=0.898, train_wall=22, gb_free=6.8, wall=13714
2021-03-11 00:35:23 | INFO | train_inner | epoch 055:    238 / 1103 loss=3.115, nll_loss=1.577, ppl=2.98, wps=15828.6, ups=4.47, wpb=3544, bsz=129.7, num_updates=59800, lr=0.000129315, gnorm=0.964, train_wall=22, gb_free=7, wall=13736
2021-03-11 00:35:46 | INFO | train_inner | epoch 055:    338 / 1103 loss=3.1, nll_loss=1.56, ppl=2.95, wps=15910.1, ups=4.4, wpb=3618.1, bsz=148.6, num_updates=59900, lr=0.000129207, gnorm=0.911, train_wall=23, gb_free=6.8, wall=13759
2021-03-11 00:36:09 | INFO | train_inner | epoch 055:    438 / 1103 loss=3.121, nll_loss=1.586, ppl=3, wps=15913.4, ups=4.45, wpb=3575.5, bsz=145.7, num_updates=60000, lr=0.000129099, gnorm=0.934, train_wall=22, gb_free=7.1, wall=13782
2021-03-11 00:36:31 | INFO | train_inner | epoch 055:    538 / 1103 loss=3.142, nll_loss=1.606, ppl=3.04, wps=15693.7, ups=4.46, wpb=3522.1, bsz=125.4, num_updates=60100, lr=0.000128992, gnorm=0.958, train_wall=22, gb_free=7.3, wall=13804
2021-03-11 00:36:54 | INFO | train_inner | epoch 055:    638 / 1103 loss=3.138, nll_loss=1.605, ppl=3.04, wps=15980.9, ups=4.42, wpb=3614.5, bsz=137.8, num_updates=60200, lr=0.000128885, gnorm=0.922, train_wall=23, gb_free=6.9, wall=13827
2021-03-11 00:37:16 | INFO | train_inner | epoch 055:    738 / 1103 loss=3.118, nll_loss=1.586, ppl=3, wps=15957.9, ups=4.43, wpb=3599.9, bsz=167.4, num_updates=60300, lr=0.000128778, gnorm=0.944, train_wall=22, gb_free=6.9, wall=13849
2021-03-11 00:37:38 | INFO | train_inner | epoch 055:    838 / 1103 loss=3.19, nll_loss=1.666, ppl=3.17, wps=16223.1, ups=4.5, wpb=3603, bsz=140.8, num_updates=60400, lr=0.000128671, gnorm=0.97, train_wall=22, gb_free=6.8, wall=13872
2021-03-11 00:38:01 | INFO | train_inner | epoch 055:    938 / 1103 loss=3.125, nll_loss=1.593, ppl=3.02, wps=15847.3, ups=4.41, wpb=3590.4, bsz=163.8, num_updates=60500, lr=0.000128565, gnorm=0.925, train_wall=23, gb_free=6.7, wall=13894
2021-03-11 00:38:23 | INFO | train_inner | epoch 055:   1038 / 1103 loss=3.184, nll_loss=1.658, ppl=3.16, wps=15850.7, ups=4.5, wpb=3519.7, bsz=139.5, num_updates=60600, lr=0.000128459, gnorm=0.964, train_wall=22, gb_free=6.9, wall=13916
2021-03-11 00:38:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-11 00:38:41 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 3.949 | nll_loss 2.396 | ppl 5.26 | wps 48176.4 | wpb 2873.1 | bsz 115.6 | num_updates 60665 | best_loss 3.91
2021-03-11 00:38:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 55 @ 60665 updates
2021-03-11 00:38:41 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 00:38:43 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 00:38:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt (epoch 55 @ 60665 updates, score 3.949) (writing took 2.04968399181962 seconds)
2021-03-11 00:38:43 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2021-03-11 00:38:43 | INFO | train | epoch 055 | loss 3.133 | nll_loss 1.6 | ppl 3.03 | wps 15553.7 | ups 4.35 | wpb 3577.8 | bsz 145.3 | num_updates 60665 | lr 0.00012839 | gnorm 0.94 | train_wall 246 | gb_free 7 | wall 13936
2021-03-11 00:38:43 | INFO | fairseq.trainer | begin training epoch 56
2021-03-11 00:38:43 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-11 00:38:51 | INFO | train_inner | epoch 056:     35 / 1103 loss=3.157, nll_loss=1.628, ppl=3.09, wps=12678.8, ups=3.55, wpb=3570, bsz=140.2, num_updates=60700, lr=0.000128353, gnorm=0.945, train_wall=22, gb_free=6.9, wall=13945
2021-03-11 00:39:14 | INFO | train_inner | epoch 056:    135 / 1103 loss=3.055, nll_loss=1.51, ppl=2.85, wps=15892.2, ups=4.42, wpb=3592.3, bsz=156.1, num_updates=60800, lr=0.000128247, gnorm=0.906, train_wall=22, gb_free=6.7, wall=13967
2021-03-11 00:39:36 | INFO | train_inner | epoch 056:    235 / 1103 loss=3.111, nll_loss=1.574, ppl=2.98, wps=15933.3, ups=4.49, wpb=3545.4, bsz=145.7, num_updates=60900, lr=0.000128142, gnorm=0.928, train_wall=22, gb_free=7, wall=13989
2021-03-11 00:39:59 | INFO | train_inner | epoch 056:    335 / 1103 loss=3.115, nll_loss=1.578, ppl=2.98, wps=15941.1, ups=4.45, wpb=3578.7, bsz=139, num_updates=61000, lr=0.000128037, gnorm=0.938, train_wall=22, gb_free=7.2, wall=14012
2021-03-11 00:40:21 | INFO | train_inner | epoch 056:    435 / 1103 loss=3.141, nll_loss=1.607, ppl=3.05, wps=15966.5, ups=4.45, wpb=3589.5, bsz=136.2, num_updates=61100, lr=0.000127932, gnorm=0.959, train_wall=22, gb_free=7, wall=14034
2021-03-11 00:40:44 | INFO | train_inner | epoch 056:    535 / 1103 loss=3.135, nll_loss=1.602, ppl=3.04, wps=16009.2, ups=4.45, wpb=3597.4, bsz=143.3, num_updates=61200, lr=0.000127827, gnorm=0.943, train_wall=22, gb_free=6.9, wall=14057
2021-03-11 00:41:06 | INFO | train_inner | epoch 056:    635 / 1103 loss=3.127, nll_loss=1.592, ppl=3.02, wps=15787.3, ups=4.43, wpb=3560.9, bsz=151.8, num_updates=61300, lr=0.000127723, gnorm=0.939, train_wall=22, gb_free=7.1, wall=14079
2021-03-11 00:41:29 | INFO | train_inner | epoch 056:    735 / 1103 loss=3.143, nll_loss=1.61, ppl=3.05, wps=15859.4, ups=4.46, wpb=3554.6, bsz=134.7, num_updates=61400, lr=0.000127619, gnorm=0.971, train_wall=22, gb_free=7.2, wall=14102
2021-03-11 00:41:51 | INFO | train_inner | epoch 056:    835 / 1103 loss=3.163, nll_loss=1.634, ppl=3.1, wps=15974.6, ups=4.49, wpb=3555.1, bsz=140.5, num_updates=61500, lr=0.000127515, gnorm=0.96, train_wall=22, gb_free=6.9, wall=14124
2021-03-11 00:42:13 | INFO | train_inner | epoch 056:    935 / 1103 loss=3.133, nll_loss=1.6, ppl=3.03, wps=15898.1, ups=4.44, wpb=3580, bsz=148.2, num_updates=61600, lr=0.000127412, gnorm=0.954, train_wall=22, gb_free=7.1, wall=14147
2021-03-11 00:42:36 | INFO | train_inner | epoch 056:   1035 / 1103 loss=3.128, nll_loss=1.596, ppl=3.02, wps=15986.2, ups=4.4, wpb=3631.5, bsz=156.2, num_updates=61700, lr=0.000127309, gnorm=0.922, train_wall=23, gb_free=7.2, wall=14169
2021-03-11 00:42:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-11 00:42:55 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 3.957 | nll_loss 2.403 | ppl 5.29 | wps 48235 | wpb 2873.1 | bsz 115.6 | num_updates 61768 | best_loss 3.91
2021-03-11 00:42:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 56 @ 61768 updates
2021-03-11 00:42:55 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 00:42:57 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 00:42:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt (epoch 56 @ 61768 updates, score 3.957) (writing took 2.15019054338336 seconds)
2021-03-11 00:42:57 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2021-03-11 00:42:57 | INFO | train | epoch 056 | loss 3.126 | nll_loss 1.591 | ppl 3.01 | wps 15551.7 | ups 4.35 | wpb 3577.8 | bsz 145.3 | num_updates 61768 | lr 0.000127238 | gnorm 0.941 | train_wall 246 | gb_free 6.9 | wall 14190
2021-03-11 00:42:57 | INFO | fairseq.trainer | begin training epoch 57
2021-03-11 00:42:57 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-11 00:43:05 | INFO | train_inner | epoch 057:     32 / 1103 loss=3.116, nll_loss=1.581, ppl=2.99, wps=12504.6, ups=3.51, wpb=3558.4, bsz=147.9, num_updates=61800, lr=0.000127205, gnorm=0.936, train_wall=22, gb_free=7.2, wall=14198
2021-03-11 00:43:27 | INFO | train_inner | epoch 057:    132 / 1103 loss=3.08, nll_loss=1.536, ppl=2.9, wps=15890.6, ups=4.45, wpb=3573.8, bsz=143.5, num_updates=61900, lr=0.000127103, gnorm=0.922, train_wall=22, gb_free=7.8, wall=14220
2021-03-11 00:43:49 | INFO | train_inner | epoch 057:    232 / 1103 loss=3.072, nll_loss=1.528, ppl=2.88, wps=15603.6, ups=4.46, wpb=3496.2, bsz=147, num_updates=62000, lr=0.000127, gnorm=0.951, train_wall=22, gb_free=7.1, wall=14243
2021-03-11 00:44:12 | INFO | train_inner | epoch 057:    332 / 1103 loss=3.112, nll_loss=1.575, ppl=2.98, wps=16012, ups=4.48, wpb=3572.9, bsz=140.6, num_updates=62100, lr=0.000126898, gnorm=0.956, train_wall=22, gb_free=6.9, wall=14265
2021-03-11 00:44:34 | INFO | train_inner | epoch 057:    432 / 1103 loss=3.1, nll_loss=1.56, ppl=2.95, wps=15912.9, ups=4.42, wpb=3600.6, bsz=144.6, num_updates=62200, lr=0.000126796, gnorm=0.923, train_wall=23, gb_free=7.4, wall=14288
2021-03-11 00:44:57 | INFO | train_inner | epoch 057:    532 / 1103 loss=3.105, nll_loss=1.568, ppl=2.96, wps=15873.8, ups=4.44, wpb=3575, bsz=150.9, num_updates=62300, lr=0.000126694, gnorm=0.948, train_wall=22, gb_free=7, wall=14310
2021-03-11 00:45:19 | INFO | train_inner | epoch 057:    632 / 1103 loss=3.122, nll_loss=1.587, ppl=3, wps=16040.6, ups=4.46, wpb=3594.4, bsz=152.4, num_updates=62400, lr=0.000126592, gnorm=0.939, train_wall=22, gb_free=7.2, wall=14332
2021-03-11 00:45:42 | INFO | train_inner | epoch 057:    732 / 1103 loss=3.124, nll_loss=1.59, ppl=3.01, wps=15948.8, ups=4.44, wpb=3593.5, bsz=151.7, num_updates=62500, lr=0.000126491, gnorm=0.933, train_wall=22, gb_free=7, wall=14355
2021-03-11 00:46:04 | INFO | train_inner | epoch 057:    832 / 1103 loss=3.157, nll_loss=1.627, ppl=3.09, wps=15973.4, ups=4.49, wpb=3561.5, bsz=135.6, num_updates=62600, lr=0.00012639, gnorm=0.967, train_wall=22, gb_free=7.2, wall=14377
2021-03-11 00:46:27 | INFO | train_inner | epoch 057:    932 / 1103 loss=3.164, nll_loss=1.636, ppl=3.11, wps=16166.4, ups=4.45, wpb=3634.1, bsz=142, num_updates=62700, lr=0.000126289, gnorm=0.949, train_wall=22, gb_free=7.3, wall=14400
2021-03-11 00:46:49 | INFO | train_inner | epoch 057:   1032 / 1103 loss=3.141, nll_loss=1.608, ppl=3.05, wps=15896.1, ups=4.47, wpb=3560, bsz=146.1, num_updates=62800, lr=0.000126189, gnorm=0.946, train_wall=22, gb_free=6.9, wall=14422
2021-03-11 00:47:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-11 00:47:09 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 3.96 | nll_loss 2.41 | ppl 5.31 | wps 48309.9 | wpb 2873.1 | bsz 115.6 | num_updates 62871 | best_loss 3.91
2021-03-11 00:47:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 57 @ 62871 updates
2021-03-11 00:47:09 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 00:47:11 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 00:47:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt (epoch 57 @ 62871 updates, score 3.96) (writing took 2.063488654792309 seconds)
2021-03-11 00:47:11 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2021-03-11 00:47:11 | INFO | train | epoch 057 | loss 3.118 | nll_loss 1.582 | ppl 2.99 | wps 15564.4 | ups 4.35 | wpb 3577.8 | bsz 145.3 | num_updates 62871 | lr 0.000126117 | gnorm 0.944 | train_wall 246 | gb_free 7.4 | wall 14444
2021-03-11 00:47:11 | INFO | fairseq.trainer | begin training epoch 58
2021-03-11 00:47:11 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-11 00:47:17 | INFO | train_inner | epoch 058:     29 / 1103 loss=3.134, nll_loss=1.6, ppl=3.03, wps=12897, ups=3.61, wpb=3569.8, bsz=141.8, num_updates=62900, lr=0.000126088, gnorm=0.951, train_wall=22, gb_free=7.1, wall=14450
2021-03-11 00:47:37 | INFO | train_inner | epoch 058:    129 / 1103 loss=3.083, nll_loss=1.541, ppl=2.91, wps=17733.2, ups=4.86, wpb=3646.4, bsz=147.1, num_updates=63000, lr=0.000125988, gnorm=0.912, train_wall=20, gb_free=6.9, wall=14470
2021-03-11 00:47:58 | INFO | train_inner | epoch 058:    229 / 1103 loss=3.06, nll_loss=1.517, ppl=2.86, wps=17584.6, ups=4.86, wpb=3615.9, bsz=166, num_updates=63100, lr=0.000125888, gnorm=0.912, train_wall=20, gb_free=7, wall=14491
2021-03-11 00:48:18 | INFO | train_inner | epoch 058:    329 / 1103 loss=3.101, nll_loss=1.561, ppl=2.95, wps=17323.9, ups=4.86, wpb=3561.6, bsz=142.4, num_updates=63200, lr=0.000125789, gnorm=0.954, train_wall=20, gb_free=7.1, wall=14512
2021-03-11 00:48:39 | INFO | train_inner | epoch 058:    429 / 1103 loss=3.127, nll_loss=1.591, ppl=3.01, wps=17794.5, ups=4.94, wpb=3601.1, bsz=135.8, num_updates=63300, lr=0.000125689, gnorm=0.948, train_wall=20, gb_free=6.7, wall=14532
2021-03-11 00:48:59 | INFO | train_inner | epoch 058:    529 / 1103 loss=3.116, nll_loss=1.578, ppl=2.99, wps=17548.5, ups=4.94, wpb=3550, bsz=139.7, num_updates=63400, lr=0.00012559, gnorm=0.95, train_wall=20, gb_free=7.3, wall=14552
2021-03-11 00:49:19 | INFO | train_inner | epoch 058:    629 / 1103 loss=3.12, nll_loss=1.585, ppl=3, wps=17482, ups=4.87, wpb=3587.9, bsz=146.2, num_updates=63500, lr=0.000125491, gnorm=0.949, train_wall=20, gb_free=7.4, wall=14573
2021-03-11 00:49:40 | INFO | train_inner | epoch 058:    729 / 1103 loss=3.125, nll_loss=1.59, ppl=3.01, wps=17418.7, ups=4.87, wpb=3577.9, bsz=143.5, num_updates=63600, lr=0.000125392, gnorm=0.949, train_wall=20, gb_free=7, wall=14593
2021-03-11 00:50:00 | INFO | train_inner | epoch 058:    829 / 1103 loss=3.13, nll_loss=1.596, ppl=3.02, wps=17465.4, ups=4.9, wpb=3563.3, bsz=140.5, num_updates=63700, lr=0.000125294, gnorm=0.963, train_wall=20, gb_free=7, wall=14613
2021-03-11 00:50:21 | INFO | train_inner | epoch 058:    929 / 1103 loss=3.128, nll_loss=1.593, ppl=3.02, wps=17239.5, ups=4.9, wpb=3517.6, bsz=136.4, num_updates=63800, lr=0.000125196, gnorm=0.979, train_wall=20, gb_free=7.1, wall=14634
2021-03-11 00:50:41 | INFO | train_inner | epoch 058:   1029 / 1103 loss=3.148, nll_loss=1.616, ppl=3.07, wps=17483.6, ups=4.88, wpb=3580.4, bsz=142.5, num_updates=63900, lr=0.000125098, gnorm=0.951, train_wall=20, gb_free=7, wall=14654
2021-03-11 00:50:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-11 00:51:00 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 3.983 | nll_loss 2.423 | ppl 5.36 | wps 48223.2 | wpb 2873.1 | bsz 115.6 | num_updates 63974 | best_loss 3.91
2021-03-11 00:51:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 58 @ 63974 updates
2021-03-11 00:51:00 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 00:51:03 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 00:51:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt (epoch 58 @ 63974 updates, score 3.983) (writing took 2.516845263540745 seconds)
2021-03-11 00:51:03 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2021-03-11 00:51:03 | INFO | train | epoch 058 | loss 3.111 | nll_loss 1.574 | ppl 2.98 | wps 17001.6 | ups 4.75 | wpb 3577.8 | bsz 145.3 | num_updates 63974 | lr 0.000125025 | gnorm 0.946 | train_wall 225 | gb_free 7 | wall 14676
2021-03-11 00:51:03 | INFO | fairseq.trainer | begin training epoch 59
2021-03-11 00:51:03 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-11 00:51:08 | INFO | train_inner | epoch 059:     26 / 1103 loss=3.08, nll_loss=1.54, ppl=2.91, wps=13052.1, ups=3.72, wpb=3511.9, bsz=157.6, num_updates=64000, lr=0.000125, gnorm=0.945, train_wall=20, gb_free=7.3, wall=14681
2021-03-11 00:51:29 | INFO | train_inner | epoch 059:    126 / 1103 loss=3.085, nll_loss=1.542, ppl=2.91, wps=17588.9, ups=4.87, wpb=3611.8, bsz=140.5, num_updates=64100, lr=0.000124902, gnorm=0.924, train_wall=20, gb_free=7, wall=14702
2021-03-11 00:51:49 | INFO | train_inner | epoch 059:    226 / 1103 loss=3.066, nll_loss=1.521, ppl=2.87, wps=17329, ups=4.88, wpb=3549.8, bsz=147.9, num_updates=64200, lr=0.000124805, gnorm=0.948, train_wall=20, gb_free=6.7, wall=14722
2021-03-11 00:52:09 | INFO | train_inner | epoch 059:    326 / 1103 loss=3.09, nll_loss=1.546, ppl=2.92, wps=17253.8, ups=4.92, wpb=3506.6, bsz=126.4, num_updates=64300, lr=0.000124708, gnorm=0.968, train_wall=20, gb_free=7, wall=14743
2021-03-11 00:52:30 | INFO | train_inner | epoch 059:    426 / 1103 loss=3.082, nll_loss=1.541, ppl=2.91, wps=17484.3, ups=4.86, wpb=3598.1, bsz=153.5, num_updates=64400, lr=0.000124611, gnorm=0.937, train_wall=20, gb_free=7.4, wall=14763
2021-03-11 00:52:50 | INFO | train_inner | epoch 059:    526 / 1103 loss=3.119, nll_loss=1.58, ppl=2.99, wps=17175.7, ups=4.96, wpb=3464.3, bsz=132.8, num_updates=64500, lr=0.000124515, gnorm=0.996, train_wall=20, gb_free=7.2, wall=14783
2021-03-11 00:53:11 | INFO | train_inner | epoch 059:    626 / 1103 loss=3.113, nll_loss=1.575, ppl=2.98, wps=17411.1, ups=4.88, wpb=3568.9, bsz=139.7, num_updates=64600, lr=0.000124418, gnorm=0.944, train_wall=20, gb_free=7.1, wall=14804
2021-03-11 00:53:31 | INFO | train_inner | epoch 059:    726 / 1103 loss=3.13, nll_loss=1.595, ppl=3.02, wps=17658.4, ups=4.94, wpb=3576.4, bsz=145.4, num_updates=64700, lr=0.000124322, gnorm=0.96, train_wall=20, gb_free=7.8, wall=14824
2021-03-11 00:53:52 | INFO | train_inner | epoch 059:    826 / 1103 loss=3.1, nll_loss=1.563, ppl=2.95, wps=17608, ups=4.84, wpb=3636.8, bsz=154.9, num_updates=64800, lr=0.000124226, gnorm=0.932, train_wall=21, gb_free=7, wall=14845
2021-03-11 00:54:12 | INFO | train_inner | epoch 059:    926 / 1103 loss=3.131, nll_loss=1.598, ppl=3.03, wps=17749.1, ups=4.83, wpb=3675.5, bsz=154.6, num_updates=64900, lr=0.00012413, gnorm=0.932, train_wall=21, gb_free=7.2, wall=14865
2021-03-11 00:54:33 | INFO | train_inner | epoch 059:   1026 / 1103 loss=3.118, nll_loss=1.584, ppl=3, wps=17584.1, ups=4.86, wpb=3620.1, bsz=150.3, num_updates=65000, lr=0.000124035, gnorm=0.933, train_wall=20, gb_free=6.8, wall=14886
2021-03-11 00:54:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-11 00:54:52 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 3.964 | nll_loss 2.408 | ppl 5.31 | wps 48243.1 | wpb 2873.1 | bsz 115.6 | num_updates 65077 | best_loss 3.91
2021-03-11 00:54:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 59 @ 65077 updates
2021-03-11 00:54:52 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 00:54:55 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 00:54:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt (epoch 59 @ 65077 updates, score 3.964) (writing took 2.308833599090576 seconds)
2021-03-11 00:54:55 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2021-03-11 00:54:55 | INFO | train | epoch 059 | loss 3.104 | nll_loss 1.565 | ppl 2.96 | wps 17007.3 | ups 4.75 | wpb 3577.8 | bsz 145.3 | num_updates 65077 | lr 0.000123961 | gnorm 0.948 | train_wall 225 | gb_free 7.2 | wall 14908
2021-03-11 00:54:55 | INFO | fairseq.trainer | begin training epoch 60
2021-03-11 00:54:55 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-11 00:55:00 | INFO | train_inner | epoch 060:     23 / 1103 loss=3.097, nll_loss=1.56, ppl=2.95, wps=13377.8, ups=3.7, wpb=3616.3, bsz=164.2, num_updates=65100, lr=0.000123939, gnorm=0.932, train_wall=21, gb_free=7, wall=14913
2021-03-11 00:55:22 | INFO | train_inner | epoch 060:    123 / 1103 loss=3.023, nll_loss=1.472, ppl=2.77, wps=15687.4, ups=4.48, wpb=3502.6, bsz=158.6, num_updates=65200, lr=0.000123844, gnorm=0.937, train_wall=22, gb_free=7.4, wall=14935
2021-03-11 00:55:45 | INFO | train_inner | epoch 060:    223 / 1103 loss=3.072, nll_loss=1.53, ppl=2.89, wps=16081.3, ups=4.45, wpb=3615.5, bsz=157.3, num_updates=65300, lr=0.000123749, gnorm=0.926, train_wall=22, gb_free=7, wall=14958
2021-03-11 00:56:07 | INFO | train_inner | epoch 060:    323 / 1103 loss=3.097, nll_loss=1.555, ppl=2.94, wps=15795.4, ups=4.48, wpb=3525.3, bsz=124.4, num_updates=65400, lr=0.000123655, gnorm=0.97, train_wall=22, gb_free=7.3, wall=14980
2021-03-11 00:56:29 | INFO | train_inner | epoch 060:    423 / 1103 loss=3.102, nll_loss=1.561, ppl=2.95, wps=16019.6, ups=4.5, wpb=3561.4, bsz=135, num_updates=65500, lr=0.00012356, gnorm=0.957, train_wall=22, gb_free=7, wall=15002
2021-03-11 00:56:52 | INFO | train_inner | epoch 060:    523 / 1103 loss=3.089, nll_loss=1.548, ppl=2.92, wps=16126.4, ups=4.46, wpb=3618, bsz=147.5, num_updates=65600, lr=0.000123466, gnorm=0.94, train_wall=22, gb_free=6.9, wall=15025
2021-03-11 00:57:14 | INFO | train_inner | epoch 060:    623 / 1103 loss=3.085, nll_loss=1.544, ppl=2.92, wps=15813, ups=4.46, wpb=3544.1, bsz=155.4, num_updates=65700, lr=0.000123372, gnorm=0.954, train_wall=22, gb_free=7.6, wall=15047
2021-03-11 00:57:37 | INFO | train_inner | epoch 060:    723 / 1103 loss=3.147, nll_loss=1.615, ppl=3.06, wps=16198.9, ups=4.47, wpb=3622.7, bsz=141.4, num_updates=65800, lr=0.000123278, gnorm=0.965, train_wall=22, gb_free=7.4, wall=15070
2021-03-11 00:57:59 | INFO | train_inner | epoch 060:    823 / 1103 loss=3.125, nll_loss=1.59, ppl=3.01, wps=16184.6, ups=4.45, wpb=3639.2, bsz=136.1, num_updates=65900, lr=0.000123185, gnorm=0.95, train_wall=22, gb_free=7.4, wall=15092
2021-03-11 00:58:22 | INFO | train_inner | epoch 060:    923 / 1103 loss=3.128, nll_loss=1.594, ppl=3.02, wps=16073.7, ups=4.42, wpb=3634.9, bsz=146.2, num_updates=66000, lr=0.000123091, gnorm=0.964, train_wall=23, gb_free=7.4, wall=15115
2021-03-11 00:58:44 | INFO | train_inner | epoch 060:   1023 / 1103 loss=3.128, nll_loss=1.593, ppl=3.02, wps=15850.5, ups=4.47, wpb=3549.6, bsz=141.4, num_updates=66100, lr=0.000122998, gnorm=0.986, train_wall=22, gb_free=6.9, wall=15137
2021-03-11 00:59:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-11 00:59:06 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 3.971 | nll_loss 2.416 | ppl 5.34 | wps 48271.8 | wpb 2873.1 | bsz 115.6 | num_updates 66180 | best_loss 3.91
2021-03-11 00:59:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 60 @ 66180 updates
2021-03-11 00:59:06 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 00:59:08 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 00:59:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt (epoch 60 @ 66180 updates, score 3.971) (writing took 2.254071157425642 seconds)
2021-03-11 00:59:08 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2021-03-11 00:59:08 | INFO | train | epoch 060 | loss 3.098 | nll_loss 1.558 | ppl 2.95 | wps 15587.8 | ups 4.36 | wpb 3577.8 | bsz 145.3 | num_updates 66180 | lr 0.000122924 | gnorm 0.954 | train_wall 246 | gb_free 7.1 | wall 15161
2021-03-11 00:59:08 | INFO | fairseq.trainer | begin training epoch 61
2021-03-11 00:59:08 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-11 00:59:12 | INFO | train_inner | epoch 061:     20 / 1103 loss=3.099, nll_loss=1.56, ppl=2.95, wps=12419.9, ups=3.55, wpb=3496.9, bsz=143.3, num_updates=66200, lr=0.000122905, gnorm=0.975, train_wall=22, gb_free=7.6, wall=15165
2021-03-11 00:59:33 | INFO | train_inner | epoch 061:    120 / 1103 loss=3.075, nll_loss=1.529, ppl=2.89, wps=17533.1, ups=4.92, wpb=3567, bsz=128.5, num_updates=66300, lr=0.000122813, gnorm=0.953, train_wall=20, gb_free=6.9, wall=15186
2021-03-11 00:59:53 | INFO | train_inner | epoch 061:    220 / 1103 loss=3.065, nll_loss=1.519, ppl=2.87, wps=17646.9, ups=4.85, wpb=3637.3, bsz=148.2, num_updates=66400, lr=0.00012272, gnorm=0.925, train_wall=21, gb_free=7, wall=15206
2021-03-11 01:00:14 | INFO | train_inner | epoch 061:    320 / 1103 loss=3.072, nll_loss=1.528, ppl=2.88, wps=17455.7, ups=4.87, wpb=3583.7, bsz=145.4, num_updates=66500, lr=0.000122628, gnorm=0.937, train_wall=20, gb_free=6.9, wall=15227
2021-03-11 01:00:34 | INFO | train_inner | epoch 061:    420 / 1103 loss=3.067, nll_loss=1.523, ppl=2.87, wps=17624, ups=4.86, wpb=3625.5, bsz=148.3, num_updates=66600, lr=0.000122536, gnorm=0.948, train_wall=20, gb_free=6.9, wall=15247
2021-03-11 01:00:55 | INFO | train_inner | epoch 061:    520 / 1103 loss=3.073, nll_loss=1.53, ppl=2.89, wps=17475.5, ups=4.89, wpb=3576.6, bsz=158.5, num_updates=66700, lr=0.000122444, gnorm=0.944, train_wall=20, gb_free=7, wall=15268
2021-03-11 01:01:15 | INFO | train_inner | epoch 061:    620 / 1103 loss=3.117, nll_loss=1.58, ppl=2.99, wps=17577, ups=4.9, wpb=3584.1, bsz=138.2, num_updates=66800, lr=0.000122352, gnorm=0.959, train_wall=20, gb_free=7.1, wall=15288
2021-03-11 01:01:35 | INFO | train_inner | epoch 061:    720 / 1103 loss=3.123, nll_loss=1.587, ppl=3, wps=17598.2, ups=4.93, wpb=3570.2, bsz=143.8, num_updates=66900, lr=0.000122261, gnorm=0.967, train_wall=20, gb_free=7, wall=15309
2021-03-11 01:01:56 | INFO | train_inner | epoch 061:    820 / 1103 loss=3.088, nll_loss=1.548, ppl=2.92, wps=17355.4, ups=4.86, wpb=3568.6, bsz=152, num_updates=67000, lr=0.000122169, gnorm=0.945, train_wall=20, gb_free=7, wall=15329
2021-03-11 01:02:17 | INFO | train_inner | epoch 061:    920 / 1103 loss=3.099, nll_loss=1.56, ppl=2.95, wps=17461.2, ups=4.85, wpb=3598.5, bsz=147.4, num_updates=67100, lr=0.000122078, gnorm=0.953, train_wall=21, gb_free=7, wall=15350
2021-03-11 01:02:37 | INFO | train_inner | epoch 061:   1020 / 1103 loss=3.109, nll_loss=1.571, ppl=2.97, wps=17288.6, ups=4.9, wpb=3527.8, bsz=142.1, num_updates=67200, lr=0.000121988, gnorm=0.979, train_wall=20, gb_free=6.8, wall=15370
2021-03-11 01:02:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-11 01:02:59 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 3.984 | nll_loss 2.423 | ppl 5.36 | wps 48193 | wpb 2873.1 | bsz 115.6 | num_updates 67283 | best_loss 3.91
2021-03-11 01:02:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 61 @ 67283 updates
2021-03-11 01:02:59 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 01:03:01 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 01:03:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt (epoch 61 @ 67283 updates, score 3.984) (writing took 2.185986455529928 seconds)
2021-03-11 01:03:01 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2021-03-11 01:03:01 | INFO | train | epoch 061 | loss 3.09 | nll_loss 1.55 | ppl 2.93 | wps 16906 | ups 4.73 | wpb 3577.8 | bsz 145.3 | num_updates 67283 | lr 0.000121912 | gnorm 0.954 | train_wall 226 | gb_free 7 | wall 15395
2021-03-11 01:03:01 | INFO | fairseq.trainer | begin training epoch 62
2021-03-11 01:03:01 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-11 01:03:05 | INFO | train_inner | epoch 062:     17 / 1103 loss=3.104, nll_loss=1.566, ppl=2.96, wps=12452.7, ups=3.53, wpb=3532.4, bsz=148.2, num_updates=67300, lr=0.000121897, gnorm=0.969, train_wall=22, gb_free=6.8, wall=15398
2021-03-11 01:03:26 | INFO | train_inner | epoch 062:    117 / 1103 loss=3.034, nll_loss=1.485, ppl=2.8, wps=17211.9, ups=4.92, wpb=3495.8, bsz=156.6, num_updates=67400, lr=0.000121806, gnorm=0.958, train_wall=20, gb_free=7.4, wall=15419
2021-03-11 01:03:46 | INFO | train_inner | epoch 062:    217 / 1103 loss=3.052, nll_loss=1.505, ppl=2.84, wps=17209.9, ups=4.86, wpb=3542.9, bsz=151.8, num_updates=67500, lr=0.000121716, gnorm=0.942, train_wall=20, gb_free=6.9, wall=15439
2021-03-11 01:04:09 | INFO | train_inner | epoch 062:    317 / 1103 loss=3.062, nll_loss=1.519, ppl=2.87, wps=16428.4, ups=4.44, wpb=3702.7, bsz=166.6, num_updates=67600, lr=0.000121626, gnorm=0.908, train_wall=22, gb_free=6.8, wall=15462
2021-03-11 01:04:31 | INFO | train_inner | epoch 062:    417 / 1103 loss=3.093, nll_loss=1.551, ppl=2.93, wps=15910.2, ups=4.45, wpb=3571.5, bsz=131, num_updates=67700, lr=0.000121536, gnorm=0.969, train_wall=22, gb_free=6.8, wall=15484
2021-03-11 01:04:54 | INFO | train_inner | epoch 062:    517 / 1103 loss=3.082, nll_loss=1.539, ppl=2.91, wps=16105.4, ups=4.41, wpb=3651.1, bsz=145, num_updates=67800, lr=0.000121447, gnorm=0.941, train_wall=23, gb_free=7.1, wall=15507
2021-03-11 01:05:15 | INFO | train_inner | epoch 062:    617 / 1103 loss=3.126, nll_loss=1.59, ppl=3.01, wps=16563.8, ups=4.64, wpb=3573.2, bsz=131, num_updates=67900, lr=0.000121357, gnorm=0.981, train_wall=21, gb_free=6.9, wall=15529
2021-03-11 01:05:36 | INFO | train_inner | epoch 062:    717 / 1103 loss=3.105, nll_loss=1.566, ppl=2.96, wps=17392.7, ups=4.95, wpb=3516.9, bsz=135.8, num_updates=68000, lr=0.000121268, gnorm=0.98, train_wall=20, gb_free=7.1, wall=15549
2021-03-11 01:05:56 | INFO | train_inner | epoch 062:    817 / 1103 loss=3.092, nll_loss=1.551, ppl=2.93, wps=17323.5, ups=4.89, wpb=3543.6, bsz=145, num_updates=68100, lr=0.000121179, gnorm=0.975, train_wall=20, gb_free=7.1, wall=15569
2021-03-11 01:06:18 | INFO | train_inner | epoch 062:    917 / 1103 loss=3.108, nll_loss=1.567, ppl=2.96, wps=16017.5, ups=4.47, wpb=3581.1, bsz=132.4, num_updates=68200, lr=0.00012109, gnorm=0.964, train_wall=22, gb_free=6.9, wall=15592
2021-03-11 01:06:41 | INFO | train_inner | epoch 062:   1017 / 1103 loss=3.085, nll_loss=1.546, ppl=2.92, wps=16056.8, ups=4.41, wpb=3642.6, bsz=161.7, num_updates=68300, lr=0.000121001, gnorm=0.935, train_wall=23, gb_free=7, wall=15614
2021-03-11 01:07:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-11 01:07:04 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 3.977 | nll_loss 2.42 | ppl 5.35 | wps 48211.7 | wpb 2873.1 | bsz 115.6 | num_updates 68386 | best_loss 3.91
2021-03-11 01:07:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 62 @ 68386 updates
2021-03-11 01:07:04 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 01:07:06 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 01:07:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt (epoch 62 @ 68386 updates, score 3.977) (writing took 2.163457367569208 seconds)
2021-03-11 01:07:06 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2021-03-11 01:07:06 | INFO | train | epoch 062 | loss 3.085 | nll_loss 1.543 | ppl 2.91 | wps 16110.2 | ups 4.5 | wpb 3577.8 | bsz 145.3 | num_updates 68386 | lr 0.000120925 | gnorm 0.957 | train_wall 238 | gb_free 7 | wall 15639
2021-03-11 01:07:06 | INFO | fairseq.trainer | begin training epoch 63
2021-03-11 01:07:06 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-11 01:07:10 | INFO | train_inner | epoch 063:     14 / 1103 loss=3.089, nll_loss=1.547, ppl=2.92, wps=12423.6, ups=3.5, wpb=3544.8, bsz=138.6, num_updates=68400, lr=0.000120913, gnorm=0.968, train_wall=22, gb_free=7.1, wall=15643
2021-03-11 01:07:32 | INFO | train_inner | epoch 063:    114 / 1103 loss=3.059, nll_loss=1.512, ppl=2.85, wps=15965, ups=4.5, wpb=3551.4, bsz=137.2, num_updates=68500, lr=0.000120824, gnorm=0.954, train_wall=22, gb_free=7.2, wall=15665
2021-03-11 01:07:54 | INFO | train_inner | epoch 063:    214 / 1103 loss=3.058, nll_loss=1.511, ppl=2.85, wps=16006.2, ups=4.47, wpb=3578.8, bsz=145.4, num_updates=68600, lr=0.000120736, gnorm=0.96, train_wall=22, gb_free=6.9, wall=15687
2021-03-11 01:08:17 | INFO | train_inner | epoch 063:    314 / 1103 loss=3.054, nll_loss=1.507, ppl=2.84, wps=15780.8, ups=4.47, wpb=3527.5, bsz=145.3, num_updates=68700, lr=0.000120648, gnorm=0.961, train_wall=22, gb_free=6.9, wall=15710
2021-03-11 01:08:39 | INFO | train_inner | epoch 063:    414 / 1103 loss=3.055, nll_loss=1.51, ppl=2.85, wps=15924.9, ups=4.43, wpb=3597.7, bsz=154.9, num_updates=68800, lr=0.000120561, gnorm=0.971, train_wall=22, gb_free=6.9, wall=15732
2021-03-11 01:09:02 | INFO | train_inner | epoch 063:    514 / 1103 loss=3.085, nll_loss=1.542, ppl=2.91, wps=15955.7, ups=4.46, wpb=3577.9, bsz=131.8, num_updates=68900, lr=0.000120473, gnorm=0.974, train_wall=22, gb_free=7.2, wall=15755
2021-03-11 01:09:24 | INFO | train_inner | epoch 063:    614 / 1103 loss=3.108, nll_loss=1.57, ppl=2.97, wps=16105.1, ups=4.46, wpb=3613.4, bsz=146.7, num_updates=69000, lr=0.000120386, gnorm=0.954, train_wall=22, gb_free=7, wall=15777
2021-03-11 01:09:46 | INFO | train_inner | epoch 063:    714 / 1103 loss=3.095, nll_loss=1.554, ppl=2.94, wps=15892.9, ups=4.49, wpb=3538.3, bsz=143.1, num_updates=69100, lr=0.000120299, gnorm=0.973, train_wall=22, gb_free=7, wall=15800
2021-03-11 01:10:09 | INFO | train_inner | epoch 063:    814 / 1103 loss=3.07, nll_loss=1.528, ppl=2.88, wps=15941.3, ups=4.43, wpb=3601.8, bsz=158.9, num_updates=69200, lr=0.000120212, gnorm=0.961, train_wall=22, gb_free=7, wall=15822
2021-03-11 01:10:32 | INFO | train_inner | epoch 063:    914 / 1103 loss=3.085, nll_loss=1.544, ppl=2.92, wps=15996.9, ups=4.4, wpb=3639.1, bsz=153.6, num_updates=69300, lr=0.000120125, gnorm=0.936, train_wall=23, gb_free=6.7, wall=15845
2021-03-11 01:10:54 | INFO | train_inner | epoch 063:   1014 / 1103 loss=3.093, nll_loss=1.554, ppl=2.94, wps=16084, ups=4.43, wpb=3628.3, bsz=156.6, num_updates=69400, lr=0.000120038, gnorm=0.952, train_wall=22, gb_free=7.4, wall=15867
2021-03-11 01:11:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-11 01:11:18 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 3.979 | nll_loss 2.424 | ppl 5.37 | wps 48285.1 | wpb 2873.1 | bsz 115.6 | num_updates 69489 | best_loss 3.91
2021-03-11 01:11:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 63 @ 69489 updates
2021-03-11 01:11:18 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 01:11:20 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 01:11:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt (epoch 63 @ 69489 updates, score 3.979) (writing took 2.149413112550974 seconds)
2021-03-11 01:11:20 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2021-03-11 01:11:20 | INFO | train | epoch 063 | loss 3.078 | nll_loss 1.535 | ppl 2.9 | wps 15552.7 | ups 4.35 | wpb 3577.8 | bsz 145.3 | num_updates 69489 | lr 0.000119962 | gnorm 0.962 | train_wall 246 | gb_free 7.1 | wall 15893
2021-03-11 01:11:20 | INFO | fairseq.trainer | begin training epoch 64
2021-03-11 01:11:20 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-11 01:11:23 | INFO | train_inner | epoch 064:     11 / 1103 loss=3.083, nll_loss=1.54, ppl=2.91, wps=12230.7, ups=3.51, wpb=3484.1, bsz=130.7, num_updates=69500, lr=0.000119952, gnorm=0.986, train_wall=22, gb_free=7, wall=15896
2021-03-11 01:11:45 | INFO | train_inner | epoch 064:    111 / 1103 loss=3.061, nll_loss=1.512, ppl=2.85, wps=16043.2, ups=4.46, wpb=3595.4, bsz=130, num_updates=69600, lr=0.000119866, gnorm=0.958, train_wall=22, gb_free=6.9, wall=15918
2021-03-11 01:12:07 | INFO | train_inner | epoch 064:    211 / 1103 loss=3.046, nll_loss=1.498, ppl=2.82, wps=16036.8, ups=4.48, wpb=3579.9, bsz=154.2, num_updates=69700, lr=0.00011978, gnorm=0.967, train_wall=22, gb_free=7.1, wall=15941
2021-03-11 01:12:30 | INFO | train_inner | epoch 064:    311 / 1103 loss=3.038, nll_loss=1.488, ppl=2.81, wps=15878.2, ups=4.47, wpb=3554.9, bsz=147, num_updates=69800, lr=0.000119694, gnorm=0.964, train_wall=22, gb_free=7, wall=15963
2021-03-11 01:12:52 | INFO | train_inner | epoch 064:    411 / 1103 loss=3.062, nll_loss=1.517, ppl=2.86, wps=15986.9, ups=4.47, wpb=3580.5, bsz=150.2, num_updates=69900, lr=0.000119608, gnorm=0.957, train_wall=22, gb_free=6.9, wall=15985
2021-03-11 01:13:15 | INFO | train_inner | epoch 064:    511 / 1103 loss=3.049, nll_loss=1.504, ppl=2.84, wps=16028.6, ups=4.45, wpb=3602.1, bsz=157.1, num_updates=70000, lr=0.000119523, gnorm=0.934, train_wall=22, gb_free=6.9, wall=16008
2021-03-11 01:13:37 | INFO | train_inner | epoch 064:    611 / 1103 loss=3.072, nll_loss=1.526, ppl=2.88, wps=15814.6, ups=4.47, wpb=3540, bsz=143, num_updates=70100, lr=0.000119438, gnorm=0.981, train_wall=22, gb_free=7, wall=16030
2021-03-11 01:13:59 | INFO | train_inner | epoch 064:    711 / 1103 loss=3.102, nll_loss=1.561, ppl=2.95, wps=15953.1, ups=4.48, wpb=3563.7, bsz=133.8, num_updates=70200, lr=0.000119352, gnorm=0.986, train_wall=22, gb_free=6.9, wall=16053
2021-03-11 01:14:22 | INFO | train_inner | epoch 064:    811 / 1103 loss=3.087, nll_loss=1.546, ppl=2.92, wps=15964.9, ups=4.46, wpb=3583.2, bsz=139.6, num_updates=70300, lr=0.000119268, gnorm=0.955, train_wall=22, gb_free=7.1, wall=16075
2021-03-11 01:14:45 | INFO | train_inner | epoch 064:    911 / 1103 loss=3.1, nll_loss=1.561, ppl=2.95, wps=16010.4, ups=4.42, wpb=3624.2, bsz=142.3, num_updates=70400, lr=0.000119183, gnorm=0.972, train_wall=23, gb_free=7.5, wall=16098
2021-03-11 01:15:07 | INFO | train_inner | epoch 064:   1011 / 1103 loss=3.104, nll_loss=1.564, ppl=2.96, wps=15939.5, ups=4.48, wpb=3558.5, bsz=142.9, num_updates=70500, lr=0.000119098, gnorm=0.966, train_wall=22, gb_free=7.7, wall=16120
2021-03-11 01:15:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-11 01:15:31 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 3.983 | nll_loss 2.425 | ppl 5.37 | wps 48181.5 | wpb 2873.1 | bsz 115.6 | num_updates 70592 | best_loss 3.91
2021-03-11 01:15:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 64 @ 70592 updates
2021-03-11 01:15:31 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 01:15:34 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 01:15:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt (epoch 64 @ 70592 updates, score 3.983) (writing took 2.3449752256274223 seconds)
2021-03-11 01:15:34 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2021-03-11 01:15:34 | INFO | train | epoch 064 | loss 3.072 | nll_loss 1.527 | ppl 2.88 | wps 15564.1 | ups 4.35 | wpb 3577.8 | bsz 145.3 | num_updates 70592 | lr 0.000119021 | gnorm 0.964 | train_wall 246 | gb_free 7.1 | wall 16147
2021-03-11 01:15:34 | INFO | fairseq.trainer | begin training epoch 65
2021-03-11 01:15:34 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-11 01:15:36 | INFO | train_inner | epoch 065:      8 / 1103 loss=3.078, nll_loss=1.537, ppl=2.9, wps=12459.1, ups=3.47, wpb=3589.8, bsz=152.4, num_updates=70600, lr=0.000119014, gnorm=0.963, train_wall=22, gb_free=7.1, wall=16149
2021-03-11 01:15:58 | INFO | train_inner | epoch 065:    108 / 1103 loss=3.035, nll_loss=1.482, ppl=2.79, wps=15773.5, ups=4.47, wpb=3526.4, bsz=129.7, num_updates=70700, lr=0.00011893, gnorm=0.968, train_wall=22, gb_free=6.9, wall=16171
2021-03-11 01:16:21 | INFO | train_inner | epoch 065:    208 / 1103 loss=3.045, nll_loss=1.496, ppl=2.82, wps=15925.1, ups=4.43, wpb=3598.4, bsz=146.8, num_updates=70800, lr=0.000118846, gnorm=0.966, train_wall=22, gb_free=6.8, wall=16194
2021-03-11 01:16:43 | INFO | train_inner | epoch 065:    308 / 1103 loss=3.055, nll_loss=1.507, ppl=2.84, wps=15971, ups=4.41, wpb=3617.7, bsz=139.2, num_updates=70900, lr=0.000118762, gnorm=0.959, train_wall=23, gb_free=6.9, wall=16216
2021-03-11 01:17:06 | INFO | train_inner | epoch 065:    408 / 1103 loss=3.047, nll_loss=1.496, ppl=2.82, wps=15761.5, ups=4.45, wpb=3545.5, bsz=135.7, num_updates=71000, lr=0.000118678, gnorm=0.962, train_wall=22, gb_free=6.8, wall=16239
2021-03-11 01:17:28 | INFO | train_inner | epoch 065:    508 / 1103 loss=3.051, nll_loss=1.505, ppl=2.84, wps=15779.4, ups=4.49, wpb=3515.3, bsz=151, num_updates=71100, lr=0.000118595, gnorm=0.964, train_wall=22, gb_free=6.8, wall=16261
2021-03-11 01:17:50 | INFO | train_inner | epoch 065:    608 / 1103 loss=3.087, nll_loss=1.546, ppl=2.92, wps=16290.7, ups=4.5, wpb=3619.7, bsz=148.1, num_updates=71200, lr=0.000118511, gnorm=0.96, train_wall=22, gb_free=6.9, wall=16283
2021-03-11 01:18:13 | INFO | train_inner | epoch 065:    708 / 1103 loss=3.066, nll_loss=1.521, ppl=2.87, wps=15930.8, ups=4.48, wpb=3555.9, bsz=151.8, num_updates=71300, lr=0.000118428, gnorm=0.966, train_wall=22, gb_free=7, wall=16306
2021-03-11 01:18:35 | INFO | train_inner | epoch 065:    808 / 1103 loss=3.085, nll_loss=1.542, ppl=2.91, wps=15792.3, ups=4.46, wpb=3542.4, bsz=136.2, num_updates=71400, lr=0.000118345, gnorm=0.99, train_wall=22, gb_free=7.5, wall=16328
2021-03-11 01:18:58 | INFO | train_inner | epoch 065:    908 / 1103 loss=3.068, nll_loss=1.526, ppl=2.88, wps=16142.5, ups=4.42, wpb=3655.8, bsz=158.9, num_updates=71500, lr=0.000118262, gnorm=0.947, train_wall=23, gb_free=7.2, wall=16351
2021-03-11 01:19:20 | INFO | train_inner | epoch 065:   1008 / 1103 loss=3.105, nll_loss=1.568, ppl=2.96, wps=15899.3, ups=4.47, wpb=3555.4, bsz=155, num_updates=71600, lr=0.00011818, gnorm=0.984, train_wall=22, gb_free=7.1, wall=16373
2021-03-11 01:19:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-11 01:19:45 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 3.972 | nll_loss 2.419 | ppl 5.35 | wps 48213.4 | wpb 2873.1 | bsz 115.6 | num_updates 71695 | best_loss 3.91
2021-03-11 01:19:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 65 @ 71695 updates
2021-03-11 01:19:45 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 01:19:47 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 01:19:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt (epoch 65 @ 71695 updates, score 3.972) (writing took 2.2210671454668045 seconds)
2021-03-11 01:19:47 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2021-03-11 01:19:47 | INFO | train | epoch 065 | loss 3.066 | nll_loss 1.521 | ppl 2.87 | wps 15549.3 | ups 4.35 | wpb 3577.8 | bsz 145.3 | num_updates 71695 | lr 0.000118102 | gnorm 0.965 | train_wall 246 | gb_free 7.5 | wall 16401
2021-03-11 01:19:47 | INFO | fairseq.trainer | begin training epoch 66
2021-03-11 01:19:47 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-11 01:19:49 | INFO | train_inner | epoch 066:      5 / 1103 loss=3.09, nll_loss=1.549, ppl=2.93, wps=12629.6, ups=3.49, wpb=3617.5, bsz=141.8, num_updates=71700, lr=0.000118097, gnorm=0.951, train_wall=22, gb_free=6.8, wall=16402
2021-03-11 01:20:11 | INFO | train_inner | epoch 066:    105 / 1103 loss=2.989, nll_loss=1.436, ppl=2.7, wps=16063.5, ups=4.44, wpb=3616.4, bsz=175.1, num_updates=71800, lr=0.000118015, gnorm=0.934, train_wall=22, gb_free=7.1, wall=16424
2021-03-11 01:20:34 | INFO | train_inner | epoch 066:    205 / 1103 loss=3.015, nll_loss=1.461, ppl=2.75, wps=15742.2, ups=4.44, wpb=3549.1, bsz=140.9, num_updates=71900, lr=0.000117933, gnorm=0.957, train_wall=22, gb_free=7, wall=16447
2021-03-11 01:20:56 | INFO | train_inner | epoch 066:    305 / 1103 loss=3.027, nll_loss=1.477, ppl=2.78, wps=15953.3, ups=4.44, wpb=3594.9, bsz=153.7, num_updates=72000, lr=0.000117851, gnorm=0.957, train_wall=22, gb_free=6.9, wall=16469
2021-03-11 01:21:19 | INFO | train_inner | epoch 066:    405 / 1103 loss=3.066, nll_loss=1.518, ppl=2.86, wps=15705, ups=4.44, wpb=3541, bsz=130.2, num_updates=72100, lr=0.000117769, gnorm=0.977, train_wall=22, gb_free=7.1, wall=16492
2021-03-11 01:21:41 | INFO | train_inner | epoch 066:    505 / 1103 loss=3.066, nll_loss=1.519, ppl=2.87, wps=15938.3, ups=4.5, wpb=3544.7, bsz=134.4, num_updates=72200, lr=0.000117688, gnorm=0.981, train_wall=22, gb_free=7, wall=16514
2021-03-11 01:22:03 | INFO | train_inner | epoch 066:    605 / 1103 loss=3.094, nll_loss=1.551, ppl=2.93, wps=16108.9, ups=4.48, wpb=3599.1, bsz=127.5, num_updates=72300, lr=0.000117606, gnorm=0.985, train_wall=22, gb_free=6.9, wall=16537
2021-03-11 01:22:26 | INFO | train_inner | epoch 066:    705 / 1103 loss=3.067, nll_loss=1.522, ppl=2.87, wps=16004.6, ups=4.44, wpb=3604.8, bsz=148.2, num_updates=72400, lr=0.000117525, gnorm=0.977, train_wall=22, gb_free=7, wall=16559
2021-03-11 01:22:48 | INFO | train_inner | epoch 066:    805 / 1103 loss=3.077, nll_loss=1.534, ppl=2.9, wps=16118.3, ups=4.45, wpb=3623.7, bsz=149, num_updates=72500, lr=0.000117444, gnorm=0.954, train_wall=22, gb_free=7, wall=16582
2021-03-11 01:23:11 | INFO | train_inner | epoch 066:    905 / 1103 loss=3.078, nll_loss=1.535, ppl=2.9, wps=15931.6, ups=4.45, wpb=3576.7, bsz=144.9, num_updates=72600, lr=0.000117363, gnorm=0.975, train_wall=22, gb_free=7, wall=16604
2021-03-11 01:23:33 | INFO | train_inner | epoch 066:   1005 / 1103 loss=3.074, nll_loss=1.531, ppl=2.89, wps=15855.7, ups=4.48, wpb=3537, bsz=148, num_updates=72700, lr=0.000117282, gnorm=0.964, train_wall=22, gb_free=6.9, wall=16626
2021-03-11 01:23:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-11 01:23:59 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 3.986 | nll_loss 2.43 | ppl 5.39 | wps 48154.4 | wpb 2873.1 | bsz 115.6 | num_updates 72798 | best_loss 3.91
2021-03-11 01:23:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 66 @ 72798 updates
2021-03-11 01:23:59 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 01:24:01 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 01:24:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt (epoch 66 @ 72798 updates, score 3.986) (writing took 2.222533155232668 seconds)
2021-03-11 01:24:01 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2021-03-11 01:24:01 | INFO | train | epoch 066 | loss 3.059 | nll_loss 1.513 | ppl 2.85 | wps 15558.3 | ups 4.35 | wpb 3577.8 | bsz 145.3 | num_updates 72798 | lr 0.000117203 | gnorm 0.967 | train_wall 246 | gb_free 7 | wall 16654
2021-03-11 01:24:01 | INFO | fairseq.trainer | begin training epoch 67
2021-03-11 01:24:01 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-11 01:24:02 | INFO | train_inner | epoch 067:      2 / 1103 loss=3.088, nll_loss=1.548, ppl=2.92, wps=12521, ups=3.51, wpb=3568, bsz=148, num_updates=72800, lr=0.000117202, gnorm=0.974, train_wall=22, gb_free=7, wall=16655
2021-03-11 01:24:24 | INFO | train_inner | epoch 067:    102 / 1103 loss=2.992, nll_loss=1.436, ppl=2.71, wps=15940, ups=4.47, wpb=3566.3, bsz=157, num_updates=72900, lr=0.000117121, gnorm=0.945, train_wall=22, gb_free=6.9, wall=16677
2021-03-11 01:24:46 | INFO | train_inner | epoch 067:    202 / 1103 loss=3.058, nll_loss=1.51, ppl=2.85, wps=16198.2, ups=4.46, wpb=3628.5, bsz=139.5, num_updates=73000, lr=0.000117041, gnorm=0.953, train_wall=22, gb_free=6.9, wall=16700
2021-03-11 01:25:09 | INFO | train_inner | epoch 067:    302 / 1103 loss=3.028, nll_loss=1.476, ppl=2.78, wps=15854.9, ups=4.44, wpb=3567.7, bsz=147.2, num_updates=73100, lr=0.000116961, gnorm=0.962, train_wall=22, gb_free=7.1, wall=16722
2021-03-11 01:25:31 | INFO | train_inner | epoch 067:    402 / 1103 loss=3.01, nll_loss=1.457, ppl=2.74, wps=15809.2, ups=4.44, wpb=3563.1, bsz=149.7, num_updates=73200, lr=0.000116881, gnorm=0.958, train_wall=22, gb_free=7.2, wall=16745
2021-03-11 01:25:54 | INFO | train_inner | epoch 067:    502 / 1103 loss=3.053, nll_loss=1.505, ppl=2.84, wps=15964.3, ups=4.42, wpb=3613.2, bsz=141, num_updates=73300, lr=0.000116801, gnorm=0.968, train_wall=23, gb_free=7, wall=16767
2021-03-11 01:26:16 | INFO | train_inner | epoch 067:    602 / 1103 loss=3.056, nll_loss=1.509, ppl=2.85, wps=15764.3, ups=4.49, wpb=3514.4, bsz=147.3, num_updates=73400, lr=0.000116722, gnorm=0.988, train_wall=22, gb_free=7.8, wall=16790
2021-03-11 01:26:39 | INFO | train_inner | epoch 067:    702 / 1103 loss=3.07, nll_loss=1.525, ppl=2.88, wps=15897.2, ups=4.46, wpb=3564.9, bsz=142.1, num_updates=73500, lr=0.000116642, gnorm=0.972, train_wall=22, gb_free=7.1, wall=16812
2021-03-11 01:27:01 | INFO | train_inner | epoch 067:    802 / 1103 loss=3.06, nll_loss=1.517, ppl=2.86, wps=16037.6, ups=4.44, wpb=3611.1, bsz=159.3, num_updates=73600, lr=0.000116563, gnorm=0.972, train_wall=22, gb_free=7, wall=16835
2021-03-11 01:27:24 | INFO | train_inner | epoch 067:    902 / 1103 loss=3.078, nll_loss=1.534, ppl=2.9, wps=15736.6, ups=4.49, wpb=3501, bsz=136, num_updates=73700, lr=0.000116484, gnorm=1, train_wall=22, gb_free=7, wall=16857
2021-03-11 01:27:46 | INFO | train_inner | epoch 067:   1002 / 1103 loss=3.097, nll_loss=1.556, ppl=2.94, wps=16063.5, ups=4.44, wpb=3614.1, bsz=140.4, num_updates=73800, lr=0.000116405, gnorm=0.968, train_wall=22, gb_free=7.2, wall=16879
2021-03-11 01:28:09 | INFO | train_inner | epoch 067:   1102 / 1103 loss=3.087, nll_loss=1.545, ppl=2.92, wps=16091.9, ups=4.47, wpb=3603.5, bsz=138, num_updates=73900, lr=0.000116326, gnorm=0.964, train_wall=22, gb_free=6.8, wall=16902
2021-03-11 01:28:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-11 01:28:13 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 3.992 | nll_loss 2.436 | ppl 5.41 | wps 48179.7 | wpb 2873.1 | bsz 115.6 | num_updates 73901 | best_loss 3.91
2021-03-11 01:28:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 67 @ 73901 updates
2021-03-11 01:28:13 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 01:28:15 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 01:28:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt (epoch 67 @ 73901 updates, score 3.992) (writing took 2.182992424815893 seconds)
2021-03-11 01:28:15 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2021-03-11 01:28:15 | INFO | train | epoch 067 | loss 3.053 | nll_loss 1.506 | ppl 2.84 | wps 15555.6 | ups 4.35 | wpb 3577.8 | bsz 145.3 | num_updates 73901 | lr 0.000116325 | gnorm 0.968 | train_wall 246 | gb_free 6.8 | wall 16908
2021-03-11 01:28:15 | INFO | fairseq.trainer | begin training epoch 68
2021-03-11 01:28:15 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-11 01:28:37 | INFO | train_inner | epoch 068:     99 / 1103 loss=3.003, nll_loss=1.447, ppl=2.73, wps=12445.4, ups=3.5, wpb=3555.8, bsz=148.8, num_updates=74000, lr=0.000116248, gnorm=0.963, train_wall=22, gb_free=6.9, wall=16930
2021-03-11 01:29:00 | INFO | train_inner | epoch 068:    199 / 1103 loss=3.021, nll_loss=1.469, ppl=2.77, wps=16085.2, ups=4.44, wpb=3626.3, bsz=155.6, num_updates=74100, lr=0.000116169, gnorm=0.947, train_wall=22, gb_free=7.1, wall=16953
2021-03-11 01:29:22 | INFO | train_inner | epoch 068:    299 / 1103 loss=3.05, nll_loss=1.501, ppl=2.83, wps=16039.2, ups=4.48, wpb=3579.5, bsz=142.3, num_updates=74200, lr=0.000116091, gnorm=0.976, train_wall=22, gb_free=7, wall=16975
2021-03-11 01:29:45 | INFO | train_inner | epoch 068:    399 / 1103 loss=3.027, nll_loss=1.475, ppl=2.78, wps=15926.8, ups=4.42, wpb=3604, bsz=138.9, num_updates=74300, lr=0.000116013, gnorm=0.962, train_wall=23, gb_free=6.9, wall=16998
2021-03-11 01:30:07 | INFO | train_inner | epoch 068:    499 / 1103 loss=3.014, nll_loss=1.462, ppl=2.76, wps=15824.6, ups=4.49, wpb=3528.1, bsz=156.8, num_updates=74400, lr=0.000115935, gnorm=0.983, train_wall=22, gb_free=7.5, wall=17020
2021-03-11 01:30:29 | INFO | train_inner | epoch 068:    599 / 1103 loss=3.054, nll_loss=1.506, ppl=2.84, wps=15807.6, ups=4.47, wpb=3535.2, bsz=144.2, num_updates=74500, lr=0.000115857, gnorm=0.977, train_wall=22, gb_free=7.3, wall=17042
2021-03-11 01:30:52 | INFO | train_inner | epoch 068:    699 / 1103 loss=3.025, nll_loss=1.476, ppl=2.78, wps=15928, ups=4.46, wpb=3572, bsz=161.6, num_updates=74600, lr=0.000115779, gnorm=0.96, train_wall=22, gb_free=6.9, wall=17065
2021-03-11 01:31:14 | INFO | train_inner | epoch 068:    799 / 1103 loss=3.066, nll_loss=1.523, ppl=2.87, wps=16121.3, ups=4.47, wpb=3607, bsz=152.7, num_updates=74700, lr=0.000115702, gnorm=0.975, train_wall=22, gb_free=7.1, wall=17087
2021-03-11 01:31:36 | INFO | train_inner | epoch 068:    899 / 1103 loss=3.073, nll_loss=1.527, ppl=2.88, wps=15757.1, ups=4.48, wpb=3513.8, bsz=128.2, num_updates=74800, lr=0.000115624, gnorm=0.99, train_wall=22, gb_free=7.1, wall=17109
2021-03-11 01:31:59 | INFO | train_inner | epoch 068:    999 / 1103 loss=3.123, nll_loss=1.584, ppl=3, wps=16163.1, ups=4.46, wpb=3623, bsz=125.4, num_updates=74900, lr=0.000115547, gnorm=0.995, train_wall=22, gb_free=7.3, wall=17132
2021-03-11 01:32:21 | INFO | train_inner | epoch 068:   1099 / 1103 loss=3.069, nll_loss=1.525, ppl=2.88, wps=16068.5, ups=4.45, wpb=3609.9, bsz=144.2, num_updates=75000, lr=0.00011547, gnorm=0.992, train_wall=22, gb_free=7, wall=17154
2021-03-11 01:32:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-11 01:32:26 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 3.975 | nll_loss 2.419 | ppl 5.35 | wps 48175.2 | wpb 2873.1 | bsz 115.6 | num_updates 75004 | best_loss 3.91
2021-03-11 01:32:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 68 @ 75004 updates
2021-03-11 01:32:26 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 01:32:28 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 01:32:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt (epoch 68 @ 75004 updates, score 3.975) (writing took 2.073491208255291 seconds)
2021-03-11 01:32:28 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2021-03-11 01:32:28 | INFO | train | epoch 068 | loss 3.048 | nll_loss 1.5 | ppl 2.83 | wps 15584.2 | ups 4.36 | wpb 3577.8 | bsz 145.3 | num_updates 75004 | lr 0.000115467 | gnorm 0.975 | train_wall 246 | gb_free 6.6 | wall 17161
2021-03-11 01:32:28 | INFO | fairseq.trainer | begin training epoch 69
2021-03-11 01:32:28 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-11 01:32:50 | INFO | train_inner | epoch 069:     96 / 1103 loss=3.027, nll_loss=1.473, ppl=2.78, wps=12598.1, ups=3.49, wpb=3608.3, bsz=133.9, num_updates=75100, lr=0.000115393, gnorm=0.959, train_wall=22, gb_free=7.2, wall=17183
2021-03-11 01:33:12 | INFO | train_inner | epoch 069:    196 / 1103 loss=2.996, nll_loss=1.442, ppl=2.72, wps=16008.2, ups=4.49, wpb=3563.2, bsz=164.2, num_updates=75200, lr=0.000115316, gnorm=0.953, train_wall=22, gb_free=6.8, wall=17205
2021-03-11 01:33:35 | INFO | train_inner | epoch 069:    296 / 1103 loss=3.036, nll_loss=1.484, ppl=2.8, wps=16045.1, ups=4.46, wpb=3599.1, bsz=138.2, num_updates=75300, lr=0.00011524, gnorm=0.972, train_wall=22, gb_free=7.5, wall=17228
2021-03-11 01:33:57 | INFO | train_inner | epoch 069:    396 / 1103 loss=3.028, nll_loss=1.475, ppl=2.78, wps=15746.2, ups=4.48, wpb=3512.9, bsz=140.4, num_updates=75400, lr=0.000115163, gnorm=0.986, train_wall=22, gb_free=6.9, wall=17250
2021-03-11 01:34:20 | INFO | train_inner | epoch 069:    496 / 1103 loss=3.034, nll_loss=1.483, ppl=2.8, wps=15823.3, ups=4.4, wpb=3593.4, bsz=145, num_updates=75500, lr=0.000115087, gnorm=0.969, train_wall=23, gb_free=7.2, wall=17273
2021-03-11 01:34:42 | INFO | train_inner | epoch 069:    596 / 1103 loss=3.042, nll_loss=1.494, ppl=2.82, wps=16007.3, ups=4.43, wpb=3611.1, bsz=155, num_updates=75600, lr=0.000115011, gnorm=0.967, train_wall=22, gb_free=7.1, wall=17295
2021-03-11 01:35:05 | INFO | train_inner | epoch 069:    696 / 1103 loss=3.052, nll_loss=1.503, ppl=2.83, wps=15926.1, ups=4.45, wpb=3580.3, bsz=136.6, num_updates=75700, lr=0.000114935, gnorm=0.974, train_wall=22, gb_free=6.8, wall=17318
2021-03-11 01:35:27 | INFO | train_inner | epoch 069:    796 / 1103 loss=3.063, nll_loss=1.516, ppl=2.86, wps=15896.8, ups=4.45, wpb=3569.5, bsz=141.6, num_updates=75800, lr=0.000114859, gnorm=0.984, train_wall=22, gb_free=7.1, wall=17340
2021-03-11 01:35:50 | INFO | train_inner | epoch 069:    896 / 1103 loss=3.038, nll_loss=1.49, ppl=2.81, wps=15887, ups=4.45, wpb=3566.8, bsz=149.7, num_updates=75900, lr=0.000114783, gnorm=0.997, train_wall=22, gb_free=6.9, wall=17363
2021-03-11 01:36:12 | INFO | train_inner | epoch 069:    996 / 1103 loss=3.079, nll_loss=1.537, ppl=2.9, wps=15986, ups=4.46, wpb=3583.3, bsz=144.4, num_updates=76000, lr=0.000114708, gnorm=0.986, train_wall=22, gb_free=7.2, wall=17385
2021-03-11 01:36:34 | INFO | train_inner | epoch 069:   1096 / 1103 loss=3.073, nll_loss=1.529, ppl=2.89, wps=16032.4, ups=4.47, wpb=3587.8, bsz=148.5, num_updates=76100, lr=0.000114632, gnorm=0.974, train_wall=22, gb_free=6.9, wall=17407
2021-03-11 01:36:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-11 01:36:40 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 3.994 | nll_loss 2.441 | ppl 5.43 | wps 48287.4 | wpb 2873.1 | bsz 115.6 | num_updates 76107 | best_loss 3.91
2021-03-11 01:36:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 69 @ 76107 updates
2021-03-11 01:36:40 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 01:36:42 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 01:36:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt (epoch 69 @ 76107 updates, score 3.994) (writing took 2.0525691360235214 seconds)
2021-03-11 01:36:42 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2021-03-11 01:36:42 | INFO | train | epoch 069 | loss 3.042 | nll_loss 1.493 | ppl 2.81 | wps 15558.2 | ups 4.35 | wpb 3577.8 | bsz 145.3 | num_updates 76107 | lr 0.000114627 | gnorm 0.975 | train_wall 246 | gb_free 7.1 | wall 17415
2021-03-11 01:36:42 | INFO | fairseq.trainer | begin training epoch 70
2021-03-11 01:36:42 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-11 01:37:02 | INFO | train_inner | epoch 070:     93 / 1103 loss=3.018, nll_loss=1.463, ppl=2.76, wps=12391.2, ups=3.59, wpb=3453.2, bsz=129.9, num_updates=76200, lr=0.000114557, gnorm=1.023, train_wall=22, gb_free=7.1, wall=17435
2021-03-11 01:37:24 | INFO | train_inner | epoch 070:    193 / 1103 loss=2.996, nll_loss=1.441, ppl=2.71, wps=16205.2, ups=4.49, wpb=3607.8, bsz=157.5, num_updates=76300, lr=0.000114482, gnorm=0.942, train_wall=22, gb_free=7.1, wall=17458
2021-03-11 01:37:47 | INFO | train_inner | epoch 070:    293 / 1103 loss=3.007, nll_loss=1.452, ppl=2.74, wps=16010.4, ups=4.42, wpb=3619.1, bsz=144.1, num_updates=76400, lr=0.000114407, gnorm=0.949, train_wall=22, gb_free=7.5, wall=17480
2021-03-11 01:38:09 | INFO | train_inner | epoch 070:    393 / 1103 loss=3.04, nll_loss=1.488, ppl=2.81, wps=15854.2, ups=4.47, wpb=3545.7, bsz=135.9, num_updates=76500, lr=0.000114332, gnorm=1.005, train_wall=22, gb_free=6.9, wall=17503
2021-03-11 01:38:32 | INFO | train_inner | epoch 070:    493 / 1103 loss=3.032, nll_loss=1.482, ppl=2.79, wps=15960.5, ups=4.43, wpb=3601.3, bsz=150.2, num_updates=76600, lr=0.000114258, gnorm=0.974, train_wall=22, gb_free=6.9, wall=17525
2021-03-11 01:38:54 | INFO | train_inner | epoch 070:    593 / 1103 loss=3.052, nll_loss=1.503, ppl=2.83, wps=15828.4, ups=4.46, wpb=3550.8, bsz=137.5, num_updates=76700, lr=0.000114183, gnorm=0.99, train_wall=22, gb_free=7.1, wall=17548
2021-03-11 01:39:17 | INFO | train_inner | epoch 070:    693 / 1103 loss=3.012, nll_loss=1.458, ppl=2.75, wps=15626.2, ups=4.49, wpb=3478.2, bsz=152.9, num_updates=76800, lr=0.000114109, gnorm=1.003, train_wall=22, gb_free=6.9, wall=17570
2021-03-11 01:39:39 | INFO | train_inner | epoch 070:    793 / 1103 loss=3.07, nll_loss=1.526, ppl=2.88, wps=16350.9, ups=4.46, wpb=3667.2, bsz=147.7, num_updates=76900, lr=0.000114035, gnorm=0.97, train_wall=22, gb_free=7, wall=17592
2021-03-11 01:40:02 | INFO | train_inner | epoch 070:    893 / 1103 loss=3.047, nll_loss=1.499, ppl=2.83, wps=15969, ups=4.46, wpb=3583.3, bsz=143.8, num_updates=77000, lr=0.000113961, gnorm=0.976, train_wall=22, gb_free=7.1, wall=17615
2021-03-11 01:40:24 | INFO | train_inner | epoch 070:    993 / 1103 loss=3.057, nll_loss=1.512, ppl=2.85, wps=16276.9, ups=4.52, wpb=3602.9, bsz=148.4, num_updates=77100, lr=0.000113887, gnorm=0.977, train_wall=22, gb_free=6.9, wall=17637
2021-03-11 01:40:46 | INFO | train_inner | epoch 070:   1093 / 1103 loss=3.057, nll_loss=1.512, ppl=2.85, wps=16329.1, ups=4.51, wpb=3624.2, bsz=147.8, num_updates=77200, lr=0.000113813, gnorm=0.969, train_wall=22, gb_free=7, wall=17659
2021-03-11 01:40:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-11 01:40:52 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 3.988 | nll_loss 2.437 | ppl 5.41 | wps 48214 | wpb 2873.1 | bsz 115.6 | num_updates 77210 | best_loss 3.91
2021-03-11 01:40:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 70 @ 77210 updates
2021-03-11 01:40:52 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 01:40:54 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 01:40:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt (epoch 70 @ 77210 updates, score 3.988) (writing took 2.052996013313532 seconds)
2021-03-11 01:40:54 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2021-03-11 01:40:54 | INFO | train | epoch 070 | loss 3.036 | nll_loss 1.486 | ppl 2.8 | wps 15647.3 | ups 4.37 | wpb 3577.8 | bsz 145.3 | num_updates 77210 | lr 0.000113805 | gnorm 0.98 | train_wall 245 | gb_free 6.8 | wall 17667
2021-03-11 01:40:54 | INFO | fairseq.trainer | begin training epoch 71
2021-03-11 01:40:54 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-11 01:41:14 | INFO | train_inner | epoch 071:     90 / 1103 loss=3.048, nll_loss=1.496, ppl=2.82, wps=12648.5, ups=3.54, wpb=3569.8, bsz=125.3, num_updates=77300, lr=0.000113739, gnorm=0.999, train_wall=22, gb_free=7, wall=17687
2021-03-11 01:41:37 | INFO | train_inner | epoch 071:    190 / 1103 loss=3.026, nll_loss=1.474, ppl=2.78, wps=16155.7, ups=4.45, wpb=3631, bsz=145, num_updates=77400, lr=0.000113666, gnorm=0.964, train_wall=22, gb_free=6.7, wall=17710
2021-03-11 01:41:59 | INFO | train_inner | epoch 071:    290 / 1103 loss=2.997, nll_loss=1.44, ppl=2.71, wps=15950.3, ups=4.44, wpb=3593.5, bsz=148, num_updates=77500, lr=0.000113592, gnorm=0.959, train_wall=22, gb_free=7.1, wall=17732
2021-03-11 01:42:22 | INFO | train_inner | epoch 071:    390 / 1103 loss=3.031, nll_loss=1.479, ppl=2.79, wps=16123.6, ups=4.43, wpb=3638.8, bsz=142.6, num_updates=77600, lr=0.000113519, gnorm=0.976, train_wall=22, gb_free=7.2, wall=17755
2021-03-11 01:42:44 | INFO | train_inner | epoch 071:    490 / 1103 loss=3.019, nll_loss=1.467, ppl=2.76, wps=15953.1, ups=4.44, wpb=3592.7, bsz=149.8, num_updates=77700, lr=0.000113446, gnorm=0.97, train_wall=22, gb_free=6.8, wall=17777
2021-03-11 01:43:06 | INFO | train_inner | epoch 071:    590 / 1103 loss=3.029, nll_loss=1.477, ppl=2.78, wps=15908.2, ups=4.49, wpb=3546.2, bsz=136.1, num_updates=77800, lr=0.000113373, gnorm=0.988, train_wall=22, gb_free=6.8, wall=17800
2021-03-11 01:43:29 | INFO | train_inner | epoch 071:    690 / 1103 loss=3.043, nll_loss=1.494, ppl=2.82, wps=16040.1, ups=4.42, wpb=3632.1, bsz=145.8, num_updates=77900, lr=0.0001133, gnorm=0.966, train_wall=23, gb_free=7, wall=17822
2021-03-11 01:43:52 | INFO | train_inner | epoch 071:    790 / 1103 loss=3.039, nll_loss=1.49, ppl=2.81, wps=15986, ups=4.44, wpb=3602.7, bsz=150.9, num_updates=78000, lr=0.000113228, gnorm=0.977, train_wall=22, gb_free=7, wall=17845
2021-03-11 01:44:14 | INFO | train_inner | epoch 071:    890 / 1103 loss=3.014, nll_loss=1.464, ppl=2.76, wps=15748.9, ups=4.5, wpb=3498.1, bsz=171.1, num_updates=78100, lr=0.000113155, gnorm=0.977, train_wall=22, gb_free=7.7, wall=17867
2021-03-11 01:44:36 | INFO | train_inner | epoch 071:    990 / 1103 loss=3.054, nll_loss=1.506, ppl=2.84, wps=15853.3, ups=4.45, wpb=3565.7, bsz=136.6, num_updates=78200, lr=0.000113083, gnorm=0.989, train_wall=22, gb_free=7, wall=17889
2021-03-11 01:44:59 | INFO | train_inner | epoch 071:   1090 / 1103 loss=3.033, nll_loss=1.484, ppl=2.8, wps=15747.1, ups=4.47, wpb=3526.7, bsz=155.7, num_updates=78300, lr=0.000113011, gnorm=0.994, train_wall=22, gb_free=6.7, wall=17912
2021-03-11 01:45:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-11 01:45:05 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 3.994 | nll_loss 2.441 | ppl 5.43 | wps 48259.3 | wpb 2873.1 | bsz 115.6 | num_updates 78313 | best_loss 3.91
2021-03-11 01:45:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 71 @ 78313 updates
2021-03-11 01:45:05 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 01:45:07 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 01:45:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt (epoch 71 @ 78313 updates, score 3.994) (writing took 2.190216187387705 seconds)
2021-03-11 01:45:07 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2021-03-11 01:45:07 | INFO | train | epoch 071 | loss 3.03 | nll_loss 1.479 | ppl 2.79 | wps 15560.4 | ups 4.35 | wpb 3577.8 | bsz 145.3 | num_updates 78313 | lr 0.000113001 | gnorm 0.98 | train_wall 246 | gb_free 6.9 | wall 17921
2021-03-11 01:45:08 | INFO | fairseq.trainer | begin training epoch 72
2021-03-11 01:45:08 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-11 01:45:27 | INFO | train_inner | epoch 072:     87 / 1103 loss=3.038, nll_loss=1.485, ppl=2.8, wps=12541.6, ups=3.52, wpb=3563.1, bsz=124.5, num_updates=78400, lr=0.000112938, gnorm=1.006, train_wall=22, gb_free=7, wall=17940
2021-03-11 01:45:50 | INFO | train_inner | epoch 072:    187 / 1103 loss=3.005, nll_loss=1.449, ppl=2.73, wps=16054.8, ups=4.44, wpb=3618.9, bsz=149.9, num_updates=78500, lr=0.000112867, gnorm=0.963, train_wall=22, gb_free=7.2, wall=17963
2021-03-11 01:46:12 | INFO | train_inner | epoch 072:    287 / 1103 loss=2.999, nll_loss=1.443, ppl=2.72, wps=15835.6, ups=4.45, wpb=3560, bsz=144.4, num_updates=78600, lr=0.000112795, gnorm=0.975, train_wall=22, gb_free=7.5, wall=17985
2021-03-11 01:46:34 | INFO | train_inner | epoch 072:    387 / 1103 loss=3.027, nll_loss=1.474, ppl=2.78, wps=16023, ups=4.49, wpb=3570.8, bsz=136.1, num_updates=78700, lr=0.000112723, gnorm=0.996, train_wall=22, gb_free=7.6, wall=18008
2021-03-11 01:46:57 | INFO | train_inner | epoch 072:    487 / 1103 loss=3.016, nll_loss=1.461, ppl=2.75, wps=15751.9, ups=4.51, wpb=3494.8, bsz=142, num_updates=78800, lr=0.000112651, gnorm=0.992, train_wall=22, gb_free=7, wall=18030
2021-03-11 01:47:19 | INFO | train_inner | epoch 072:    587 / 1103 loss=2.999, nll_loss=1.447, ppl=2.73, wps=16135.7, ups=4.43, wpb=3642.9, bsz=170, num_updates=78900, lr=0.00011258, gnorm=0.96, train_wall=22, gb_free=7.6, wall=18052
2021-03-11 01:47:42 | INFO | train_inner | epoch 072:    687 / 1103 loss=3.035, nll_loss=1.486, ppl=2.8, wps=16199.8, ups=4.46, wpb=3633.6, bsz=157.7, num_updates=79000, lr=0.000112509, gnorm=0.973, train_wall=22, gb_free=7.1, wall=18075
2021-03-11 01:48:04 | INFO | train_inner | epoch 072:    787 / 1103 loss=3.019, nll_loss=1.468, ppl=2.77, wps=15879.9, ups=4.44, wpb=3579.3, bsz=159.1, num_updates=79100, lr=0.000112438, gnorm=0.968, train_wall=22, gb_free=7.2, wall=18097
2021-03-11 01:48:27 | INFO | train_inner | epoch 072:    887 / 1103 loss=3.056, nll_loss=1.509, ppl=2.85, wps=15933.9, ups=4.46, wpb=3572.1, bsz=148.6, num_updates=79200, lr=0.000112367, gnorm=0.994, train_wall=22, gb_free=7, wall=18120
2021-03-11 01:48:49 | INFO | train_inner | epoch 072:    987 / 1103 loss=3.051, nll_loss=1.5, ppl=2.83, wps=15554.9, ups=4.47, wpb=3478.7, bsz=124.3, num_updates=79300, lr=0.000112296, gnorm=1.021, train_wall=22, gb_free=7.2, wall=18142
2021-03-11 01:49:11 | INFO | train_inner | epoch 072:   1087 / 1103 loss=3.051, nll_loss=1.503, ppl=2.83, wps=15994.6, ups=4.46, wpb=3584.2, bsz=132.2, num_updates=79400, lr=0.000112225, gnorm=0.999, train_wall=22, gb_free=6.8, wall=18165
2021-03-11 01:49:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-11 01:49:19 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 4 | nll_loss 2.446 | ppl 5.45 | wps 48175.7 | wpb 2873.1 | bsz 115.6 | num_updates 79416 | best_loss 3.91
2021-03-11 01:49:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 72 @ 79416 updates
2021-03-11 01:49:19 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 01:49:21 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 01:49:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt (epoch 72 @ 79416 updates, score 4.0) (writing took 2.131737008690834 seconds)
2021-03-11 01:49:21 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2021-03-11 01:49:21 | INFO | train | epoch 072 | loss 3.026 | nll_loss 1.474 | ppl 2.78 | wps 15568.3 | ups 4.35 | wpb 3577.8 | bsz 145.3 | num_updates 79416 | lr 0.000112214 | gnorm 0.983 | train_wall 246 | gb_free 6.9 | wall 18174
2021-03-11 01:49:21 | INFO | fairseq.trainer | begin training epoch 73
2021-03-11 01:49:21 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-11 01:49:40 | INFO | train_inner | epoch 073:     84 / 1103 loss=3.004, nll_loss=1.447, ppl=2.73, wps=12666.3, ups=3.5, wpb=3620.6, bsz=139.5, num_updates=79500, lr=0.000112154, gnorm=0.965, train_wall=22, gb_free=7, wall=18193
2021-03-11 01:50:02 | INFO | train_inner | epoch 073:    184 / 1103 loss=3.011, nll_loss=1.456, ppl=2.74, wps=16006.5, ups=4.48, wpb=3573, bsz=144.6, num_updates=79600, lr=0.000112084, gnorm=0.974, train_wall=22, gb_free=7, wall=18215
2021-03-11 01:50:25 | INFO | train_inner | epoch 073:    284 / 1103 loss=3.011, nll_loss=1.456, ppl=2.74, wps=15927.6, ups=4.44, wpb=3586.5, bsz=142.2, num_updates=79700, lr=0.000112014, gnorm=0.98, train_wall=22, gb_free=7, wall=18238
2021-03-11 01:50:47 | INFO | train_inner | epoch 073:    384 / 1103 loss=3.004, nll_loss=1.449, ppl=2.73, wps=15937.4, ups=4.42, wpb=3606.1, bsz=148, num_updates=79800, lr=0.000111943, gnorm=0.97, train_wall=23, gb_free=6.9, wall=18261
2021-03-11 01:51:10 | INFO | train_inner | epoch 073:    484 / 1103 loss=3.014, nll_loss=1.461, ppl=2.75, wps=15918.6, ups=4.44, wpb=3587.3, bsz=149.1, num_updates=79900, lr=0.000111873, gnorm=0.987, train_wall=22, gb_free=6.9, wall=18283
2021-03-11 01:51:32 | INFO | train_inner | epoch 073:    584 / 1103 loss=3.045, nll_loss=1.496, ppl=2.82, wps=16055.1, ups=4.47, wpb=3593.3, bsz=137, num_updates=80000, lr=0.000111803, gnorm=0.996, train_wall=22, gb_free=6.8, wall=18306
2021-03-11 01:51:55 | INFO | train_inner | epoch 073:    684 / 1103 loss=3.028, nll_loss=1.476, ppl=2.78, wps=15936.8, ups=4.46, wpb=3576.5, bsz=146.1, num_updates=80100, lr=0.000111734, gnorm=0.993, train_wall=22, gb_free=6.9, wall=18328
2021-03-11 01:52:17 | INFO | train_inner | epoch 073:    784 / 1103 loss=3.019, nll_loss=1.468, ppl=2.77, wps=15942.1, ups=4.45, wpb=3578.8, bsz=155.4, num_updates=80200, lr=0.000111664, gnorm=0.991, train_wall=22, gb_free=7.4, wall=18350
2021-03-11 01:52:39 | INFO | train_inner | epoch 073:    884 / 1103 loss=3.026, nll_loss=1.476, ppl=2.78, wps=15944.3, ups=4.5, wpb=3542.9, bsz=155.4, num_updates=80300, lr=0.000111594, gnorm=1.017, train_wall=22, gb_free=7, wall=18373
2021-03-11 01:53:02 | INFO | train_inner | epoch 073:    984 / 1103 loss=3.021, nll_loss=1.469, ppl=2.77, wps=15792.9, ups=4.46, wpb=3540.2, bsz=149.7, num_updates=80400, lr=0.000111525, gnorm=0.985, train_wall=22, gb_free=7, wall=18395
2021-03-11 01:53:24 | INFO | train_inner | epoch 073:   1084 / 1103 loss=3.031, nll_loss=1.479, ppl=2.79, wps=16012.8, ups=4.49, wpb=3563.8, bsz=136.6, num_updates=80500, lr=0.000111456, gnorm=0.994, train_wall=22, gb_free=6.9, wall=18417
2021-03-11 01:53:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-11 01:53:32 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 3.994 | nll_loss 2.445 | ppl 5.44 | wps 48250.8 | wpb 2873.1 | bsz 115.6 | num_updates 80519 | best_loss 3.91
2021-03-11 01:53:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 73 @ 80519 updates
2021-03-11 01:53:32 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 01:53:34 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 01:53:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt (epoch 73 @ 80519 updates, score 3.994) (writing took 2.051988083869219 seconds)
2021-03-11 01:53:34 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2021-03-11 01:53:34 | INFO | train | epoch 073 | loss 3.02 | nll_loss 1.468 | ppl 2.77 | wps 15586.1 | ups 4.36 | wpb 3577.8 | bsz 145.3 | num_updates 80519 | lr 0.000111442 | gnorm 0.988 | train_wall 246 | gb_free 7.3 | wall 18427
2021-03-11 01:53:34 | INFO | fairseq.trainer | begin training epoch 74
2021-03-11 01:53:34 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-11 01:53:52 | INFO | train_inner | epoch 074:     81 / 1103 loss=2.991, nll_loss=1.434, ppl=2.7, wps=12506.8, ups=3.57, wpb=3498.8, bsz=148, num_updates=80600, lr=0.000111386, gnorm=1.008, train_wall=22, gb_free=7, wall=18445
2021-03-11 01:54:15 | INFO | train_inner | epoch 074:    181 / 1103 loss=2.99, nll_loss=1.433, ppl=2.7, wps=16035.8, ups=4.41, wpb=3639, bsz=147, num_updates=80700, lr=0.000111317, gnorm=0.966, train_wall=23, gb_free=6.9, wall=18468
2021-03-11 01:54:37 | INFO | train_inner | epoch 074:    281 / 1103 loss=2.989, nll_loss=1.432, ppl=2.7, wps=15960.8, ups=4.43, wpb=3606.9, bsz=150, num_updates=80800, lr=0.000111249, gnorm=0.968, train_wall=22, gb_free=7.2, wall=18491
2021-03-11 01:55:00 | INFO | train_inner | epoch 074:    381 / 1103 loss=3.032, nll_loss=1.48, ppl=2.79, wps=16201.8, ups=4.46, wpb=3631.5, bsz=139.9, num_updates=80900, lr=0.00011118, gnorm=0.989, train_wall=22, gb_free=7.3, wall=18513
2021-03-11 01:55:22 | INFO | train_inner | epoch 074:    481 / 1103 loss=3.02, nll_loss=1.466, ppl=2.76, wps=15896.1, ups=4.46, wpb=3560.3, bsz=138.4, num_updates=81000, lr=0.000111111, gnorm=0.997, train_wall=22, gb_free=7.1, wall=18535
2021-03-11 01:55:45 | INFO | train_inner | epoch 074:    581 / 1103 loss=3.011, nll_loss=1.458, ppl=2.75, wps=15910.6, ups=4.45, wpb=3576.3, bsz=153.9, num_updates=81100, lr=0.000111043, gnorm=0.979, train_wall=22, gb_free=7.1, wall=18558
2021-03-11 01:56:07 | INFO | train_inner | epoch 074:    681 / 1103 loss=2.992, nll_loss=1.435, ppl=2.7, wps=15705.9, ups=4.43, wpb=3542.6, bsz=154.3, num_updates=81200, lr=0.000110974, gnorm=0.988, train_wall=22, gb_free=7.1, wall=18580
2021-03-11 01:56:30 | INFO | train_inner | epoch 074:    781 / 1103 loss=3.031, nll_loss=1.477, ppl=2.78, wps=15818, ups=4.46, wpb=3542.9, bsz=133.6, num_updates=81300, lr=0.000110906, gnorm=1.012, train_wall=22, gb_free=7, wall=18603
2021-03-11 01:56:52 | INFO | train_inner | epoch 074:    881 / 1103 loss=3.018, nll_loss=1.464, ppl=2.76, wps=15694.6, ups=4.43, wpb=3543.4, bsz=140.5, num_updates=81400, lr=0.000110838, gnorm=0.995, train_wall=22, gb_free=6.9, wall=18625
2021-03-11 01:57:15 | INFO | train_inner | epoch 074:    981 / 1103 loss=3.055, nll_loss=1.508, ppl=2.84, wps=16190.5, ups=4.45, wpb=3639.1, bsz=145.1, num_updates=81500, lr=0.00011077, gnorm=0.976, train_wall=22, gb_free=6.9, wall=18648
2021-03-11 01:57:37 | INFO | train_inner | epoch 074:   1081 / 1103 loss=3.044, nll_loss=1.495, ppl=2.82, wps=16037.2, ups=4.47, wpb=3588.2, bsz=144.6, num_updates=81600, lr=0.000110702, gnorm=1.001, train_wall=22, gb_free=7.1, wall=18670
2021-03-11 01:57:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-11 01:57:46 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 4.007 | nll_loss 2.456 | ppl 5.49 | wps 48213.9 | wpb 2873.1 | bsz 115.6 | num_updates 81622 | best_loss 3.91
2021-03-11 01:57:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 74 @ 81622 updates
2021-03-11 01:57:46 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 01:57:48 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 01:57:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt (epoch 74 @ 81622 updates, score 4.007) (writing took 2.058373052626848 seconds)
2021-03-11 01:57:48 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2021-03-11 01:57:48 | INFO | train | epoch 074 | loss 3.015 | nll_loss 1.462 | ppl 2.75 | wps 15562.4 | ups 4.35 | wpb 3577.8 | bsz 145.3 | num_updates 81622 | lr 0.000110687 | gnorm 0.989 | train_wall 246 | gb_free 7 | wall 18681
2021-03-11 01:57:48 | INFO | fairseq.trainer | begin training epoch 75
2021-03-11 01:57:48 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-11 01:58:05 | INFO | train_inner | epoch 075:     78 / 1103 loss=2.991, nll_loss=1.432, ppl=2.7, wps=12561, ups=3.52, wpb=3567.6, bsz=138.5, num_updates=81700, lr=0.000110634, gnorm=0.984, train_wall=22, gb_free=7, wall=18699
2021-03-11 01:58:28 | INFO | train_inner | epoch 075:    178 / 1103 loss=2.987, nll_loss=1.428, ppl=2.69, wps=15968.8, ups=4.45, wpb=3589.4, bsz=137, num_updates=81800, lr=0.000110566, gnorm=0.967, train_wall=22, gb_free=6.8, wall=18721
2021-03-11 01:58:50 | INFO | train_inner | epoch 075:    278 / 1103 loss=2.997, nll_loss=1.442, ppl=2.72, wps=16151.3, ups=4.48, wpb=3601.4, bsz=162.3, num_updates=81900, lr=0.000110499, gnorm=0.985, train_wall=22, gb_free=7.1, wall=18743
2021-03-11 01:59:13 | INFO | train_inner | epoch 075:    378 / 1103 loss=3.003, nll_loss=1.448, ppl=2.73, wps=16092.1, ups=4.44, wpb=3623.3, bsz=143.6, num_updates=82000, lr=0.000110432, gnorm=0.979, train_wall=22, gb_free=6.8, wall=18766
2021-03-11 01:59:35 | INFO | train_inner | epoch 075:    478 / 1103 loss=3.014, nll_loss=1.459, ppl=2.75, wps=15912.1, ups=4.5, wpb=3534.3, bsz=139.2, num_updates=82100, lr=0.000110364, gnorm=1.031, train_wall=22, gb_free=6.8, wall=18788
2021-03-11 01:59:58 | INFO | train_inner | epoch 075:    578 / 1103 loss=2.973, nll_loss=1.413, ppl=2.66, wps=15689.8, ups=4.4, wpb=3567.3, bsz=159.3, num_updates=82200, lr=0.000110297, gnorm=0.972, train_wall=23, gb_free=6.9, wall=18811
2021-03-11 02:00:20 | INFO | train_inner | epoch 075:    678 / 1103 loss=3.011, nll_loss=1.46, ppl=2.75, wps=16074, ups=4.45, wpb=3609.4, bsz=162.5, num_updates=82300, lr=0.00011023, gnorm=0.988, train_wall=22, gb_free=7.6, wall=18833
2021-03-11 02:00:43 | INFO | train_inner | epoch 075:    778 / 1103 loss=3.033, nll_loss=1.482, ppl=2.79, wps=16052.5, ups=4.39, wpb=3656.1, bsz=143.4, num_updates=82400, lr=0.000110163, gnorm=0.995, train_wall=23, gb_free=7, wall=18856
2021-03-11 02:01:05 | INFO | train_inner | epoch 075:    878 / 1103 loss=3.04, nll_loss=1.49, ppl=2.81, wps=15952, ups=4.48, wpb=3563.1, bsz=134.7, num_updates=82500, lr=0.000110096, gnorm=1.001, train_wall=22, gb_free=7.2, wall=18878
2021-03-11 02:01:28 | INFO | train_inner | epoch 075:    978 / 1103 loss=3.032, nll_loss=1.48, ppl=2.79, wps=15770.9, ups=4.44, wpb=3550, bsz=134.2, num_updates=82600, lr=0.00011003, gnorm=1.013, train_wall=22, gb_free=7.4, wall=18901
2021-03-11 02:01:50 | INFO | train_inner | epoch 075:   1078 / 1103 loss=3.044, nll_loss=1.493, ppl=2.82, wps=15917.3, ups=4.52, wpb=3518.6, bsz=136.2, num_updates=82700, lr=0.000109963, gnorm=1.007, train_wall=22, gb_free=7, wall=18923
2021-03-11 02:01:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-11 02:01:59 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 4.005 | nll_loss 2.452 | ppl 5.47 | wps 48214.9 | wpb 2873.1 | bsz 115.6 | num_updates 82725 | best_loss 3.91
2021-03-11 02:01:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 75 @ 82725 updates
2021-03-11 02:01:59 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 02:02:01 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 02:02:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt (epoch 75 @ 82725 updates, score 4.005) (writing took 2.059489395469427 seconds)
2021-03-11 02:02:01 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2021-03-11 02:02:01 | INFO | train | epoch 075 | loss 3.01 | nll_loss 1.456 | ppl 2.74 | wps 15562.7 | ups 4.35 | wpb 3577.8 | bsz 145.3 | num_updates 82725 | lr 0.000109947 | gnorm 0.993 | train_wall 246 | gb_free 6.8 | wall 18934
2021-03-11 02:02:01 | INFO | fairseq.trainer | begin training epoch 76
2021-03-11 02:02:01 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-11 02:02:18 | INFO | train_inner | epoch 076:     75 / 1103 loss=2.985, nll_loss=1.427, ppl=2.69, wps=12726.4, ups=3.5, wpb=3631.4, bsz=152.3, num_updates=82800, lr=0.000109897, gnorm=0.969, train_wall=22, gb_free=7, wall=18952
2021-03-11 02:02:41 | INFO | train_inner | epoch 076:    175 / 1103 loss=2.978, nll_loss=1.418, ppl=2.67, wps=16018.3, ups=4.46, wpb=3590.1, bsz=144.3, num_updates=82900, lr=0.00010983, gnorm=0.988, train_wall=22, gb_free=6.8, wall=18974
2021-03-11 02:03:04 | INFO | train_inner | epoch 076:    275 / 1103 loss=2.954, nll_loss=1.391, ppl=2.62, wps=15834.7, ups=4.41, wpb=3592.7, bsz=157.5, num_updates=83000, lr=0.000109764, gnorm=0.96, train_wall=23, gb_free=6.8, wall=18997
2021-03-11 02:03:26 | INFO | train_inner | epoch 076:    375 / 1103 loss=3, nll_loss=1.444, ppl=2.72, wps=15907.7, ups=4.46, wpb=3563.8, bsz=140.9, num_updates=83100, lr=0.000109698, gnorm=1, train_wall=22, gb_free=6.8, wall=19019
2021-03-11 02:03:48 | INFO | train_inner | epoch 076:    475 / 1103 loss=2.985, nll_loss=1.428, ppl=2.69, wps=15982.7, ups=4.44, wpb=3598.1, bsz=157.4, num_updates=83200, lr=0.000109632, gnorm=0.971, train_wall=22, gb_free=6.7, wall=19042
2021-03-11 02:04:11 | INFO | train_inner | epoch 076:    575 / 1103 loss=2.991, nll_loss=1.434, ppl=2.7, wps=15891.1, ups=4.45, wpb=3573, bsz=153.4, num_updates=83300, lr=0.000109566, gnorm=0.984, train_wall=22, gb_free=6.8, wall=19064
2021-03-11 02:04:33 | INFO | train_inner | epoch 076:    675 / 1103 loss=3.042, nll_loss=1.49, ppl=2.81, wps=15888.4, ups=4.46, wpb=3560.3, bsz=123.8, num_updates=83400, lr=0.000109501, gnorm=1.025, train_wall=22, gb_free=7, wall=19086
2021-03-11 02:04:56 | INFO | train_inner | epoch 076:    775 / 1103 loss=3.011, nll_loss=1.455, ppl=2.74, wps=15764.1, ups=4.45, wpb=3543.4, bsz=133.6, num_updates=83500, lr=0.000109435, gnorm=1.007, train_wall=22, gb_free=7.3, wall=19109
2021-03-11 02:05:18 | INFO | train_inner | epoch 076:    875 / 1103 loss=3.023, nll_loss=1.47, ppl=2.77, wps=15791.9, ups=4.48, wpb=3528.6, bsz=141.7, num_updates=83600, lr=0.00010937, gnorm=1.009, train_wall=22, gb_free=7.1, wall=19131
2021-03-11 02:05:40 | INFO | train_inner | epoch 076:    975 / 1103 loss=3.037, nll_loss=1.487, ppl=2.8, wps=15870.1, ups=4.49, wpb=3536.4, bsz=149, num_updates=83700, lr=0.000109304, gnorm=1.013, train_wall=22, gb_free=7.5, wall=19154
2021-03-11 02:06:03 | INFO | train_inner | epoch 076:   1075 / 1103 loss=3.029, nll_loss=1.478, ppl=2.79, wps=15956.7, ups=4.44, wpb=3593.8, bsz=150.2, num_updates=83800, lr=0.000109239, gnorm=0.99, train_wall=22, gb_free=7, wall=19176
2021-03-11 02:06:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-11 02:06:13 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 4 | nll_loss 2.452 | ppl 5.47 | wps 48186.8 | wpb 2873.1 | bsz 115.6 | num_updates 83828 | best_loss 3.91
2021-03-11 02:06:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 76 @ 83828 updates
2021-03-11 02:06:13 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 02:06:15 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 02:06:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt (epoch 76 @ 83828 updates, score 4.0) (writing took 2.163887072354555 seconds)
2021-03-11 02:06:15 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2021-03-11 02:06:15 | INFO | train | epoch 076 | loss 3.005 | nll_loss 1.45 | ppl 2.73 | wps 15551.3 | ups 4.35 | wpb 3577.8 | bsz 145.3 | num_updates 83828 | lr 0.000109221 | gnorm 0.992 | train_wall 246 | gb_free 7.2 | wall 19188
2021-03-11 02:06:15 | INFO | fairseq.trainer | begin training epoch 77
2021-03-11 02:06:15 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-11 02:06:31 | INFO | train_inner | epoch 077:     72 / 1103 loss=3.008, nll_loss=1.452, ppl=2.74, wps=12659.1, ups=3.55, wpb=3568.3, bsz=134.5, num_updates=83900, lr=0.000109174, gnorm=0.995, train_wall=22, gb_free=7, wall=19204
2021-03-11 02:06:54 | INFO | train_inner | epoch 077:    172 / 1103 loss=2.968, nll_loss=1.406, ppl=2.65, wps=16040, ups=4.41, wpb=3639.4, bsz=150.8, num_updates=84000, lr=0.000109109, gnorm=0.961, train_wall=23, gb_free=7.1, wall=19227
2021-03-11 02:07:16 | INFO | train_inner | epoch 077:    272 / 1103 loss=2.954, nll_loss=1.392, ppl=2.62, wps=15839.6, ups=4.45, wpb=3557.8, bsz=153.8, num_updates=84100, lr=0.000109044, gnorm=0.97, train_wall=22, gb_free=7.2, wall=19249
2021-03-11 02:07:39 | INFO | train_inner | epoch 077:    372 / 1103 loss=2.981, nll_loss=1.421, ppl=2.68, wps=15851.7, ups=4.43, wpb=3577.4, bsz=145.7, num_updates=84200, lr=0.000108979, gnorm=0.999, train_wall=22, gb_free=7.2, wall=19272
2021-03-11 02:08:01 | INFO | train_inner | epoch 077:    472 / 1103 loss=3.002, nll_loss=1.446, ppl=2.72, wps=15953.7, ups=4.46, wpb=3580, bsz=140.1, num_updates=84300, lr=0.000108915, gnorm=0.997, train_wall=22, gb_free=7.6, wall=19294
2021-03-11 02:08:24 | INFO | train_inner | epoch 077:    572 / 1103 loss=3.037, nll_loss=1.485, ppl=2.8, wps=16026.8, ups=4.48, wpb=3577.8, bsz=133.8, num_updates=84400, lr=0.00010885, gnorm=1.025, train_wall=22, gb_free=6.9, wall=19317
2021-03-11 02:08:46 | INFO | train_inner | epoch 077:    672 / 1103 loss=3.013, nll_loss=1.457, ppl=2.75, wps=15865.7, ups=4.49, wpb=3532.3, bsz=143.8, num_updates=84500, lr=0.000108786, gnorm=1.004, train_wall=22, gb_free=7.7, wall=19339
2021-03-11 02:09:08 | INFO | train_inner | epoch 077:    772 / 1103 loss=3.014, nll_loss=1.46, ppl=2.75, wps=15955.3, ups=4.46, wpb=3576.6, bsz=140.3, num_updates=84600, lr=0.000108721, gnorm=0.995, train_wall=22, gb_free=7.2, wall=19361
2021-03-11 02:09:31 | INFO | train_inner | epoch 077:    872 / 1103 loss=2.995, nll_loss=1.441, ppl=2.71, wps=15901.5, ups=4.44, wpb=3582.2, bsz=160.9, num_updates=84700, lr=0.000108657, gnorm=0.99, train_wall=22, gb_free=7, wall=19384
2021-03-11 02:09:53 | INFO | train_inner | epoch 077:    972 / 1103 loss=3.019, nll_loss=1.466, ppl=2.76, wps=15896.2, ups=4.43, wpb=3586.9, bsz=141.8, num_updates=84800, lr=0.000108593, gnorm=1.015, train_wall=22, gb_free=7.3, wall=19407
2021-03-11 02:10:16 | INFO | train_inner | epoch 077:   1072 / 1103 loss=3.023, nll_loss=1.47, ppl=2.77, wps=15910.7, ups=4.43, wpb=3591.1, bsz=136.1, num_updates=84900, lr=0.000108529, gnorm=0.995, train_wall=22, gb_free=7, wall=19429
2021-03-11 02:10:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-11 02:10:27 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 4.018 | nll_loss 2.463 | ppl 5.51 | wps 48262.1 | wpb 2873.1 | bsz 115.6 | num_updates 84931 | best_loss 3.91
2021-03-11 02:10:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 77 @ 84931 updates
2021-03-11 02:10:27 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 02:10:29 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 02:10:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt (epoch 77 @ 84931 updates, score 4.018) (writing took 2.1528105549514294 seconds)
2021-03-11 02:10:29 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2021-03-11 02:10:29 | INFO | train | epoch 077 | loss 2.998 | nll_loss 1.442 | ppl 2.72 | wps 15549.2 | ups 4.35 | wpb 3577.8 | bsz 145.3 | num_updates 84931 | lr 0.000108509 | gnorm 0.995 | train_wall 246 | gb_free 7.1 | wall 19442
2021-03-11 02:10:29 | INFO | fairseq.trainer | begin training epoch 78
2021-03-11 02:10:29 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-11 02:10:45 | INFO | train_inner | epoch 078:     69 / 1103 loss=2.97, nll_loss=1.41, ppl=2.66, wps=12672.2, ups=3.5, wpb=3620.5, bsz=153.7, num_updates=85000, lr=0.000108465, gnorm=0.969, train_wall=22, gb_free=7.3, wall=19458
2021-03-11 02:11:07 | INFO | train_inner | epoch 078:    169 / 1103 loss=2.969, nll_loss=1.405, ppl=2.65, wps=15607.1, ups=4.47, wpb=3491.5, bsz=141.3, num_updates=85100, lr=0.000108401, gnorm=1.017, train_wall=22, gb_free=7, wall=19480
2021-03-11 02:11:30 | INFO | train_inner | epoch 078:    269 / 1103 loss=2.964, nll_loss=1.402, ppl=2.64, wps=15997.8, ups=4.41, wpb=3624.3, bsz=153.5, num_updates=85200, lr=0.000108338, gnorm=0.961, train_wall=23, gb_free=6.9, wall=19503
2021-03-11 02:11:52 | INFO | train_inner | epoch 078:    369 / 1103 loss=2.988, nll_loss=1.43, ppl=2.7, wps=16030, ups=4.48, wpb=3579.6, bsz=144.6, num_updates=85300, lr=0.000108274, gnorm=0.994, train_wall=22, gb_free=7.2, wall=19525
2021-03-11 02:12:14 | INFO | train_inner | epoch 078:    469 / 1103 loss=2.974, nll_loss=1.413, ppl=2.66, wps=15823.3, ups=4.45, wpb=3555.2, bsz=142.9, num_updates=85400, lr=0.000108211, gnorm=1.013, train_wall=22, gb_free=7.2, wall=19548
2021-03-11 02:12:37 | INFO | train_inner | epoch 078:    569 / 1103 loss=2.995, nll_loss=1.438, ppl=2.71, wps=16002.3, ups=4.43, wpb=3612.9, bsz=152.2, num_updates=85500, lr=0.000108148, gnorm=0.988, train_wall=22, gb_free=6.8, wall=19570
2021-03-11 02:12:59 | INFO | train_inner | epoch 078:    669 / 1103 loss=2.989, nll_loss=1.433, ppl=2.7, wps=15979.7, ups=4.49, wpb=3555.2, bsz=157.8, num_updates=85600, lr=0.000108084, gnorm=0.985, train_wall=22, gb_free=7.2, wall=19592
2021-03-11 02:13:22 | INFO | train_inner | epoch 078:    769 / 1103 loss=3.024, nll_loss=1.471, ppl=2.77, wps=15972.7, ups=4.48, wpb=3565.3, bsz=141.4, num_updates=85700, lr=0.000108021, gnorm=1.018, train_wall=22, gb_free=7.2, wall=19615
2021-03-11 02:13:44 | INFO | train_inner | epoch 078:    869 / 1103 loss=3.042, nll_loss=1.491, ppl=2.81, wps=15996.8, ups=4.48, wpb=3567.3, bsz=133.5, num_updates=85800, lr=0.000107958, gnorm=1.02, train_wall=22, gb_free=7, wall=19637
2021-03-11 02:14:06 | INFO | train_inner | epoch 078:    969 / 1103 loss=3.018, nll_loss=1.465, ppl=2.76, wps=15952, ups=4.48, wpb=3561.4, bsz=147.8, num_updates=85900, lr=0.000107896, gnorm=1.003, train_wall=22, gb_free=6.9, wall=19659
2021-03-11 02:14:29 | INFO | train_inner | epoch 078:   1069 / 1103 loss=2.992, nll_loss=1.435, ppl=2.7, wps=15872.3, ups=4.4, wpb=3610.8, bsz=147.9, num_updates=86000, lr=0.000107833, gnorm=0.99, train_wall=23, gb_free=6.8, wall=19682
2021-03-11 02:14:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-11 02:14:40 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 4.009 | nll_loss 2.455 | ppl 5.48 | wps 48200.7 | wpb 2873.1 | bsz 115.6 | num_updates 86034 | best_loss 3.91
2021-03-11 02:14:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 78 @ 86034 updates
2021-03-11 02:14:40 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 02:14:43 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 02:14:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt (epoch 78 @ 86034 updates, score 4.009) (writing took 2.4115727432072163 seconds)
2021-03-11 02:14:43 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2021-03-11 02:14:43 | INFO | train | epoch 078 | loss 2.995 | nll_loss 1.438 | ppl 2.71 | wps 15548.3 | ups 4.35 | wpb 3577.8 | bsz 145.3 | num_updates 86034 | lr 0.000107811 | gnorm 0.997 | train_wall 246 | gb_free 7 | wall 19696
2021-03-11 02:14:43 | INFO | fairseq.trainer | begin training epoch 79
2021-03-11 02:14:43 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-11 02:14:57 | INFO | train_inner | epoch 079:     66 / 1103 loss=2.994, nll_loss=1.435, ppl=2.7, wps=12462.3, ups=3.51, wpb=3552.8, bsz=133.5, num_updates=86100, lr=0.00010777, gnorm=1.017, train_wall=22, gb_free=7.6, wall=19711
2021-03-11 02:15:20 | INFO | train_inner | epoch 079:    166 / 1103 loss=2.946, nll_loss=1.382, ppl=2.61, wps=15893.7, ups=4.42, wpb=3595.9, bsz=150.4, num_updates=86200, lr=0.000107708, gnorm=0.965, train_wall=23, gb_free=7.2, wall=19733
2021-03-11 02:15:42 | INFO | train_inner | epoch 079:    266 / 1103 loss=2.978, nll_loss=1.414, ppl=2.66, wps=15699.4, ups=4.47, wpb=3510.6, bsz=128.7, num_updates=86300, lr=0.000107645, gnorm=1.014, train_wall=22, gb_free=7.2, wall=19756
2021-03-11 02:16:05 | INFO | train_inner | epoch 079:    366 / 1103 loss=2.965, nll_loss=1.402, ppl=2.64, wps=15816.8, ups=4.48, wpb=3528.3, bsz=143, num_updates=86400, lr=0.000107583, gnorm=1.011, train_wall=22, gb_free=7, wall=19778
2021-03-11 02:16:27 | INFO | train_inner | epoch 079:    466 / 1103 loss=2.988, nll_loss=1.431, ppl=2.7, wps=16050.2, ups=4.44, wpb=3611.8, bsz=152.6, num_updates=86500, lr=0.000107521, gnorm=0.99, train_wall=22, gb_free=7.5, wall=19800
2021-03-11 02:16:50 | INFO | train_inner | epoch 079:    566 / 1103 loss=2.964, nll_loss=1.402, ppl=2.64, wps=15733, ups=4.48, wpb=3515.7, bsz=148.6, num_updates=86600, lr=0.000107459, gnorm=1.007, train_wall=22, gb_free=6.9, wall=19823
2021-03-11 02:17:12 | INFO | train_inner | epoch 079:    666 / 1103 loss=3.009, nll_loss=1.453, ppl=2.74, wps=16059.2, ups=4.46, wpb=3599.6, bsz=137.2, num_updates=86700, lr=0.000107397, gnorm=0.996, train_wall=22, gb_free=7.3, wall=19845
2021-03-11 02:17:34 | INFO | train_inner | epoch 079:    766 / 1103 loss=3.014, nll_loss=1.459, ppl=2.75, wps=16234.7, ups=4.44, wpb=3654, bsz=134.8, num_updates=86800, lr=0.000107335, gnorm=1.001, train_wall=22, gb_free=7, wall=19868
2021-03-11 02:17:57 | INFO | train_inner | epoch 079:    866 / 1103 loss=3.036, nll_loss=1.484, ppl=2.8, wps=15973, ups=4.47, wpb=3569.9, bsz=134.5, num_updates=86900, lr=0.000107273, gnorm=1.019, train_wall=22, gb_free=7.1, wall=19890
2021-03-11 02:18:19 | INFO | train_inner | epoch 079:    966 / 1103 loss=2.994, nll_loss=1.441, ppl=2.71, wps=15925.2, ups=4.43, wpb=3592.8, bsz=170.4, num_updates=87000, lr=0.000107211, gnorm=0.99, train_wall=22, gb_free=7.2, wall=19913
2021-03-11 02:18:42 | INFO | train_inner | epoch 079:   1066 / 1103 loss=2.996, nll_loss=1.441, ppl=2.71, wps=15996.7, ups=4.4, wpb=3634, bsz=153.8, num_updates=87100, lr=0.00010715, gnorm=0.99, train_wall=23, gb_free=6.9, wall=19935
2021-03-11 02:18:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-11 02:18:54 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 4.011 | nll_loss 2.461 | ppl 5.51 | wps 48180.8 | wpb 2873.1 | bsz 115.6 | num_updates 87137 | best_loss 3.91
2021-03-11 02:18:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 79 @ 87137 updates
2021-03-11 02:18:54 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 02:18:56 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 02:18:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt (epoch 79 @ 87137 updates, score 4.011) (writing took 2.2257236391305923 seconds)
2021-03-11 02:18:56 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2021-03-11 02:18:56 | INFO | train | epoch 079 | loss 2.99 | nll_loss 1.432 | ppl 2.7 | wps 15550.9 | ups 4.35 | wpb 3577.8 | bsz 145.3 | num_updates 87137 | lr 0.000107127 | gnorm 0.999 | train_wall 246 | gb_free 6.6 | wall 19950
2021-03-11 02:18:56 | INFO | fairseq.trainer | begin training epoch 80
2021-03-11 02:18:56 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-11 02:19:11 | INFO | train_inner | epoch 080:     63 / 1103 loss=2.972, nll_loss=1.414, ppl=2.66, wps=12503.5, ups=3.49, wpb=3586.3, bsz=162.5, num_updates=87200, lr=0.000107088, gnorm=0.979, train_wall=22, gb_free=7.1, wall=19964
2021-03-11 02:19:33 | INFO | train_inner | epoch 080:    163 / 1103 loss=2.973, nll_loss=1.412, ppl=2.66, wps=16026.8, ups=4.43, wpb=3615.7, bsz=143.5, num_updates=87300, lr=0.000107027, gnorm=1.009, train_wall=22, gb_free=6.9, wall=19987
2021-03-11 02:19:56 | INFO | train_inner | epoch 080:    263 / 1103 loss=2.958, nll_loss=1.396, ppl=2.63, wps=15799.7, ups=4.47, wpb=3536.1, bsz=148.2, num_updates=87400, lr=0.000106966, gnorm=1.003, train_wall=22, gb_free=7, wall=20009
2021-03-11 02:20:18 | INFO | train_inner | epoch 080:    363 / 1103 loss=2.934, nll_loss=1.369, ppl=2.58, wps=15871.2, ups=4.41, wpb=3598.9, bsz=167.5, num_updates=87500, lr=0.000106904, gnorm=0.968, train_wall=23, gb_free=7.3, wall=20032
2021-03-11 02:20:41 | INFO | train_inner | epoch 080:    463 / 1103 loss=2.976, nll_loss=1.415, ppl=2.67, wps=15927.2, ups=4.46, wpb=3573.4, bsz=145.4, num_updates=87600, lr=0.000106843, gnorm=0.999, train_wall=22, gb_free=6.9, wall=20054
2021-03-11 02:21:03 | INFO | train_inner | epoch 080:    563 / 1103 loss=2.979, nll_loss=1.418, ppl=2.67, wps=15736.6, ups=4.51, wpb=3491.6, bsz=134.9, num_updates=87700, lr=0.000106783, gnorm=1.028, train_wall=22, gb_free=7.5, wall=20076
2021-03-11 02:21:25 | INFO | train_inner | epoch 080:    663 / 1103 loss=3.013, nll_loss=1.457, ppl=2.74, wps=16056.9, ups=4.46, wpb=3598.4, bsz=129, num_updates=87800, lr=0.000106722, gnorm=1.013, train_wall=22, gb_free=7.1, wall=20099
2021-03-11 02:21:48 | INFO | train_inner | epoch 080:    763 / 1103 loss=3.008, nll_loss=1.451, ppl=2.73, wps=15969.4, ups=4.44, wpb=3595.2, bsz=129.3, num_updates=87900, lr=0.000106661, gnorm=1.01, train_wall=22, gb_free=6.8, wall=20121
2021-03-11 02:22:10 | INFO | train_inner | epoch 080:    863 / 1103 loss=3.017, nll_loss=1.463, ppl=2.76, wps=16040.9, ups=4.49, wpb=3573.7, bsz=143.5, num_updates=88000, lr=0.0001066, gnorm=1.01, train_wall=22, gb_free=6.8, wall=20143
2021-03-11 02:22:33 | INFO | train_inner | epoch 080:    963 / 1103 loss=3.008, nll_loss=1.456, ppl=2.74, wps=16273.5, ups=4.48, wpb=3634.3, bsz=157.6, num_updates=88100, lr=0.00010654, gnorm=0.989, train_wall=22, gb_free=7.1, wall=20166
2021-03-11 02:22:55 | INFO | train_inner | epoch 080:   1063 / 1103 loss=3.002, nll_loss=1.446, ppl=2.72, wps=16056.1, ups=4.51, wpb=3560, bsz=146.2, num_updates=88200, lr=0.000106479, gnorm=1.008, train_wall=22, gb_free=7, wall=20188
2021-03-11 02:23:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-11 02:23:07 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 4.018 | nll_loss 2.462 | ppl 5.51 | wps 48246.4 | wpb 2873.1 | bsz 115.6 | num_updates 88240 | best_loss 3.91
2021-03-11 02:23:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 88240 updates
2021-03-11 02:23:07 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 02:23:10 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 02:23:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt (epoch 80 @ 88240 updates, score 4.018) (writing took 2.14547024294734 seconds)
2021-03-11 02:23:10 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2021-03-11 02:23:10 | INFO | train | epoch 080 | loss 2.985 | nll_loss 1.426 | ppl 2.69 | wps 15591 | ups 4.36 | wpb 3577.8 | bsz 145.3 | num_updates 88240 | lr 0.000106455 | gnorm 1.002 | train_wall 246 | gb_free 7.4 | wall 20203
2021-03-11 02:23:10 | INFO | fairseq.trainer | begin training epoch 81
2021-03-11 02:23:10 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-11 02:23:23 | INFO | train_inner | epoch 081:     60 / 1103 loss=2.975, nll_loss=1.415, ppl=2.67, wps=12694.7, ups=3.51, wpb=3614.3, bsz=143.2, num_updates=88300, lr=0.000106419, gnorm=0.981, train_wall=22, gb_free=6.7, wall=20216
2021-03-11 02:23:46 | INFO | train_inner | epoch 081:    160 / 1103 loss=2.955, nll_loss=1.39, ppl=2.62, wps=15883.1, ups=4.45, wpb=3568.6, bsz=145.7, num_updates=88400, lr=0.000106359, gnorm=1.006, train_wall=22, gb_free=6.8, wall=20239
2021-03-11 02:24:08 | INFO | train_inner | epoch 081:    260 / 1103 loss=2.942, nll_loss=1.377, ppl=2.6, wps=15778.2, ups=4.44, wpb=3554, bsz=150.3, num_updates=88500, lr=0.000106299, gnorm=1.003, train_wall=22, gb_free=7.1, wall=20261
2021-03-11 02:24:31 | INFO | train_inner | epoch 081:    360 / 1103 loss=2.963, nll_loss=1.4, ppl=2.64, wps=15806.8, ups=4.48, wpb=3526.5, bsz=142.2, num_updates=88600, lr=0.000106239, gnorm=1.011, train_wall=22, gb_free=7.1, wall=20284
2021-03-11 02:24:53 | INFO | train_inner | epoch 081:    460 / 1103 loss=2.97, nll_loss=1.407, ppl=2.65, wps=15681.4, ups=4.51, wpb=3477.4, bsz=140, num_updates=88700, lr=0.000106179, gnorm=1.016, train_wall=22, gb_free=7.1, wall=20306
2021-03-11 02:25:15 | INFO | train_inner | epoch 081:    560 / 1103 loss=3.007, nll_loss=1.451, ppl=2.73, wps=16146.9, ups=4.44, wpb=3637.9, bsz=139.4, num_updates=88800, lr=0.000106119, gnorm=1.007, train_wall=22, gb_free=7, wall=20328
2021-03-11 02:25:38 | INFO | train_inner | epoch 081:    660 / 1103 loss=2.954, nll_loss=1.393, ppl=2.63, wps=16013, ups=4.41, wpb=3627.1, bsz=162.2, num_updates=88900, lr=0.000106059, gnorm=0.982, train_wall=23, gb_free=6.9, wall=20351
2021-03-11 02:26:00 | INFO | train_inner | epoch 081:    760 / 1103 loss=2.975, nll_loss=1.415, ppl=2.67, wps=15716.3, ups=4.46, wpb=3526.4, bsz=150.1, num_updates=89000, lr=0.000106, gnorm=1.004, train_wall=22, gb_free=7, wall=20373
2021-03-11 02:26:23 | INFO | train_inner | epoch 081:    860 / 1103 loss=3.005, nll_loss=1.45, ppl=2.73, wps=15982.5, ups=4.45, wpb=3592.6, bsz=149.8, num_updates=89100, lr=0.00010594, gnorm=1.008, train_wall=22, gb_free=7, wall=20396
2021-03-11 02:26:45 | INFO | train_inner | epoch 081:    960 / 1103 loss=3.017, nll_loss=1.462, ppl=2.76, wps=15955.9, ups=4.47, wpb=3571.9, bsz=139, num_updates=89200, lr=0.000105881, gnorm=1.023, train_wall=22, gb_free=7.2, wall=20418
2021-03-11 02:27:08 | INFO | train_inner | epoch 081:   1060 / 1103 loss=3.019, nll_loss=1.465, ppl=2.76, wps=16012.2, ups=4.42, wpb=3625.4, bsz=131.4, num_updates=89300, lr=0.000105822, gnorm=1.015, train_wall=23, gb_free=7.2, wall=20441
2021-03-11 02:27:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-11 02:27:21 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 3.999 | nll_loss 2.452 | ppl 5.47 | wps 48256.9 | wpb 2873.1 | bsz 115.6 | num_updates 89343 | best_loss 3.91
2021-03-11 02:27:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 81 @ 89343 updates
2021-03-11 02:27:21 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 02:27:23 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 02:27:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt (epoch 81 @ 89343 updates, score 3.999) (writing took 2.143554352223873 seconds)
2021-03-11 02:27:23 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2021-03-11 02:27:23 | INFO | train | epoch 081 | loss 2.982 | nll_loss 1.422 | ppl 2.68 | wps 15551.6 | ups 4.35 | wpb 3577.8 | bsz 145.3 | num_updates 89343 | lr 0.000105796 | gnorm 1.007 | train_wall 246 | gb_free 7.2 | wall 20456
2021-03-11 02:27:23 | INFO | fairseq.trainer | begin training epoch 82
2021-03-11 02:27:23 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-11 02:27:36 | INFO | train_inner | epoch 082:     57 / 1103 loss=2.987, nll_loss=1.429, ppl=2.69, wps=12704, ups=3.51, wpb=3616.2, bsz=146.2, num_updates=89400, lr=0.000105762, gnorm=1.023, train_wall=22, gb_free=6.6, wall=20469
2021-03-11 02:27:59 | INFO | train_inner | epoch 082:    157 / 1103 loss=2.939, nll_loss=1.373, ppl=2.59, wps=15900.3, ups=4.46, wpb=3564.3, bsz=151.3, num_updates=89500, lr=0.000105703, gnorm=1.007, train_wall=22, gb_free=6.9, wall=20492
2021-03-11 02:28:21 | INFO | train_inner | epoch 082:    257 / 1103 loss=2.975, nll_loss=1.413, ppl=2.66, wps=16027.7, ups=4.44, wpb=3613.1, bsz=133.6, num_updates=89600, lr=0.000105644, gnorm=1, train_wall=22, gb_free=7.2, wall=20514
2021-03-11 02:28:44 | INFO | train_inner | epoch 082:    357 / 1103 loss=2.963, nll_loss=1.398, ppl=2.64, wps=15837.4, ups=4.45, wpb=3557.9, bsz=133.6, num_updates=89700, lr=0.000105585, gnorm=1.006, train_wall=22, gb_free=7.3, wall=20537
2021-03-11 02:29:06 | INFO | train_inner | epoch 082:    457 / 1103 loss=2.978, nll_loss=1.418, ppl=2.67, wps=16132.2, ups=4.48, wpb=3604.5, bsz=142.6, num_updates=89800, lr=0.000105527, gnorm=0.995, train_wall=22, gb_free=7, wall=20559
2021-03-11 02:29:29 | INFO | train_inner | epoch 082:    557 / 1103 loss=2.981, nll_loss=1.423, ppl=2.68, wps=16061.1, ups=4.42, wpb=3630, bsz=151.5, num_updates=89900, lr=0.000105468, gnorm=0.992, train_wall=22, gb_free=7.2, wall=20582
2021-03-11 02:29:51 | INFO | train_inner | epoch 082:    657 / 1103 loss=2.967, nll_loss=1.407, ppl=2.65, wps=15879.6, ups=4.47, wpb=3550.3, bsz=161.5, num_updates=90000, lr=0.000105409, gnorm=1.004, train_wall=22, gb_free=7.1, wall=20604
2021-03-11 02:30:14 | INFO | train_inner | epoch 082:    757 / 1103 loss=2.995, nll_loss=1.438, ppl=2.71, wps=15994, ups=4.43, wpb=3610.7, bsz=139.3, num_updates=90100, lr=0.000105351, gnorm=1.001, train_wall=22, gb_free=6.4, wall=20627
2021-03-11 02:30:36 | INFO | train_inner | epoch 082:    857 / 1103 loss=2.987, nll_loss=1.43, ppl=2.69, wps=16119.4, ups=4.45, wpb=3622.4, bsz=158.2, num_updates=90200, lr=0.000105292, gnorm=0.995, train_wall=22, gb_free=7.1, wall=20649
2021-03-11 02:30:58 | INFO | train_inner | epoch 082:    957 / 1103 loss=2.967, nll_loss=1.404, ppl=2.65, wps=15446.5, ups=4.46, wpb=3460.4, bsz=139.6, num_updates=90300, lr=0.000105234, gnorm=1.033, train_wall=22, gb_free=6.8, wall=20672
2021-03-11 02:31:21 | INFO | train_inner | epoch 082:   1057 / 1103 loss=2.983, nll_loss=1.424, ppl=2.68, wps=15819.3, ups=4.48, wpb=3533.8, bsz=150.2, num_updates=90400, lr=0.000105176, gnorm=1.019, train_wall=22, gb_free=6.7, wall=20694
2021-03-11 02:31:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-11 02:31:35 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 4.018 | nll_loss 2.468 | ppl 5.53 | wps 48142.5 | wpb 2873.1 | bsz 115.6 | num_updates 90446 | best_loss 3.91
2021-03-11 02:31:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 82 @ 90446 updates
2021-03-11 02:31:35 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 02:31:37 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 02:31:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt (epoch 82 @ 90446 updates, score 4.018) (writing took 2.20364161580801 seconds)
2021-03-11 02:31:37 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2021-03-11 02:31:37 | INFO | train | epoch 082 | loss 2.975 | nll_loss 1.414 | ppl 2.67 | wps 15551.9 | ups 4.35 | wpb 3577.8 | bsz 145.3 | num_updates 90446 | lr 0.000105149 | gnorm 1.005 | train_wall 246 | gb_free 6.9 | wall 20710
2021-03-11 02:31:37 | INFO | fairseq.trainer | begin training epoch 83
2021-03-11 02:31:37 | INFO | fairseq_cli.train | Start iterating over samples
2021-03-11 02:31:49 | INFO | train_inner | epoch 083:     54 / 1103 loss=2.983, nll_loss=1.425, ppl=2.69, wps=12723.6, ups=3.51, wpb=3630, bsz=147.1, num_updates=90500, lr=0.000105118, gnorm=0.991, train_wall=22, gb_free=7.5, wall=20722
2021-03-11 02:32:12 | INFO | train_inner | epoch 083:    154 / 1103 loss=2.944, nll_loss=1.378, ppl=2.6, wps=16106.4, ups=4.49, wpb=3586.7, bsz=144.9, num_updates=90600, lr=0.00010506, gnorm=0.989, train_wall=22, gb_free=7, wall=20745
2021-03-11 02:32:34 | INFO | train_inner | epoch 083:    254 / 1103 loss=2.963, nll_loss=1.398, ppl=2.63, wps=15921.1, ups=4.48, wpb=3550.6, bsz=128.4, num_updates=90700, lr=0.000105002, gnorm=1.025, train_wall=22, gb_free=6.9, wall=20767
2021-03-11 02:32:56 | INFO | train_inner | epoch 083:    354 / 1103 loss=2.985, nll_loss=1.424, ppl=2.68, wps=16149, ups=4.49, wpb=3599.7, bsz=134.6, num_updates=90800, lr=0.000104944, gnorm=1.012, train_wall=22, gb_free=7.2, wall=20789
2021-03-11 02:33:18 | INFO | train_inner | epoch 083:    454 / 1103 loss=2.953, nll_loss=1.389, ppl=2.62, wps=15701.8, ups=4.49, wpb=3498.9, bsz=146.6, num_updates=90900, lr=0.000104886, gnorm=1.018, train_wall=22, gb_free=7, wall=20812
2021-03-11 02:33:41 | INFO | train_inner | epoch 083:    554 / 1103 loss=2.982, nll_loss=1.422, ppl=2.68, wps=16129.1, ups=4.49, wpb=3593.9, bsz=139.4, num_updates=91000, lr=0.000104828, gnorm=1.02, train_wall=22, gb_free=7, wall=20834
2021-03-11 02:34:03 | INFO | train_inner | epoch 083:    654 / 1103 loss=2.965, nll_loss=1.405, ppl=2.65, wps=16120.3, ups=4.43, wpb=3640.5, bsz=158.9, num_updates=91100, lr=0.000104771, gnorm=0.991, train_wall=22, gb_free=7.2, wall=20856
2021-03-11 02:34:26 | INFO | train_inner | epoch 083:    754 / 1103 loss=2.983, nll_loss=1.425, ppl=2.69, wps=15963.6, ups=4.49, wpb=3559, bsz=151.4, num_updates=91200, lr=0.000104713, gnorm=1.012, train_wall=22, gb_free=7.1, wall=20879
2021-03-11 02:34:48 | INFO | train_inner | epoch 083:    854 / 1103 loss=2.981, nll_loss=1.421, ppl=2.68, wps=15926.2, ups=4.46, wpb=3570, bsz=143, num_updates=91300, lr=0.000104656, gnorm=1.013, train_wall=22, gb_free=7.2, wall=20901
2021-03-11 02:35:10 | INFO | train_inner | epoch 083:    954 / 1103 loss=2.968, nll_loss=1.406, ppl=2.65, wps=15750.2, ups=4.48, wpb=3517.9, bsz=147.4, num_updates=91400, lr=0.000104599, gnorm=1.027, train_wall=22, gb_free=6.8, wall=20924
2021-03-11 02:35:33 | INFO | train_inner | epoch 083:   1054 / 1103 loss=2.998, nll_loss=1.442, ppl=2.72, wps=16175, ups=4.45, wpb=3637.4, bsz=146.9, num_updates=91500, lr=0.000104542, gnorm=1.006, train_wall=22, gb_free=6.9, wall=20946
2021-03-11 02:35:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-03-11 02:35:48 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 4.017 | nll_loss 2.467 | ppl 5.53 | wps 48164.1 | wpb 2873.1 | bsz 115.6 | num_updates 91549 | best_loss 3.91
2021-03-11 02:35:48 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 50 runs
2021-03-11 02:35:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 83 @ 91549 updates
2021-03-11 02:35:48 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 02:35:50 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt
2021-03-11 02:35:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/iwslt/multifeatgen_baseline_new/checkpoint_last.pt (epoch 83 @ 91549 updates, score 4.017) (writing took 2.066120717674494 seconds)
2021-03-11 02:35:50 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2021-03-11 02:35:50 | INFO | train | epoch 083 | loss 2.971 | nll_loss 1.41 | ppl 2.66 | wps 15618.4 | ups 4.37 | wpb 3577.8 | bsz 145.3 | num_updates 91549 | lr 0.000104514 | gnorm 1.009 | train_wall 245 | gb_free 7.2 | wall 20963
2021-03-11 02:35:50 | INFO | fairseq_cli.train | done training in 20962.8 seconds
Start training...
2021-04-04 23:32:04 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:17209
2021-04-04 23:32:04 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:17209
2021-04-04 23:32:04 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:17209
2021-04-04 23:32:04 | INFO | fairseq.distributed.utils | initialized host haroldl as rank 1
2021-04-04 23:32:04 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:17209
2021-04-04 23:32:04 | INFO | fairseq.distributed.utils | initialized host haroldl as rank 3
Start training...
2021-04-04 23:32:17 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:18639
2021-04-04 23:32:17 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:18639
2021-04-04 23:32:17 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:18639
2021-04-04 23:32:17 | INFO | fairseq.distributed.utils | initialized host haroldl as rank 3
2021-04-04 23:32:17 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:18639
2021-04-04 23:32:17 | INFO | fairseq.distributed.utils | initialized host haroldl as rank 1
2021-04-04 23:32:18 | INFO | fairseq.distributed.utils | initialized host haroldl as rank 2
2021-04-04 23:32:18 | INFO | fairseq.distributed.utils | initialized host haroldl as rank 0
2021-04-04 23:32:20 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:18639', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'tpu': False, 'distributed_num_procs': 4}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 8192, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 8192, 'batch_size_valid': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 200, 'max_update': 200000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': 50, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'model_parallel_size': 1, 'distributed_rank': 0}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='vslstm_tf_fc4_attnfeat_wmt', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='vslstm_tf_fc4_attnfeat_wmt', attention_dropout=0.1, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', curriculum=0, data='data-bin/wmt16_en_de_bpe32k', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', dec_layernorm_embedding=False, decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_layerdrop=0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=4, dropout=0.3, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=6, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=False, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, ffoncell=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', heartbeat_timeout=-1, ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, kernel_size=1, label_smoothing=0.1, layer_wise_attention=False, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', mask_dummy_for_fgate=False, max_epoch=200, max_source_positions=1024, max_target_positions=1024, max_tokens=8192, max_tokens_valid=8192, max_update=200000, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_layer=False, min_loss_scale=0.0001, model_parallel_size=1, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=4, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', pad=1, patience=50, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=False, simul_type=None, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, suppress_crashes=False, target_lang=None, task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[1], upsample_primary=-1, use_bmuf=False, use_last_global=False, use_layerwise_global=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin/wmt16_en_de_bpe32k', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'simul_type': None}
2021-04-04 23:32:20 | INFO | fairseq.tasks.translation | [en] dictionary: 32768 types
2021-04-04 23:32:20 | INFO | fairseq.tasks.translation | [de] dictionary: 32768 types
2021-04-04 23:32:20 | INFO | fairseq.data.data_utils | loaded 3,000 examples from: data-bin/wmt16_en_de_bpe32k/valid.en-de.en
2021-04-04 23:32:20 | INFO | fairseq.data.data_utils | loaded 3,000 examples from: data-bin/wmt16_en_de_bpe32k/valid.en-de.de
2021-04-04 23:32:20 | INFO | fairseq.tasks.translation | data-bin/wmt16_en_de_bpe32k valid en-de 3000 examples
2021-04-04 23:32:20 | INFO | fairseq_cli.train | VanillaSlstmFeatTransformerModel(
  (encoder): SLSTMEncoder(
    (embed_tokens): Embedding(32768, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): VanillaSLSTMFeat(
      (norm_gate): Linear(in_features=2048, out_features=3584, bias=True)
      (emb_gate_linear): Linear(in_features=512, out_features=3584, bias=False)
      (peep_gate_linear): Linear(in_features=512, out_features=3584, bias=False)
      (attn_feautre): MultiheadAttention(
        (dropout_module): FairseqDropout()
        (k_proj): Linear(in_features=512, out_features=512, bias=True)
        (v_proj): Linear(in_features=512, out_features=512, bias=True)
        (q_proj): Linear(in_features=512, out_features=512, bias=True)
        (out_proj): Linear(in_features=512, out_features=512, bias=True)
        (relpos_k): RelativePosition()
        (relpos_v): RelativePosition()
      )
      (fc1): Linear(in_features=512, out_features=2048, bias=True)
      (fc2): Linear(in_features=2048, out_features=512, bias=True)
      (act_func): ReLU(inplace=True)
      (ffn_LN): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(32768, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=32768, bias=False)
  )
)
2021-04-04 23:32:20 | INFO | fairseq_cli.train | task: TranslationTask
2021-04-04 23:32:20 | INFO | fairseq_cli.train | model: VanillaSlstmFeatTransformerModel
2021-04-04 23:32:20 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2021-04-04 23:32:20 | INFO | fairseq_cli.train | num. model params: 56,170,624 (num. trained: 56,170,624)
2021-04-04 23:32:20 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2021-04-04 23:32:20 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2021-04-04 23:32:20 | INFO | fairseq.trainer | detected shared parameter: encoder.layers.emb_gate_linear.bias <- encoder.layers.peep_gate_linear.bias
2021-04-04 23:32:20 | INFO | fairseq.trainer | detected shared parameter: encoder.layers.emb_gate_linear.bias <- decoder.output_projection.bias
2021-04-04 23:32:20 | INFO | fairseq.utils | ***********************CUDA enviroments for all 4 workers***********************
2021-04-04 23:32:20 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = GeForce RTX 2080 Ti                     
2021-04-04 23:32:20 | INFO | fairseq.utils | rank   1: capabilities =  7.5  ; total memory = 10.761 GB ; name = GeForce RTX 2080 Ti                     
2021-04-04 23:32:20 | INFO | fairseq.utils | rank   2: capabilities =  7.5  ; total memory = 10.761 GB ; name = GeForce RTX 2080 Ti                     
2021-04-04 23:32:20 | INFO | fairseq.utils | rank   3: capabilities =  7.5  ; total memory = 10.760 GB ; name = GeForce RTX 2080 Ti                     
2021-04-04 23:32:20 | INFO | fairseq.utils | ***********************CUDA enviroments for all 4 workers***********************
2021-04-04 23:32:20 | INFO | fairseq_cli.train | training on 4 devices (GPUs/TPUs)
2021-04-04 23:32:20 | INFO | fairseq_cli.train | max tokens per GPU = 8192 and batch size per GPU = None
2021-04-04 23:32:20 | INFO | fairseq.trainer | Preparing to load checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-04 23:32:20 | INFO | fairseq.trainer | No existing checkpoint found /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-04 23:32:20 | INFO | fairseq.trainer | loading train data for epoch 1
2021-04-04 23:32:21 | INFO | fairseq.data.data_utils | loaded 4,500,966 examples from: data-bin/wmt16_en_de_bpe32k/train.en-de.en
2021-04-04 23:32:21 | INFO | fairseq.data.data_utils | loaded 4,500,966 examples from: data-bin/wmt16_en_de_bpe32k/train.en-de.de
2021-04-04 23:32:21 | INFO | fairseq.tasks.translation | data-bin/wmt16_en_de_bpe32k train en-de 4500966 examples
2021-04-04 23:32:22 | INFO | fairseq.trainer | begin training epoch 1
2021-04-04 23:32:22 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-04 23:32:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
Traceback (most recent call last):
  File "/home/amax/Codes/flstm-nmt/fairseq_cli/train.py", line 454, in <module>
    cli_main()
  File "/home/amax/Codes/flstm-nmt/fairseq_cli/train.py", line 450, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/home/amax/Codes/flstm-nmt/fairseq/distributed/utils.py", line 342, in call_main
    torch.multiprocessing.spawn(
  File "/home/amax/miniconda3/envs/nmt/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 200, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/home/amax/miniconda3/envs/nmt/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 158, in start_processes
    while not context.join():
  File "/home/amax/miniconda3/envs/nmt/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 119, in join
    raise Exception(msg)
Exception: 

-- Process 0 terminated with the following error:
Traceback (most recent call last):
  File "/home/amax/miniconda3/envs/nmt/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 20, in _wrap
    fn(i, *args)
  File "/home/amax/Codes/flstm-nmt/fairseq/distributed/utils.py", line 326, in distributed_main
    main(cfg, **kwargs)
  File "/home/amax/Codes/flstm-nmt/fairseq_cli/train.py", line 143, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/home/amax/miniconda3/envs/nmt/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/home/amax/Codes/flstm-nmt/fairseq_cli/train.py", line 244, in train
    log_output = trainer.train_step(samples)
  File "/home/amax/miniconda3/envs/nmt/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/home/amax/Codes/flstm-nmt/fairseq/trainer.py", line 588, in train_step
    raise e
  File "/home/amax/Codes/flstm-nmt/fairseq/trainer.py", line 556, in train_step
    loss, sample_size_i, logging_output = self.task.train_step(
  File "/home/amax/Codes/flstm-nmt/fairseq/tasks/fairseq_task.py", line 475, in train_step
    loss, sample_size, logging_output = criterion(model, sample)
  File "/home/amax/miniconda3/envs/nmt/lib/python3.8/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/amax/Codes/flstm-nmt/fairseq/criterions/label_smoothed_cross_entropy.py", line 79, in forward
    net_output = model(**sample["net_input"])
  File "/home/amax/miniconda3/envs/nmt/lib/python3.8/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/amax/Codes/flstm-nmt/fairseq/distributed/distributed_timeout_wrapper.py", line 79, in forward
    return self.module(*args, **kwargs)
  File "/home/amax/miniconda3/envs/nmt/lib/python3.8/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/amax/Codes/flstm-nmt/fairseq/distributed/module_proxy_wrapper.py", line 55, in forward
    return self.module(*args, **kwargs)
  File "/home/amax/miniconda3/envs/nmt/lib/python3.8/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/amax/miniconda3/envs/nmt/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 475, in forward
    self.reducer.prepare_for_backward([])
RuntimeError: Expected to have finished reduction in the prior iteration before starting a new one. This error indicates that your module has parameters that were not used in producing loss. You can enable unused parameter detection by (1) passing the keyword argument `find_unused_parameters=True` to `torch.nn.parallel.DistributedDataParallel`; (2) making sure all `forward` function outputs participate in calculating loss. If you already have done the above two steps, then the distributed data parallel module wasn't able to locate the output tensors in the return value of your module's `forward` function. Please include the loss function and the structure of the return value of `forward` of your module when reporting this issue (e.g. list, dict, iterable).

/home/amax/miniconda3/envs/nmt/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 15 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
Start training...
2021-04-05 00:22:52 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:18469
2021-04-05 00:22:52 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:18469
2021-04-05 00:22:52 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:18469
2021-04-05 00:22:52 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:18469
2021-04-05 00:22:52 | INFO | fairseq.distributed.utils | initialized host haroldl as rank 2
2021-04-05 00:22:53 | INFO | fairseq.distributed.utils | initialized host haroldl as rank 1
2021-04-05 00:22:53 | INFO | fairseq.distributed.utils | initialized host haroldl as rank 3
2021-04-05 00:22:53 | INFO | fairseq.distributed.utils | initialized host haroldl as rank 0
2021-04-05 00:22:55 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:18469', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'tpu': False, 'distributed_num_procs': 4}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 8192, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 8192, 'batch_size_valid': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 200, 'max_update': 200000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': 50, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'model_parallel_size': 1, 'distributed_rank': 0}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='vslstm_tf_fc4_attnfeat_wmt', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='vslstm_tf_fc4_attnfeat_wmt', attention_dropout=0.1, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', curriculum=0, data='data-bin/wmt16_en_de_bpe32k', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', dec_layernorm_embedding=False, decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_layerdrop=0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=4, dropout=0.3, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=6, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=False, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, ffoncell=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', heartbeat_timeout=-1, ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, kernel_size=1, label_smoothing=0.1, layer_wise_attention=False, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', mask_dummy_for_fgate=False, max_epoch=200, max_source_positions=1024, max_target_positions=1024, max_tokens=8192, max_tokens_valid=8192, max_update=200000, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_layer=False, min_loss_scale=0.0001, model_parallel_size=1, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=4, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', pad=1, patience=50, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=False, simul_type=None, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, suppress_crashes=False, target_lang=None, task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[1], upsample_primary=-1, use_bmuf=False, use_last_global=False, use_layerwise_global=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin/wmt16_en_de_bpe32k', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'simul_type': None}
2021-04-05 00:22:55 | INFO | fairseq.tasks.translation | [en] dictionary: 32768 types
2021-04-05 00:22:55 | INFO | fairseq.tasks.translation | [de] dictionary: 32768 types
2021-04-05 00:22:55 | INFO | fairseq.data.data_utils | loaded 3,000 examples from: data-bin/wmt16_en_de_bpe32k/valid.en-de.en
2021-04-05 00:22:55 | INFO | fairseq.data.data_utils | loaded 3,000 examples from: data-bin/wmt16_en_de_bpe32k/valid.en-de.de
2021-04-05 00:22:55 | INFO | fairseq.tasks.translation | data-bin/wmt16_en_de_bpe32k valid en-de 3000 examples
2021-04-05 00:22:56 | INFO | fairseq_cli.train | VanillaSlstmFeatTransformerModel(
  (encoder): SLSTMEncoder(
    (embed_tokens): Embedding(32768, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): VanillaSLSTMFeat(
      (norm_gate): Linear(in_features=2048, out_features=3584, bias=True)
      (emb_gate_linear): Linear(in_features=512, out_features=3584, bias=False)
      (peep_gate_linear): Linear(in_features=512, out_features=3584, bias=False)
      (attn_feautre): MultiheadAttention(
        (dropout_module): FairseqDropout()
        (k_proj): Linear(in_features=512, out_features=512, bias=True)
        (v_proj): Linear(in_features=512, out_features=512, bias=True)
        (q_proj): Linear(in_features=512, out_features=512, bias=True)
        (out_proj): Linear(in_features=512, out_features=512, bias=True)
        (relpos_k): RelativePosition()
        (relpos_v): RelativePosition()
      )
      (fc1): Linear(in_features=512, out_features=2048, bias=True)
      (fc2): Linear(in_features=2048, out_features=512, bias=True)
      (act_func): ReLU(inplace=True)
      (ffn_LN): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(32768, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=32768, bias=False)
  )
)
2021-04-05 00:22:56 | INFO | fairseq_cli.train | task: TranslationTask
2021-04-05 00:22:56 | INFO | fairseq_cli.train | model: VanillaSlstmFeatTransformerModel
2021-04-05 00:22:56 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2021-04-05 00:22:56 | INFO | fairseq_cli.train | num. model params: 56,170,624 (num. trained: 56,170,624)
2021-04-05 00:22:56 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2021-04-05 00:22:56 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2021-04-05 00:22:56 | INFO | fairseq.trainer | detected shared parameter: encoder.layers.norm_gates_b <- encoder.layers.norm_gate.bias
2021-04-05 00:22:56 | INFO | fairseq.trainer | detected shared parameter: encoder.layers.emb_gate_linear.bias <- encoder.layers.peep_gate_linear.bias
2021-04-05 00:22:56 | INFO | fairseq.trainer | detected shared parameter: encoder.layers.emb_gate_linear.bias <- decoder.output_projection.bias
2021-04-05 00:22:56 | INFO | fairseq.utils | ***********************CUDA enviroments for all 4 workers***********************
2021-04-05 00:22:56 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = GeForce RTX 2080 Ti                     
2021-04-05 00:22:56 | INFO | fairseq.utils | rank   1: capabilities =  7.5  ; total memory = 10.761 GB ; name = GeForce RTX 2080 Ti                     
2021-04-05 00:22:56 | INFO | fairseq.utils | rank   2: capabilities =  7.5  ; total memory = 10.761 GB ; name = GeForce RTX 2080 Ti                     
2021-04-05 00:22:56 | INFO | fairseq.utils | rank   3: capabilities =  7.5  ; total memory = 10.760 GB ; name = GeForce RTX 2080 Ti                     
2021-04-05 00:22:56 | INFO | fairseq.utils | ***********************CUDA enviroments for all 4 workers***********************
2021-04-05 00:22:56 | INFO | fairseq_cli.train | training on 4 devices (GPUs/TPUs)
2021-04-05 00:22:56 | INFO | fairseq_cli.train | max tokens per GPU = 8192 and batch size per GPU = None
2021-04-05 00:22:56 | INFO | fairseq.trainer | Preparing to load checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-05 00:22:56 | INFO | fairseq.trainer | No existing checkpoint found /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-05 00:22:56 | INFO | fairseq.trainer | loading train data for epoch 1
2021-04-05 00:22:56 | INFO | fairseq.data.data_utils | loaded 4,500,966 examples from: data-bin/wmt16_en_de_bpe32k/train.en-de.en
2021-04-05 00:22:56 | INFO | fairseq.data.data_utils | loaded 4,500,966 examples from: data-bin/wmt16_en_de_bpe32k/train.en-de.de
2021-04-05 00:22:56 | INFO | fairseq.tasks.translation | data-bin/wmt16_en_de_bpe32k train en-de 4500966 examples
2021-04-05 00:22:58 | INFO | fairseq.trainer | begin training epoch 1
2021-04-05 00:22:58 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-05 00:23:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2021-04-05 00:23:00 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2021-04-05 00:23:32 | INFO | train_inner | epoch 001:    102 / 4673 loss=14.598, nll_loss=14.471, ppl=22703.9, wps=91730.9, ups=3.12, wpb=29445.2, bsz=983, num_updates=100, lr=1.25e-05, gnorm=2.309, loss_scale=32, train_wall=33, gb_free=2.8, wall=36
2021-04-05 00:24:04 | INFO | train_inner | epoch 001:    202 / 4673 loss=13.154, nll_loss=12.869, ppl=7481.02, wps=92035.5, ups=3.15, wpb=29237.4, bsz=950.4, num_updates=200, lr=2.5e-05, gnorm=0.922, loss_scale=32, train_wall=32, gb_free=3.1, wall=68
2021-04-05 00:24:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2021-04-05 00:24:36 | INFO | train_inner | epoch 001:    303 / 4673 loss=12.092, nll_loss=11.668, ppl=3254.72, wps=92408.4, ups=3.11, wpb=29756, bsz=990.5, num_updates=300, lr=3.75e-05, gnorm=1.047, loss_scale=16, train_wall=32, gb_free=2.7, wall=100
2021-04-05 00:25:08 | INFO | train_inner | epoch 001:    403 / 4673 loss=11.603, nll_loss=11.074, ppl=2155.55, wps=92339.4, ups=3.12, wpb=29610.6, bsz=968.7, num_updates=400, lr=5e-05, gnorm=0.882, loss_scale=16, train_wall=32, gb_free=3.1, wall=132
2021-04-05 00:25:40 | INFO | train_inner | epoch 001:    503 / 4673 loss=11.341, nll_loss=10.752, ppl=1724.14, wps=92399.8, ups=3.11, wpb=29687.6, bsz=1021.7, num_updates=500, lr=6.25e-05, gnorm=0.913, loss_scale=16, train_wall=32, gb_free=3.7, wall=164
2021-04-05 00:26:12 | INFO | train_inner | epoch 001:    603 / 4673 loss=11.175, nll_loss=10.557, ppl=1506.68, wps=92395.4, ups=3.12, wpb=29597.9, bsz=975.4, num_updates=600, lr=7.5e-05, gnorm=0.966, loss_scale=16, train_wall=32, gb_free=2.7, wall=196
2021-04-05 00:26:33 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 864.00 MiB (GPU 0; 10.76 GiB total capacity; 7.79 GiB already allocated; 726.12 MiB free; 9.26 GiB reserved in total by PyTorch) (malloc at /opt/conda/conda-bld/pytorch_1591914858187/work/c10/cuda/CUDACachingAllocator.cpp:289)
frame #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x4e (0x7f12f01eeb5e in /home/amax/miniconda3/envs/nmt/lib/python3.8/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1f39d (0x7f12f043a39d in /home/amax/miniconda3/envs/nmt/lib/python3.8/site-packages/torch/lib/libc10_cuda.so)
frame #2: <unknown function> + 0x2058e (0x7f12f043b58e in /home/amax/miniconda3/envs/nmt/lib/python3.8/site-packages/torch/lib/libc10_cuda.so)
frame #3: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x291 (0x7f127e9f7401 in /home/amax/miniconda3/envs/nmt/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xdc454b (0x7f127ccaa54b in /home/amax/miniconda3/envs/nmt/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xe0de37 (0x7f127ccf3e37 in /home/amax/miniconda3/envs/nmt/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xdd2339 (0x7f12a7c02339 in /home/amax/miniconda3/envs/nmt/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)
frame #7: <unknown function> + 0xdd2677 (0x7f12a7c02677 in /home/amax/miniconda3/envs/nmt/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)
frame #8: <unknown function> + 0xb993be (0x7f12a79c93be in /home/amax/miniconda3/envs/nmt/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)
frame #9: at::TensorIterator::allocate_outputs() + 0x38c (0x7f12a79c98dc in /home/amax/miniconda3/envs/nmt/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)
frame #10: at::TensorIterator::build() + 0x208 (0x7f12a79cacb8 in /home/amax/miniconda3/envs/nmt/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)
frame #11: at::TensorIterator::binary_op(at::Tensor&, at::Tensor const&, at::Tensor const&, bool) + 0x146 (0x7f12a79cb1a6 in /home/amax/miniconda3/envs/nmt/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)
frame #12: at::native::add(at::Tensor const&, at::Tensor const&, c10::Scalar) + 0x45 (0x7f12a76e94d5 in /home/amax/miniconda3/envs/nmt/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)
frame #13: <unknown function> + 0xdbeb45 (0x7f127cca4b45 in /home/amax/miniconda3/envs/nmt/lib/python3.8/site-packages/torch/lib/libtorch_cuda.so)
frame #14: <unknown function> + 0xe2294b (0x7f12a7c5294b in /home/amax/miniconda3/envs/nmt/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0x296a898 (0x7f12a979a898 in /home/amax/miniconda3/envs/nmt/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)
frame #16: <unknown function> + 0xe2294b (0x7f12a7c5294b in /home/amax/miniconda3/envs/nmt/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)
frame #17: <unknown function> + 0x2af769d (0x7f12a992769d in /home/amax/miniconda3/envs/nmt/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)
frame #18: <unknown function> + 0x2af8b44 (0x7f12a9928b44 in /home/amax/miniconda3/envs/nmt/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)
frame #19: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&) + 0xf5b (0x7f12a991495b in /home/amax/miniconda3/envs/nmt/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)
frame #20: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&, bool) + 0x3d2 (0x7f12a9915ed2 in /home/amax/miniconda3/envs/nmt/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)
frame #21: torch::autograd::Engine::thread_init(int) + 0x39 (0x7f12a990e549 in /home/amax/miniconda3/envs/nmt/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so)
frame #22: torch::autograd::python::PythonEngine::thread_init(int) + 0x38 (0x7f12de57cb08 in /home/amax/miniconda3/envs/nmt/lib/python3.8/site-packages/torch/lib/libtorch_python.so)
frame #23: <unknown function> + 0xc819d (0x7f12f2cad19d in /home/amax/miniconda3/envs/nmt/lib/python3.8/site-packages/torch/lib/../../../.././libstdc++.so.6)
frame #24: <unknown function> + 0x76db (0x7f12fa25a6db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #25: clone + 0x3f (0x7f12f9f83a3f in /lib/x86_64-linux-gnu/libc.so.6)

2021-04-05 00:26:33 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 2         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7114 MB |    7979 MB |   11631 GB |   11624 GB |
|       from large pool |    7082 MB |    7946 MB |   11586 GB |   11579 GB |
|       from small pool |      32 MB |      52 MB |      44 GB |      44 GB |
|---------------------------------------------------------------------------|
| Active memory         |    7114 MB |    7979 MB |   11631 GB |   11624 GB |
|       from large pool |    7082 MB |    7946 MB |   11586 GB |   11579 GB |
|       from small pool |      32 MB |      52 MB |      44 GB |      44 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    9478 MB |    9696 MB |   29048 MB |   19570 MB |
|       from large pool |    9444 MB |    9504 MB |   28826 MB |   19382 MB |
|       from small pool |      34 MB |     192 MB |     222 MB |     188 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1339 MB |    1499 MB |   10141 GB |   10140 GB |
|       from large pool |    1337 MB |    1497 MB |   10087 GB |   10086 GB |
|       from small pool |       1 MB |       9 MB |      54 GB |      54 GB |
|---------------------------------------------------------------------------|
| Allocations           |     668    |     673    |    1618 K  |    1617 K  |
|       from large pool |     399    |     403    |    1040 K  |    1040 K  |
|       from small pool |     269    |     374    |     577 K  |     577 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     668    |     673    |    1618 K  |    1617 K  |
|       from large pool |     399    |     403    |    1040 K  |    1040 K  |
|       from small pool |     269    |     374    |     577 K  |     577 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     147    |     229    |     579    |     432    |
|       from large pool |     130    |     133    |     468    |     338    |
|       from small pool |      17    |      96    |     111    |      94    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     104    |     106    |     993 K  |     992 K  |
|       from large pool |      87    |      88    |     716 K  |     716 K  |
|       from small pool |      17    |      26    |     276 K  |     276 K  |
|===========================================================================|

2021-04-05 00:26:33 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2021-04-05 00:26:33 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2021-04-05 00:26:33 | WARNING | fairseq.trainer | |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2021-04-05 00:26:33 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass
Start training...
2021-04-05 00:36:37 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:13991
2021-04-05 00:36:37 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:13991
2021-04-05 00:36:37 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:13991
2021-04-05 00:36:37 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:13991
2021-04-05 00:36:38 | INFO | fairseq.distributed.utils | initialized host haroldl as rank 1
2021-04-05 00:36:38 | INFO | fairseq.distributed.utils | initialized host haroldl as rank 3
2021-04-05 00:36:38 | INFO | fairseq.distributed.utils | initialized host haroldl as rank 2
2021-04-05 00:36:38 | INFO | fairseq.distributed.utils | initialized host haroldl as rank 0
2021-04-05 00:36:40 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:13991', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'tpu': False, 'distributed_num_procs': 4}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4096, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4096, 'batch_size_valid': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 200, 'max_update': 200000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [2], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': 50, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'model_parallel_size': 1, 'distributed_rank': 0}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='vslstm_tf_fc4_attnfeat_wmt', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='vslstm_tf_fc4_attnfeat_wmt', attention_dropout=0.1, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', curriculum=0, data='data-bin/wmt16_en_de_bpe32k', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', dec_layernorm_embedding=False, decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_layerdrop=0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=4, dropout=0.3, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=6, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=False, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, ffoncell=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', heartbeat_timeout=-1, ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, kernel_size=1, label_smoothing=0.1, layer_wise_attention=False, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', mask_dummy_for_fgate=False, max_epoch=200, max_source_positions=1024, max_target_positions=1024, max_tokens=4096, max_tokens_valid=4096, max_update=200000, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_layer=False, min_loss_scale=0.0001, model_parallel_size=1, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=4, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', pad=1, patience=50, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=False, simul_type=None, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, suppress_crashes=False, target_lang=None, task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[2], upsample_primary=-1, use_bmuf=False, use_last_global=False, use_layerwise_global=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin/wmt16_en_de_bpe32k', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'simul_type': None}
2021-04-05 00:36:40 | INFO | fairseq.tasks.translation | [en] dictionary: 32768 types
2021-04-05 00:36:40 | INFO | fairseq.tasks.translation | [de] dictionary: 32768 types
2021-04-05 00:36:40 | INFO | fairseq.data.data_utils | loaded 3,000 examples from: data-bin/wmt16_en_de_bpe32k/valid.en-de.en
2021-04-05 00:36:40 | INFO | fairseq.data.data_utils | loaded 3,000 examples from: data-bin/wmt16_en_de_bpe32k/valid.en-de.de
2021-04-05 00:36:40 | INFO | fairseq.tasks.translation | data-bin/wmt16_en_de_bpe32k valid en-de 3000 examples
2021-04-05 00:36:41 | INFO | fairseq_cli.train | VanillaSlstmFeatTransformerModel(
  (encoder): SLSTMEncoder(
    (embed_tokens): Embedding(32768, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): VanillaSLSTMFeat(
      (norm_gate): Linear(in_features=2048, out_features=3584, bias=True)
      (emb_gate_linear): Linear(in_features=512, out_features=3584, bias=False)
      (peep_gate_linear): Linear(in_features=512, out_features=3584, bias=False)
      (attn_feautre): MultiheadAttention(
        (dropout_module): FairseqDropout()
        (k_proj): Linear(in_features=512, out_features=512, bias=True)
        (v_proj): Linear(in_features=512, out_features=512, bias=True)
        (q_proj): Linear(in_features=512, out_features=512, bias=True)
        (out_proj): Linear(in_features=512, out_features=512, bias=True)
        (relpos_k): RelativePosition()
        (relpos_v): RelativePosition()
      )
      (fc1): Linear(in_features=512, out_features=2048, bias=True)
      (fc2): Linear(in_features=2048, out_features=512, bias=True)
      (act_func): ReLU(inplace=True)
      (ffn_LN): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(32768, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=32768, bias=False)
  )
)
2021-04-05 00:36:41 | INFO | fairseq_cli.train | task: TranslationTask
2021-04-05 00:36:41 | INFO | fairseq_cli.train | model: VanillaSlstmFeatTransformerModel
2021-04-05 00:36:41 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2021-04-05 00:36:41 | INFO | fairseq_cli.train | num. model params: 56,170,624 (num. trained: 56,170,624)
2021-04-05 00:36:41 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2021-04-05 00:36:41 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2021-04-05 00:36:41 | INFO | fairseq.trainer | detected shared parameter: encoder.layers.norm_gates_b <- encoder.layers.norm_gate.bias
2021-04-05 00:36:41 | INFO | fairseq.trainer | detected shared parameter: encoder.layers.emb_gate_linear.bias <- encoder.layers.peep_gate_linear.bias
2021-04-05 00:36:41 | INFO | fairseq.trainer | detected shared parameter: encoder.layers.emb_gate_linear.bias <- decoder.output_projection.bias
2021-04-05 00:36:41 | INFO | fairseq.utils | ***********************CUDA enviroments for all 4 workers***********************
2021-04-05 00:36:41 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = GeForce RTX 2080 Ti                     
2021-04-05 00:36:41 | INFO | fairseq.utils | rank   1: capabilities =  7.5  ; total memory = 10.761 GB ; name = GeForce RTX 2080 Ti                     
2021-04-05 00:36:41 | INFO | fairseq.utils | rank   2: capabilities =  7.5  ; total memory = 10.761 GB ; name = GeForce RTX 2080 Ti                     
2021-04-05 00:36:41 | INFO | fairseq.utils | rank   3: capabilities =  7.5  ; total memory = 10.760 GB ; name = GeForce RTX 2080 Ti                     
2021-04-05 00:36:41 | INFO | fairseq.utils | ***********************CUDA enviroments for all 4 workers***********************
2021-04-05 00:36:41 | INFO | fairseq_cli.train | training on 4 devices (GPUs/TPUs)
2021-04-05 00:36:41 | INFO | fairseq_cli.train | max tokens per GPU = 4096 and batch size per GPU = None
2021-04-05 00:36:41 | INFO | fairseq.trainer | Preparing to load checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-05 00:36:41 | INFO | fairseq.trainer | No existing checkpoint found /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-05 00:36:41 | INFO | fairseq.trainer | loading train data for epoch 1
2021-04-05 00:36:42 | INFO | fairseq.data.data_utils | loaded 4,500,966 examples from: data-bin/wmt16_en_de_bpe32k/train.en-de.en
2021-04-05 00:36:42 | INFO | fairseq.data.data_utils | loaded 4,500,966 examples from: data-bin/wmt16_en_de_bpe32k/train.en-de.de
2021-04-05 00:36:42 | INFO | fairseq.tasks.translation | data-bin/wmt16_en_de_bpe32k train en-de 4500966 examples
2021-04-05 00:36:43 | INFO | fairseq.trainer | begin training epoch 1
2021-04-05 00:36:43 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-05 00:36:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
Start training...
2021-04-05 00:37:12 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:19954
2021-04-05 00:37:12 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:19954
2021-04-05 00:37:12 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:19954
2021-04-05 00:37:12 | INFO | fairseq.distributed.utils | initialized host haroldl as rank 2
2021-04-05 00:37:12 | INFO | fairseq.distributed.utils | initialized host haroldl as rank 1
2021-04-05 00:37:12 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:19954
2021-04-05 00:37:12 | INFO | fairseq.distributed.utils | initialized host haroldl as rank 3
2021-04-05 00:37:12 | INFO | fairseq.distributed.utils | initialized host haroldl as rank 0
2021-04-05 00:37:14 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:19954', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'tpu': False, 'distributed_num_procs': 4}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4096, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4096, 'batch_size_valid': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 200, 'max_update': 200000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [2], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': 50, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'model_parallel_size': 1, 'distributed_rank': 0}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='vslstm_tf_fc4_attnfeat_wmt', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='vslstm_tf_fc4_attnfeat_wmt', attention_dropout=0.1, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', curriculum=0, data='data-bin/wmt16_en_de_bpe32k', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', dec_layernorm_embedding=False, decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_layerdrop=0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=4, dropout=0.3, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=6, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=False, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, ffoncell=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', heartbeat_timeout=-1, ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, kernel_size=1, label_smoothing=0.1, layer_wise_attention=False, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', mask_dummy_for_fgate=False, max_epoch=200, max_source_positions=1024, max_target_positions=1024, max_tokens=4096, max_tokens_valid=4096, max_update=200000, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_layer=False, min_loss_scale=0.0001, model_parallel_size=1, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=4, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', pad=1, patience=50, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=False, simul_type=None, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, suppress_crashes=False, target_lang=None, task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[2], upsample_primary=-1, use_bmuf=False, use_last_global=False, use_layerwise_global=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin/wmt16_en_de_bpe32k', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'simul_type': None}
2021-04-05 00:37:14 | INFO | fairseq.tasks.translation | [en] dictionary: 32768 types
2021-04-05 00:37:14 | INFO | fairseq.tasks.translation | [de] dictionary: 32768 types
2021-04-05 00:37:14 | INFO | fairseq.data.data_utils | loaded 3,000 examples from: data-bin/wmt16_en_de_bpe32k/valid.en-de.en
2021-04-05 00:37:14 | INFO | fairseq.data.data_utils | loaded 3,000 examples from: data-bin/wmt16_en_de_bpe32k/valid.en-de.de
2021-04-05 00:37:14 | INFO | fairseq.tasks.translation | data-bin/wmt16_en_de_bpe32k valid en-de 3000 examples
2021-04-05 00:37:15 | INFO | fairseq_cli.train | VanillaSlstmFeatTransformerModel(
  (encoder): SLSTMEncoder(
    (embed_tokens): Embedding(32768, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): VanillaSLSTMFeat(
      (norm_gate): Linear(in_features=2048, out_features=3584, bias=True)
      (emb_gate_linear): Linear(in_features=512, out_features=3584, bias=False)
      (peep_gate_linear): Linear(in_features=512, out_features=3584, bias=False)
      (attn_feautre): MultiheadAttention(
        (dropout_module): FairseqDropout()
        (k_proj): Linear(in_features=512, out_features=512, bias=True)
        (v_proj): Linear(in_features=512, out_features=512, bias=True)
        (q_proj): Linear(in_features=512, out_features=512, bias=True)
        (out_proj): Linear(in_features=512, out_features=512, bias=True)
        (relpos_k): RelativePosition()
        (relpos_v): RelativePosition()
      )
      (fc1): Linear(in_features=512, out_features=2048, bias=True)
      (fc2): Linear(in_features=2048, out_features=512, bias=True)
      (act_func): ReLU(inplace=True)
      (ffn_LN): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(32768, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=32768, bias=False)
  )
)
2021-04-05 00:37:15 | INFO | fairseq_cli.train | task: TranslationTask
2021-04-05 00:37:15 | INFO | fairseq_cli.train | model: VanillaSlstmFeatTransformerModel
2021-04-05 00:37:15 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2021-04-05 00:37:15 | INFO | fairseq_cli.train | num. model params: 56,170,624 (num. trained: 56,170,624)
2021-04-05 00:37:15 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2021-04-05 00:37:15 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2021-04-05 00:37:15 | INFO | fairseq.trainer | detected shared parameter: encoder.layers.norm_gates_b <- encoder.layers.norm_gate.bias
2021-04-05 00:37:15 | INFO | fairseq.trainer | detected shared parameter: encoder.layers.emb_gate_linear.bias <- encoder.layers.peep_gate_linear.bias
2021-04-05 00:37:15 | INFO | fairseq.trainer | detected shared parameter: encoder.layers.emb_gate_linear.bias <- decoder.output_projection.bias
2021-04-05 00:37:15 | INFO | fairseq.utils | ***********************CUDA enviroments for all 4 workers***********************
2021-04-05 00:37:15 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = GeForce RTX 2080 Ti                     
2021-04-05 00:37:15 | INFO | fairseq.utils | rank   1: capabilities =  7.5  ; total memory = 10.761 GB ; name = GeForce RTX 2080 Ti                     
2021-04-05 00:37:15 | INFO | fairseq.utils | rank   2: capabilities =  7.5  ; total memory = 10.761 GB ; name = GeForce RTX 2080 Ti                     
2021-04-05 00:37:15 | INFO | fairseq.utils | rank   3: capabilities =  7.5  ; total memory = 10.760 GB ; name = GeForce RTX 2080 Ti                     
2021-04-05 00:37:15 | INFO | fairseq.utils | ***********************CUDA enviroments for all 4 workers***********************
2021-04-05 00:37:15 | INFO | fairseq_cli.train | training on 4 devices (GPUs/TPUs)
2021-04-05 00:37:15 | INFO | fairseq_cli.train | max tokens per GPU = 4096 and batch size per GPU = None
2021-04-05 00:37:15 | INFO | fairseq.trainer | Preparing to load checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-05 00:37:15 | INFO | fairseq.trainer | No existing checkpoint found /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-05 00:37:15 | INFO | fairseq.trainer | loading train data for epoch 1
2021-04-05 00:37:15 | INFO | fairseq.data.data_utils | loaded 4,500,966 examples from: data-bin/wmt16_en_de_bpe32k/train.en-de.en
2021-04-05 00:37:15 | INFO | fairseq.data.data_utils | loaded 4,500,966 examples from: data-bin/wmt16_en_de_bpe32k/train.en-de.de
2021-04-05 00:37:15 | INFO | fairseq.tasks.translation | data-bin/wmt16_en_de_bpe32k train en-de 4500966 examples
2021-04-05 00:37:17 | INFO | fairseq.trainer | begin training epoch 1
2021-04-05 00:37:17 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-05 00:37:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2021-04-05 00:37:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2021-04-05 00:37:52 | INFO | train_inner | epoch 001:    102 / 4751 loss=14.605, nll_loss=14.479, ppl=22830.3, wps=88783, ups=3.04, wpb=29167.4, bsz=941, num_updates=100, lr=1.25e-05, gnorm=2.245, loss_scale=32, train_wall=34, gb_free=6.5, wall=36
2021-04-05 00:38:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2021-04-05 00:38:25 | INFO | train_inner | epoch 001:    203 / 4751 loss=13.131, nll_loss=12.843, ppl=7345.29, wps=88225.5, ups=3.04, wpb=29055.9, bsz=955.3, num_updates=200, lr=2.5e-05, gnorm=0.923, loss_scale=16, train_wall=33, gb_free=6.2, wall=69
2021-04-05 00:38:57 | INFO | train_inner | epoch 001:    303 / 4751 loss=12.085, nll_loss=11.659, ppl=3234.41, wps=87116.6, ups=3.06, wpb=28490.6, bsz=953.8, num_updates=300, lr=3.75e-05, gnorm=0.907, loss_scale=16, train_wall=33, gb_free=6.3, wall=102
2021-04-05 00:39:30 | INFO | train_inner | epoch 001:    403 / 4751 loss=11.588, nll_loss=11.056, ppl=2129.27, wps=87659, ups=3.04, wpb=28859, bsz=927.9, num_updates=400, lr=5e-05, gnorm=0.792, loss_scale=16, train_wall=33, gb_free=6.3, wall=135
2021-04-05 00:40:03 | INFO | train_inner | epoch 001:    503 / 4751 loss=11.383, nll_loss=10.799, ppl=1782.07, wps=88526.8, ups=3.06, wpb=28904.8, bsz=934.3, num_updates=500, lr=6.25e-05, gnorm=0.865, loss_scale=16, train_wall=33, gb_free=6.3, wall=168
2021-04-05 00:40:36 | INFO | train_inner | epoch 001:    603 / 4751 loss=11.164, nll_loss=10.545, ppl=1494.52, wps=87951.4, ups=3.04, wpb=28954.8, bsz=937.9, num_updates=600, lr=7.5e-05, gnorm=0.886, loss_scale=16, train_wall=33, gb_free=6.1, wall=201
2021-04-05 00:41:09 | INFO | train_inner | epoch 001:    703 / 4751 loss=10.87, nll_loss=10.204, ppl=1179.92, wps=87671.6, ups=3.02, wpb=29023, bsz=963, num_updates=700, lr=8.75e-05, gnorm=1.005, loss_scale=16, train_wall=33, gb_free=6.5, wall=234
2021-04-05 00:41:42 | INFO | train_inner | epoch 001:    803 / 4751 loss=10.594, nll_loss=9.88, ppl=942.6, wps=87911.8, ups=3.05, wpb=28799.6, bsz=943.2, num_updates=800, lr=0.0001, gnorm=1.018, loss_scale=16, train_wall=33, gb_free=6.3, wall=266
2021-04-05 00:42:15 | INFO | train_inner | epoch 001:    903 / 4751 loss=10.388, nll_loss=9.638, ppl=796.6, wps=88033.1, ups=3.04, wpb=28949.8, bsz=906.6, num_updates=900, lr=0.0001125, gnorm=0.966, loss_scale=16, train_wall=33, gb_free=6.5, wall=299
2021-04-05 00:42:48 | INFO | train_inner | epoch 001:   1003 / 4751 loss=10.099, nll_loss=9.302, ppl=631.35, wps=87587.1, ups=3.03, wpb=28953.9, bsz=965.7, num_updates=1000, lr=0.000125, gnorm=1.103, loss_scale=16, train_wall=33, gb_free=6.3, wall=332
2021-04-05 00:43:20 | INFO | train_inner | epoch 001:   1103 / 4751 loss=9.925, nll_loss=9.097, ppl=547.52, wps=89122, ups=3.07, wpb=29030.9, bsz=895.1, num_updates=1100, lr=0.0001375, gnorm=0.938, loss_scale=16, train_wall=32, gb_free=6.4, wall=365
2021-04-05 00:43:53 | INFO | train_inner | epoch 001:   1203 / 4751 loss=9.713, nll_loss=8.849, ppl=461.08, wps=88052.9, ups=3.02, wpb=29126.9, bsz=935.8, num_updates=1200, lr=0.00015, gnorm=0.913, loss_scale=16, train_wall=33, gb_free=6.3, wall=398
2021-04-05 00:44:26 | INFO | train_inner | epoch 001:   1303 / 4751 loss=9.506, nll_loss=8.608, ppl=390.13, wps=87867.4, ups=3.04, wpb=28919.7, bsz=993.4, num_updates=1300, lr=0.0001625, gnorm=0.909, loss_scale=16, train_wall=33, gb_free=6.3, wall=431
2021-04-05 00:44:59 | INFO | train_inner | epoch 001:   1403 / 4751 loss=9.376, nll_loss=8.454, ppl=350.58, wps=87259.8, ups=3.03, wpb=28833.9, bsz=949.8, num_updates=1400, lr=0.000175, gnorm=0.928, loss_scale=16, train_wall=33, gb_free=6.2, wall=464
2021-04-05 00:45:32 | INFO | train_inner | epoch 001:   1503 / 4751 loss=9.185, nll_loss=8.233, ppl=300.78, wps=87259.5, ups=3.02, wpb=28904.8, bsz=943, num_updates=1500, lr=0.0001875, gnorm=0.921, loss_scale=16, train_wall=33, gb_free=6.5, wall=497
2021-04-05 00:46:05 | INFO | train_inner | epoch 001:   1603 / 4751 loss=9.029, nll_loss=8.05, ppl=265.07, wps=87936, ups=3.03, wpb=28995.3, bsz=972, num_updates=1600, lr=0.0002, gnorm=0.894, loss_scale=16, train_wall=33, gb_free=6.2, wall=530
2021-04-05 00:46:38 | INFO | train_inner | epoch 001:   1703 / 4751 loss=8.869, nll_loss=7.864, ppl=232.98, wps=88336.4, ups=3.03, wpb=29116.4, bsz=958.1, num_updates=1700, lr=0.0002125, gnorm=0.888, loss_scale=16, train_wall=33, gb_free=6.2, wall=563
2021-04-05 00:47:11 | INFO | train_inner | epoch 001:   1803 / 4751 loss=8.762, nll_loss=7.737, ppl=213.31, wps=86034.7, ups=3.02, wpb=28465.2, bsz=954.4, num_updates=1800, lr=0.000225, gnorm=0.889, loss_scale=16, train_wall=33, gb_free=6.2, wall=596
2021-04-05 00:47:44 | INFO | train_inner | epoch 001:   1903 / 4751 loss=8.602, nll_loss=7.551, ppl=187.58, wps=88364.9, ups=3.05, wpb=29013.8, bsz=950.2, num_updates=1900, lr=0.0002375, gnorm=0.844, loss_scale=16, train_wall=33, gb_free=6.1, wall=629
2021-04-05 00:48:17 | INFO | train_inner | epoch 001:   2003 / 4751 loss=8.437, nll_loss=7.36, ppl=164.25, wps=87630.6, ups=3.03, wpb=28899.3, bsz=942.6, num_updates=2000, lr=0.00025, gnorm=0.85, loss_scale=16, train_wall=33, gb_free=6.3, wall=662
2021-04-05 00:48:50 | INFO | train_inner | epoch 001:   2103 / 4751 loss=8.286, nll_loss=7.184, ppl=145.37, wps=87560.7, ups=3.03, wpb=28899.8, bsz=917.7, num_updates=2100, lr=0.0002625, gnorm=0.864, loss_scale=16, train_wall=33, gb_free=6.6, wall=695
2021-04-05 00:49:23 | INFO | train_inner | epoch 001:   2203 / 4751 loss=8.134, nll_loss=7.006, ppl=128.58, wps=87417.4, ups=3.03, wpb=28804.5, bsz=968.5, num_updates=2200, lr=0.000275, gnorm=0.852, loss_scale=32, train_wall=33, gb_free=6.2, wall=728
2021-04-05 00:49:56 | INFO | train_inner | epoch 001:   2303 / 4751 loss=7.972, nll_loss=6.817, ppl=112.79, wps=88185.7, ups=3.04, wpb=28983.9, bsz=947.4, num_updates=2300, lr=0.0002875, gnorm=0.851, loss_scale=32, train_wall=33, gb_free=6.3, wall=761
2021-04-05 00:50:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2021-04-05 00:50:29 | INFO | train_inner | epoch 001:   2404 / 4751 loss=7.798, nll_loss=6.615, ppl=98.02, wps=87007.4, ups=3.01, wpb=28927.6, bsz=961.8, num_updates=2400, lr=0.0003, gnorm=0.833, loss_scale=16, train_wall=33, gb_free=6.8, wall=794
2021-04-05 00:51:02 | INFO | train_inner | epoch 001:   2504 / 4751 loss=7.638, nll_loss=6.428, ppl=86.12, wps=88477.1, ups=3.04, wpb=29061.2, bsz=969.8, num_updates=2500, lr=0.0003125, gnorm=0.836, loss_scale=16, train_wall=33, gb_free=6, wall=827
2021-04-05 00:51:35 | INFO | train_inner | epoch 001:   2604 / 4751 loss=7.538, nll_loss=6.31, ppl=79.36, wps=88378.1, ups=3.06, wpb=28918.1, bsz=909, num_updates=2600, lr=0.000325, gnorm=0.818, loss_scale=16, train_wall=33, gb_free=6.1, wall=860
2021-04-05 00:52:08 | INFO | train_inner | epoch 001:   2704 / 4751 loss=7.324, nll_loss=6.063, ppl=66.84, wps=87638.9, ups=3.03, wpb=28886.6, bsz=943.9, num_updates=2700, lr=0.0003375, gnorm=0.774, loss_scale=16, train_wall=33, gb_free=6.1, wall=893
2021-04-05 00:52:41 | INFO | train_inner | epoch 001:   2804 / 4751 loss=7.192, nll_loss=5.908, ppl=60.05, wps=85655.9, ups=2.98, wpb=28747.3, bsz=934.7, num_updates=2800, lr=0.00035, gnorm=0.771, loss_scale=16, train_wall=33, gb_free=6.1, wall=926
2021-04-05 00:53:14 | INFO | train_inner | epoch 001:   2904 / 4751 loss=7.099, nll_loss=5.798, ppl=55.65, wps=89102.7, ups=3.04, wpb=29274.7, bsz=960.6, num_updates=2900, lr=0.0003625, gnorm=0.761, loss_scale=16, train_wall=33, gb_free=6.3, wall=959
2021-04-05 00:53:47 | INFO | train_inner | epoch 001:   3004 / 4751 loss=6.992, nll_loss=5.674, ppl=51.06, wps=88055.3, ups=3.03, wpb=29067.6, bsz=917.4, num_updates=3000, lr=0.000375, gnorm=0.745, loss_scale=16, train_wall=33, gb_free=6.6, wall=992
2021-04-05 00:54:20 | INFO | train_inner | epoch 001:   3104 / 4751 loss=6.863, nll_loss=5.525, ppl=46.05, wps=87833.6, ups=3.03, wpb=28974.7, bsz=920.6, num_updates=3100, lr=0.0003875, gnorm=0.751, loss_scale=16, train_wall=33, gb_free=6.5, wall=1025
2021-04-05 00:54:53 | INFO | train_inner | epoch 001:   3204 / 4751 loss=6.776, nll_loss=5.424, ppl=42.94, wps=88042.9, ups=3.02, wpb=29158.7, bsz=930, num_updates=3200, lr=0.0004, gnorm=0.698, loss_scale=16, train_wall=33, gb_free=6.2, wall=1058
2021-04-05 00:55:27 | INFO | train_inner | epoch 001:   3304 / 4751 loss=6.671, nll_loss=5.303, ppl=39.49, wps=87047.4, ups=3, wpb=28977.7, bsz=954.4, num_updates=3300, lr=0.0004125, gnorm=0.714, loss_scale=16, train_wall=33, gb_free=6.2, wall=1091
2021-04-05 00:56:00 | INFO | train_inner | epoch 001:   3404 / 4751 loss=6.539, nll_loss=5.153, ppl=35.57, wps=87980.5, ups=3.03, wpb=28996.5, bsz=971.6, num_updates=3400, lr=0.000425, gnorm=0.691, loss_scale=16, train_wall=33, gb_free=6, wall=1124
2021-04-05 00:56:33 | INFO | train_inner | epoch 001:   3504 / 4751 loss=6.563, nll_loss=5.179, ppl=36.23, wps=87519, ups=3.02, wpb=28955.1, bsz=930.5, num_updates=3500, lr=0.0004375, gnorm=0.674, loss_scale=16, train_wall=33, gb_free=6.2, wall=1157
2021-04-05 00:57:06 | INFO | train_inner | epoch 001:   3604 / 4751 loss=6.427, nll_loss=5.024, ppl=32.54, wps=87493.8, ups=3.04, wpb=28815.7, bsz=930.2, num_updates=3600, lr=0.00045, gnorm=0.646, loss_scale=16, train_wall=33, gb_free=6.1, wall=1190
2021-04-05 00:57:39 | INFO | train_inner | epoch 001:   3704 / 4751 loss=6.351, nll_loss=4.937, ppl=30.64, wps=88311, ups=3.03, wpb=29188.2, bsz=968.2, num_updates=3700, lr=0.0004625, gnorm=0.645, loss_scale=16, train_wall=33, gb_free=6.1, wall=1223
2021-04-05 00:58:12 | INFO | train_inner | epoch 001:   3804 / 4751 loss=6.337, nll_loss=4.922, ppl=30.31, wps=88483.6, ups=3.04, wpb=29111.3, bsz=958.7, num_updates=3800, lr=0.000475, gnorm=0.628, loss_scale=16, train_wall=33, gb_free=6.2, wall=1256
2021-04-05 00:58:45 | INFO | train_inner | epoch 001:   3904 / 4751 loss=6.185, nll_loss=4.75, ppl=26.9, wps=88724.7, ups=3.01, wpb=29452, bsz=976.4, num_updates=3900, lr=0.0004875, gnorm=0.604, loss_scale=16, train_wall=33, gb_free=6.2, wall=1290
2021-04-05 00:59:18 | INFO | train_inner | epoch 001:   4004 / 4751 loss=6.175, nll_loss=4.739, ppl=26.7, wps=87252.9, ups=3.02, wpb=28930.3, bsz=965, num_updates=4000, lr=0.0005, gnorm=0.6, loss_scale=16, train_wall=33, gb_free=6.5, wall=1323
2021-04-05 00:59:51 | INFO | train_inner | epoch 001:   4104 / 4751 loss=6.195, nll_loss=4.763, ppl=27.15, wps=88081.7, ups=3.04, wpb=29000.5, bsz=960.3, num_updates=4100, lr=0.000493865, gnorm=0.603, loss_scale=16, train_wall=33, gb_free=6.3, wall=1356
2021-04-05 01:00:24 | INFO | train_inner | epoch 001:   4204 / 4751 loss=6.109, nll_loss=4.665, ppl=25.37, wps=87007.2, ups=3.01, wpb=28866.7, bsz=958.6, num_updates=4200, lr=0.00048795, gnorm=0.624, loss_scale=16, train_wall=33, gb_free=6.3, wall=1389
2021-04-05 01:00:57 | INFO | train_inner | epoch 001:   4304 / 4751 loss=6.044, nll_loss=4.592, ppl=24.11, wps=86618.8, ups=3.01, wpb=28788.3, bsz=946.1, num_updates=4300, lr=0.000482243, gnorm=0.566, loss_scale=16, train_wall=33, gb_free=6.2, wall=1422
2021-04-05 01:01:30 | INFO | train_inner | epoch 001:   4404 / 4751 loss=6.048, nll_loss=4.598, ppl=24.22, wps=87910.3, ups=3.06, wpb=28723.9, bsz=943.2, num_updates=4400, lr=0.000476731, gnorm=0.578, loss_scale=32, train_wall=33, gb_free=6.4, wall=1455
2021-04-05 01:02:03 | INFO | train_inner | epoch 001:   4504 / 4751 loss=6.016, nll_loss=4.562, ppl=23.63, wps=87490.8, ups=3.02, wpb=29012.7, bsz=941.9, num_updates=4500, lr=0.000471405, gnorm=0.543, loss_scale=32, train_wall=33, gb_free=6.3, wall=1488
2021-04-05 01:02:36 | INFO | train_inner | epoch 001:   4604 / 4751 loss=5.97, nll_loss=4.511, ppl=22.79, wps=88101.2, ups=3.03, wpb=29068.4, bsz=952.5, num_updates=4600, lr=0.000466252, gnorm=0.534, loss_scale=32, train_wall=33, gb_free=6.2, wall=1521
2021-04-05 01:03:09 | INFO | train_inner | epoch 001:   4704 / 4751 loss=5.892, nll_loss=4.423, ppl=21.44, wps=89532.7, ups=3.03, wpb=29567, bsz=939.4, num_updates=4700, lr=0.000461266, gnorm=0.542, loss_scale=32, train_wall=33, gb_free=6.1, wall=1554
2021-04-05 01:03:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-05 01:03:26 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 5.51 | nll_loss 3.819 | ppl 14.11 | wps 216158 | wpb 10489.1 | bsz 375 | num_updates 4747
2021-04-05 01:03:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 4747 updates
2021-04-05 01:03:26 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 01:03:26 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 01:03:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt (epoch 1 @ 4747 updates, score 5.51) (writing took 0.9968964122235775 seconds)
2021-04-05 01:03:27 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2021-04-05 01:03:27 | INFO | train | epoch 001 | loss 8.281 | nll_loss 7.184 | ppl 145.45 | wps 87706.2 | ups 3.03 | wpb 28969.1 | bsz 946.8 | num_updates 4747 | lr 0.000458976 | gnorm 0.815 | loss_scale 32 | train_wall 1560 | gb_free 6.7 | wall 1572
2021-04-05 01:03:27 | INFO | fairseq.trainer | begin training epoch 2
2021-04-05 01:03:27 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-05 01:03:45 | INFO | train_inner | epoch 002:     53 / 4751 loss=5.896, nll_loss=4.429, ppl=21.54, wps=79747.2, ups=2.76, wpb=28901.6, bsz=960.8, num_updates=4800, lr=0.000456435, gnorm=0.523, loss_scale=32, train_wall=33, gb_free=6.3, wall=1590
2021-04-05 01:04:18 | INFO | train_inner | epoch 002:    153 / 4751 loss=5.875, nll_loss=4.404, ppl=21.17, wps=88635.3, ups=3.04, wpb=29188.7, bsz=918.5, num_updates=4900, lr=0.000451754, gnorm=0.521, loss_scale=32, train_wall=33, gb_free=6.2, wall=1623
2021-04-05 01:04:51 | INFO | train_inner | epoch 002:    253 / 4751 loss=5.891, nll_loss=4.424, ppl=21.47, wps=89138.2, ups=3.05, wpb=29248.9, bsz=970.8, num_updates=5000, lr=0.000447214, gnorm=0.53, loss_scale=32, train_wall=33, gb_free=6.2, wall=1656
2021-04-05 01:05:24 | INFO | train_inner | epoch 002:    353 / 4751 loss=5.822, nll_loss=4.345, ppl=20.33, wps=88677.6, ups=3.04, wpb=29174.8, bsz=931.6, num_updates=5100, lr=0.000442807, gnorm=0.532, loss_scale=32, train_wall=33, gb_free=6.1, wall=1689
2021-04-05 01:05:57 | INFO | train_inner | epoch 002:    453 / 4751 loss=5.812, nll_loss=4.336, ppl=20.2, wps=88550.2, ups=3.04, wpb=29159.1, bsz=962.2, num_updates=5200, lr=0.000438529, gnorm=0.506, loss_scale=32, train_wall=33, gb_free=6.2, wall=1722
2021-04-05 01:06:30 | INFO | train_inner | epoch 002:    553 / 4751 loss=5.84, nll_loss=4.368, ppl=20.65, wps=87498.4, ups=3.03, wpb=28876.4, bsz=937.5, num_updates=5300, lr=0.000434372, gnorm=0.529, loss_scale=32, train_wall=33, gb_free=6.2, wall=1755
2021-04-05 01:07:03 | INFO | train_inner | epoch 002:    653 / 4751 loss=5.759, nll_loss=4.277, ppl=19.39, wps=88391.9, ups=3.04, wpb=29055.2, bsz=932.9, num_updates=5400, lr=0.000430331, gnorm=0.503, loss_scale=32, train_wall=33, gb_free=6.3, wall=1788
2021-04-05 01:07:36 | INFO | train_inner | epoch 002:    753 / 4751 loss=5.696, nll_loss=4.206, ppl=18.45, wps=88451.2, ups=3.05, wpb=29018.4, bsz=998.1, num_updates=5500, lr=0.000426401, gnorm=0.502, loss_scale=32, train_wall=33, gb_free=6.7, wall=1820
2021-04-05 01:08:09 | INFO | train_inner | epoch 002:    853 / 4751 loss=5.694, nll_loss=4.204, ppl=18.42, wps=87056.7, ups=3.02, wpb=28840.4, bsz=918.2, num_updates=5600, lr=0.000422577, gnorm=0.509, loss_scale=32, train_wall=33, gb_free=5.9, wall=1854
2021-04-05 01:08:42 | INFO | train_inner | epoch 002:    953 / 4751 loss=5.7, nll_loss=4.211, ppl=18.52, wps=86602, ups=3.01, wpb=28760.3, bsz=932.4, num_updates=5700, lr=0.000418854, gnorm=0.493, loss_scale=32, train_wall=33, gb_free=6.2, wall=1887
2021-04-05 01:09:15 | INFO | train_inner | epoch 002:   1053 / 4751 loss=5.661, nll_loss=4.168, ppl=17.98, wps=87838, ups=3.03, wpb=28947.4, bsz=945.4, num_updates=5800, lr=0.000415227, gnorm=0.494, loss_scale=32, train_wall=33, gb_free=6.1, wall=1920
2021-04-05 01:09:48 | INFO | train_inner | epoch 002:   1153 / 4751 loss=5.63, nll_loss=4.133, ppl=17.54, wps=88289.4, ups=3.04, wpb=29079.3, bsz=939.2, num_updates=5900, lr=0.000411693, gnorm=0.496, loss_scale=32, train_wall=33, gb_free=6.1, wall=1953
2021-04-05 01:10:21 | INFO | train_inner | epoch 002:   1253 / 4751 loss=5.608, nll_loss=4.108, ppl=17.24, wps=88777.8, ups=3.04, wpb=29161.4, bsz=933, num_updates=6000, lr=0.000408248, gnorm=0.479, loss_scale=32, train_wall=33, gb_free=6.3, wall=1985
2021-04-05 01:10:54 | INFO | train_inner | epoch 002:   1353 / 4751 loss=5.602, nll_loss=4.103, ppl=17.19, wps=87632.5, ups=3.04, wpb=28844.6, bsz=968.4, num_updates=6100, lr=0.000404888, gnorm=0.487, loss_scale=32, train_wall=33, gb_free=6.1, wall=2018
2021-04-05 01:11:26 | INFO | train_inner | epoch 002:   1453 / 4751 loss=5.676, nll_loss=4.187, ppl=18.22, wps=87756.3, ups=3.05, wpb=28786.2, bsz=907.9, num_updates=6200, lr=0.00040161, gnorm=0.49, loss_scale=32, train_wall=33, gb_free=6.4, wall=2051
2021-04-05 01:11:59 | INFO | train_inner | epoch 002:   1553 / 4751 loss=5.628, nll_loss=4.134, ppl=17.55, wps=88354, ups=3.03, wpb=29183.5, bsz=949.7, num_updates=6300, lr=0.00039841, gnorm=0.481, loss_scale=32, train_wall=33, gb_free=6.4, wall=2084
2021-04-05 01:12:32 | INFO | train_inner | epoch 002:   1653 / 4751 loss=5.554, nll_loss=4.049, ppl=16.56, wps=87467.2, ups=3.03, wpb=28872.8, bsz=924.5, num_updates=6400, lr=0.000395285, gnorm=0.491, loss_scale=32, train_wall=33, gb_free=6, wall=2117
2021-04-05 01:12:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2021-04-05 01:13:06 | INFO | train_inner | epoch 002:   1754 / 4751 loss=5.563, nll_loss=4.06, ppl=16.68, wps=86407.3, ups=2.99, wpb=28862.8, bsz=977, num_updates=6500, lr=0.000392232, gnorm=0.483, loss_scale=32, train_wall=33, gb_free=6.3, wall=2151
2021-04-05 01:13:39 | INFO | train_inner | epoch 002:   1854 / 4751 loss=5.537, nll_loss=4.032, ppl=16.36, wps=87875.7, ups=3.03, wpb=28986.7, bsz=942.2, num_updates=6600, lr=0.000389249, gnorm=0.481, loss_scale=32, train_wall=33, gb_free=6.3, wall=2184
2021-04-05 01:14:12 | INFO | train_inner | epoch 002:   1954 / 4751 loss=5.575, nll_loss=4.075, ppl=16.85, wps=86977.4, ups=3.02, wpb=28776.6, bsz=923.8, num_updates=6700, lr=0.000386334, gnorm=0.478, loss_scale=32, train_wall=33, gb_free=6.3, wall=2217
2021-04-05 01:14:45 | INFO | train_inner | epoch 002:   2054 / 4751 loss=5.495, nll_loss=3.984, ppl=15.83, wps=87708, ups=3.03, wpb=28964.6, bsz=949.1, num_updates=6800, lr=0.000383482, gnorm=0.482, loss_scale=32, train_wall=33, gb_free=6.4, wall=2250
2021-04-05 01:15:18 | INFO | train_inner | epoch 002:   2154 / 4751 loss=5.466, nll_loss=3.952, ppl=15.48, wps=87486.8, ups=3.04, wpb=28787.1, bsz=952.6, num_updates=6900, lr=0.000380693, gnorm=0.468, loss_scale=32, train_wall=33, gb_free=6.3, wall=2283
2021-04-05 01:15:51 | INFO | train_inner | epoch 002:   2254 / 4751 loss=5.518, nll_loss=4.012, ppl=16.14, wps=87575.3, ups=3.03, wpb=28920.5, bsz=977.3, num_updates=7000, lr=0.000377964, gnorm=0.461, loss_scale=32, train_wall=33, gb_free=6.1, wall=2316
2021-04-05 01:16:24 | INFO | train_inner | epoch 002:   2354 / 4751 loss=5.485, nll_loss=3.974, ppl=15.72, wps=88088.1, ups=3.03, wpb=29078.8, bsz=962.9, num_updates=7100, lr=0.000375293, gnorm=0.453, loss_scale=32, train_wall=33, gb_free=6.2, wall=2349
2021-04-05 01:16:57 | INFO | train_inner | epoch 002:   2454 / 4751 loss=5.519, nll_loss=4.014, ppl=16.15, wps=87975.6, ups=3.04, wpb=28901.2, bsz=920.4, num_updates=7200, lr=0.000372678, gnorm=0.472, loss_scale=32, train_wall=33, gb_free=6.4, wall=2381
2021-04-05 01:17:30 | INFO | train_inner | epoch 002:   2554 / 4751 loss=5.49, nll_loss=3.982, ppl=15.8, wps=86967.5, ups=3.03, wpb=28710, bsz=920.5, num_updates=7300, lr=0.000370117, gnorm=0.471, loss_scale=32, train_wall=33, gb_free=6.4, wall=2415
2021-04-05 01:18:03 | INFO | train_inner | epoch 002:   2654 / 4751 loss=5.451, nll_loss=3.937, ppl=15.32, wps=87792.3, ups=3.02, wpb=29065, bsz=955.7, num_updates=7400, lr=0.000367607, gnorm=0.459, loss_scale=32, train_wall=33, gb_free=6.2, wall=2448
2021-04-05 01:18:36 | INFO | train_inner | epoch 002:   2754 / 4751 loss=5.461, nll_loss=3.95, ppl=15.45, wps=87566.4, ups=3.02, wpb=28973, bsz=962.6, num_updates=7500, lr=0.000365148, gnorm=0.464, loss_scale=32, train_wall=33, gb_free=6.6, wall=2481
2021-04-05 01:19:09 | INFO | train_inner | epoch 002:   2854 / 4751 loss=5.469, nll_loss=3.958, ppl=15.54, wps=87365.4, ups=3.03, wpb=28824.5, bsz=946.1, num_updates=7600, lr=0.000362738, gnorm=0.456, loss_scale=32, train_wall=33, gb_free=6.3, wall=2514
2021-04-05 01:19:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2021-04-05 01:19:42 | INFO | train_inner | epoch 002:   2955 / 4751 loss=5.5, nll_loss=3.994, ppl=15.93, wps=86466.2, ups=2.99, wpb=28875.9, bsz=917.6, num_updates=7700, lr=0.000360375, gnorm=0.465, loss_scale=16, train_wall=33, gb_free=6.1, wall=2547
2021-04-05 01:20:16 | INFO | train_inner | epoch 002:   3055 / 4751 loss=5.445, nll_loss=3.933, ppl=15.27, wps=87011.3, ups=3.01, wpb=28918.6, bsz=968, num_updates=7800, lr=0.000358057, gnorm=0.455, loss_scale=16, train_wall=33, gb_free=6.3, wall=2580
2021-04-05 01:20:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2021-04-05 01:20:49 | INFO | train_inner | epoch 002:   3156 / 4751 loss=5.427, nll_loss=3.912, ppl=15.05, wps=86502.4, ups=3, wpb=28828.3, bsz=967.3, num_updates=7900, lr=0.000355784, gnorm=0.467, loss_scale=8, train_wall=33, gb_free=6.3, wall=2614
2021-04-05 01:21:22 | INFO | train_inner | epoch 002:   3256 / 4751 loss=5.367, nll_loss=3.844, ppl=14.36, wps=86773.1, ups=3.01, wpb=28803.2, bsz=949.5, num_updates=8000, lr=0.000353553, gnorm=0.458, loss_scale=8, train_wall=33, gb_free=6.1, wall=2647
2021-04-05 01:21:55 | INFO | train_inner | epoch 002:   3356 / 4751 loss=5.447, nll_loss=3.936, ppl=15.31, wps=87266.5, ups=3.04, wpb=28719.9, bsz=942.9, num_updates=8100, lr=0.000351364, gnorm=0.454, loss_scale=8, train_wall=33, gb_free=6.1, wall=2680
2021-04-05 01:22:28 | INFO | train_inner | epoch 002:   3456 / 4751 loss=5.411, nll_loss=3.895, ppl=14.88, wps=88731.1, ups=3.03, wpb=29251.4, bsz=937.3, num_updates=8200, lr=0.000349215, gnorm=0.454, loss_scale=8, train_wall=33, gb_free=6.7, wall=2713
2021-04-05 01:23:01 | INFO | train_inner | epoch 002:   3556 / 4751 loss=5.365, nll_loss=3.843, ppl=14.35, wps=88213, ups=3.04, wpb=29057.4, bsz=990, num_updates=8300, lr=0.000347105, gnorm=0.461, loss_scale=8, train_wall=33, gb_free=6.2, wall=2746
2021-04-05 01:23:34 | INFO | train_inner | epoch 002:   3656 / 4751 loss=5.333, nll_loss=3.806, ppl=13.99, wps=87742.3, ups=3.02, wpb=29039.7, bsz=952.5, num_updates=8400, lr=0.000345033, gnorm=0.437, loss_scale=8, train_wall=33, gb_free=6.2, wall=2779
2021-04-05 01:24:07 | INFO | train_inner | epoch 002:   3756 / 4751 loss=5.455, nll_loss=3.947, ppl=15.42, wps=88623.1, ups=3.05, wpb=29087.6, bsz=933.2, num_updates=8500, lr=0.000342997, gnorm=0.456, loss_scale=8, train_wall=33, gb_free=6.2, wall=2812
2021-04-05 01:24:40 | INFO | train_inner | epoch 002:   3856 / 4751 loss=5.337, nll_loss=3.811, ppl=14.04, wps=88155.3, ups=3.05, wpb=28945, bsz=947.2, num_updates=8600, lr=0.000340997, gnorm=0.446, loss_scale=8, train_wall=33, gb_free=6.1, wall=2844
2021-04-05 01:25:13 | INFO | train_inner | epoch 002:   3956 / 4751 loss=5.347, nll_loss=3.824, ppl=14.16, wps=88106.5, ups=3.03, wpb=29115, bsz=937, num_updates=8700, lr=0.000339032, gnorm=0.447, loss_scale=8, train_wall=33, gb_free=6.2, wall=2877
2021-04-05 01:25:45 | INFO | train_inner | epoch 002:   4056 / 4751 loss=5.39, nll_loss=3.873, ppl=14.66, wps=88526.1, ups=3.05, wpb=29030.8, bsz=960.9, num_updates=8800, lr=0.0003371, gnorm=0.447, loss_scale=8, train_wall=33, gb_free=6, wall=2910
2021-04-05 01:26:18 | INFO | train_inner | epoch 002:   4156 / 4751 loss=5.307, nll_loss=3.779, ppl=13.73, wps=87777.8, ups=3.03, wpb=28949.8, bsz=945.2, num_updates=8900, lr=0.000335201, gnorm=0.443, loss_scale=8, train_wall=33, gb_free=6, wall=2943
2021-04-05 01:26:52 | INFO | train_inner | epoch 002:   4256 / 4751 loss=5.302, nll_loss=3.773, ppl=13.67, wps=87115.5, ups=3.01, wpb=28916.8, bsz=948.6, num_updates=9000, lr=0.000333333, gnorm=0.451, loss_scale=8, train_wall=33, gb_free=6.3, wall=2976
2021-04-05 01:27:25 | INFO | train_inner | epoch 002:   4356 / 4751 loss=5.335, nll_loss=3.811, ppl=14.03, wps=88147.8, ups=3.02, wpb=29184.4, bsz=929.9, num_updates=9100, lr=0.000331497, gnorm=0.47, loss_scale=8, train_wall=33, gb_free=6, wall=3010
2021-04-05 01:27:58 | INFO | train_inner | epoch 002:   4456 / 4751 loss=5.283, nll_loss=3.753, ppl=13.48, wps=87212.3, ups=3.03, wpb=28817.7, bsz=973.9, num_updates=9200, lr=0.00032969, gnorm=0.475, loss_scale=8, train_wall=33, gb_free=6.1, wall=3043
2021-04-05 01:28:31 | INFO | train_inner | epoch 002:   4556 / 4751 loss=5.341, nll_loss=3.818, ppl=14.1, wps=86217.6, ups=3.03, wpb=28483.7, bsz=920.6, num_updates=9300, lr=0.000327913, gnorm=0.434, loss_scale=8, train_wall=33, gb_free=6.2, wall=3076
2021-04-05 01:29:04 | INFO | train_inner | epoch 002:   4656 / 4751 loss=5.316, nll_loss=3.79, ppl=13.84, wps=87025.1, ups=2.97, wpb=29282.7, bsz=925.9, num_updates=9400, lr=0.000326164, gnorm=0.44, loss_scale=8, train_wall=34, gb_free=6.5, wall=3109
2021-04-05 01:29:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-05 01:29:37 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 4.883 | nll_loss 3.139 | ppl 8.81 | wps 210527 | wpb 10489.1 | bsz 375 | num_updates 9495 | best_loss 4.883
2021-04-05 01:29:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 9495 updates
2021-04-05 01:29:37 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 01:29:43 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 01:29:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt (epoch 2 @ 9495 updates, score 4.883) (writing took 12.817564744502306 seconds)
2021-04-05 01:29:50 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2021-04-05 01:29:50 | INFO | train | epoch 002 | loss 5.524 | nll_loss 4.018 | ppl 16.2 | wps 86889.9 | ups 3 | wpb 28967.9 | bsz 946.6 | num_updates 9495 | lr 0.000324528 | gnorm 0.474 | loss_scale 8 | train_wall 1561 | gb_free 6.7 | wall 3154
2021-04-05 01:29:50 | INFO | fairseq.trainer | begin training epoch 3
2021-04-05 01:29:50 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-05 01:29:53 | INFO | train_inner | epoch 003:      5 / 4751 loss=5.239, nll_loss=3.702, ppl=13.02, wps=60552.6, ups=2.08, wpb=29141.8, bsz=961.9, num_updates=9500, lr=0.000324443, gnorm=0.428, loss_scale=8, train_wall=33, gb_free=6.3, wall=3157
2021-04-05 01:30:25 | INFO | train_inner | epoch 003:    105 / 4751 loss=5.26, nll_loss=3.727, ppl=13.24, wps=89064.5, ups=3.07, wpb=29036, bsz=978.7, num_updates=9600, lr=0.000322749, gnorm=0.477, loss_scale=8, train_wall=32, gb_free=6.2, wall=3190
2021-04-05 01:30:58 | INFO | train_inner | epoch 003:    205 / 4751 loss=5.287, nll_loss=3.757, ppl=13.52, wps=88076.9, ups=3.04, wpb=28961.2, bsz=936.7, num_updates=9700, lr=0.000321081, gnorm=0.437, loss_scale=8, train_wall=33, gb_free=6.1, wall=3223
2021-04-05 01:31:31 | INFO | train_inner | epoch 003:    305 / 4751 loss=5.273, nll_loss=3.742, ppl=13.38, wps=88429.9, ups=3.04, wpb=29064.7, bsz=967.2, num_updates=9800, lr=0.000319438, gnorm=0.449, loss_scale=8, train_wall=33, gb_free=6.5, wall=3256
2021-04-05 01:32:04 | INFO | train_inner | epoch 003:    405 / 4751 loss=5.253, nll_loss=3.719, ppl=13.17, wps=88438.5, ups=3.04, wpb=29048.3, bsz=961.5, num_updates=9900, lr=0.000317821, gnorm=0.439, loss_scale=8, train_wall=33, gb_free=6.2, wall=3289
2021-04-05 01:32:37 | INFO | train_inner | epoch 003:    505 / 4751 loss=5.227, nll_loss=3.689, ppl=12.9, wps=87833.3, ups=3.02, wpb=29114.5, bsz=932.4, num_updates=10000, lr=0.000316228, gnorm=0.433, loss_scale=16, train_wall=33, gb_free=6.3, wall=3322
2021-04-05 01:33:10 | INFO | train_inner | epoch 003:    605 / 4751 loss=5.277, nll_loss=3.747, ppl=13.43, wps=87668.3, ups=3.04, wpb=28817.4, bsz=927.8, num_updates=10100, lr=0.000314658, gnorm=0.432, loss_scale=16, train_wall=33, gb_free=6.1, wall=3355
2021-04-05 01:33:43 | INFO | train_inner | epoch 003:    705 / 4751 loss=5.253, nll_loss=3.72, ppl=13.17, wps=88572.2, ups=3.05, wpb=29073.1, bsz=947.1, num_updates=10200, lr=0.000313112, gnorm=0.43, loss_scale=16, train_wall=33, gb_free=6.7, wall=3387
2021-04-05 01:34:16 | INFO | train_inner | epoch 003:    805 / 4751 loss=5.226, nll_loss=3.69, ppl=12.9, wps=88338.2, ups=3.03, wpb=29125.8, bsz=964.6, num_updates=10300, lr=0.000311588, gnorm=0.436, loss_scale=16, train_wall=33, gb_free=6.4, wall=3420
2021-04-05 01:34:49 | INFO | train_inner | epoch 003:    905 / 4751 loss=5.28, nll_loss=3.751, ppl=13.46, wps=87679.9, ups=3.03, wpb=28902.3, bsz=915.7, num_updates=10400, lr=0.000310087, gnorm=0.44, loss_scale=16, train_wall=33, gb_free=6.1, wall=3453
2021-04-05 01:34:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2021-04-05 01:35:22 | INFO | train_inner | epoch 003:   1006 / 4751 loss=5.245, nll_loss=3.711, ppl=13.09, wps=85561.9, ups=2.97, wpb=28783.8, bsz=942.5, num_updates=10500, lr=0.000308607, gnorm=0.438, loss_scale=8, train_wall=33, gb_free=6, wall=3487
2021-04-05 01:35:55 | INFO | train_inner | epoch 003:   1106 / 4751 loss=5.26, nll_loss=3.728, ppl=13.25, wps=87140.6, ups=3.03, wpb=28757, bsz=929.5, num_updates=10600, lr=0.000307148, gnorm=0.436, loss_scale=8, train_wall=33, gb_free=6.3, wall=3520
2021-04-05 01:36:28 | INFO | train_inner | epoch 003:   1206 / 4751 loss=5.255, nll_loss=3.723, ppl=13.21, wps=86815.2, ups=3.03, wpb=28628.5, bsz=925.5, num_updates=10700, lr=0.000305709, gnorm=0.436, loss_scale=8, train_wall=33, gb_free=6.3, wall=3553
2021-04-05 01:37:01 | INFO | train_inner | epoch 003:   1306 / 4751 loss=5.254, nll_loss=3.723, ppl=13.2, wps=88311.2, ups=3.05, wpb=28985.8, bsz=953.4, num_updates=10800, lr=0.00030429, gnorm=0.443, loss_scale=8, train_wall=33, gb_free=6.3, wall=3586
2021-04-05 01:37:34 | INFO | train_inner | epoch 003:   1406 / 4751 loss=5.259, nll_loss=3.728, ppl=13.25, wps=87918.5, ups=3.03, wpb=28993.3, bsz=917.3, num_updates=10900, lr=0.000302891, gnorm=0.431, loss_scale=8, train_wall=33, gb_free=6.2, wall=3619
2021-04-05 01:38:07 | INFO | train_inner | epoch 003:   1506 / 4751 loss=5.241, nll_loss=3.708, ppl=13.07, wps=87968.7, ups=3.03, wpb=29037.4, bsz=958.1, num_updates=11000, lr=0.000301511, gnorm=0.427, loss_scale=8, train_wall=33, gb_free=6.1, wall=3652
2021-04-05 01:38:40 | INFO | train_inner | epoch 003:   1606 / 4751 loss=5.2, nll_loss=3.661, ppl=12.65, wps=88850.4, ups=3.04, wpb=29262.7, bsz=947.1, num_updates=11100, lr=0.00030015, gnorm=0.431, loss_scale=8, train_wall=33, gb_free=6.3, wall=3685
2021-04-05 01:39:13 | INFO | train_inner | epoch 003:   1706 / 4751 loss=5.172, nll_loss=3.63, ppl=12.38, wps=88301.9, ups=3.04, wpb=29056.3, bsz=961.2, num_updates=11200, lr=0.000298807, gnorm=0.434, loss_scale=8, train_wall=33, gb_free=6.3, wall=3718
2021-04-05 01:39:46 | INFO | train_inner | epoch 003:   1806 / 4751 loss=5.272, nll_loss=3.744, ppl=13.4, wps=88237.2, ups=3.03, wpb=29103.3, bsz=945.8, num_updates=11300, lr=0.000297482, gnorm=0.428, loss_scale=8, train_wall=33, gb_free=6.3, wall=3751
2021-04-05 01:40:19 | INFO | train_inner | epoch 003:   1906 / 4751 loss=5.239, nll_loss=3.707, ppl=13.06, wps=88291.1, ups=3.04, wpb=29062.5, bsz=978.2, num_updates=11400, lr=0.000296174, gnorm=0.431, loss_scale=8, train_wall=33, gb_free=6.4, wall=3784
2021-04-05 01:40:52 | INFO | train_inner | epoch 003:   2006 / 4751 loss=5.163, nll_loss=3.62, ppl=12.3, wps=87945, ups=3.01, wpb=29214.3, bsz=986.2, num_updates=11500, lr=0.000294884, gnorm=0.437, loss_scale=8, train_wall=33, gb_free=6.1, wall=3817
2021-04-05 01:41:25 | INFO | train_inner | epoch 003:   2106 / 4751 loss=5.133, nll_loss=3.586, ppl=12.01, wps=86577.3, ups=3, wpb=28813.4, bsz=985.2, num_updates=11600, lr=0.00029361, gnorm=0.432, loss_scale=8, train_wall=33, gb_free=6.3, wall=3850
2021-04-05 01:41:58 | INFO | train_inner | epoch 003:   2206 / 4751 loss=5.181, nll_loss=3.641, ppl=12.48, wps=87737.8, ups=3.05, wpb=28809.4, bsz=969.8, num_updates=11700, lr=0.000292353, gnorm=0.438, loss_scale=8, train_wall=33, gb_free=6.1, wall=3883
2021-04-05 01:42:31 | INFO | train_inner | epoch 003:   2306 / 4751 loss=5.144, nll_loss=3.599, ppl=12.12, wps=88378.5, ups=3.01, wpb=29357.4, bsz=931, num_updates=11800, lr=0.000291111, gnorm=0.419, loss_scale=8, train_wall=33, gb_free=6.2, wall=3916
2021-04-05 01:43:05 | INFO | train_inner | epoch 003:   2406 / 4751 loss=5.194, nll_loss=3.657, ppl=12.61, wps=85483.5, ups=2.96, wpb=28858, bsz=955.5, num_updates=11900, lr=0.000289886, gnorm=0.431, loss_scale=8, train_wall=34, gb_free=6.4, wall=3950
2021-04-05 01:43:38 | INFO | train_inner | epoch 003:   2506 / 4751 loss=5.122, nll_loss=3.575, ppl=11.92, wps=88780, ups=3.03, wpb=29257.2, bsz=970, num_updates=12000, lr=0.000288675, gnorm=0.419, loss_scale=8, train_wall=33, gb_free=6.2, wall=3983
2021-04-05 01:44:11 | INFO | train_inner | epoch 003:   2606 / 4751 loss=5.184, nll_loss=3.646, ppl=12.51, wps=86385.1, ups=3.02, wpb=28632.7, bsz=943.8, num_updates=12100, lr=0.00028748, gnorm=0.424, loss_scale=8, train_wall=33, gb_free=6.2, wall=4016
2021-04-05 01:44:44 | INFO | train_inner | epoch 003:   2706 / 4751 loss=5.195, nll_loss=3.659, ppl=12.63, wps=87686.4, ups=3.05, wpb=28709.6, bsz=944.2, num_updates=12200, lr=0.000286299, gnorm=0.431, loss_scale=8, train_wall=33, gb_free=6.1, wall=4049
2021-04-05 01:45:17 | INFO | train_inner | epoch 003:   2806 / 4751 loss=5.181, nll_loss=3.642, ppl=12.49, wps=88190.6, ups=3.06, wpb=28862.4, bsz=917.3, num_updates=12300, lr=0.000285133, gnorm=0.422, loss_scale=8, train_wall=33, gb_free=6.1, wall=4081
2021-04-05 01:45:49 | INFO | train_inner | epoch 003:   2906 / 4751 loss=5.171, nll_loss=3.631, ppl=12.39, wps=88485.2, ups=3.05, wpb=29039.3, bsz=955.8, num_updates=12400, lr=0.000283981, gnorm=0.43, loss_scale=8, train_wall=33, gb_free=6.1, wall=4114
2021-04-05 01:46:22 | INFO | train_inner | epoch 003:   3006 / 4751 loss=5.201, nll_loss=3.666, ppl=12.69, wps=87046.4, ups=3.03, wpb=28773.6, bsz=936.6, num_updates=12500, lr=0.000282843, gnorm=0.431, loss_scale=16, train_wall=33, gb_free=6, wall=4147
2021-04-05 01:46:55 | INFO | train_inner | epoch 003:   3106 / 4751 loss=5.162, nll_loss=3.621, ppl=12.3, wps=88718.6, ups=3.05, wpb=29126.5, bsz=947.8, num_updates=12600, lr=0.000281718, gnorm=0.414, loss_scale=16, train_wall=33, gb_free=6, wall=4180
2021-04-05 01:47:28 | INFO | train_inner | epoch 003:   3206 / 4751 loss=5.182, nll_loss=3.644, ppl=12.51, wps=87416.5, ups=3.03, wpb=28841.4, bsz=941, num_updates=12700, lr=0.000280607, gnorm=0.435, loss_scale=16, train_wall=33, gb_free=6.6, wall=4213
2021-04-05 01:48:01 | INFO | train_inner | epoch 003:   3306 / 4751 loss=5.149, nll_loss=3.608, ppl=12.19, wps=88410, ups=3.03, wpb=29164.7, bsz=975, num_updates=12800, lr=0.000279508, gnorm=0.411, loss_scale=16, train_wall=33, gb_free=6.1, wall=4246
2021-04-05 01:48:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2021-04-05 01:48:35 | INFO | train_inner | epoch 003:   3407 / 4751 loss=5.167, nll_loss=3.627, ppl=12.36, wps=87238.3, ups=3, wpb=29050.3, bsz=934.7, num_updates=12900, lr=0.000278423, gnorm=0.43, loss_scale=8, train_wall=33, gb_free=6.5, wall=4279
2021-04-05 01:49:07 | INFO | train_inner | epoch 003:   3507 / 4751 loss=5.15, nll_loss=3.608, ppl=12.19, wps=89279.3, ups=3.06, wpb=29223.1, bsz=933, num_updates=13000, lr=0.00027735, gnorm=0.426, loss_scale=8, train_wall=33, gb_free=6.1, wall=4312
2021-04-05 01:49:40 | INFO | train_inner | epoch 003:   3607 / 4751 loss=5.116, nll_loss=3.57, ppl=11.87, wps=87320.9, ups=3.03, wpb=28817.6, bsz=959, num_updates=13100, lr=0.000276289, gnorm=0.415, loss_scale=8, train_wall=33, gb_free=6.2, wall=4345
2021-04-05 01:50:13 | INFO | train_inner | epoch 003:   3707 / 4751 loss=5.089, nll_loss=3.538, ppl=11.62, wps=87346.4, ups=3.02, wpb=28954, bsz=912.1, num_updates=13200, lr=0.000275241, gnorm=0.43, loss_scale=8, train_wall=33, gb_free=6.3, wall=4378
2021-04-05 01:50:46 | INFO | train_inner | epoch 003:   3807 / 4751 loss=5.101, nll_loss=3.553, ppl=11.73, wps=87891, ups=3.03, wpb=29020.4, bsz=944.3, num_updates=13300, lr=0.000274204, gnorm=0.417, loss_scale=8, train_wall=33, gb_free=6.1, wall=4411
2021-04-05 01:51:20 | INFO | train_inner | epoch 003:   3907 / 4751 loss=5.121, nll_loss=3.575, ppl=11.92, wps=87295.6, ups=3.01, wpb=28997.9, bsz=965.1, num_updates=13400, lr=0.000273179, gnorm=0.424, loss_scale=8, train_wall=33, gb_free=6.7, wall=4445
2021-04-05 01:51:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2021-04-05 01:51:53 | INFO | train_inner | epoch 003:   4008 / 4751 loss=5.123, nll_loss=3.578, ppl=11.94, wps=86753.8, ups=3.01, wpb=28836.5, bsz=922.2, num_updates=13500, lr=0.000272166, gnorm=0.425, loss_scale=4, train_wall=33, gb_free=6.1, wall=4478
2021-04-05 01:52:26 | INFO | train_inner | epoch 003:   4108 / 4751 loss=5.093, nll_loss=3.544, ppl=11.67, wps=86791.8, ups=3.03, wpb=28600.1, bsz=959.9, num_updates=13600, lr=0.000271163, gnorm=0.422, loss_scale=4, train_wall=33, gb_free=6.6, wall=4511
2021-04-05 01:52:59 | INFO | train_inner | epoch 003:   4208 / 4751 loss=5.124, nll_loss=3.58, ppl=11.96, wps=87492.2, ups=3.01, wpb=29044.2, bsz=939, num_updates=13700, lr=0.000270172, gnorm=0.428, loss_scale=4, train_wall=33, gb_free=6.1, wall=4544
2021-04-05 01:53:32 | INFO | train_inner | epoch 003:   4308 / 4751 loss=5.129, nll_loss=3.585, ppl=12, wps=87657.8, ups=3.03, wpb=28912.8, bsz=945, num_updates=13800, lr=0.000269191, gnorm=0.419, loss_scale=4, train_wall=33, gb_free=6.3, wall=4577
2021-04-05 01:54:05 | INFO | train_inner | epoch 003:   4408 / 4751 loss=5.101, nll_loss=3.553, ppl=11.74, wps=87548.3, ups=3.02, wpb=29013.8, bsz=937.9, num_updates=13900, lr=0.000268221, gnorm=0.42, loss_scale=4, train_wall=33, gb_free=6.3, wall=4610
2021-04-05 01:54:38 | INFO | train_inner | epoch 003:   4508 / 4751 loss=5.097, nll_loss=3.549, ppl=11.71, wps=88579.3, ups=3.05, wpb=29066.7, bsz=932.5, num_updates=14000, lr=0.000267261, gnorm=0.416, loss_scale=4, train_wall=33, gb_free=6.4, wall=4643
2021-04-05 01:55:11 | INFO | train_inner | epoch 003:   4608 / 4751 loss=5.127, nll_loss=3.583, ppl=11.99, wps=87154.7, ups=3.02, wpb=28855.2, bsz=952.4, num_updates=14100, lr=0.000266312, gnorm=0.421, loss_scale=4, train_wall=33, gb_free=6.3, wall=4676
2021-04-05 01:55:44 | INFO | train_inner | epoch 003:   4708 / 4751 loss=5.107, nll_loss=3.561, ppl=11.8, wps=87971.9, ups=3.03, wpb=29013.3, bsz=946.3, num_updates=14200, lr=0.000265372, gnorm=0.414, loss_scale=4, train_wall=33, gb_free=6.2, wall=4709
2021-04-05 01:55:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-05 01:55:59 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 4.693 | nll_loss 2.938 | ppl 7.66 | wps 198078 | wpb 10489.1 | bsz 375 | num_updates 14243 | best_loss 4.693
2021-04-05 01:55:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 14243 updates
2021-04-05 01:55:59 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 01:56:06 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 01:56:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt (epoch 3 @ 14243 updates, score 4.693) (writing took 13.340670142322779 seconds)
2021-04-05 01:56:13 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2021-04-05 01:56:13 | INFO | train | epoch 003 | loss 5.185 | nll_loss 3.646 | ppl 12.52 | wps 86884 | ups 3 | wpb 28967.8 | bsz 946.9 | num_updates 14243 | lr 0.000264972 | gnorm 0.429 | loss_scale 4 | train_wall 1560 | gb_free 6.3 | wall 4737
2021-04-05 01:56:13 | INFO | fairseq.trainer | begin training epoch 4
2021-04-05 01:56:13 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-05 01:56:33 | INFO | train_inner | epoch 004:     57 / 4751 loss=5.122, nll_loss=3.578, ppl=11.94, wps=58792.8, ups=2.06, wpb=28550.8, bsz=904.1, num_updates=14300, lr=0.000264443, gnorm=0.419, loss_scale=4, train_wall=33, gb_free=6.3, wall=4758
2021-04-05 01:57:06 | INFO | train_inner | epoch 004:    157 / 4751 loss=5.042, nll_loss=3.487, ppl=11.21, wps=86869.3, ups=3.02, wpb=28752.4, bsz=955, num_updates=14400, lr=0.000263523, gnorm=0.415, loss_scale=4, train_wall=33, gb_free=6.5, wall=4791
2021-04-05 01:57:39 | INFO | train_inner | epoch 004:    257 / 4751 loss=5.113, nll_loss=3.568, ppl=11.86, wps=87761.7, ups=3.03, wpb=28995.5, bsz=914.6, num_updates=14500, lr=0.000262613, gnorm=0.418, loss_scale=4, train_wall=33, gb_free=6.6, wall=4824
2021-04-05 01:58:12 | INFO | train_inner | epoch 004:    357 / 4751 loss=5.089, nll_loss=3.54, ppl=11.64, wps=88111.3, ups=3.05, wpb=28878.2, bsz=953.3, num_updates=14600, lr=0.000261712, gnorm=0.427, loss_scale=4, train_wall=33, gb_free=6.5, wall=4856
2021-04-05 01:58:45 | INFO | train_inner | epoch 004:    457 / 4751 loss=5.081, nll_loss=3.531, ppl=11.56, wps=86648.1, ups=3.03, wpb=28598.7, bsz=940.3, num_updates=14700, lr=0.00026082, gnorm=0.419, loss_scale=4, train_wall=33, gb_free=6.1, wall=4889
2021-04-05 01:59:17 | INFO | train_inner | epoch 004:    557 / 4751 loss=5.146, nll_loss=3.605, ppl=12.17, wps=87735.8, ups=3.05, wpb=28763.1, bsz=934.5, num_updates=14800, lr=0.000259938, gnorm=0.427, loss_scale=4, train_wall=33, gb_free=6.7, wall=4922
2021-04-05 01:59:50 | INFO | train_inner | epoch 004:    657 / 4751 loss=5.041, nll_loss=3.486, ppl=11.2, wps=88302.3, ups=3.04, wpb=29064.5, bsz=944.4, num_updates=14900, lr=0.000259064, gnorm=0.416, loss_scale=4, train_wall=33, gb_free=6.6, wall=4955
2021-04-05 02:00:24 | INFO | train_inner | epoch 004:    757 / 4751 loss=5.105, nll_loss=3.559, ppl=11.79, wps=85678.7, ups=2.97, wpb=28882, bsz=960.8, num_updates=15000, lr=0.000258199, gnorm=0.43, loss_scale=4, train_wall=34, gb_free=6.2, wall=4989
2021-04-05 02:00:57 | INFO | train_inner | epoch 004:    857 / 4751 loss=5.052, nll_loss=3.499, ppl=11.31, wps=88590.9, ups=3.05, wpb=29066, bsz=942.8, num_updates=15100, lr=0.000257343, gnorm=0.421, loss_scale=4, train_wall=33, gb_free=6.1, wall=5022
2021-04-05 02:01:30 | INFO | train_inner | epoch 004:    957 / 4751 loss=5.056, nll_loss=3.503, ppl=11.33, wps=89280.3, ups=3.04, wpb=29340.7, bsz=932.2, num_updates=15200, lr=0.000256495, gnorm=0.412, loss_scale=4, train_wall=33, gb_free=6.3, wall=5055
2021-04-05 02:02:03 | INFO | train_inner | epoch 004:   1057 / 4751 loss=5.073, nll_loss=3.523, ppl=11.5, wps=87583.3, ups=3, wpb=29167.8, bsz=929.7, num_updates=15300, lr=0.000255655, gnorm=0.413, loss_scale=4, train_wall=33, gb_free=6.1, wall=5088
2021-04-05 02:02:36 | INFO | train_inner | epoch 004:   1157 / 4751 loss=5.052, nll_loss=3.499, ppl=11.31, wps=88478.2, ups=3.03, wpb=29197.7, bsz=955.5, num_updates=15400, lr=0.000254824, gnorm=0.408, loss_scale=4, train_wall=33, gb_free=6.5, wall=5121
2021-04-05 02:03:09 | INFO | train_inner | epoch 004:   1257 / 4751 loss=5.026, nll_loss=3.47, ppl=11.08, wps=88456.9, ups=3.04, wpb=29086.4, bsz=917.2, num_updates=15500, lr=0.000254, gnorm=0.415, loss_scale=8, train_wall=33, gb_free=6.1, wall=5154
2021-04-05 02:03:42 | INFO | train_inner | epoch 004:   1357 / 4751 loss=5.077, nll_loss=3.528, ppl=11.53, wps=88371.1, ups=3.03, wpb=29155.2, bsz=976.1, num_updates=15600, lr=0.000253185, gnorm=0.412, loss_scale=8, train_wall=33, gb_free=6.1, wall=5187
2021-04-05 02:04:15 | INFO | train_inner | epoch 004:   1457 / 4751 loss=5.07, nll_loss=3.52, ppl=11.47, wps=88314.5, ups=3.04, wpb=29032.3, bsz=921.8, num_updates=15700, lr=0.000252377, gnorm=0.419, loss_scale=8, train_wall=33, gb_free=6.3, wall=5220
2021-04-05 02:04:48 | INFO | train_inner | epoch 004:   1557 / 4751 loss=5.016, nll_loss=3.458, ppl=10.99, wps=88195.9, ups=3.03, wpb=29098.2, bsz=968.2, num_updates=15800, lr=0.000251577, gnorm=0.418, loss_scale=8, train_wall=33, gb_free=6.3, wall=5253
2021-04-05 02:05:21 | INFO | train_inner | epoch 004:   1657 / 4751 loss=5.038, nll_loss=3.484, ppl=11.19, wps=88024.8, ups=3.04, wpb=28942.5, bsz=981.6, num_updates=15900, lr=0.000250785, gnorm=0.417, loss_scale=8, train_wall=33, gb_free=6.2, wall=5285
2021-04-05 02:05:53 | INFO | train_inner | epoch 004:   1757 / 4751 loss=5.065, nll_loss=3.515, ppl=11.43, wps=88779.6, ups=3.04, wpb=29181.5, bsz=932.2, num_updates=16000, lr=0.00025, gnorm=0.414, loss_scale=8, train_wall=33, gb_free=6.2, wall=5318
2021-04-05 02:06:26 | INFO | train_inner | epoch 004:   1857 / 4751 loss=5.013, nll_loss=3.456, ppl=10.97, wps=88431.5, ups=3.03, wpb=29180.4, bsz=954.1, num_updates=16100, lr=0.000249222, gnorm=0.418, loss_scale=8, train_wall=33, gb_free=6.3, wall=5351
2021-04-05 02:06:59 | INFO | train_inner | epoch 004:   1957 / 4751 loss=5.086, nll_loss=3.539, ppl=11.62, wps=88194.9, ups=3.04, wpb=28980.6, bsz=947.4, num_updates=16200, lr=0.000248452, gnorm=0.41, loss_scale=8, train_wall=33, gb_free=6.2, wall=5384
2021-04-05 02:07:32 | INFO | train_inner | epoch 004:   2057 / 4751 loss=5.053, nll_loss=3.501, ppl=11.32, wps=87621.6, ups=3.03, wpb=28882.3, bsz=930.6, num_updates=16300, lr=0.000247689, gnorm=0.424, loss_scale=8, train_wall=33, gb_free=6.2, wall=5417
2021-04-05 02:08:05 | INFO | train_inner | epoch 004:   2157 / 4751 loss=5.093, nll_loss=3.547, ppl=11.69, wps=88173.6, ups=3.05, wpb=28945.8, bsz=935.9, num_updates=16400, lr=0.000246932, gnorm=0.419, loss_scale=8, train_wall=33, gb_free=6.2, wall=5450
2021-04-05 02:08:38 | INFO | train_inner | epoch 004:   2257 / 4751 loss=5.096, nll_loss=3.551, ppl=11.72, wps=87867, ups=3.04, wpb=28943.5, bsz=951.9, num_updates=16500, lr=0.000246183, gnorm=0.414, loss_scale=8, train_wall=33, gb_free=6.3, wall=5483
2021-04-05 02:09:11 | INFO | train_inner | epoch 004:   2357 / 4751 loss=5.049, nll_loss=3.497, ppl=11.29, wps=87777.6, ups=3.02, wpb=29084.4, bsz=957.7, num_updates=16600, lr=0.00024544, gnorm=0.405, loss_scale=8, train_wall=33, gb_free=6.1, wall=5516
2021-04-05 02:09:44 | INFO | train_inner | epoch 004:   2457 / 4751 loss=4.997, nll_loss=3.438, ppl=10.84, wps=88181.3, ups=3.03, wpb=29143.9, bsz=981.6, num_updates=16700, lr=0.000244704, gnorm=0.408, loss_scale=8, train_wall=33, gb_free=6.2, wall=5549
2021-04-05 02:10:17 | INFO | train_inner | epoch 004:   2557 / 4751 loss=5.043, nll_loss=3.49, ppl=11.24, wps=88521.2, ups=3.04, wpb=29114.8, bsz=932.8, num_updates=16800, lr=0.000243975, gnorm=0.414, loss_scale=8, train_wall=33, gb_free=6.5, wall=5582
2021-04-05 02:10:50 | INFO | train_inner | epoch 004:   2657 / 4751 loss=5.069, nll_loss=3.52, ppl=11.47, wps=89095.9, ups=3.06, wpb=29151.7, bsz=953.5, num_updates=16900, lr=0.000243252, gnorm=0.411, loss_scale=8, train_wall=33, gb_free=6.3, wall=5615
2021-04-05 02:11:23 | INFO | train_inner | epoch 004:   2757 / 4751 loss=5.081, nll_loss=3.534, ppl=11.58, wps=87852.7, ups=3.02, wpb=29110.4, bsz=949, num_updates=17000, lr=0.000242536, gnorm=0.414, loss_scale=8, train_wall=33, gb_free=6.1, wall=5648
2021-04-05 02:11:37 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2021-04-05 02:11:56 | INFO | train_inner | epoch 004:   2858 / 4751 loss=5.025, nll_loss=3.47, ppl=11.08, wps=86977.8, ups=2.99, wpb=29054.2, bsz=946.3, num_updates=17100, lr=0.000241825, gnorm=0.409, loss_scale=4, train_wall=33, gb_free=6.1, wall=5681
2021-04-05 02:12:30 | INFO | train_inner | epoch 004:   2958 / 4751 loss=5.004, nll_loss=3.447, ppl=10.9, wps=86310.5, ups=3.01, wpb=28654.7, bsz=948.6, num_updates=17200, lr=0.000241121, gnorm=0.418, loss_scale=4, train_wall=33, gb_free=6.9, wall=5714
2021-04-05 02:13:03 | INFO | train_inner | epoch 004:   3058 / 4751 loss=4.983, nll_loss=3.422, ppl=10.72, wps=86771.5, ups=3.02, wpb=28747.1, bsz=913.9, num_updates=17300, lr=0.000240424, gnorm=0.411, loss_scale=4, train_wall=33, gb_free=6.5, wall=5748
2021-04-05 02:13:36 | INFO | train_inner | epoch 004:   3158 / 4751 loss=5.035, nll_loss=3.482, ppl=11.18, wps=88050.3, ups=3.03, wpb=29050.7, bsz=974.8, num_updates=17400, lr=0.000239732, gnorm=0.415, loss_scale=4, train_wall=33, gb_free=6.1, wall=5781
2021-04-05 02:14:09 | INFO | train_inner | epoch 004:   3258 / 4751 loss=5.034, nll_loss=3.481, ppl=11.17, wps=88447, ups=3.05, wpb=29009.9, bsz=942.2, num_updates=17500, lr=0.000239046, gnorm=0.41, loss_scale=4, train_wall=33, gb_free=6.1, wall=5813
2021-04-05 02:14:42 | INFO | train_inner | epoch 004:   3358 / 4751 loss=5.025, nll_loss=3.471, ppl=11.09, wps=86041.1, ups=3.01, wpb=28552.2, bsz=962.5, num_updates=17600, lr=0.000238366, gnorm=0.421, loss_scale=4, train_wall=33, gb_free=6.2, wall=5847
2021-04-05 02:15:15 | INFO | train_inner | epoch 004:   3458 / 4751 loss=5.023, nll_loss=3.468, ppl=11.07, wps=88612.5, ups=3.05, wpb=29075.3, bsz=941.5, num_updates=17700, lr=0.000237691, gnorm=0.411, loss_scale=4, train_wall=33, gb_free=6.1, wall=5879
2021-04-05 02:15:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-05 02:15:48 | INFO | train_inner | epoch 004:   3559 / 4751 loss=4.976, nll_loss=3.416, ppl=10.67, wps=86997.4, ups=3, wpb=28955.1, bsz=951.6, num_updates=17800, lr=0.000237023, gnorm=0.406, loss_scale=2, train_wall=33, gb_free=6.3, wall=5913
2021-04-05 02:16:21 | INFO | train_inner | epoch 004:   3659 / 4751 loss=5.042, nll_loss=3.49, ppl=11.23, wps=87274.1, ups=3.04, wpb=28690.2, bsz=941.3, num_updates=17900, lr=0.00023636, gnorm=0.432, loss_scale=2, train_wall=33, gb_free=6, wall=5946
2021-04-05 02:16:54 | INFO | train_inner | epoch 004:   3759 / 4751 loss=4.994, nll_loss=3.437, ppl=10.83, wps=87500.2, ups=3.05, wpb=28722, bsz=969.8, num_updates=18000, lr=0.000235702, gnorm=0.409, loss_scale=2, train_wall=33, gb_free=6, wall=5978
2021-04-05 02:17:26 | INFO | train_inner | epoch 004:   3859 / 4751 loss=4.996, nll_loss=3.438, ppl=10.84, wps=87242.4, ups=3.06, wpb=28540.8, bsz=936.6, num_updates=18100, lr=0.00023505, gnorm=0.42, loss_scale=2, train_wall=33, gb_free=6.3, wall=6011
2021-04-05 02:17:59 | INFO | train_inner | epoch 004:   3959 / 4751 loss=4.981, nll_loss=3.422, ppl=10.72, wps=88248.1, ups=3.04, wpb=28984.2, bsz=938.6, num_updates=18200, lr=0.000234404, gnorm=0.411, loss_scale=2, train_wall=33, gb_free=6.4, wall=6044
2021-04-05 02:18:32 | INFO | train_inner | epoch 004:   4059 / 4751 loss=5.043, nll_loss=3.493, ppl=11.26, wps=88145.3, ups=3.04, wpb=28967.1, bsz=956.6, num_updates=18300, lr=0.000233762, gnorm=0.441, loss_scale=2, train_wall=33, gb_free=6.4, wall=6077
2021-04-05 02:19:05 | INFO | train_inner | epoch 004:   4159 / 4751 loss=4.987, nll_loss=3.428, ppl=10.76, wps=88003.5, ups=3.02, wpb=29137.1, bsz=925.7, num_updates=18400, lr=0.000233126, gnorm=0.414, loss_scale=2, train_wall=33, gb_free=6.2, wall=6110
2021-04-05 02:19:38 | INFO | train_inner | epoch 004:   4259 / 4751 loss=5.006, nll_loss=3.449, ppl=10.92, wps=88064.9, ups=3.03, wpb=29063.1, bsz=931.4, num_updates=18500, lr=0.000232495, gnorm=0.404, loss_scale=2, train_wall=33, gb_free=6.2, wall=6143
2021-04-05 02:20:11 | INFO | train_inner | epoch 004:   4359 / 4751 loss=4.946, nll_loss=3.382, ppl=10.42, wps=88562.6, ups=3.02, wpb=29295.8, bsz=959.3, num_updates=18600, lr=0.000231869, gnorm=0.405, loss_scale=2, train_wall=33, gb_free=6.1, wall=6176
2021-04-05 02:20:44 | INFO | train_inner | epoch 004:   4459 / 4751 loss=4.999, nll_loss=3.443, ppl=10.87, wps=87315.6, ups=3.03, wpb=28809.4, bsz=964.5, num_updates=18700, lr=0.000231249, gnorm=0.407, loss_scale=2, train_wall=33, gb_free=6.6, wall=6209
2021-04-05 02:21:17 | INFO | train_inner | epoch 004:   4559 / 4751 loss=5.044, nll_loss=3.494, ppl=11.27, wps=88298.9, ups=3.04, wpb=29024.7, bsz=953.2, num_updates=18800, lr=0.000230633, gnorm=0.421, loss_scale=2, train_wall=33, gb_free=6.1, wall=6242
2021-04-05 02:21:50 | INFO | train_inner | epoch 004:   4659 / 4751 loss=4.989, nll_loss=3.432, ppl=10.79, wps=87874.6, ups=3.02, wpb=29092.7, bsz=991.4, num_updates=18900, lr=0.000230022, gnorm=0.404, loss_scale=2, train_wall=33, gb_free=6.2, wall=6275
2021-04-05 02:22:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-05 02:22:21 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 4.571 | nll_loss 2.81 | ppl 7.01 | wps 178141 | wpb 10489.1 | bsz 375 | num_updates 18992 | best_loss 4.571
2021-04-05 02:22:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 18992 updates
2021-04-05 02:22:21 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 02:22:28 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 02:22:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt (epoch 4 @ 18992 updates, score 4.571) (writing took 13.262616042047739 seconds)
2021-04-05 02:22:35 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2021-04-05 02:22:35 | INFO | train | epoch 004 | loss 5.042 | nll_loss 3.489 | ppl 11.22 | wps 86957.2 | ups 3 | wpb 28967.6 | bsz 946.7 | num_updates 18992 | lr 0.000229464 | gnorm 0.415 | loss_scale 2 | train_wall 1559 | gb_free 6.4 | wall 6319
2021-04-05 02:22:35 | INFO | fairseq.trainer | begin training epoch 5
2021-04-05 02:22:35 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-05 02:22:39 | INFO | train_inner | epoch 005:      8 / 4751 loss=5.053, nll_loss=3.504, ppl=11.34, wps=58715, ups=2.06, wpb=28461.4, bsz=909.1, num_updates=19000, lr=0.000229416, gnorm=0.416, loss_scale=2, train_wall=33, gb_free=6.2, wall=6323
2021-04-05 02:23:11 | INFO | train_inner | epoch 005:    108 / 4751 loss=5, nll_loss=3.443, ppl=10.87, wps=87431.9, ups=3.04, wpb=28722.5, bsz=944.9, num_updates=19100, lr=0.000228814, gnorm=0.411, loss_scale=2, train_wall=33, gb_free=6.1, wall=6356
2021-04-05 02:23:44 | INFO | train_inner | epoch 005:    208 / 4751 loss=4.98, nll_loss=3.42, ppl=10.7, wps=87868.9, ups=3.05, wpb=28801.1, bsz=940.2, num_updates=19200, lr=0.000228218, gnorm=0.41, loss_scale=2, train_wall=33, gb_free=6.2, wall=6389
2021-04-05 02:24:17 | INFO | train_inner | epoch 005:    308 / 4751 loss=4.975, nll_loss=3.415, ppl=10.67, wps=88461.5, ups=3.05, wpb=28959.2, bsz=991.3, num_updates=19300, lr=0.000227626, gnorm=0.406, loss_scale=2, train_wall=33, gb_free=6.1, wall=6422
2021-04-05 02:24:50 | INFO | train_inner | epoch 005:    408 / 4751 loss=5, nll_loss=3.443, ppl=10.88, wps=88388.3, ups=3.06, wpb=28908, bsz=972, num_updates=19400, lr=0.000227038, gnorm=0.406, loss_scale=2, train_wall=33, gb_free=6.2, wall=6454
2021-04-05 02:25:23 | INFO | train_inner | epoch 005:    508 / 4751 loss=4.959, nll_loss=3.396, ppl=10.53, wps=87839.4, ups=3.03, wpb=28964.5, bsz=935.7, num_updates=19500, lr=0.000226455, gnorm=0.412, loss_scale=2, train_wall=33, gb_free=6, wall=6487
2021-04-05 02:25:56 | INFO | train_inner | epoch 005:    608 / 4751 loss=5.006, nll_loss=3.45, ppl=10.93, wps=86329.6, ups=3.02, wpb=28560.9, bsz=943.8, num_updates=19600, lr=0.000225877, gnorm=0.419, loss_scale=2, train_wall=33, gb_free=6.3, wall=6521
2021-04-05 02:26:29 | INFO | train_inner | epoch 005:    708 / 4751 loss=4.951, nll_loss=3.388, ppl=10.47, wps=88292, ups=3.04, wpb=29016.2, bsz=933, num_updates=19700, lr=0.000225303, gnorm=0.414, loss_scale=2, train_wall=33, gb_free=6.2, wall=6553
2021-04-05 02:27:01 | INFO | train_inner | epoch 005:    808 / 4751 loss=4.988, nll_loss=3.429, ppl=10.77, wps=89087.4, ups=3.05, wpb=29222.8, bsz=965.9, num_updates=19800, lr=0.000224733, gnorm=0.407, loss_scale=4, train_wall=33, gb_free=6.4, wall=6586
2021-04-05 02:27:34 | INFO | train_inner | epoch 005:    908 / 4751 loss=4.934, nll_loss=3.369, ppl=10.33, wps=87975.9, ups=3.03, wpb=29068.5, bsz=963.2, num_updates=19900, lr=0.000224168, gnorm=0.418, loss_scale=4, train_wall=33, gb_free=6.3, wall=6619
2021-04-05 02:28:07 | INFO | train_inner | epoch 005:   1008 / 4751 loss=4.994, nll_loss=3.437, ppl=10.83, wps=87834.9, ups=3.05, wpb=28776.3, bsz=949, num_updates=20000, lr=0.000223607, gnorm=0.409, loss_scale=4, train_wall=33, gb_free=6.5, wall=6652
2021-04-05 02:28:40 | INFO | train_inner | epoch 005:   1108 / 4751 loss=4.96, nll_loss=3.399, ppl=10.55, wps=88596.2, ups=3.04, wpb=29100.5, bsz=938.4, num_updates=20100, lr=0.00022305, gnorm=0.405, loss_scale=4, train_wall=33, gb_free=6.3, wall=6685
2021-04-05 02:29:13 | INFO | train_inner | epoch 005:   1208 / 4751 loss=4.915, nll_loss=3.348, ppl=10.18, wps=88198.8, ups=3.04, wpb=28994, bsz=989.5, num_updates=20200, lr=0.000222497, gnorm=0.407, loss_scale=4, train_wall=33, gb_free=6.1, wall=6718
2021-04-05 02:29:46 | INFO | train_inner | epoch 005:   1308 / 4751 loss=4.947, nll_loss=3.384, ppl=10.44, wps=88087.4, ups=3.03, wpb=29052.8, bsz=973.5, num_updates=20300, lr=0.000221948, gnorm=0.41, loss_scale=4, train_wall=33, gb_free=6.2, wall=6751
2021-04-05 02:30:19 | INFO | train_inner | epoch 005:   1408 / 4751 loss=4.979, nll_loss=3.42, ppl=10.7, wps=86483.7, ups=3.02, wpb=28604.5, bsz=953.8, num_updates=20400, lr=0.000221404, gnorm=0.417, loss_scale=4, train_wall=33, gb_free=6.2, wall=6784
2021-04-05 02:30:52 | INFO | train_inner | epoch 005:   1508 / 4751 loss=4.936, nll_loss=3.372, ppl=10.35, wps=87319.3, ups=3.03, wpb=28800.2, bsz=934.6, num_updates=20500, lr=0.000220863, gnorm=0.409, loss_scale=4, train_wall=33, gb_free=6.1, wall=6817
2021-04-05 02:31:25 | INFO | train_inner | epoch 005:   1608 / 4751 loss=4.988, nll_loss=3.43, ppl=10.78, wps=88392.2, ups=3.05, wpb=29027.7, bsz=954.6, num_updates=20600, lr=0.000220326, gnorm=0.417, loss_scale=4, train_wall=33, gb_free=6.1, wall=6850
2021-04-05 02:31:58 | INFO | train_inner | epoch 005:   1708 / 4751 loss=4.952, nll_loss=3.39, ppl=10.48, wps=88419.8, ups=3.03, wpb=29149.1, bsz=943.8, num_updates=20700, lr=0.000219793, gnorm=0.411, loss_scale=4, train_wall=33, gb_free=6.2, wall=6883
2021-04-05 02:32:31 | INFO | train_inner | epoch 005:   1808 / 4751 loss=4.982, nll_loss=3.425, ppl=10.74, wps=88387, ups=3.05, wpb=28996.4, bsz=969.8, num_updates=20800, lr=0.000219265, gnorm=0.411, loss_scale=4, train_wall=33, gb_free=6.3, wall=6915
2021-04-05 02:33:03 | INFO | train_inner | epoch 005:   1908 / 4751 loss=4.966, nll_loss=3.405, ppl=10.6, wps=88271, ups=3.04, wpb=28991.1, bsz=923.1, num_updates=20900, lr=0.000218739, gnorm=0.42, loss_scale=4, train_wall=33, gb_free=6.2, wall=6948
2021-04-05 02:33:36 | INFO | train_inner | epoch 005:   2008 / 4751 loss=4.994, nll_loss=3.437, ppl=10.83, wps=88493.1, ups=3.06, wpb=28917.2, bsz=922.3, num_updates=21000, lr=0.000218218, gnorm=0.413, loss_scale=4, train_wall=33, gb_free=6.8, wall=6981
2021-04-05 02:34:09 | INFO | train_inner | epoch 005:   2108 / 4751 loss=5.042, nll_loss=3.492, ppl=11.25, wps=88069.6, ups=3.06, wpb=28819.5, bsz=902.4, num_updates=21100, lr=0.0002177, gnorm=0.417, loss_scale=4, train_wall=33, gb_free=6.5, wall=7014
2021-04-05 02:34:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-05 02:34:42 | INFO | train_inner | epoch 005:   2209 / 4751 loss=4.939, nll_loss=3.376, ppl=10.38, wps=87398.1, ups=3.01, wpb=28995.1, bsz=973.5, num_updates=21200, lr=0.000217186, gnorm=0.404, loss_scale=2, train_wall=33, gb_free=6.2, wall=7047
2021-04-05 02:35:15 | INFO | train_inner | epoch 005:   2309 / 4751 loss=4.875, nll_loss=3.303, ppl=9.87, wps=87185.9, ups=3.01, wpb=28959, bsz=969.8, num_updates=21300, lr=0.000216676, gnorm=0.416, loss_scale=2, train_wall=33, gb_free=5.6, wall=7080
2021-04-05 02:35:48 | INFO | train_inner | epoch 005:   2409 / 4751 loss=5.005, nll_loss=3.45, ppl=10.93, wps=88016.4, ups=3.03, wpb=29019.5, bsz=946.9, num_updates=21400, lr=0.000216169, gnorm=0.412, loss_scale=2, train_wall=33, gb_free=6.3, wall=7113
2021-04-05 02:36:21 | INFO | train_inner | epoch 005:   2509 / 4751 loss=4.968, nll_loss=3.408, ppl=10.61, wps=87876.3, ups=3.03, wpb=29024.9, bsz=926.7, num_updates=21500, lr=0.000215666, gnorm=0.425, loss_scale=2, train_wall=33, gb_free=6.1, wall=7146
2021-04-05 02:36:54 | INFO | train_inner | epoch 005:   2609 / 4751 loss=4.89, nll_loss=3.32, ppl=9.99, wps=88612.9, ups=3.03, wpb=29273.9, bsz=996.4, num_updates=21600, lr=0.000215166, gnorm=0.407, loss_scale=2, train_wall=33, gb_free=7, wall=7179
2021-04-05 02:37:27 | INFO | train_inner | epoch 005:   2709 / 4751 loss=4.963, nll_loss=3.403, ppl=10.57, wps=87872.6, ups=3.04, wpb=28942.8, bsz=899.3, num_updates=21700, lr=0.000214669, gnorm=0.413, loss_scale=2, train_wall=33, gb_free=6.4, wall=7212
2021-04-05 02:38:00 | INFO | train_inner | epoch 005:   2809 / 4751 loss=5.018, nll_loss=3.465, ppl=11.04, wps=87536.2, ups=3.04, wpb=28783.2, bsz=912.2, num_updates=21800, lr=0.000214176, gnorm=0.409, loss_scale=2, train_wall=33, gb_free=6.3, wall=7245
2021-04-05 02:38:33 | INFO | train_inner | epoch 005:   2909 / 4751 loss=4.963, nll_loss=3.403, ppl=10.58, wps=89221.4, ups=3.05, wpb=29296.5, bsz=924.2, num_updates=21900, lr=0.000213687, gnorm=0.407, loss_scale=2, train_wall=33, gb_free=6.1, wall=7278
2021-04-05 02:39:06 | INFO | train_inner | epoch 005:   3009 / 4751 loss=4.885, nll_loss=3.315, ppl=9.95, wps=88048.8, ups=3.04, wpb=28974.8, bsz=987.5, num_updates=22000, lr=0.000213201, gnorm=0.411, loss_scale=2, train_wall=33, gb_free=6.9, wall=7311
2021-04-05 02:39:39 | INFO | train_inner | epoch 005:   3109 / 4751 loss=4.942, nll_loss=3.379, ppl=10.4, wps=87821, ups=3.02, wpb=29054.2, bsz=949.8, num_updates=22100, lr=0.000212718, gnorm=0.405, loss_scale=2, train_wall=33, gb_free=6.2, wall=7344
2021-04-05 02:40:12 | INFO | train_inner | epoch 005:   3209 / 4751 loss=4.973, nll_loss=3.415, ppl=10.67, wps=88792, ups=3.03, wpb=29261.5, bsz=953.2, num_updates=22200, lr=0.000212238, gnorm=0.41, loss_scale=2, train_wall=33, gb_free=6.4, wall=7377
2021-04-05 02:40:45 | INFO | train_inner | epoch 005:   3309 / 4751 loss=4.93, nll_loss=3.366, ppl=10.31, wps=87444.4, ups=3.03, wpb=28886.9, bsz=929, num_updates=22300, lr=0.000211762, gnorm=0.412, loss_scale=2, train_wall=33, gb_free=6.5, wall=7410
2021-04-05 02:41:18 | INFO | train_inner | epoch 005:   3409 / 4751 loss=4.902, nll_loss=3.334, ppl=10.09, wps=86869.1, ups=3.01, wpb=28835.2, bsz=940.9, num_updates=22400, lr=0.000211289, gnorm=0.407, loss_scale=2, train_wall=33, gb_free=6, wall=7443
2021-04-05 02:41:51 | INFO | train_inner | epoch 005:   3509 / 4751 loss=4.947, nll_loss=3.385, ppl=10.45, wps=87614.9, ups=3.03, wpb=28888.9, bsz=949.3, num_updates=22500, lr=0.000210819, gnorm=0.411, loss_scale=2, train_wall=33, gb_free=5.9, wall=7476
2021-04-05 02:42:25 | INFO | train_inner | epoch 005:   3609 / 4751 loss=4.932, nll_loss=3.368, ppl=10.32, wps=85756.5, ups=2.97, wpb=28826.1, bsz=931, num_updates=22600, lr=0.000210352, gnorm=0.409, loss_scale=2, train_wall=33, gb_free=6.3, wall=7509
2021-04-05 02:42:57 | INFO | train_inner | epoch 005:   3709 / 4751 loss=4.932, nll_loss=3.369, ppl=10.33, wps=89416.6, ups=3.05, wpb=29337.5, bsz=953.4, num_updates=22700, lr=0.000209888, gnorm=0.405, loss_scale=2, train_wall=33, gb_free=6.3, wall=7542
2021-04-05 02:43:30 | INFO | train_inner | epoch 005:   3809 / 4751 loss=4.93, nll_loss=3.366, ppl=10.31, wps=88083.9, ups=3.03, wpb=29056.3, bsz=960.4, num_updates=22800, lr=0.000209427, gnorm=0.415, loss_scale=2, train_wall=33, gb_free=6, wall=7575
2021-04-05 02:44:03 | INFO | train_inner | epoch 005:   3909 / 4751 loss=4.93, nll_loss=3.367, ppl=10.31, wps=89528.7, ups=3.05, wpb=29397.3, bsz=960.9, num_updates=22900, lr=0.000208969, gnorm=0.403, loss_scale=2, train_wall=33, gb_free=6.3, wall=7608
2021-04-05 02:44:36 | INFO | train_inner | epoch 005:   4009 / 4751 loss=4.962, nll_loss=3.403, ppl=10.58, wps=88160.1, ups=3.05, wpb=28914.9, bsz=905.5, num_updates=23000, lr=0.000208514, gnorm=0.416, loss_scale=2, train_wall=33, gb_free=6.1, wall=7641
2021-04-05 02:45:09 | INFO | train_inner | epoch 005:   4109 / 4751 loss=4.998, nll_loss=3.443, ppl=10.87, wps=87100.7, ups=3.02, wpb=28841.9, bsz=934.5, num_updates=23100, lr=0.000208063, gnorm=0.451, loss_scale=2, train_wall=33, gb_free=6.2, wall=7674
2021-04-05 02:45:42 | INFO | train_inner | epoch 005:   4209 / 4751 loss=4.953, nll_loss=3.394, ppl=10.51, wps=87802.2, ups=3.03, wpb=28997.2, bsz=949.6, num_updates=23200, lr=0.000207614, gnorm=0.41, loss_scale=2, train_wall=33, gb_free=6.2, wall=7707
2021-04-05 02:46:15 | INFO | train_inner | epoch 005:   4309 / 4751 loss=4.885, nll_loss=3.316, ppl=9.96, wps=87663, ups=3.03, wpb=28912.8, bsz=993.5, num_updates=23300, lr=0.000207168, gnorm=0.406, loss_scale=4, train_wall=33, gb_free=6.5, wall=7740
2021-04-05 02:46:48 | INFO | train_inner | epoch 005:   4409 / 4751 loss=4.963, nll_loss=3.404, ppl=10.59, wps=88418.6, ups=3.04, wpb=29070.3, bsz=924.3, num_updates=23400, lr=0.000206725, gnorm=0.411, loss_scale=4, train_wall=33, gb_free=6.3, wall=7773
2021-04-05 02:47:21 | INFO | train_inner | epoch 005:   4509 / 4751 loss=4.928, nll_loss=3.365, ppl=10.3, wps=88072.4, ups=3.05, wpb=28923.1, bsz=957.4, num_updates=23500, lr=0.000206284, gnorm=0.419, loss_scale=4, train_wall=33, gb_free=6.2, wall=7806
2021-04-05 02:47:54 | INFO | train_inner | epoch 005:   4609 / 4751 loss=4.93, nll_loss=3.367, ppl=10.32, wps=87552.8, ups=3.04, wpb=28837.3, bsz=921, num_updates=23600, lr=0.000205847, gnorm=0.408, loss_scale=4, train_wall=33, gb_free=6.2, wall=7839
2021-04-05 02:48:27 | INFO | train_inner | epoch 005:   4709 / 4751 loss=4.937, nll_loss=3.375, ppl=10.37, wps=88296.1, ups=3.04, wpb=29072.3, bsz=937.7, num_updates=23700, lr=0.000205412, gnorm=0.406, loss_scale=4, train_wall=33, gb_free=6.2, wall=7872
2021-04-05 02:48:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-05 02:48:42 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 4.506 | nll_loss 2.752 | ppl 6.73 | wps 214596 | wpb 10489.1 | bsz 375 | num_updates 23742 | best_loss 4.506
2021-04-05 02:48:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 23742 updates
2021-04-05 02:48:42 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 02:48:48 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 02:48:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt (epoch 5 @ 23742 updates, score 4.506) (writing took 12.849207289516926 seconds)
2021-04-05 02:48:54 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2021-04-05 02:48:54 | INFO | train | epoch 005 | loss 4.955 | nll_loss 3.394 | ppl 10.51 | wps 87101.1 | ups 3.01 | wpb 28968.2 | bsz 947.1 | num_updates 23742 | lr 0.00020523 | gnorm 0.412 | loss_scale 4 | train_wall 1558 | gb_free 6.6 | wall 7899
2021-04-05 02:48:55 | INFO | fairseq.trainer | begin training epoch 6
2021-04-05 02:48:55 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-05 02:49:15 | INFO | train_inner | epoch 006:     58 / 4751 loss=4.875, nll_loss=3.304, ppl=9.88, wps=60013.2, ups=2.08, wpb=28803.5, bsz=936.2, num_updates=23800, lr=0.00020498, gnorm=0.401, loss_scale=4, train_wall=32, gb_free=6, wall=7920
2021-04-05 02:49:48 | INFO | train_inner | epoch 006:    158 / 4751 loss=4.937, nll_loss=3.374, ppl=10.37, wps=88423.8, ups=3.04, wpb=29131, bsz=941.8, num_updates=23900, lr=0.000204551, gnorm=0.408, loss_scale=4, train_wall=33, gb_free=6.4, wall=7953
2021-04-05 02:50:21 | INFO | train_inner | epoch 006:    258 / 4751 loss=4.96, nll_loss=3.4, ppl=10.56, wps=87984.3, ups=3.04, wpb=28930.2, bsz=926.6, num_updates=24000, lr=0.000204124, gnorm=0.41, loss_scale=4, train_wall=33, gb_free=6.6, wall=7985
2021-04-05 02:50:53 | INFO | train_inner | epoch 006:    358 / 4751 loss=4.931, nll_loss=3.367, ppl=10.32, wps=88187.2, ups=3.05, wpb=28880.3, bsz=933.2, num_updates=24100, lr=0.0002037, gnorm=0.411, loss_scale=4, train_wall=33, gb_free=6.1, wall=8018
2021-04-05 02:51:26 | INFO | train_inner | epoch 006:    458 / 4751 loss=4.914, nll_loss=3.348, ppl=10.18, wps=87517.8, ups=3.03, wpb=28926.2, bsz=950.9, num_updates=24200, lr=0.000203279, gnorm=0.403, loss_scale=4, train_wall=33, gb_free=6.4, wall=8051
2021-04-05 02:51:59 | INFO | train_inner | epoch 006:    558 / 4751 loss=4.9, nll_loss=3.333, ppl=10.08, wps=87407.6, ups=3.03, wpb=28862.7, bsz=954.6, num_updates=24300, lr=0.00020286, gnorm=0.412, loss_scale=4, train_wall=33, gb_free=6.2, wall=8084
2021-04-05 02:52:32 | INFO | train_inner | epoch 006:    658 / 4751 loss=4.867, nll_loss=3.295, ppl=9.82, wps=87514, ups=3.02, wpb=28931.5, bsz=958.7, num_updates=24400, lr=0.000202444, gnorm=0.412, loss_scale=4, train_wall=33, gb_free=6.2, wall=8117
2021-04-05 02:53:05 | INFO | train_inner | epoch 006:    758 / 4751 loss=4.879, nll_loss=3.309, ppl=9.91, wps=88085.1, ups=3.03, wpb=29031.9, bsz=956.2, num_updates=24500, lr=0.000202031, gnorm=0.419, loss_scale=4, train_wall=33, gb_free=6.3, wall=8150
2021-04-05 02:53:39 | INFO | train_inner | epoch 006:    858 / 4751 loss=4.91, nll_loss=3.343, ppl=10.15, wps=86904.6, ups=3.01, wpb=28854.6, bsz=926.6, num_updates=24600, lr=0.000201619, gnorm=0.411, loss_scale=4, train_wall=33, gb_free=6.3, wall=8183
2021-04-05 02:54:12 | INFO | train_inner | epoch 006:    958 / 4751 loss=4.927, nll_loss=3.363, ppl=10.29, wps=87917.2, ups=3.03, wpb=29033.9, bsz=903, num_updates=24700, lr=0.000201211, gnorm=0.405, loss_scale=4, train_wall=33, gb_free=6.2, wall=8216
2021-04-05 02:54:45 | INFO | train_inner | epoch 006:   1058 / 4751 loss=4.902, nll_loss=3.336, ppl=10.09, wps=88128.6, ups=3.03, wpb=29118.9, bsz=955.4, num_updates=24800, lr=0.000200805, gnorm=0.404, loss_scale=4, train_wall=33, gb_free=6.2, wall=8250
2021-04-05 02:55:17 | INFO | train_inner | epoch 006:   1158 / 4751 loss=4.944, nll_loss=3.383, ppl=10.43, wps=87468, ups=3.05, wpb=28673.5, bsz=918.2, num_updates=24900, lr=0.000200401, gnorm=0.414, loss_scale=4, train_wall=33, gb_free=6, wall=8282
2021-04-05 02:55:51 | INFO | train_inner | epoch 006:   1258 / 4751 loss=4.95, nll_loss=3.389, ppl=10.48, wps=87710.3, ups=3.02, wpb=29031, bsz=939.6, num_updates=25000, lr=0.0002, gnorm=0.431, loss_scale=4, train_wall=33, gb_free=6.1, wall=8315
2021-04-05 02:56:24 | INFO | train_inner | epoch 006:   1358 / 4751 loss=4.872, nll_loss=3.3, ppl=9.85, wps=87466.3, ups=3.01, wpb=29017.3, bsz=932.6, num_updates=25100, lr=0.000199601, gnorm=0.41, loss_scale=4, train_wall=33, gb_free=6.1, wall=8349
2021-04-05 02:56:57 | INFO | train_inner | epoch 006:   1458 / 4751 loss=4.861, nll_loss=3.288, ppl=9.77, wps=87336.5, ups=3.04, wpb=28766.7, bsz=887.7, num_updates=25200, lr=0.000199205, gnorm=0.413, loss_scale=4, train_wall=33, gb_free=6.8, wall=8382
2021-04-05 02:57:30 | INFO | train_inner | epoch 006:   1558 / 4751 loss=4.913, nll_loss=3.347, ppl=10.18, wps=87473.8, ups=3.03, wpb=28823.5, bsz=928.3, num_updates=25300, lr=0.000198811, gnorm=0.409, loss_scale=8, train_wall=33, gb_free=6.2, wall=8414
2021-04-05 02:58:03 | INFO | train_inner | epoch 006:   1658 / 4751 loss=4.952, nll_loss=3.392, ppl=10.5, wps=86883.8, ups=3.01, wpb=28844.9, bsz=945.7, num_updates=25400, lr=0.000198419, gnorm=0.418, loss_scale=8, train_wall=33, gb_free=6.2, wall=8448
2021-04-05 02:58:36 | INFO | train_inner | epoch 006:   1758 / 4751 loss=4.874, nll_loss=3.304, ppl=9.87, wps=87609, ups=3.03, wpb=28926.5, bsz=960.1, num_updates=25500, lr=0.00019803, gnorm=0.404, loss_scale=8, train_wall=33, gb_free=6, wall=8481
2021-04-05 02:59:09 | INFO | train_inner | epoch 006:   1858 / 4751 loss=4.92, nll_loss=3.356, ppl=10.24, wps=88011.7, ups=3.04, wpb=28940.4, bsz=936.6, num_updates=25600, lr=0.000197642, gnorm=0.411, loss_scale=8, train_wall=33, gb_free=6.1, wall=8514
2021-04-05 02:59:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2021-04-05 02:59:42 | INFO | train_inner | epoch 006:   1959 / 4751 loss=4.924, nll_loss=3.36, ppl=10.27, wps=86500.2, ups=3.01, wpb=28783.3, bsz=963.4, num_updates=25700, lr=0.000197257, gnorm=0.409, loss_scale=4, train_wall=33, gb_free=6.4, wall=8547
2021-04-05 03:00:15 | INFO | train_inner | epoch 006:   2059 / 4751 loss=4.954, nll_loss=3.394, ppl=10.51, wps=87687.2, ups=3.04, wpb=28868.5, bsz=941.8, num_updates=25800, lr=0.000196875, gnorm=0.41, loss_scale=4, train_wall=33, gb_free=6.3, wall=8580
2021-04-05 03:00:48 | INFO | train_inner | epoch 006:   2159 / 4751 loss=4.895, nll_loss=3.327, ppl=10.04, wps=87942.6, ups=3.02, wpb=29073.4, bsz=954.9, num_updates=25900, lr=0.000196494, gnorm=0.407, loss_scale=4, train_wall=33, gb_free=6.2, wall=8613
2021-04-05 03:00:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-05 03:01:21 | INFO | train_inner | epoch 006:   2260 / 4751 loss=4.929, nll_loss=3.367, ppl=10.31, wps=86782.8, ups=2.99, wpb=29006.1, bsz=989.8, num_updates=26000, lr=0.000196116, gnorm=0.409, loss_scale=2, train_wall=33, gb_free=6.1, wall=8646
2021-04-05 03:01:54 | INFO | train_inner | epoch 006:   2360 / 4751 loss=4.912, nll_loss=3.347, ppl=10.18, wps=88761.9, ups=3.05, wpb=29127.4, bsz=971.8, num_updates=26100, lr=0.00019574, gnorm=0.401, loss_scale=2, train_wall=33, gb_free=6.3, wall=8679
2021-04-05 03:02:27 | INFO | train_inner | epoch 006:   2460 / 4751 loss=4.938, nll_loss=3.377, ppl=10.39, wps=88016.3, ups=3.05, wpb=28829.5, bsz=921.4, num_updates=26200, lr=0.000195366, gnorm=0.417, loss_scale=2, train_wall=33, gb_free=6.6, wall=8712
2021-04-05 03:03:00 | INFO | train_inner | epoch 006:   2560 / 4751 loss=4.835, nll_loss=3.259, ppl=9.58, wps=88709.8, ups=3.03, wpb=29320.8, bsz=954, num_updates=26300, lr=0.000194994, gnorm=0.404, loss_scale=2, train_wall=33, gb_free=6.2, wall=8745
2021-04-05 03:03:33 | INFO | train_inner | epoch 006:   2660 / 4751 loss=4.887, nll_loss=3.319, ppl=9.98, wps=89526.1, ups=3.05, wpb=29398.3, bsz=945.7, num_updates=26400, lr=0.000194625, gnorm=0.404, loss_scale=2, train_wall=33, gb_free=6.5, wall=8778
2021-04-05 03:04:06 | INFO | train_inner | epoch 006:   2760 / 4751 loss=4.868, nll_loss=3.297, ppl=9.83, wps=86226.6, ups=2.98, wpb=28915.7, bsz=961.3, num_updates=26500, lr=0.000194257, gnorm=0.399, loss_scale=2, train_wall=33, gb_free=6.4, wall=8811
2021-04-05 03:04:39 | INFO | train_inner | epoch 006:   2860 / 4751 loss=4.901, nll_loss=3.334, ppl=10.09, wps=88077, ups=3.05, wpb=28916.6, bsz=922.6, num_updates=26600, lr=0.000193892, gnorm=0.408, loss_scale=2, train_wall=33, gb_free=6.3, wall=8844
2021-04-05 03:05:12 | INFO | train_inner | epoch 006:   2960 / 4751 loss=4.842, nll_loss=3.268, ppl=9.63, wps=87892.9, ups=3.02, wpb=29132.3, bsz=978.3, num_updates=26700, lr=0.000193528, gnorm=0.407, loss_scale=2, train_wall=33, gb_free=6.3, wall=8877
2021-04-05 03:05:45 | INFO | train_inner | epoch 006:   3060 / 4751 loss=4.953, nll_loss=3.394, ppl=10.51, wps=87189.3, ups=3.03, wpb=28796.2, bsz=907.5, num_updates=26800, lr=0.000193167, gnorm=0.407, loss_scale=2, train_wall=33, gb_free=6.1, wall=8910
2021-04-05 03:06:19 | INFO | train_inner | epoch 006:   3160 / 4751 loss=4.87, nll_loss=3.3, ppl=9.85, wps=87647.7, ups=3.02, wpb=29028.7, bsz=906.7, num_updates=26900, lr=0.000192807, gnorm=0.419, loss_scale=2, train_wall=33, gb_free=6.2, wall=8943
2021-04-05 03:06:51 | INFO | train_inner | epoch 006:   3260 / 4751 loss=4.914, nll_loss=3.349, ppl=10.19, wps=88545.7, ups=3.05, wpb=29075.3, bsz=919.4, num_updates=27000, lr=0.00019245, gnorm=0.404, loss_scale=2, train_wall=33, gb_free=6.2, wall=8976
2021-04-05 03:07:24 | INFO | train_inner | epoch 006:   3360 / 4751 loss=4.828, nll_loss=3.252, ppl=9.53, wps=89279.9, ups=3.04, wpb=29408, bsz=955.4, num_updates=27100, lr=0.000192095, gnorm=0.405, loss_scale=2, train_wall=33, gb_free=6.2, wall=9009
2021-04-05 03:07:57 | INFO | train_inner | epoch 006:   3460 / 4751 loss=4.843, nll_loss=3.269, ppl=9.64, wps=88801.7, ups=3.05, wpb=29142.5, bsz=971.6, num_updates=27200, lr=0.000191741, gnorm=0.412, loss_scale=2, train_wall=33, gb_free=6.7, wall=9042
2021-04-05 03:08:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-04-05 03:08:31 | INFO | train_inner | epoch 006:   3561 / 4751 loss=4.884, nll_loss=3.316, ppl=9.96, wps=86850.3, ups=3, wpb=28988.7, bsz=976.6, num_updates=27300, lr=0.00019139, gnorm=0.42, loss_scale=1, train_wall=33, gb_free=6.3, wall=9075
2021-04-05 03:09:03 | INFO | train_inner | epoch 006:   3661 / 4751 loss=4.948, nll_loss=3.388, ppl=10.47, wps=88545.1, ups=3.06, wpb=28975.4, bsz=936, num_updates=27400, lr=0.00019104, gnorm=0.413, loss_scale=1, train_wall=33, gb_free=6.2, wall=9108
2021-04-05 03:09:36 | INFO | train_inner | epoch 006:   3761 / 4751 loss=4.883, nll_loss=3.316, ppl=9.96, wps=87262.3, ups=3.03, wpb=28780.6, bsz=963, num_updates=27500, lr=0.000190693, gnorm=0.423, loss_scale=1, train_wall=33, gb_free=6.1, wall=9141
2021-04-05 03:10:09 | INFO | train_inner | epoch 006:   3861 / 4751 loss=4.833, nll_loss=3.258, ppl=9.57, wps=89214.7, ups=3.05, wpb=29294.5, bsz=957.4, num_updates=27600, lr=0.000190347, gnorm=0.393, loss_scale=1, train_wall=33, gb_free=6.2, wall=9174
2021-04-05 03:10:42 | INFO | train_inner | epoch 006:   3961 / 4751 loss=4.914, nll_loss=3.35, ppl=10.2, wps=86801.8, ups=3.02, wpb=28769.6, bsz=937.5, num_updates=27700, lr=0.000190003, gnorm=0.409, loss_scale=1, train_wall=33, gb_free=6.5, wall=9207
2021-04-05 03:11:15 | INFO | train_inner | epoch 006:   4061 / 4751 loss=4.886, nll_loss=3.319, ppl=9.98, wps=87741, ups=3.03, wpb=28983.6, bsz=963.3, num_updates=27800, lr=0.000189661, gnorm=0.416, loss_scale=1, train_wall=33, gb_free=6.1, wall=9240
2021-04-05 03:11:48 | INFO | train_inner | epoch 006:   4161 / 4751 loss=4.834, nll_loss=3.259, ppl=9.58, wps=88848.2, ups=3.04, wpb=29245.8, bsz=960.6, num_updates=27900, lr=0.000189321, gnorm=0.402, loss_scale=1, train_wall=33, gb_free=6, wall=9273
2021-04-05 03:12:21 | INFO | train_inner | epoch 006:   4261 / 4751 loss=4.854, nll_loss=3.283, ppl=9.73, wps=87528.5, ups=3.03, wpb=28846.4, bsz=982.5, num_updates=28000, lr=0.000188982, gnorm=0.405, loss_scale=1, train_wall=33, gb_free=6.3, wall=9306
2021-04-05 03:12:54 | INFO | train_inner | epoch 006:   4361 / 4751 loss=4.879, nll_loss=3.311, ppl=9.92, wps=88156.4, ups=3.06, wpb=28799.9, bsz=941.2, num_updates=28100, lr=0.000188646, gnorm=0.411, loss_scale=1, train_wall=33, gb_free=6.1, wall=9339
2021-04-05 03:13:27 | INFO | train_inner | epoch 006:   4461 / 4751 loss=4.925, nll_loss=3.364, ppl=10.29, wps=87320.9, ups=3.04, wpb=28708.1, bsz=966.6, num_updates=28200, lr=0.000188311, gnorm=0.414, loss_scale=1, train_wall=33, gb_free=6.2, wall=9371
2021-04-05 03:14:00 | INFO | train_inner | epoch 006:   4561 / 4751 loss=4.835, nll_loss=3.261, ppl=9.59, wps=87332.5, ups=3.03, wpb=28801.8, bsz=940.9, num_updates=28300, lr=0.000187978, gnorm=0.406, loss_scale=1, train_wall=33, gb_free=6.2, wall=9404
2021-04-05 03:14:33 | INFO | train_inner | epoch 006:   4661 / 4751 loss=4.877, nll_loss=3.31, ppl=9.92, wps=87231.7, ups=3.03, wpb=28770.2, bsz=984.9, num_updates=28400, lr=0.000187647, gnorm=0.411, loss_scale=1, train_wall=33, gb_free=6.3, wall=9437
2021-04-05 03:15:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-05 03:15:03 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 4.446 | nll_loss 2.686 | ppl 6.43 | wps 210584 | wpb 10489.1 | bsz 375 | num_updates 28490 | best_loss 4.446
2021-04-05 03:15:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 28490 updates
2021-04-05 03:15:03 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 03:15:10 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 03:15:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt (epoch 6 @ 28490 updates, score 4.446) (writing took 13.351501032710075 seconds)
2021-04-05 03:15:17 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2021-04-05 03:15:17 | INFO | train | epoch 006 | loss 4.896 | nll_loss 3.329 | ppl 10.05 | wps 86928.8 | ups 3 | wpb 28968.7 | bsz 946.6 | num_updates 28490 | lr 0.00018735 | gnorm 0.41 | loss_scale 1 | train_wall 1559 | gb_free 6 | wall 9481
2021-04-05 03:15:17 | INFO | fairseq.trainer | begin training epoch 7
2021-04-05 03:15:17 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-05 03:15:21 | INFO | train_inner | epoch 007:     10 / 4751 loss=4.867, nll_loss=3.297, ppl=9.83, wps=59566.1, ups=2.06, wpb=28937.3, bsz=964.5, num_updates=28500, lr=0.000187317, gnorm=0.405, loss_scale=1, train_wall=33, gb_free=6.5, wall=9486
2021-04-05 03:15:54 | INFO | train_inner | epoch 007:    110 / 4751 loss=4.783, nll_loss=3.202, ppl=9.2, wps=89188, ups=3.06, wpb=29191, bsz=964.6, num_updates=28600, lr=0.000186989, gnorm=0.405, loss_scale=1, train_wall=33, gb_free=6.3, wall=9519
2021-04-05 03:16:27 | INFO | train_inner | epoch 007:    210 / 4751 loss=4.829, nll_loss=3.253, ppl=9.54, wps=87969.9, ups=3.03, wpb=29057.6, bsz=938.2, num_updates=28700, lr=0.000186663, gnorm=0.404, loss_scale=1, train_wall=33, gb_free=6, wall=9552
2021-04-05 03:17:00 | INFO | train_inner | epoch 007:    310 / 4751 loss=4.879, nll_loss=3.31, ppl=9.92, wps=87662.2, ups=3.04, wpb=28857.9, bsz=931.8, num_updates=28800, lr=0.000186339, gnorm=0.408, loss_scale=1, train_wall=33, gb_free=6.2, wall=9585
2021-04-05 03:17:33 | INFO | train_inner | epoch 007:    410 / 4751 loss=4.842, nll_loss=3.269, ppl=9.64, wps=88280.7, ups=3.04, wpb=29004.5, bsz=966, num_updates=28900, lr=0.000186016, gnorm=0.403, loss_scale=1, train_wall=33, gb_free=6.2, wall=9618
2021-04-05 03:18:06 | INFO | train_inner | epoch 007:    510 / 4751 loss=4.859, nll_loss=3.287, ppl=9.76, wps=87993.7, ups=3.03, wpb=29056.5, bsz=933.9, num_updates=29000, lr=0.000185695, gnorm=0.412, loss_scale=1, train_wall=33, gb_free=6.4, wall=9651
2021-04-05 03:18:39 | INFO | train_inner | epoch 007:    610 / 4751 loss=4.853, nll_loss=3.281, ppl=9.72, wps=88344.3, ups=3.03, wpb=29201.5, bsz=955.3, num_updates=29100, lr=0.000185376, gnorm=0.401, loss_scale=1, train_wall=33, gb_free=6.3, wall=9684
2021-04-05 03:19:12 | INFO | train_inner | epoch 007:    710 / 4751 loss=4.854, nll_loss=3.282, ppl=9.73, wps=87988, ups=3.04, wpb=28945.7, bsz=916.6, num_updates=29200, lr=0.000185058, gnorm=0.403, loss_scale=1, train_wall=33, gb_free=6.3, wall=9717
2021-04-05 03:19:45 | INFO | train_inner | epoch 007:    810 / 4751 loss=4.839, nll_loss=3.265, ppl=9.61, wps=88431.6, ups=3.05, wpb=29034.2, bsz=939.6, num_updates=29300, lr=0.000184742, gnorm=0.411, loss_scale=1, train_wall=33, gb_free=6.3, wall=9749
2021-04-05 03:20:17 | INFO | train_inner | epoch 007:    910 / 4751 loss=4.869, nll_loss=3.299, ppl=9.84, wps=88362.7, ups=3.04, wpb=29084.3, bsz=971, num_updates=29400, lr=0.000184428, gnorm=0.405, loss_scale=2, train_wall=33, gb_free=6.2, wall=9782
2021-04-05 03:20:50 | INFO | train_inner | epoch 007:   1010 / 4751 loss=4.837, nll_loss=3.262, ppl=9.59, wps=88047, ups=3.03, wpb=29025.1, bsz=919.9, num_updates=29500, lr=0.000184115, gnorm=0.409, loss_scale=2, train_wall=33, gb_free=6.4, wall=9815
2021-04-05 03:21:23 | INFO | train_inner | epoch 007:   1110 / 4751 loss=4.825, nll_loss=3.249, ppl=9.51, wps=88479.5, ups=3.04, wpb=29114.1, bsz=948, num_updates=29600, lr=0.000183804, gnorm=0.402, loss_scale=2, train_wall=33, gb_free=6.3, wall=9848
2021-04-05 03:21:57 | INFO | train_inner | epoch 007:   1210 / 4751 loss=4.917, nll_loss=3.353, ppl=10.22, wps=86797.3, ups=3.01, wpb=28828.3, bsz=933.2, num_updates=29700, lr=0.000183494, gnorm=0.407, loss_scale=2, train_wall=33, gb_free=6.2, wall=9881
2021-04-05 03:22:29 | INFO | train_inner | epoch 007:   1310 / 4751 loss=4.8, nll_loss=3.222, ppl=9.33, wps=87052.6, ups=3.04, wpb=28656.8, bsz=963.7, num_updates=29800, lr=0.000183186, gnorm=0.413, loss_scale=2, train_wall=33, gb_free=6.3, wall=9914
2021-04-05 03:23:02 | INFO | train_inner | epoch 007:   1410 / 4751 loss=4.878, nll_loss=3.31, ppl=9.92, wps=88279.8, ups=3.04, wpb=29033.1, bsz=956.3, num_updates=29900, lr=0.000182879, gnorm=0.412, loss_scale=2, train_wall=33, gb_free=6.2, wall=9947
2021-04-05 03:23:35 | INFO | train_inner | epoch 007:   1510 / 4751 loss=4.831, nll_loss=3.257, ppl=9.56, wps=87682.7, ups=3.04, wpb=28838.6, bsz=944.7, num_updates=30000, lr=0.000182574, gnorm=0.406, loss_scale=2, train_wall=33, gb_free=6.2, wall=9980
2021-04-05 03:24:08 | INFO | train_inner | epoch 007:   1610 / 4751 loss=4.905, nll_loss=3.34, ppl=10.13, wps=86842.4, ups=3.04, wpb=28579.9, bsz=943.8, num_updates=30100, lr=0.000182271, gnorm=0.415, loss_scale=2, train_wall=33, gb_free=6.6, wall=10013
2021-04-05 03:24:41 | INFO | train_inner | epoch 007:   1710 / 4751 loss=4.871, nll_loss=3.301, ppl=9.86, wps=89426.3, ups=3.05, wpb=29299.4, bsz=936.6, num_updates=30200, lr=0.000181969, gnorm=0.409, loss_scale=2, train_wall=33, gb_free=6.4, wall=10046
2021-04-05 03:25:14 | INFO | train_inner | epoch 007:   1810 / 4751 loss=4.876, nll_loss=3.308, ppl=9.9, wps=87736.4, ups=3.04, wpb=28832.2, bsz=938.8, num_updates=30300, lr=0.000181668, gnorm=0.411, loss_scale=2, train_wall=33, gb_free=6.3, wall=10079
2021-04-05 03:25:47 | INFO | train_inner | epoch 007:   1910 / 4751 loss=4.863, nll_loss=3.292, ppl=9.8, wps=86014.4, ups=3.01, wpb=28538.9, bsz=919.5, num_updates=30400, lr=0.000181369, gnorm=0.405, loss_scale=2, train_wall=33, gb_free=6.4, wall=10112
2021-04-05 03:26:20 | INFO | train_inner | epoch 007:   2010 / 4751 loss=4.851, nll_loss=3.28, ppl=9.71, wps=87988.7, ups=3.03, wpb=29045.5, bsz=946.6, num_updates=30500, lr=0.000181071, gnorm=0.404, loss_scale=2, train_wall=33, gb_free=6.5, wall=10145
2021-04-05 03:26:54 | INFO | train_inner | epoch 007:   2110 / 4751 loss=4.883, nll_loss=3.317, ppl=9.96, wps=86397.2, ups=2.96, wpb=29140.8, bsz=989.5, num_updates=30600, lr=0.000180775, gnorm=0.421, loss_scale=2, train_wall=34, gb_free=6.2, wall=10179
2021-04-05 03:27:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-04-05 03:27:27 | INFO | train_inner | epoch 007:   2211 / 4751 loss=4.864, nll_loss=3.294, ppl=9.81, wps=86810.9, ups=3, wpb=28941.4, bsz=932.5, num_updates=30700, lr=0.000180481, gnorm=0.405, loss_scale=1, train_wall=33, gb_free=6.6, wall=10212
2021-04-05 03:28:00 | INFO | train_inner | epoch 007:   2311 / 4751 loss=4.815, nll_loss=3.239, ppl=9.44, wps=86662.3, ups=3.01, wpb=28796.8, bsz=939.7, num_updates=30800, lr=0.000180187, gnorm=0.404, loss_scale=1, train_wall=33, gb_free=5.9, wall=10245
2021-04-05 03:28:33 | INFO | train_inner | epoch 007:   2411 / 4751 loss=4.867, nll_loss=3.299, ppl=9.84, wps=87219.3, ups=3.03, wpb=28807.8, bsz=959.1, num_updates=30900, lr=0.000179896, gnorm=0.408, loss_scale=1, train_wall=33, gb_free=6.6, wall=10278
2021-04-05 03:29:06 | INFO | train_inner | epoch 007:   2511 / 4751 loss=4.794, nll_loss=3.215, ppl=9.29, wps=89212.9, ups=3.06, wpb=29121.8, bsz=987.4, num_updates=31000, lr=0.000179605, gnorm=0.408, loss_scale=1, train_wall=32, gb_free=6.2, wall=10311
2021-04-05 03:29:39 | INFO | train_inner | epoch 007:   2611 / 4751 loss=4.826, nll_loss=3.251, ppl=9.52, wps=88488.2, ups=3.04, wpb=29118, bsz=929.6, num_updates=31100, lr=0.000179316, gnorm=0.405, loss_scale=1, train_wall=33, gb_free=5.9, wall=10344
2021-04-05 03:30:12 | INFO | train_inner | epoch 007:   2711 / 4751 loss=4.912, nll_loss=3.349, ppl=10.19, wps=88493.1, ups=3.06, wpb=28944.7, bsz=923, num_updates=31200, lr=0.000179029, gnorm=0.416, loss_scale=1, train_wall=33, gb_free=6.2, wall=10376
2021-04-05 03:30:44 | INFO | train_inner | epoch 007:   2811 / 4751 loss=4.858, nll_loss=3.287, ppl=9.76, wps=88157.8, ups=3.04, wpb=28963.9, bsz=938.1, num_updates=31300, lr=0.000178743, gnorm=0.408, loss_scale=1, train_wall=33, gb_free=6.4, wall=10409
2021-04-05 03:31:17 | INFO | train_inner | epoch 007:   2911 / 4751 loss=4.88, nll_loss=3.313, ppl=9.94, wps=88243.8, ups=3.03, wpb=29138.1, bsz=957.4, num_updates=31400, lr=0.000178458, gnorm=0.453, loss_scale=1, train_wall=33, gb_free=6, wall=10442
2021-04-05 03:31:50 | INFO | train_inner | epoch 007:   3011 / 4751 loss=4.847, nll_loss=3.275, ppl=9.68, wps=88229.7, ups=3.05, wpb=28975, bsz=942.6, num_updates=31500, lr=0.000178174, gnorm=0.413, loss_scale=1, train_wall=33, gb_free=6.4, wall=10475
2021-04-05 03:32:23 | INFO | train_inner | epoch 007:   3111 / 4751 loss=4.855, nll_loss=3.284, ppl=9.74, wps=88572.3, ups=3.05, wpb=29037.8, bsz=953.2, num_updates=31600, lr=0.000177892, gnorm=0.407, loss_scale=1, train_wall=33, gb_free=6.3, wall=10508
2021-04-05 03:32:56 | INFO | train_inner | epoch 007:   3211 / 4751 loss=4.88, nll_loss=3.313, ppl=9.94, wps=88572.5, ups=3.05, wpb=29014.5, bsz=956.3, num_updates=31700, lr=0.000177611, gnorm=0.405, loss_scale=1, train_wall=33, gb_free=6.2, wall=10541
2021-04-05 03:33:29 | INFO | train_inner | epoch 007:   3311 / 4751 loss=4.883, nll_loss=3.316, ppl=9.96, wps=88525.5, ups=3.06, wpb=28968.3, bsz=945.9, num_updates=31800, lr=0.000177332, gnorm=0.403, loss_scale=1, train_wall=33, gb_free=6.6, wall=10573
2021-04-05 03:34:01 | INFO | train_inner | epoch 007:   3411 / 4751 loss=4.886, nll_loss=3.32, ppl=9.99, wps=87803.6, ups=3.04, wpb=28916, bsz=954, num_updates=31900, lr=0.000177054, gnorm=0.412, loss_scale=1, train_wall=33, gb_free=6.7, wall=10606
2021-04-05 03:34:35 | INFO | train_inner | epoch 007:   3511 / 4751 loss=4.836, nll_loss=3.263, ppl=9.6, wps=87605.1, ups=3.03, wpb=28951.7, bsz=947.1, num_updates=32000, lr=0.000176777, gnorm=0.418, loss_scale=1, train_wall=33, gb_free=6.2, wall=10639
2021-04-05 03:35:07 | INFO | train_inner | epoch 007:   3611 / 4751 loss=4.894, nll_loss=3.329, ppl=10.05, wps=88604.1, ups=3.04, wpb=29120.4, bsz=932.1, num_updates=32100, lr=0.000176501, gnorm=0.413, loss_scale=1, train_wall=33, gb_free=6.2, wall=10672
2021-04-05 03:35:41 | INFO | train_inner | epoch 007:   3711 / 4751 loss=4.833, nll_loss=3.26, ppl=9.58, wps=86233.6, ups=3.01, wpb=28638.5, bsz=935.4, num_updates=32200, lr=0.000176227, gnorm=0.415, loss_scale=1, train_wall=33, gb_free=6.1, wall=10705
2021-04-05 03:36:13 | INFO | train_inner | epoch 007:   3811 / 4751 loss=4.88, nll_loss=3.313, ppl=9.94, wps=88721.8, ups=3.04, wpb=29152.4, bsz=927, num_updates=32300, lr=0.000175954, gnorm=0.424, loss_scale=1, train_wall=33, gb_free=6.2, wall=10738
2021-04-05 03:36:47 | INFO | train_inner | epoch 007:   3911 / 4751 loss=4.818, nll_loss=3.242, ppl=9.46, wps=86620, ups=3.02, wpb=28657.4, bsz=919, num_updates=32400, lr=0.000175682, gnorm=0.407, loss_scale=1, train_wall=33, gb_free=6, wall=10771
2021-04-05 03:37:19 | INFO | train_inner | epoch 007:   4011 / 4751 loss=4.808, nll_loss=3.232, ppl=9.4, wps=87904.7, ups=3.04, wpb=28869.5, bsz=944.8, num_updates=32500, lr=0.000175412, gnorm=0.403, loss_scale=1, train_wall=33, gb_free=6.3, wall=10804
2021-04-05 03:37:52 | INFO | train_inner | epoch 007:   4111 / 4751 loss=4.874, nll_loss=3.306, ppl=9.89, wps=88306.6, ups=3.06, wpb=28883.4, bsz=951.4, num_updates=32600, lr=0.000175142, gnorm=0.409, loss_scale=1, train_wall=33, gb_free=6.1, wall=10837
2021-04-05 03:38:25 | INFO | train_inner | epoch 007:   4211 / 4751 loss=4.819, nll_loss=3.243, ppl=9.47, wps=88480.4, ups=3.03, wpb=29166.5, bsz=952.2, num_updates=32700, lr=0.000174874, gnorm=0.409, loss_scale=1, train_wall=33, gb_free=6.4, wall=10870
2021-04-05 03:38:58 | INFO | train_inner | epoch 007:   4311 / 4751 loss=4.846, nll_loss=3.275, ppl=9.68, wps=88535.9, ups=3.03, wpb=29207.5, bsz=959.1, num_updates=32800, lr=0.000174608, gnorm=0.411, loss_scale=2, train_wall=33, gb_free=6.5, wall=10903
2021-04-05 03:39:31 | INFO | train_inner | epoch 007:   4411 / 4751 loss=4.793, nll_loss=3.215, ppl=9.29, wps=88840.5, ups=3.06, wpb=29033.8, bsz=986.1, num_updates=32900, lr=0.000174342, gnorm=0.403, loss_scale=2, train_wall=33, gb_free=6.2, wall=10936
2021-04-05 03:40:04 | INFO | train_inner | epoch 007:   4511 / 4751 loss=4.83, nll_loss=3.257, ppl=9.56, wps=87008.6, ups=3.02, wpb=28813.3, bsz=934.6, num_updates=33000, lr=0.000174078, gnorm=0.411, loss_scale=2, train_wall=33, gb_free=6.1, wall=10969
2021-04-05 03:40:37 | INFO | train_inner | epoch 007:   4611 / 4751 loss=4.848, nll_loss=3.278, ppl=9.7, wps=87218.6, ups=3, wpb=29035.9, bsz=955.6, num_updates=33100, lr=0.000173814, gnorm=0.402, loss_scale=2, train_wall=33, gb_free=6.7, wall=11002
2021-04-05 03:41:10 | INFO | train_inner | epoch 007:   4711 / 4751 loss=4.832, nll_loss=3.259, ppl=9.57, wps=88144.6, ups=3.04, wpb=29039.8, bsz=972.6, num_updates=33200, lr=0.000173553, gnorm=0.405, loss_scale=2, train_wall=33, gb_free=5.9, wall=11035
2021-04-05 03:41:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-05 03:41:24 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 4.418 | nll_loss 2.648 | ppl 6.27 | wps 204882 | wpb 10489.1 | bsz 375 | num_updates 33240 | best_loss 4.418
2021-04-05 03:41:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 33240 updates
2021-04-05 03:41:24 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 03:41:31 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 03:41:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt (epoch 7 @ 33240 updates, score 4.418) (writing took 13.457368567585945 seconds)
2021-04-05 03:41:38 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2021-04-05 03:41:38 | INFO | train | epoch 007 | loss 4.851 | nll_loss 3.28 | ppl 9.71 | wps 87028 | ups 3 | wpb 28968.2 | bsz 947 | num_updates 33240 | lr 0.000173448 | gnorm 0.409 | loss_scale 2 | train_wall 1558 | gb_free 7.6 | wall 11063
2021-04-05 03:41:38 | INFO | fairseq.trainer | begin training epoch 8
2021-04-05 03:41:38 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-05 03:41:59 | INFO | train_inner | epoch 008:     60 / 4751 loss=4.843, nll_loss=3.272, ppl=9.66, wps=58885.6, ups=2.06, wpb=28587.5, bsz=956.2, num_updates=33300, lr=0.000173292, gnorm=0.415, loss_scale=2, train_wall=32, gb_free=6.2, wall=11083
2021-04-05 03:42:32 | INFO | train_inner | epoch 008:    160 / 4751 loss=4.807, nll_loss=3.23, ppl=9.38, wps=88049.4, ups=3.03, wpb=29032.3, bsz=961, num_updates=33400, lr=0.000173032, gnorm=0.417, loss_scale=2, train_wall=33, gb_free=6.1, wall=11116
2021-04-05 03:43:04 | INFO | train_inner | epoch 008:    260 / 4751 loss=4.795, nll_loss=3.215, ppl=9.29, wps=88263.4, ups=3.04, wpb=29018.5, bsz=919, num_updates=33500, lr=0.000172774, gnorm=0.404, loss_scale=2, train_wall=33, gb_free=6.4, wall=11149
2021-04-05 03:43:37 | INFO | train_inner | epoch 008:    360 / 4751 loss=4.778, nll_loss=3.197, ppl=9.17, wps=87935.4, ups=3.04, wpb=28882.4, bsz=938.8, num_updates=33600, lr=0.000172516, gnorm=0.404, loss_scale=2, train_wall=33, gb_free=6, wall=11182
2021-04-05 03:44:10 | INFO | train_inner | epoch 008:    460 / 4751 loss=4.846, nll_loss=3.274, ppl=9.67, wps=87813.9, ups=3.02, wpb=29040.3, bsz=910.9, num_updates=33700, lr=0.00017226, gnorm=0.402, loss_scale=2, train_wall=33, gb_free=6.3, wall=11215
2021-04-05 03:44:43 | INFO | train_inner | epoch 008:    560 / 4751 loss=4.859, nll_loss=3.29, ppl=9.78, wps=88148.8, ups=3.03, wpb=29046, bsz=936.7, num_updates=33800, lr=0.000172005, gnorm=0.416, loss_scale=2, train_wall=33, gb_free=6.3, wall=11248
2021-04-05 03:45:16 | INFO | train_inner | epoch 008:    660 / 4751 loss=4.795, nll_loss=3.217, ppl=9.3, wps=87937.8, ups=3.02, wpb=29097.5, bsz=968.5, num_updates=33900, lr=0.000171751, gnorm=0.407, loss_scale=2, train_wall=33, gb_free=6.4, wall=11281
2021-04-05 03:45:49 | INFO | train_inner | epoch 008:    760 / 4751 loss=4.767, nll_loss=3.185, ppl=9.1, wps=89736.5, ups=3.03, wpb=29577.4, bsz=975.3, num_updates=34000, lr=0.000171499, gnorm=0.395, loss_scale=2, train_wall=33, gb_free=6.2, wall=11314
2021-04-05 03:46:22 | INFO | train_inner | epoch 008:    860 / 4751 loss=4.858, nll_loss=3.288, ppl=9.77, wps=88582.3, ups=3.03, wpb=29200.8, bsz=929.8, num_updates=34100, lr=0.000171247, gnorm=0.402, loss_scale=2, train_wall=33, gb_free=6.4, wall=11347
2021-04-05 03:46:55 | INFO | train_inner | epoch 008:    960 / 4751 loss=4.775, nll_loss=3.195, ppl=9.16, wps=88363.3, ups=3.04, wpb=29085.3, bsz=985.4, num_updates=34200, lr=0.000170996, gnorm=0.401, loss_scale=2, train_wall=33, gb_free=6.1, wall=11380
2021-04-05 03:47:28 | INFO | train_inner | epoch 008:   1060 / 4751 loss=4.798, nll_loss=3.221, ppl=9.32, wps=88092.4, ups=3.03, wpb=29080.9, bsz=967.8, num_updates=34300, lr=0.000170747, gnorm=0.406, loss_scale=2, train_wall=33, gb_free=6.3, wall=11413
2021-04-05 03:48:01 | INFO | train_inner | epoch 008:   1160 / 4751 loss=4.835, nll_loss=3.262, ppl=9.6, wps=89289.9, ups=3.04, wpb=29327.5, bsz=950.1, num_updates=34400, lr=0.000170499, gnorm=0.412, loss_scale=2, train_wall=33, gb_free=6.1, wall=11446
2021-04-05 03:48:34 | INFO | train_inner | epoch 008:   1260 / 4751 loss=4.839, nll_loss=3.267, ppl=9.62, wps=89304.1, ups=3.05, wpb=29277.4, bsz=936.9, num_updates=34500, lr=0.000170251, gnorm=0.416, loss_scale=2, train_wall=33, gb_free=6.1, wall=11479
2021-04-05 03:49:07 | INFO | train_inner | epoch 008:   1360 / 4751 loss=4.777, nll_loss=3.197, ppl=9.17, wps=87484.5, ups=3.03, wpb=28887.7, bsz=961.4, num_updates=34600, lr=0.000170005, gnorm=0.407, loss_scale=2, train_wall=33, gb_free=6.1, wall=11512
2021-04-05 03:49:40 | INFO | train_inner | epoch 008:   1460 / 4751 loss=4.881, nll_loss=3.315, ppl=9.95, wps=87488.6, ups=3.05, wpb=28651.4, bsz=925.8, num_updates=34700, lr=0.00016976, gnorm=0.42, loss_scale=2, train_wall=33, gb_free=6.2, wall=11545
2021-04-05 03:50:12 | INFO | train_inner | epoch 008:   1560 / 4751 loss=4.81, nll_loss=3.234, ppl=9.41, wps=88442.5, ups=3.05, wpb=28985.9, bsz=964.6, num_updates=34800, lr=0.000169516, gnorm=0.414, loss_scale=4, train_wall=33, gb_free=6.2, wall=11577
2021-04-05 03:50:45 | INFO | train_inner | epoch 008:   1660 / 4751 loss=4.816, nll_loss=3.241, ppl=9.46, wps=87945.7, ups=3.03, wpb=29023.2, bsz=990, num_updates=34900, lr=0.000169273, gnorm=0.402, loss_scale=4, train_wall=33, gb_free=6.1, wall=11610
2021-04-05 03:51:18 | INFO | train_inner | epoch 008:   1760 / 4751 loss=4.845, nll_loss=3.274, ppl=9.67, wps=88192.1, ups=3.04, wpb=28978.8, bsz=916.9, num_updates=35000, lr=0.000169031, gnorm=0.409, loss_scale=4, train_wall=33, gb_free=6.2, wall=11643
2021-04-05 03:51:51 | INFO | train_inner | epoch 008:   1860 / 4751 loss=4.885, nll_loss=3.319, ppl=9.98, wps=86673.2, ups=3.02, wpb=28695.3, bsz=921.9, num_updates=35100, lr=0.00016879, gnorm=0.417, loss_scale=4, train_wall=33, gb_free=6.1, wall=11676
2021-04-05 03:52:24 | INFO | train_inner | epoch 008:   1960 / 4751 loss=4.789, nll_loss=3.21, ppl=9.25, wps=87630.1, ups=3.04, wpb=28818, bsz=928.6, num_updates=35200, lr=0.00016855, gnorm=0.408, loss_scale=4, train_wall=33, gb_free=6.3, wall=11709
2021-04-05 03:52:57 | INFO | train_inner | epoch 008:   2060 / 4751 loss=4.794, nll_loss=3.216, ppl=9.29, wps=88251.1, ups=3.02, wpb=29215.8, bsz=979.2, num_updates=35300, lr=0.000168311, gnorm=0.405, loss_scale=4, train_wall=33, gb_free=6.4, wall=11742
2021-04-05 03:53:30 | INFO | train_inner | epoch 008:   2160 / 4751 loss=4.804, nll_loss=3.228, ppl=9.37, wps=87622.6, ups=3.04, wpb=28864.8, bsz=916, num_updates=35400, lr=0.000168073, gnorm=0.408, loss_scale=4, train_wall=33, gb_free=6.2, wall=11775
2021-04-05 03:53:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-05 03:54:04 | INFO | train_inner | epoch 008:   2261 / 4751 loss=4.791, nll_loss=3.213, ppl=9.27, wps=87053.1, ups=3, wpb=29014.5, bsz=1003.5, num_updates=35500, lr=0.000167836, gnorm=0.411, loss_scale=2, train_wall=33, gb_free=6.1, wall=11809
2021-04-05 03:54:37 | INFO | train_inner | epoch 008:   2361 / 4751 loss=4.824, nll_loss=3.249, ppl=9.51, wps=87859.8, ups=3.05, wpb=28848.7, bsz=905.8, num_updates=35600, lr=0.0001676, gnorm=0.408, loss_scale=2, train_wall=33, gb_free=6.2, wall=11841
2021-04-05 03:55:09 | INFO | train_inner | epoch 008:   2461 / 4751 loss=4.832, nll_loss=3.26, ppl=9.58, wps=87994.5, ups=3.05, wpb=28880.1, bsz=938.6, num_updates=35700, lr=0.000167365, gnorm=0.407, loss_scale=2, train_wall=33, gb_free=6.4, wall=11874
2021-04-05 03:55:42 | INFO | train_inner | epoch 008:   2561 / 4751 loss=4.838, nll_loss=3.267, ppl=9.63, wps=87099.1, ups=3.03, wpb=28712.5, bsz=947.8, num_updates=35800, lr=0.000167132, gnorm=0.406, loss_scale=2, train_wall=33, gb_free=6.3, wall=11907
2021-04-05 03:56:15 | INFO | train_inner | epoch 008:   2661 / 4751 loss=4.85, nll_loss=3.28, ppl=9.71, wps=86245.4, ups=3.02, wpb=28531, bsz=951.8, num_updates=35900, lr=0.000166899, gnorm=0.416, loss_scale=2, train_wall=33, gb_free=6.2, wall=11940
2021-04-05 03:56:48 | INFO | train_inner | epoch 008:   2761 / 4751 loss=4.796, nll_loss=3.219, ppl=9.31, wps=87420.4, ups=3.02, wpb=28904.9, bsz=953.2, num_updates=36000, lr=0.000166667, gnorm=0.405, loss_scale=2, train_wall=33, gb_free=6.1, wall=11973
2021-04-05 03:57:21 | INFO | train_inner | epoch 008:   2861 / 4751 loss=4.832, nll_loss=3.26, ppl=9.58, wps=87206.7, ups=3.03, wpb=28769.2, bsz=931.4, num_updates=36100, lr=0.000166436, gnorm=0.406, loss_scale=2, train_wall=33, gb_free=6.7, wall=12006
2021-04-05 03:57:54 | INFO | train_inner | epoch 008:   2961 / 4751 loss=4.811, nll_loss=3.236, ppl=9.42, wps=87650.2, ups=3.04, wpb=28822.5, bsz=919.5, num_updates=36200, lr=0.000166206, gnorm=0.411, loss_scale=2, train_wall=33, gb_free=6.3, wall=12039
2021-04-05 03:58:27 | INFO | train_inner | epoch 008:   3061 / 4751 loss=4.841, nll_loss=3.271, ppl=9.65, wps=87762.9, ups=3.04, wpb=28880.5, bsz=938.7, num_updates=36300, lr=0.000165977, gnorm=0.407, loss_scale=2, train_wall=33, gb_free=6.2, wall=12072
2021-04-05 03:59:00 | INFO | train_inner | epoch 008:   3161 / 4751 loss=4.853, nll_loss=3.283, ppl=9.74, wps=87666.9, ups=3.03, wpb=28951.4, bsz=946.9, num_updates=36400, lr=0.000165748, gnorm=0.421, loss_scale=2, train_wall=33, gb_free=6.1, wall=12105
2021-04-05 03:59:33 | INFO | train_inner | epoch 008:   3261 / 4751 loss=4.857, nll_loss=3.288, ppl=9.77, wps=88136.6, ups=3.04, wpb=28968.2, bsz=945.9, num_updates=36500, lr=0.000165521, gnorm=0.414, loss_scale=2, train_wall=33, gb_free=6.4, wall=12138
2021-04-05 04:00:06 | INFO | train_inner | epoch 008:   3361 / 4751 loss=4.808, nll_loss=3.233, ppl=9.4, wps=88212.1, ups=3.04, wpb=29005.2, bsz=967.7, num_updates=36600, lr=0.000165295, gnorm=0.414, loss_scale=2, train_wall=33, gb_free=6.7, wall=12171
2021-04-05 04:00:39 | INFO | train_inner | epoch 008:   3461 / 4751 loss=4.784, nll_loss=3.205, ppl=9.22, wps=86981.3, ups=3.01, wpb=28851.5, bsz=949.1, num_updates=36700, lr=0.00016507, gnorm=0.411, loss_scale=2, train_wall=33, gb_free=6.2, wall=12204
2021-04-05 04:01:12 | INFO | train_inner | epoch 008:   3561 / 4751 loss=4.799, nll_loss=3.222, ppl=9.33, wps=86822.6, ups=3.02, wpb=28788.3, bsz=952.6, num_updates=36800, lr=0.000164845, gnorm=0.448, loss_scale=2, train_wall=33, gb_free=6.1, wall=12237
2021-04-05 04:01:45 | INFO | train_inner | epoch 008:   3661 / 4751 loss=4.826, nll_loss=3.253, ppl=9.53, wps=87408.2, ups=3.05, wpb=28695.4, bsz=916.7, num_updates=36900, lr=0.000164622, gnorm=0.405, loss_scale=2, train_wall=33, gb_free=6.3, wall=12270
2021-04-05 04:02:18 | INFO | train_inner | epoch 008:   3761 / 4751 loss=4.864, nll_loss=3.296, ppl=9.82, wps=87184, ups=3.02, wpb=28869.7, bsz=939.9, num_updates=37000, lr=0.000164399, gnorm=0.411, loss_scale=2, train_wall=33, gb_free=6.2, wall=12303
2021-04-05 04:02:51 | INFO | train_inner | epoch 008:   3861 / 4751 loss=4.791, nll_loss=3.214, ppl=9.28, wps=88684.9, ups=3.05, wpb=29116.7, bsz=937.9, num_updates=37100, lr=0.000164177, gnorm=0.405, loss_scale=2, train_wall=33, gb_free=6.2, wall=12336
2021-04-05 04:03:24 | INFO | train_inner | epoch 008:   3961 / 4751 loss=4.832, nll_loss=3.26, ppl=9.58, wps=87194.6, ups=3.01, wpb=28937.3, bsz=979.2, num_updates=37200, lr=0.000163956, gnorm=0.416, loss_scale=2, train_wall=33, gb_free=6.3, wall=12369
2021-04-05 04:03:57 | INFO | train_inner | epoch 008:   4061 / 4751 loss=4.752, nll_loss=3.169, ppl=9, wps=88019.8, ups=3.02, wpb=29143.4, bsz=960.8, num_updates=37300, lr=0.000163737, gnorm=0.406, loss_scale=2, train_wall=33, gb_free=6.2, wall=12402
2021-04-05 04:04:30 | INFO | train_inner | epoch 008:   4161 / 4751 loss=4.797, nll_loss=3.22, ppl=9.31, wps=88441.4, ups=3.04, wpb=29103, bsz=927.8, num_updates=37400, lr=0.000163517, gnorm=0.416, loss_scale=2, train_wall=33, gb_free=6.2, wall=12435
2021-04-05 04:05:03 | INFO | train_inner | epoch 008:   4261 / 4751 loss=4.835, nll_loss=3.263, ppl=9.6, wps=87344.7, ups=3.04, wpb=28750.9, bsz=930.5, num_updates=37500, lr=0.000163299, gnorm=0.411, loss_scale=4, train_wall=33, gb_free=6.2, wall=12468
2021-04-05 04:05:36 | INFO | train_inner | epoch 008:   4361 / 4751 loss=4.763, nll_loss=3.182, ppl=9.08, wps=87447.3, ups=3.02, wpb=28919.7, bsz=977, num_updates=37600, lr=0.000163082, gnorm=0.403, loss_scale=4, train_wall=33, gb_free=6.3, wall=12501
2021-04-05 04:06:09 | INFO | train_inner | epoch 008:   4461 / 4751 loss=4.842, nll_loss=3.271, ppl=9.65, wps=89030.1, ups=3.04, wpb=29318, bsz=931.3, num_updates=37700, lr=0.000162866, gnorm=0.416, loss_scale=4, train_wall=33, gb_free=6.1, wall=12534
2021-04-05 04:06:43 | INFO | train_inner | epoch 008:   4561 / 4751 loss=4.839, nll_loss=3.269, ppl=9.64, wps=86116.7, ups=2.99, wpb=28842.7, bsz=954.4, num_updates=37800, lr=0.00016265, gnorm=0.414, loss_scale=4, train_wall=33, gb_free=6.2, wall=12568
2021-04-05 04:07:16 | INFO | train_inner | epoch 008:   4661 / 4751 loss=4.749, nll_loss=3.166, ppl=8.98, wps=88394.4, ups=3.04, wpb=29109, bsz=971.7, num_updates=37900, lr=0.000162435, gnorm=0.403, loss_scale=4, train_wall=33, gb_free=6.3, wall=12600
2021-04-05 04:07:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-05 04:07:46 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 4.392 | nll_loss 2.628 | ppl 6.18 | wps 201446 | wpb 10489.1 | bsz 375 | num_updates 37990 | best_loss 4.392
2021-04-05 04:07:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 37990 updates
2021-04-05 04:07:46 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 04:07:53 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 04:07:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt (epoch 8 @ 37990 updates, score 4.392) (writing took 12.68046848475933 seconds)
2021-04-05 04:07:59 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2021-04-05 04:07:59 | INFO | train | epoch 008 | loss 4.816 | nll_loss 3.241 | ppl 9.46 | wps 87016.9 | ups 3 | wpb 28969.5 | bsz 947.2 | num_updates 37990 | lr 0.000162243 | gnorm 0.41 | loss_scale 4 | train_wall 1559 | gb_free 7.5 | wall 12644
2021-04-05 04:07:59 | INFO | fairseq.trainer | begin training epoch 9
2021-04-05 04:07:59 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-05 04:08:04 | INFO | train_inner | epoch 009:     10 / 4751 loss=4.764, nll_loss=3.183, ppl=9.08, wps=60664.2, ups=2.08, wpb=29164.2, bsz=953.3, num_updates=38000, lr=0.000162221, gnorm=0.414, loss_scale=4, train_wall=33, gb_free=6.2, wall=12649
2021-04-05 04:08:37 | INFO | train_inner | epoch 009:    110 / 4751 loss=4.777, nll_loss=3.197, ppl=9.17, wps=88411.3, ups=3.05, wpb=29001.4, bsz=948.3, num_updates=38100, lr=0.000162008, gnorm=0.404, loss_scale=4, train_wall=33, gb_free=6.3, wall=12681
2021-04-05 04:09:10 | INFO | train_inner | epoch 009:    210 / 4751 loss=4.734, nll_loss=3.149, ppl=8.87, wps=87745.3, ups=3.03, wpb=28969.3, bsz=949, num_updates=38200, lr=0.000161796, gnorm=0.4, loss_scale=4, train_wall=33, gb_free=6.2, wall=12714
2021-04-05 04:09:43 | INFO | train_inner | epoch 009:    310 / 4751 loss=4.823, nll_loss=3.249, ppl=9.51, wps=87882.4, ups=3.03, wpb=28967, bsz=912.9, num_updates=38300, lr=0.000161585, gnorm=0.413, loss_scale=4, train_wall=33, gb_free=6.3, wall=12747
2021-04-05 04:10:15 | INFO | train_inner | epoch 009:    410 / 4751 loss=4.789, nll_loss=3.211, ppl=9.26, wps=88223.8, ups=3.05, wpb=28918.4, bsz=963.6, num_updates=38400, lr=0.000161374, gnorm=0.412, loss_scale=4, train_wall=33, gb_free=6.3, wall=12780
2021-04-05 04:10:48 | INFO | train_inner | epoch 009:    510 / 4751 loss=4.776, nll_loss=3.197, ppl=9.17, wps=88730.5, ups=3.04, wpb=29191.4, bsz=967.4, num_updates=38500, lr=0.000161165, gnorm=0.414, loss_scale=4, train_wall=33, gb_free=6.4, wall=12813
2021-04-05 04:11:21 | INFO | train_inner | epoch 009:    610 / 4751 loss=4.796, nll_loss=3.218, ppl=9.31, wps=88066.4, ups=3.04, wpb=28935.1, bsz=923.9, num_updates=38600, lr=0.000160956, gnorm=0.408, loss_scale=4, train_wall=33, gb_free=6.2, wall=12846
2021-04-05 04:11:54 | INFO | train_inner | epoch 009:    710 / 4751 loss=4.753, nll_loss=3.17, ppl=9, wps=88161.6, ups=3.03, wpb=29113.7, bsz=952, num_updates=38700, lr=0.000160748, gnorm=0.409, loss_scale=4, train_wall=33, gb_free=5.4, wall=12879
2021-04-05 04:12:27 | INFO | train_inner | epoch 009:    810 / 4751 loss=4.809, nll_loss=3.233, ppl=9.4, wps=88146.9, ups=3.04, wpb=28965.8, bsz=933.6, num_updates=38800, lr=0.00016054, gnorm=0.409, loss_scale=4, train_wall=33, gb_free=6.3, wall=12912
2021-04-05 04:13:00 | INFO | train_inner | epoch 009:    910 / 4751 loss=4.754, nll_loss=3.17, ppl=9, wps=86998.3, ups=3.01, wpb=28896.8, bsz=932.6, num_updates=38900, lr=0.000160334, gnorm=0.414, loss_scale=4, train_wall=33, gb_free=6.1, wall=12945
2021-04-05 04:13:33 | INFO | train_inner | epoch 009:   1010 / 4751 loss=4.739, nll_loss=3.154, ppl=8.9, wps=87750.6, ups=3.02, wpb=29094, bsz=948.6, num_updates=39000, lr=0.000160128, gnorm=0.413, loss_scale=4, train_wall=33, gb_free=6.2, wall=12978
2021-04-05 04:14:06 | INFO | train_inner | epoch 009:   1110 / 4751 loss=4.796, nll_loss=3.219, ppl=9.31, wps=86989.7, ups=3.03, wpb=28691.5, bsz=940.3, num_updates=39100, lr=0.000159923, gnorm=0.413, loss_scale=4, train_wall=33, gb_free=6.1, wall=13011
2021-04-05 04:14:39 | INFO | train_inner | epoch 009:   1210 / 4751 loss=4.765, nll_loss=3.184, ppl=9.09, wps=88718.9, ups=3.02, wpb=29373.6, bsz=968.6, num_updates=39200, lr=0.000159719, gnorm=0.422, loss_scale=4, train_wall=33, gb_free=6, wall=13044
2021-04-05 04:15:12 | INFO | train_inner | epoch 009:   1310 / 4751 loss=4.782, nll_loss=3.203, ppl=9.21, wps=87604.7, ups=3.03, wpb=28892.4, bsz=968.6, num_updates=39300, lr=0.000159516, gnorm=0.412, loss_scale=4, train_wall=33, gb_free=6.8, wall=13077
2021-04-05 04:15:45 | INFO | train_inner | epoch 009:   1410 / 4751 loss=4.771, nll_loss=3.191, ppl=9.13, wps=88443.6, ups=3.03, wpb=29186.6, bsz=960.4, num_updates=39400, lr=0.000159313, gnorm=0.398, loss_scale=4, train_wall=33, gb_free=6.4, wall=13110
2021-04-05 04:16:18 | INFO | train_inner | epoch 009:   1510 / 4751 loss=4.705, nll_loss=3.116, ppl=8.67, wps=88048.6, ups=3.02, wpb=29117.3, bsz=947.4, num_updates=39500, lr=0.000159111, gnorm=0.411, loss_scale=4, train_wall=33, gb_free=6, wall=13143
2021-04-05 04:16:51 | INFO | train_inner | epoch 009:   1610 / 4751 loss=4.795, nll_loss=3.219, ppl=9.31, wps=88002.5, ups=3.04, wpb=28980.5, bsz=950.5, num_updates=39600, lr=0.00015891, gnorm=0.417, loss_scale=8, train_wall=33, gb_free=6.4, wall=13176
2021-04-05 04:17:24 | INFO | train_inner | epoch 009:   1710 / 4751 loss=4.782, nll_loss=3.204, ppl=9.22, wps=88564.2, ups=3.05, wpb=29012.8, bsz=971.8, num_updates=39700, lr=0.00015871, gnorm=0.412, loss_scale=8, train_wall=33, gb_free=6, wall=13209
2021-04-05 04:17:57 | INFO | train_inner | epoch 009:   1810 / 4751 loss=4.86, nll_loss=3.292, ppl=9.8, wps=87704.5, ups=3.06, wpb=28690.6, bsz=949, num_updates=39800, lr=0.000158511, gnorm=0.415, loss_scale=8, train_wall=33, gb_free=6.2, wall=13242
2021-04-05 04:18:30 | INFO | train_inner | epoch 009:   1910 / 4751 loss=4.808, nll_loss=3.233, ppl=9.4, wps=88054.1, ups=3.04, wpb=28983.4, bsz=934.4, num_updates=39900, lr=0.000158312, gnorm=0.415, loss_scale=8, train_wall=33, gb_free=6.2, wall=13275
2021-04-05 04:19:03 | INFO | train_inner | epoch 009:   2010 / 4751 loss=4.827, nll_loss=3.255, ppl=9.55, wps=86776, ups=3.03, wpb=28614.8, bsz=959.4, num_updates=40000, lr=0.000158114, gnorm=0.412, loss_scale=8, train_wall=33, gb_free=6.6, wall=13308
2021-04-05 04:19:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2021-04-05 04:19:36 | INFO | train_inner | epoch 009:   2111 / 4751 loss=4.77, nll_loss=3.19, ppl=9.12, wps=87334, ups=3, wpb=29098, bsz=964.5, num_updates=40100, lr=0.000157917, gnorm=0.414, loss_scale=4, train_wall=33, gb_free=6.4, wall=13341
2021-04-05 04:20:09 | INFO | train_inner | epoch 009:   2211 / 4751 loss=4.801, nll_loss=3.225, ppl=9.35, wps=88085.6, ups=3.04, wpb=28937, bsz=959.4, num_updates=40200, lr=0.00015772, gnorm=0.409, loss_scale=4, train_wall=33, gb_free=6.4, wall=13374
2021-04-05 04:20:42 | INFO | train_inner | epoch 009:   2311 / 4751 loss=4.8, nll_loss=3.224, ppl=9.34, wps=88695.7, ups=3.05, wpb=29095.5, bsz=926.7, num_updates=40300, lr=0.000157524, gnorm=0.404, loss_scale=4, train_wall=33, gb_free=6.5, wall=13407
2021-04-05 04:21:15 | INFO | train_inner | epoch 009:   2411 / 4751 loss=4.765, nll_loss=3.185, ppl=9.09, wps=87251.7, ups=3.03, wpb=28783.1, bsz=975.4, num_updates=40400, lr=0.000157329, gnorm=0.413, loss_scale=4, train_wall=33, gb_free=6.1, wall=13440
2021-04-05 04:21:47 | INFO | train_inner | epoch 009:   2511 / 4751 loss=4.823, nll_loss=3.25, ppl=9.51, wps=89021.8, ups=3.05, wpb=29161.6, bsz=952, num_updates=40500, lr=0.000157135, gnorm=0.413, loss_scale=4, train_wall=33, gb_free=6.5, wall=13472
2021-04-05 04:22:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-05 04:22:21 | INFO | train_inner | epoch 009:   2612 / 4751 loss=4.831, nll_loss=3.259, ppl=9.57, wps=86416.4, ups=3.01, wpb=28687.5, bsz=927.8, num_updates=40600, lr=0.000156941, gnorm=0.414, loss_scale=2, train_wall=33, gb_free=6.2, wall=13505
2021-04-05 04:22:54 | INFO | train_inner | epoch 009:   2712 / 4751 loss=4.828, nll_loss=3.256, ppl=9.55, wps=88860.1, ups=3.04, wpb=29220.3, bsz=906.4, num_updates=40700, lr=0.000156748, gnorm=0.411, loss_scale=2, train_wall=33, gb_free=6.2, wall=13538
2021-04-05 04:23:26 | INFO | train_inner | epoch 009:   2812 / 4751 loss=4.773, nll_loss=3.193, ppl=9.15, wps=88058.5, ups=3.05, wpb=28877, bsz=931.8, num_updates=40800, lr=0.000156556, gnorm=0.409, loss_scale=2, train_wall=33, gb_free=6.2, wall=13571
2021-04-05 04:23:59 | INFO | train_inner | epoch 009:   2912 / 4751 loss=4.783, nll_loss=3.205, ppl=9.22, wps=88859.9, ups=3.05, wpb=29165.8, bsz=947.8, num_updates=40900, lr=0.000156365, gnorm=0.407, loss_scale=2, train_wall=33, gb_free=6.2, wall=13604
2021-04-05 04:24:33 | INFO | train_inner | epoch 009:   3012 / 4751 loss=4.786, nll_loss=3.209, ppl=9.24, wps=87064.1, ups=2.99, wpb=29155.5, bsz=979.7, num_updates=41000, lr=0.000156174, gnorm=0.408, loss_scale=2, train_wall=33, gb_free=6.2, wall=13637
2021-04-05 04:25:06 | INFO | train_inner | epoch 009:   3112 / 4751 loss=4.8, nll_loss=3.224, ppl=9.35, wps=86477, ups=2.99, wpb=28892.7, bsz=940.3, num_updates=41100, lr=0.000155984, gnorm=0.417, loss_scale=2, train_wall=33, gb_free=6.4, wall=13671
2021-04-05 04:25:39 | INFO | train_inner | epoch 009:   3212 / 4751 loss=4.772, nll_loss=3.193, ppl=9.14, wps=87560.8, ups=3.04, wpb=28816.2, bsz=971.4, num_updates=41200, lr=0.000155794, gnorm=0.406, loss_scale=2, train_wall=33, gb_free=6.2, wall=13704
2021-04-05 04:26:12 | INFO | train_inner | epoch 009:   3312 / 4751 loss=4.817, nll_loss=3.244, ppl=9.47, wps=88729.4, ups=3.05, wpb=29050, bsz=937.1, num_updates=41300, lr=0.000155606, gnorm=0.415, loss_scale=2, train_wall=33, gb_free=6.1, wall=13737
2021-04-05 04:26:45 | INFO | train_inner | epoch 009:   3412 / 4751 loss=4.8, nll_loss=3.225, ppl=9.35, wps=88064.9, ups=3.05, wpb=28863.8, bsz=918.5, num_updates=41400, lr=0.000155417, gnorm=0.411, loss_scale=2, train_wall=33, gb_free=6.3, wall=13769
2021-04-05 04:27:17 | INFO | train_inner | epoch 009:   3512 / 4751 loss=4.754, nll_loss=3.173, ppl=9.02, wps=88152.9, ups=3.03, wpb=29057.8, bsz=978.5, num_updates=41500, lr=0.00015523, gnorm=0.405, loss_scale=2, train_wall=33, gb_free=6.2, wall=13802
2021-04-05 04:27:50 | INFO | train_inner | epoch 009:   3612 / 4751 loss=4.766, nll_loss=3.186, ppl=9.1, wps=87693.1, ups=3.03, wpb=28941.5, bsz=956.1, num_updates=41600, lr=0.000155043, gnorm=0.411, loss_scale=2, train_wall=33, gb_free=6.2, wall=13835
2021-04-05 04:28:23 | INFO | train_inner | epoch 009:   3712 / 4751 loss=4.774, nll_loss=3.195, ppl=9.16, wps=88617.1, ups=3.05, wpb=29070.8, bsz=966.9, num_updates=41700, lr=0.000154857, gnorm=0.415, loss_scale=2, train_wall=33, gb_free=6.4, wall=13868
2021-04-05 04:28:56 | INFO | train_inner | epoch 009:   3812 / 4751 loss=4.766, nll_loss=3.186, ppl=9.1, wps=88155.5, ups=3.04, wpb=29026.6, bsz=940.6, num_updates=41800, lr=0.000154672, gnorm=0.41, loss_scale=2, train_wall=33, gb_free=6.2, wall=13901
2021-04-05 04:29:29 | INFO | train_inner | epoch 009:   3912 / 4751 loss=4.787, nll_loss=3.211, ppl=9.26, wps=87343.6, ups=3.05, wpb=28664.3, bsz=987.4, num_updates=41900, lr=0.000154487, gnorm=0.411, loss_scale=2, train_wall=33, gb_free=6.2, wall=13934
2021-04-05 04:30:02 | INFO | train_inner | epoch 009:   4012 / 4751 loss=4.79, nll_loss=3.213, ppl=9.27, wps=87092, ups=3.04, wpb=28665.9, bsz=921.7, num_updates=42000, lr=0.000154303, gnorm=0.416, loss_scale=2, train_wall=33, gb_free=6, wall=13967
2021-04-05 04:30:35 | INFO | train_inner | epoch 009:   4112 / 4751 loss=4.798, nll_loss=3.222, ppl=9.33, wps=88359.7, ups=3.04, wpb=29058, bsz=946.5, num_updates=42100, lr=0.00015412, gnorm=0.413, loss_scale=2, train_wall=33, gb_free=6.3, wall=14000
2021-04-05 04:31:08 | INFO | train_inner | epoch 009:   4212 / 4751 loss=4.768, nll_loss=3.189, ppl=9.12, wps=88778.2, ups=3.05, wpb=29108.5, bsz=955.6, num_updates=42200, lr=0.000153937, gnorm=0.405, loss_scale=2, train_wall=33, gb_free=6.1, wall=14032
2021-04-05 04:31:40 | INFO | train_inner | epoch 009:   4312 / 4751 loss=4.844, nll_loss=3.275, ppl=9.68, wps=88503.2, ups=3.04, wpb=29085.8, bsz=919.4, num_updates=42300, lr=0.000153755, gnorm=0.417, loss_scale=2, train_wall=33, gb_free=6.4, wall=14065
2021-04-05 04:32:13 | INFO | train_inner | epoch 009:   4412 / 4751 loss=4.814, nll_loss=3.24, ppl=9.45, wps=88370.7, ups=3.04, wpb=29022, bsz=929.3, num_updates=42400, lr=0.000153574, gnorm=0.426, loss_scale=2, train_wall=33, gb_free=6.3, wall=14098
2021-04-05 04:32:46 | INFO | train_inner | epoch 009:   4512 / 4751 loss=4.782, nll_loss=3.204, ppl=9.22, wps=88484.8, ups=3.04, wpb=29121.1, bsz=913.5, num_updates=42500, lr=0.000153393, gnorm=0.404, loss_scale=2, train_wall=33, gb_free=6.2, wall=14131
2021-04-05 04:33:19 | INFO | train_inner | epoch 009:   4612 / 4751 loss=4.752, nll_loss=3.17, ppl=9, wps=87275.6, ups=3.03, wpb=28758.4, bsz=941.3, num_updates=42600, lr=0.000153213, gnorm=0.417, loss_scale=2, train_wall=33, gb_free=6.3, wall=14164
2021-04-05 04:33:52 | INFO | train_inner | epoch 009:   4712 / 4751 loss=4.845, nll_loss=3.276, ppl=9.69, wps=88274.2, ups=3.06, wpb=28846.5, bsz=927.8, num_updates=42700, lr=0.000153033, gnorm=0.416, loss_scale=4, train_wall=33, gb_free=6.5, wall=14197
2021-04-05 04:34:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-05 04:34:06 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 4.376 | nll_loss 2.61 | ppl 6.11 | wps 198512 | wpb 10489.1 | bsz 375 | num_updates 42739 | best_loss 4.376
2021-04-05 04:34:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 42739 updates
2021-04-05 04:34:06 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 04:34:13 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 04:34:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt (epoch 9 @ 42739 updates, score 4.376) (writing took 13.425779655575752 seconds)
2021-04-05 04:34:19 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2021-04-05 04:34:19 | INFO | train | epoch 009 | loss 4.788 | nll_loss 3.21 | ppl 9.25 | wps 87067.2 | ups 3.01 | wpb 28967.5 | bsz 946.7 | num_updates 42739 | lr 0.000152964 | gnorm 0.412 | loss_scale 4 | train_wall 1557 | gb_free 6.7 | wall 14224
2021-04-05 04:34:19 | INFO | fairseq.trainer | begin training epoch 10
2021-04-05 04:34:19 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-05 04:34:40 | INFO | train_inner | epoch 010:     61 / 4751 loss=4.747, nll_loss=3.165, ppl=8.97, wps=58997.8, ups=2.06, wpb=28685.1, bsz=950.2, num_updates=42800, lr=0.000152854, gnorm=0.417, loss_scale=4, train_wall=33, gb_free=6.2, wall=14245
2021-04-05 04:35:13 | INFO | train_inner | epoch 010:    161 / 4751 loss=4.775, nll_loss=3.195, ppl=9.16, wps=88769.5, ups=3.07, wpb=28942, bsz=942.7, num_updates=42900, lr=0.000152676, gnorm=0.405, loss_scale=4, train_wall=32, gb_free=6, wall=14278
2021-04-05 04:35:46 | INFO | train_inner | epoch 010:    261 / 4751 loss=4.804, nll_loss=3.228, ppl=9.37, wps=88488.6, ups=3.06, wpb=28964.3, bsz=948.2, num_updates=43000, lr=0.000152499, gnorm=0.417, loss_scale=4, train_wall=33, gb_free=6.2, wall=14311
2021-04-05 04:36:19 | INFO | train_inner | epoch 010:    361 / 4751 loss=4.817, nll_loss=3.243, ppl=9.47, wps=86464.2, ups=3.03, wpb=28513.5, bsz=929.2, num_updates=43100, lr=0.000152322, gnorm=0.415, loss_scale=4, train_wall=33, gb_free=6.1, wall=14344
2021-04-05 04:36:52 | INFO | train_inner | epoch 010:    461 / 4751 loss=4.759, nll_loss=3.178, ppl=9.05, wps=88153.3, ups=3.03, wpb=29065.9, bsz=943.8, num_updates=43200, lr=0.000152145, gnorm=0.41, loss_scale=4, train_wall=33, gb_free=6.5, wall=14377
2021-04-05 04:37:25 | INFO | train_inner | epoch 010:    561 / 4751 loss=4.758, nll_loss=3.176, ppl=9.04, wps=86805.3, ups=3.03, wpb=28688.3, bsz=949.1, num_updates=43300, lr=0.000151969, gnorm=0.41, loss_scale=4, train_wall=33, gb_free=5.9, wall=14410
2021-04-05 04:37:58 | INFO | train_inner | epoch 010:    661 / 4751 loss=4.815, nll_loss=3.241, ppl=9.45, wps=87209.1, ups=3.02, wpb=28834.1, bsz=954.2, num_updates=43400, lr=0.000151794, gnorm=0.417, loss_scale=4, train_wall=33, gb_free=6.3, wall=14443
2021-04-05 04:38:32 | INFO | train_inner | epoch 010:    761 / 4751 loss=4.707, nll_loss=3.119, ppl=8.69, wps=86497.8, ups=2.96, wpb=29194.4, bsz=959.5, num_updates=43500, lr=0.00015162, gnorm=0.406, loss_scale=4, train_wall=34, gb_free=6.3, wall=14476
2021-04-05 04:39:04 | INFO | train_inner | epoch 010:    861 / 4751 loss=4.716, nll_loss=3.129, ppl=8.75, wps=88772.1, ups=3.05, wpb=29061.6, bsz=954.4, num_updates=43600, lr=0.000151446, gnorm=0.407, loss_scale=4, train_wall=33, gb_free=6.4, wall=14509
2021-04-05 04:39:37 | INFO | train_inner | epoch 010:    961 / 4751 loss=4.726, nll_loss=3.141, ppl=8.82, wps=87948.2, ups=3.03, wpb=29002.1, bsz=974.6, num_updates=43700, lr=0.000151272, gnorm=0.413, loss_scale=4, train_wall=33, gb_free=6.2, wall=14542
2021-04-05 04:40:10 | INFO | train_inner | epoch 010:   1061 / 4751 loss=4.747, nll_loss=3.165, ppl=8.97, wps=87986.3, ups=3.05, wpb=28851.6, bsz=919.8, num_updates=43800, lr=0.000151099, gnorm=0.413, loss_scale=4, train_wall=33, gb_free=6.5, wall=14575
2021-04-05 04:40:43 | INFO | train_inner | epoch 010:   1161 / 4751 loss=4.742, nll_loss=3.159, ppl=8.93, wps=88651.9, ups=3.06, wpb=28944.6, bsz=948.8, num_updates=43900, lr=0.000150927, gnorm=0.408, loss_scale=4, train_wall=33, gb_free=6.1, wall=14608
2021-04-05 04:41:16 | INFO | train_inner | epoch 010:   1261 / 4751 loss=4.762, nll_loss=3.181, ppl=9.07, wps=89115.9, ups=3.04, wpb=29346, bsz=937.4, num_updates=44000, lr=0.000150756, gnorm=0.413, loss_scale=4, train_wall=33, gb_free=6.2, wall=14641
2021-04-05 04:41:49 | INFO | train_inner | epoch 010:   1361 / 4751 loss=4.772, nll_loss=3.193, ppl=9.14, wps=87081.4, ups=3.03, wpb=28695.9, bsz=929.8, num_updates=44100, lr=0.000150585, gnorm=0.425, loss_scale=4, train_wall=33, gb_free=6.1, wall=14673
2021-04-05 04:42:21 | INFO | train_inner | epoch 010:   1461 / 4751 loss=4.757, nll_loss=3.176, ppl=9.04, wps=88512, ups=3.05, wpb=29034.2, bsz=987.3, num_updates=44200, lr=0.000150414, gnorm=0.405, loss_scale=4, train_wall=33, gb_free=6, wall=14706
2021-04-05 04:42:55 | INFO | train_inner | epoch 010:   1561 / 4751 loss=4.743, nll_loss=3.16, ppl=8.94, wps=86949.1, ups=3.01, wpb=28882.9, bsz=959, num_updates=44300, lr=0.000150244, gnorm=0.407, loss_scale=4, train_wall=33, gb_free=6, wall=14740
2021-04-05 04:43:28 | INFO | train_inner | epoch 010:   1661 / 4751 loss=4.725, nll_loss=3.139, ppl=8.81, wps=88064.5, ups=3.03, wpb=29094.4, bsz=970.3, num_updates=44400, lr=0.000150075, gnorm=0.404, loss_scale=4, train_wall=33, gb_free=6.3, wall=14773
2021-04-05 04:44:01 | INFO | train_inner | epoch 010:   1761 / 4751 loss=4.753, nll_loss=3.171, ppl=9.01, wps=89561.7, ups=3.05, wpb=29407.9, bsz=944, num_updates=44500, lr=0.000149906, gnorm=0.411, loss_scale=4, train_wall=33, gb_free=6.2, wall=14805
2021-04-05 04:44:33 | INFO | train_inner | epoch 010:   1861 / 4751 loss=4.767, nll_loss=3.187, ppl=9.11, wps=88421.9, ups=3.05, wpb=29017.3, bsz=920.5, num_updates=44600, lr=0.000149738, gnorm=0.409, loss_scale=4, train_wall=33, gb_free=6.1, wall=14838
2021-04-05 04:45:06 | INFO | train_inner | epoch 010:   1961 / 4751 loss=4.745, nll_loss=3.162, ppl=8.95, wps=88488.6, ups=3.05, wpb=29021.3, bsz=941, num_updates=44700, lr=0.000149571, gnorm=0.408, loss_scale=8, train_wall=33, gb_free=6.7, wall=14871
2021-04-05 04:45:39 | INFO | train_inner | epoch 010:   2061 / 4751 loss=4.801, nll_loss=3.226, ppl=9.35, wps=88617.5, ups=3.06, wpb=29000.1, bsz=958.6, num_updates=44800, lr=0.000149404, gnorm=0.412, loss_scale=8, train_wall=33, gb_free=6.4, wall=14904
2021-04-05 04:46:12 | INFO | train_inner | epoch 010:   2161 / 4751 loss=4.732, nll_loss=3.148, ppl=8.86, wps=87614.2, ups=3.03, wpb=28940.3, bsz=951.1, num_updates=44900, lr=0.000149237, gnorm=0.416, loss_scale=8, train_wall=33, gb_free=6.1, wall=14937
2021-04-05 04:46:45 | INFO | train_inner | epoch 010:   2261 / 4751 loss=4.782, nll_loss=3.205, ppl=9.22, wps=87701, ups=3.03, wpb=28947.2, bsz=978.8, num_updates=45000, lr=0.000149071, gnorm=0.414, loss_scale=8, train_wall=33, gb_free=6.2, wall=14970
2021-04-05 04:47:18 | INFO | train_inner | epoch 010:   2361 / 4751 loss=4.78, nll_loss=3.202, ppl=9.2, wps=88108.4, ups=3.02, wpb=29167.5, bsz=937.7, num_updates=45100, lr=0.000148906, gnorm=0.408, loss_scale=8, train_wall=33, gb_free=6.6, wall=15003
2021-04-05 04:47:51 | INFO | train_inner | epoch 010:   2461 / 4751 loss=4.75, nll_loss=3.168, ppl=8.99, wps=87343.2, ups=3.04, wpb=28755.2, bsz=945.7, num_updates=45200, lr=0.000148741, gnorm=0.412, loss_scale=8, train_wall=33, gb_free=6.2, wall=15036
2021-04-05 04:47:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2021-04-05 04:48:24 | INFO | train_inner | epoch 010:   2562 / 4751 loss=4.78, nll_loss=3.203, ppl=9.21, wps=86109.5, ups=3, wpb=28687.2, bsz=927.2, num_updates=45300, lr=0.000148577, gnorm=0.421, loss_scale=4, train_wall=33, gb_free=6.4, wall=15069
2021-04-05 04:48:57 | INFO | train_inner | epoch 010:   2662 / 4751 loss=4.791, nll_loss=3.215, ppl=9.28, wps=87469.2, ups=3.05, wpb=28696.5, bsz=937.8, num_updates=45400, lr=0.000148413, gnorm=0.422, loss_scale=4, train_wall=33, gb_free=6, wall=15102
2021-04-05 04:49:30 | INFO | train_inner | epoch 010:   2762 / 4751 loss=4.722, nll_loss=3.137, ppl=8.8, wps=87862, ups=3.03, wpb=29001.9, bsz=988.9, num_updates=45500, lr=0.00014825, gnorm=0.438, loss_scale=4, train_wall=33, gb_free=6.2, wall=15135
2021-04-05 04:50:03 | INFO | train_inner | epoch 010:   2862 / 4751 loss=4.786, nll_loss=3.209, ppl=9.25, wps=87287.2, ups=3.02, wpb=28910.8, bsz=920, num_updates=45600, lr=0.000148087, gnorm=0.422, loss_scale=4, train_wall=33, gb_free=6.5, wall=15168
2021-04-05 04:50:36 | INFO | train_inner | epoch 010:   2962 / 4751 loss=4.799, nll_loss=3.224, ppl=9.34, wps=87549.5, ups=3.05, wpb=28742.2, bsz=925.3, num_updates=45700, lr=0.000147925, gnorm=0.418, loss_scale=4, train_wall=33, gb_free=6.4, wall=15201
2021-04-05 04:51:09 | INFO | train_inner | epoch 010:   3062 / 4751 loss=4.768, nll_loss=3.188, ppl=9.12, wps=89064.7, ups=3.04, wpb=29258.6, bsz=953.4, num_updates=45800, lr=0.000147764, gnorm=0.408, loss_scale=4, train_wall=33, gb_free=6.1, wall=15234
2021-04-05 04:51:42 | INFO | train_inner | epoch 010:   3162 / 4751 loss=4.713, nll_loss=3.127, ppl=8.73, wps=88336.5, ups=3.04, wpb=29066.8, bsz=959.6, num_updates=45900, lr=0.000147602, gnorm=0.408, loss_scale=4, train_wall=33, gb_free=6.3, wall=15267
2021-04-05 04:52:15 | INFO | train_inner | epoch 010:   3262 / 4751 loss=4.826, nll_loss=3.255, ppl=9.54, wps=88632.5, ups=3.04, wpb=29116, bsz=901.6, num_updates=46000, lr=0.000147442, gnorm=0.414, loss_scale=4, train_wall=33, gb_free=6.1, wall=15299
2021-04-05 04:52:48 | INFO | train_inner | epoch 010:   3362 / 4751 loss=4.714, nll_loss=3.128, ppl=8.74, wps=86521.6, ups=3.01, wpb=28753.3, bsz=942.3, num_updates=46100, lr=0.000147282, gnorm=0.41, loss_scale=4, train_wall=33, gb_free=5.9, wall=15333
2021-04-05 04:53:21 | INFO | train_inner | epoch 010:   3462 / 4751 loss=4.825, nll_loss=3.253, ppl=9.53, wps=88700.2, ups=3.05, wpb=29108.4, bsz=949.4, num_updates=46200, lr=0.000147122, gnorm=0.431, loss_scale=4, train_wall=33, gb_free=6.3, wall=15366
2021-04-05 04:53:53 | INFO | train_inner | epoch 010:   3562 / 4751 loss=4.731, nll_loss=3.147, ppl=8.86, wps=88280.3, ups=3.05, wpb=28942.6, bsz=962, num_updates=46300, lr=0.000146964, gnorm=0.415, loss_scale=4, train_wall=33, gb_free=6.2, wall=15398
2021-04-05 04:54:26 | INFO | train_inner | epoch 010:   3662 / 4751 loss=4.753, nll_loss=3.172, ppl=9.02, wps=87900.4, ups=3.05, wpb=28823.2, bsz=931.5, num_updates=46400, lr=0.000146805, gnorm=0.413, loss_scale=4, train_wall=33, gb_free=6, wall=15431
2021-04-05 04:54:59 | INFO | train_inner | epoch 010:   3762 / 4751 loss=4.763, nll_loss=3.183, ppl=9.08, wps=88375.4, ups=3.04, wpb=29084.9, bsz=929.3, num_updates=46500, lr=0.000146647, gnorm=0.414, loss_scale=4, train_wall=33, gb_free=6.4, wall=15464
2021-04-05 04:55:32 | INFO | train_inner | epoch 010:   3862 / 4751 loss=4.758, nll_loss=3.177, ppl=9.05, wps=87196.3, ups=3.03, wpb=28753.8, bsz=935.4, num_updates=46600, lr=0.00014649, gnorm=0.412, loss_scale=4, train_wall=33, gb_free=6.3, wall=15497
2021-04-05 04:56:05 | INFO | train_inner | epoch 010:   3962 / 4751 loss=4.756, nll_loss=3.176, ppl=9.04, wps=88098.5, ups=3.03, wpb=29046, bsz=968, num_updates=46700, lr=0.000146333, gnorm=0.422, loss_scale=4, train_wall=33, gb_free=7, wall=15530
2021-04-05 04:56:38 | INFO | train_inner | epoch 010:   4062 / 4751 loss=4.771, nll_loss=3.193, ppl=9.15, wps=88962.8, ups=3.05, wpb=29211.4, bsz=987, num_updates=46800, lr=0.000146176, gnorm=0.408, loss_scale=4, train_wall=33, gb_free=6.3, wall=15563
2021-04-05 04:57:11 | INFO | train_inner | epoch 010:   4162 / 4751 loss=4.791, nll_loss=3.216, ppl=9.29, wps=88629.2, ups=3.06, wpb=28990.8, bsz=937.7, num_updates=46900, lr=0.00014602, gnorm=0.41, loss_scale=4, train_wall=33, gb_free=6.1, wall=15596
2021-04-05 04:57:44 | INFO | train_inner | epoch 010:   4262 / 4751 loss=4.732, nll_loss=3.148, ppl=8.86, wps=87757.3, ups=3.04, wpb=28878.2, bsz=923.3, num_updates=47000, lr=0.000145865, gnorm=0.412, loss_scale=4, train_wall=33, gb_free=6.4, wall=15628
2021-04-05 04:58:17 | INFO | train_inner | epoch 010:   4362 / 4751 loss=4.765, nll_loss=3.186, ppl=9.1, wps=88196.4, ups=3.03, wpb=29062.6, bsz=957.8, num_updates=47100, lr=0.00014571, gnorm=0.423, loss_scale=4, train_wall=33, gb_free=6.2, wall=15661
2021-04-05 04:58:50 | INFO | train_inner | epoch 010:   4462 / 4751 loss=4.774, nll_loss=3.196, ppl=9.16, wps=88260.5, ups=3.03, wpb=29088.8, bsz=942, num_updates=47200, lr=0.000145556, gnorm=0.412, loss_scale=4, train_wall=33, gb_free=6.4, wall=15694
2021-04-05 04:59:22 | INFO | train_inner | epoch 010:   4562 / 4751 loss=4.785, nll_loss=3.208, ppl=9.24, wps=87688.8, ups=3.04, wpb=28837.9, bsz=930.8, num_updates=47300, lr=0.000145402, gnorm=0.426, loss_scale=8, train_wall=33, gb_free=6.4, wall=15727
2021-04-05 04:59:55 | INFO | train_inner | epoch 010:   4662 / 4751 loss=4.775, nll_loss=3.197, ppl=9.17, wps=88971.8, ups=3.04, wpb=29303.5, bsz=959.6, num_updates=47400, lr=0.000145248, gnorm=0.411, loss_scale=8, train_wall=33, gb_free=6, wall=15760
2021-04-05 05:00:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-05 05:00:26 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 4.357 | nll_loss 2.592 | ppl 6.03 | wps 183178 | wpb 10489.1 | bsz 375 | num_updates 47489 | best_loss 4.357
2021-04-05 05:00:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 47489 updates
2021-04-05 05:00:26 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 05:00:32 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 05:00:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt (epoch 10 @ 47489 updates, score 4.357) (writing took 13.361128438264132 seconds)
2021-04-05 05:00:39 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2021-04-05 05:00:39 | INFO | train | epoch 010 | loss 4.764 | nll_loss 3.184 | ppl 9.09 | wps 87100.8 | ups 3.01 | wpb 28968.5 | bsz 947.3 | num_updates 47489 | lr 0.000145112 | gnorm 0.414 | loss_scale 8 | train_wall 1557 | gb_free 6.5 | wall 15804
2021-04-05 05:00:39 | INFO | fairseq.trainer | begin training epoch 11
2021-04-05 05:00:39 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-05 05:00:44 | INFO | train_inner | epoch 011:     11 / 4751 loss=4.816, nll_loss=3.244, ppl=9.47, wps=59414.3, ups=2.06, wpb=28842.2, bsz=954.2, num_updates=47500, lr=0.000145095, gnorm=0.418, loss_scale=8, train_wall=32, gb_free=6, wall=15809
2021-04-05 05:01:17 | INFO | train_inner | epoch 011:    111 / 4751 loss=4.753, nll_loss=3.171, ppl=9.01, wps=88231.7, ups=3.06, wpb=28840.4, bsz=953.4, num_updates=47600, lr=0.000144943, gnorm=0.418, loss_scale=8, train_wall=33, gb_free=6.2, wall=15841
2021-04-05 05:01:49 | INFO | train_inner | epoch 011:    211 / 4751 loss=4.731, nll_loss=3.146, ppl=8.85, wps=89092.6, ups=3.05, wpb=29208.7, bsz=946.6, num_updates=47700, lr=0.000144791, gnorm=0.405, loss_scale=8, train_wall=33, gb_free=6.3, wall=15874
2021-04-05 05:02:22 | INFO | train_inner | epoch 011:    311 / 4751 loss=4.813, nll_loss=3.24, ppl=9.45, wps=88068.8, ups=3.06, wpb=28745.4, bsz=946, num_updates=47800, lr=0.000144639, gnorm=0.416, loss_scale=8, train_wall=33, gb_free=6.1, wall=15907
2021-04-05 05:02:55 | INFO | train_inner | epoch 011:    411 / 4751 loss=4.722, nll_loss=3.136, ppl=8.79, wps=88266.4, ups=3.06, wpb=28887.3, bsz=910.9, num_updates=47900, lr=0.000144488, gnorm=0.407, loss_scale=8, train_wall=33, gb_free=6.2, wall=15940
2021-04-05 05:03:28 | INFO | train_inner | epoch 011:    511 / 4751 loss=4.773, nll_loss=3.194, ppl=9.15, wps=88878.4, ups=3.05, wpb=29185.5, bsz=950.7, num_updates=48000, lr=0.000144338, gnorm=0.412, loss_scale=8, train_wall=33, gb_free=6.2, wall=15972
2021-04-05 05:04:00 | INFO | train_inner | epoch 011:    611 / 4751 loss=4.727, nll_loss=3.142, ppl=8.82, wps=89200.3, ups=3.05, wpb=29212.9, bsz=949, num_updates=48100, lr=0.000144187, gnorm=0.409, loss_scale=8, train_wall=33, gb_free=6.3, wall=16005
2021-04-05 05:04:33 | INFO | train_inner | epoch 011:    711 / 4751 loss=4.716, nll_loss=3.129, ppl=8.75, wps=87847.9, ups=3.02, wpb=29090.5, bsz=945.8, num_updates=48200, lr=0.000144038, gnorm=0.417, loss_scale=8, train_wall=33, gb_free=6.1, wall=16038
2021-04-05 05:05:06 | INFO | train_inner | epoch 011:    811 / 4751 loss=4.818, nll_loss=3.245, ppl=9.48, wps=86313.1, ups=3.02, wpb=28543.2, bsz=940.9, num_updates=48300, lr=0.000143889, gnorm=0.426, loss_scale=8, train_wall=33, gb_free=6.5, wall=16071
2021-04-05 05:05:40 | INFO | train_inner | epoch 011:    911 / 4751 loss=4.733, nll_loss=3.149, ppl=8.87, wps=88456.6, ups=3.02, wpb=29329, bsz=943.7, num_updates=48400, lr=0.00014374, gnorm=0.405, loss_scale=8, train_wall=33, gb_free=6.1, wall=16104
2021-04-05 05:06:13 | INFO | train_inner | epoch 011:   1011 / 4751 loss=4.714, nll_loss=3.128, ppl=8.74, wps=88200.9, ups=3.04, wpb=29048.6, bsz=935.9, num_updates=48500, lr=0.000143592, gnorm=0.414, loss_scale=8, train_wall=33, gb_free=6.2, wall=16137
2021-04-05 05:06:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2021-04-05 05:06:46 | INFO | train_inner | epoch 011:   1112 / 4751 loss=4.771, nll_loss=3.192, ppl=9.14, wps=86790.3, ups=3, wpb=28895.2, bsz=894.1, num_updates=48600, lr=0.000143444, gnorm=0.411, loss_scale=4, train_wall=33, gb_free=6.2, wall=16171
2021-04-05 05:07:19 | INFO | train_inner | epoch 011:   1212 / 4751 loss=4.698, nll_loss=3.109, ppl=8.63, wps=88394.9, ups=3.04, wpb=29071, bsz=985.8, num_updates=48700, lr=0.000143296, gnorm=0.423, loss_scale=4, train_wall=33, gb_free=6, wall=16204
2021-04-05 05:07:52 | INFO | train_inner | epoch 011:   1312 / 4751 loss=4.767, nll_loss=3.188, ppl=9.12, wps=87757.7, ups=3.04, wpb=28866.7, bsz=968, num_updates=48800, lr=0.00014315, gnorm=0.417, loss_scale=4, train_wall=33, gb_free=6.2, wall=16236
2021-04-05 05:08:25 | INFO | train_inner | epoch 011:   1412 / 4751 loss=4.718, nll_loss=3.133, ppl=8.77, wps=88025, ups=3.03, wpb=29098.6, bsz=980.6, num_updates=48900, lr=0.000143003, gnorm=0.408, loss_scale=4, train_wall=33, gb_free=6.2, wall=16270
2021-04-05 05:08:57 | INFO | train_inner | epoch 011:   1512 / 4751 loss=4.749, nll_loss=3.167, ppl=8.98, wps=88219, ups=3.05, wpb=28910.1, bsz=964.7, num_updates=49000, lr=0.000142857, gnorm=0.421, loss_scale=4, train_wall=33, gb_free=6.1, wall=16302
2021-04-05 05:09:30 | INFO | train_inner | epoch 011:   1612 / 4751 loss=4.777, nll_loss=3.199, ppl=9.18, wps=87546.7, ups=3.05, wpb=28705.9, bsz=914.9, num_updates=49100, lr=0.000142712, gnorm=0.42, loss_scale=4, train_wall=33, gb_free=6.4, wall=16335
2021-04-05 05:10:03 | INFO | train_inner | epoch 011:   1712 / 4751 loss=4.696, nll_loss=3.107, ppl=8.62, wps=89293.8, ups=3.05, wpb=29309.5, bsz=935.2, num_updates=49200, lr=0.000142566, gnorm=0.408, loss_scale=4, train_wall=33, gb_free=6.2, wall=16368
2021-04-05 05:10:36 | INFO | train_inner | epoch 011:   1812 / 4751 loss=4.759, nll_loss=3.179, ppl=9.06, wps=88638.9, ups=3.05, wpb=29105.9, bsz=927.4, num_updates=49300, lr=0.000142422, gnorm=0.414, loss_scale=4, train_wall=33, gb_free=6.6, wall=16401
2021-04-05 05:11:09 | INFO | train_inner | epoch 011:   1912 / 4751 loss=4.73, nll_loss=3.146, ppl=8.85, wps=88729.7, ups=3.04, wpb=29147.8, bsz=963.6, num_updates=49400, lr=0.000142278, gnorm=0.414, loss_scale=4, train_wall=33, gb_free=6.1, wall=16434
2021-04-05 05:11:42 | INFO | train_inner | epoch 011:   2012 / 4751 loss=4.695, nll_loss=3.107, ppl=8.61, wps=85330.6, ups=2.97, wpb=28687.1, bsz=925.7, num_updates=49500, lr=0.000142134, gnorm=0.411, loss_scale=4, train_wall=33, gb_free=6.2, wall=16467
2021-04-05 05:12:15 | INFO | train_inner | epoch 011:   2112 / 4751 loss=4.75, nll_loss=3.169, ppl=8.99, wps=87866.8, ups=3.03, wpb=29021.8, bsz=956.5, num_updates=49600, lr=0.00014199, gnorm=0.409, loss_scale=4, train_wall=33, gb_free=6.3, wall=16500
2021-04-05 05:12:49 | INFO | train_inner | epoch 011:   2212 / 4751 loss=4.775, nll_loss=3.197, ppl=9.17, wps=87733.4, ups=3.02, wpb=29070.1, bsz=926.8, num_updates=49700, lr=0.000141848, gnorm=0.425, loss_scale=4, train_wall=33, gb_free=6.9, wall=16533
2021-04-05 05:13:22 | INFO | train_inner | epoch 011:   2312 / 4751 loss=4.75, nll_loss=3.168, ppl=8.99, wps=86748, ups=3.04, wpb=28578.7, bsz=921.3, num_updates=49800, lr=0.000141705, gnorm=0.422, loss_scale=4, train_wall=33, gb_free=6.4, wall=16566
2021-04-05 05:13:54 | INFO | train_inner | epoch 011:   2412 / 4751 loss=4.778, nll_loss=3.201, ppl=9.2, wps=87684.5, ups=3.04, wpb=28856.7, bsz=928.2, num_updates=49900, lr=0.000141563, gnorm=0.42, loss_scale=4, train_wall=33, gb_free=6.2, wall=16599
2021-04-05 05:14:27 | INFO | train_inner | epoch 011:   2512 / 4751 loss=4.736, nll_loss=3.153, ppl=8.89, wps=88968, ups=3.05, wpb=29200.1, bsz=935.4, num_updates=50000, lr=0.000141421, gnorm=0.413, loss_scale=4, train_wall=33, gb_free=6.4, wall=16632
2021-04-05 05:14:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-05 05:15:00 | INFO | train_inner | epoch 011:   2613 / 4751 loss=4.716, nll_loss=3.13, ppl=8.76, wps=86573.7, ups=3.01, wpb=28747.6, bsz=915.3, num_updates=50100, lr=0.00014128, gnorm=0.414, loss_scale=2, train_wall=33, gb_free=6.2, wall=16665
2021-04-05 05:15:33 | INFO | train_inner | epoch 011:   2713 / 4751 loss=4.81, nll_loss=3.237, ppl=9.43, wps=87564, ups=3.04, wpb=28781.3, bsz=908.4, num_updates=50200, lr=0.000141139, gnorm=0.43, loss_scale=2, train_wall=33, gb_free=6.3, wall=16698
2021-04-05 05:16:06 | INFO | train_inner | epoch 011:   2813 / 4751 loss=4.787, nll_loss=3.211, ppl=9.26, wps=87492, ups=3.04, wpb=28805.2, bsz=955.8, num_updates=50300, lr=0.000140999, gnorm=0.42, loss_scale=2, train_wall=33, gb_free=6.1, wall=16731
2021-04-05 05:16:40 | INFO | train_inner | epoch 011:   2913 / 4751 loss=4.703, nll_loss=3.116, ppl=8.67, wps=87511.5, ups=3.01, wpb=29113.1, bsz=963.6, num_updates=50400, lr=0.000140859, gnorm=0.408, loss_scale=2, train_wall=33, gb_free=6.2, wall=16764
2021-04-05 05:17:12 | INFO | train_inner | epoch 011:   3013 / 4751 loss=4.773, nll_loss=3.196, ppl=9.16, wps=87596.8, ups=3.04, wpb=28776.7, bsz=968.2, num_updates=50500, lr=0.00014072, gnorm=0.42, loss_scale=2, train_wall=33, gb_free=6.4, wall=16797
2021-04-05 05:17:45 | INFO | train_inner | epoch 011:   3113 / 4751 loss=4.699, nll_loss=3.111, ppl=8.64, wps=88773.5, ups=3.03, wpb=29271.8, bsz=958.3, num_updates=50600, lr=0.00014058, gnorm=0.41, loss_scale=2, train_wall=33, gb_free=6.3, wall=16830
2021-04-05 05:18:18 | INFO | train_inner | epoch 011:   3213 / 4751 loss=4.69, nll_loss=3.102, ppl=8.58, wps=87835.1, ups=3.03, wpb=28978.8, bsz=980.8, num_updates=50700, lr=0.000140442, gnorm=0.41, loss_scale=2, train_wall=33, gb_free=6.3, wall=16863
2021-04-05 05:18:51 | INFO | train_inner | epoch 011:   3313 / 4751 loss=4.768, nll_loss=3.19, ppl=9.13, wps=88125.7, ups=3.04, wpb=28944.3, bsz=959.7, num_updates=50800, lr=0.000140303, gnorm=0.412, loss_scale=2, train_wall=33, gb_free=6.1, wall=16896
2021-04-05 05:19:24 | INFO | train_inner | epoch 011:   3413 / 4751 loss=4.772, nll_loss=3.194, ppl=9.15, wps=87435.3, ups=3.02, wpb=28924.6, bsz=955.4, num_updates=50900, lr=0.000140165, gnorm=0.414, loss_scale=2, train_wall=33, gb_free=6.3, wall=16929
2021-04-05 05:19:57 | INFO | train_inner | epoch 011:   3513 / 4751 loss=4.745, nll_loss=3.164, ppl=8.96, wps=88392.5, ups=3.02, wpb=29262.1, bsz=962.2, num_updates=51000, lr=0.000140028, gnorm=0.411, loss_scale=2, train_wall=33, gb_free=6, wall=16962
2021-04-05 05:20:30 | INFO | train_inner | epoch 011:   3613 / 4751 loss=4.699, nll_loss=3.112, ppl=8.64, wps=89337, ups=3.04, wpb=29379.5, bsz=957.8, num_updates=51100, lr=0.000139891, gnorm=0.408, loss_scale=2, train_wall=33, gb_free=6.1, wall=16995
2021-04-05 05:21:03 | INFO | train_inner | epoch 011:   3713 / 4751 loss=4.759, nll_loss=3.18, ppl=9.06, wps=88450.2, ups=3.05, wpb=28968, bsz=962.3, num_updates=51200, lr=0.000139754, gnorm=0.414, loss_scale=2, train_wall=33, gb_free=6.3, wall=17028
2021-04-05 05:21:36 | INFO | train_inner | epoch 011:   3813 / 4751 loss=4.77, nll_loss=3.192, ppl=9.14, wps=88986.9, ups=3.05, wpb=29146.4, bsz=968.3, num_updates=51300, lr=0.000139618, gnorm=0.416, loss_scale=2, train_wall=33, gb_free=6.2, wall=17061
2021-04-05 05:22:09 | INFO | train_inner | epoch 011:   3913 / 4751 loss=4.763, nll_loss=3.184, ppl=9.09, wps=86870.2, ups=3.04, wpb=28575.3, bsz=918, num_updates=51400, lr=0.000139482, gnorm=0.412, loss_scale=2, train_wall=33, gb_free=6.2, wall=17093
2021-04-05 05:22:41 | INFO | train_inner | epoch 011:   4013 / 4751 loss=4.735, nll_loss=3.153, ppl=8.89, wps=88280.4, ups=3.05, wpb=28926.6, bsz=918.4, num_updates=51500, lr=0.000139347, gnorm=0.413, loss_scale=2, train_wall=33, gb_free=6.3, wall=17126
2021-04-05 05:23:14 | INFO | train_inner | epoch 011:   4113 / 4751 loss=4.719, nll_loss=3.134, ppl=8.78, wps=88401.3, ups=3.05, wpb=28994.8, bsz=938.2, num_updates=51600, lr=0.000139212, gnorm=0.408, loss_scale=2, train_wall=33, gb_free=6.4, wall=17159
2021-04-05 05:23:47 | INFO | train_inner | epoch 011:   4213 / 4751 loss=4.721, nll_loss=3.137, ppl=8.8, wps=88129.1, ups=3.04, wpb=28965.9, bsz=965, num_updates=51700, lr=0.000139077, gnorm=0.415, loss_scale=2, train_wall=33, gb_free=6.3, wall=17192
2021-04-05 05:24:20 | INFO | train_inner | epoch 011:   4313 / 4751 loss=4.751, nll_loss=3.17, ppl=9, wps=87256.2, ups=3.04, wpb=28732.6, bsz=923.7, num_updates=51800, lr=0.000138943, gnorm=0.42, loss_scale=2, train_wall=33, gb_free=6.2, wall=17225
2021-04-05 05:24:53 | INFO | train_inner | epoch 011:   4413 / 4751 loss=4.704, nll_loss=3.118, ppl=8.68, wps=88155.8, ups=3.04, wpb=28989.1, bsz=982.4, num_updates=51900, lr=0.000138809, gnorm=0.411, loss_scale=2, train_wall=33, gb_free=6.1, wall=17258
2021-04-05 05:25:26 | INFO | train_inner | epoch 011:   4513 / 4751 loss=4.722, nll_loss=3.138, ppl=8.8, wps=88202, ups=3.05, wpb=28945.9, bsz=953.7, num_updates=52000, lr=0.000138675, gnorm=0.415, loss_scale=2, train_wall=33, gb_free=6.6, wall=17291
2021-04-05 05:25:59 | INFO | train_inner | epoch 011:   4613 / 4751 loss=4.71, nll_loss=3.124, ppl=8.72, wps=87812.5, ups=3.04, wpb=28904.8, bsz=984.6, num_updates=52100, lr=0.000138542, gnorm=0.429, loss_scale=4, train_wall=33, gb_free=6.2, wall=17323
2021-04-05 05:26:32 | INFO | train_inner | epoch 011:   4713 / 4751 loss=4.75, nll_loss=3.169, ppl=9, wps=86773.8, ups=3.01, wpb=28822.4, bsz=939.9, num_updates=52200, lr=0.000138409, gnorm=0.418, loss_scale=4, train_wall=33, gb_free=6.1, wall=17357
2021-04-05 05:26:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-05 05:26:45 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 4.336 | nll_loss 2.562 | ppl 5.9 | wps 202326 | wpb 10489.1 | bsz 375 | num_updates 52238 | best_loss 4.336
2021-04-05 05:26:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 52238 updates
2021-04-05 05:26:45 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 05:26:52 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 05:26:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt (epoch 11 @ 52238 updates, score 4.336) (writing took 12.766281727701426 seconds)
2021-04-05 05:26:58 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2021-04-05 05:26:58 | INFO | train | epoch 011 | loss 4.743 | nll_loss 3.161 | ppl 8.94 | wps 87112.6 | ups 3.01 | wpb 28969.5 | bsz 946.9 | num_updates 52238 | lr 0.000138359 | gnorm 0.415 | loss_scale 4 | train_wall 1557 | gb_free 6.4 | wall 17383
2021-04-05 05:26:58 | INFO | fairseq.trainer | begin training epoch 12
2021-04-05 05:26:58 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-05 05:27:20 | INFO | train_inner | epoch 012:     62 / 4751 loss=4.717, nll_loss=3.131, ppl=8.76, wps=59913.4, ups=2.08, wpb=28740.3, bsz=940, num_updates=52300, lr=0.000138277, gnorm=0.417, loss_scale=4, train_wall=33, gb_free=6, wall=17405
2021-04-05 05:27:53 | INFO | train_inner | epoch 012:    162 / 4751 loss=4.683, nll_loss=3.093, ppl=8.53, wps=88299.8, ups=3.05, wpb=28944.5, bsz=954.4, num_updates=52400, lr=0.000138145, gnorm=0.412, loss_scale=4, train_wall=33, gb_free=6.2, wall=17437
2021-04-05 05:28:25 | INFO | train_inner | epoch 012:    262 / 4751 loss=4.722, nll_loss=3.138, ppl=8.8, wps=87739.6, ups=3.05, wpb=28797.7, bsz=954.4, num_updates=52500, lr=0.000138013, gnorm=0.411, loss_scale=4, train_wall=33, gb_free=6.2, wall=17470
2021-04-05 05:28:58 | INFO | train_inner | epoch 012:    362 / 4751 loss=4.775, nll_loss=3.197, ppl=9.17, wps=87833.6, ups=3.06, wpb=28688.3, bsz=926.2, num_updates=52600, lr=0.000137882, gnorm=0.422, loss_scale=4, train_wall=33, gb_free=6.3, wall=17503
2021-04-05 05:29:31 | INFO | train_inner | epoch 012:    462 / 4751 loss=4.68, nll_loss=3.089, ppl=8.51, wps=88638.4, ups=3.04, wpb=29133, bsz=975.5, num_updates=52700, lr=0.000137751, gnorm=0.417, loss_scale=4, train_wall=33, gb_free=6.3, wall=17536
2021-04-05 05:30:04 | INFO | train_inner | epoch 012:    562 / 4751 loss=4.731, nll_loss=3.147, ppl=8.86, wps=87877.1, ups=3.05, wpb=28821.4, bsz=919, num_updates=52800, lr=0.00013762, gnorm=0.416, loss_scale=4, train_wall=33, gb_free=6.2, wall=17569
2021-04-05 05:30:36 | INFO | train_inner | epoch 012:    662 / 4751 loss=4.689, nll_loss=3.1, ppl=8.57, wps=88834.9, ups=3.05, wpb=29097.6, bsz=945, num_updates=52900, lr=0.00013749, gnorm=0.413, loss_scale=4, train_wall=33, gb_free=6.3, wall=17601
2021-04-05 05:31:09 | INFO | train_inner | epoch 012:    762 / 4751 loss=4.712, nll_loss=3.126, ppl=8.73, wps=87595, ups=3.04, wpb=28779, bsz=947.9, num_updates=53000, lr=0.000137361, gnorm=0.421, loss_scale=4, train_wall=33, gb_free=6.1, wall=17634
2021-04-05 05:31:42 | INFO | train_inner | epoch 012:    862 / 4751 loss=4.731, nll_loss=3.147, ppl=8.86, wps=87430.2, ups=3.02, wpb=28963.7, bsz=954.6, num_updates=53100, lr=0.000137231, gnorm=0.414, loss_scale=4, train_wall=33, gb_free=6.4, wall=17667
2021-04-05 05:32:15 | INFO | train_inner | epoch 012:    962 / 4751 loss=4.735, nll_loss=3.152, ppl=8.89, wps=87869.8, ups=3.03, wpb=28963.1, bsz=941.6, num_updates=53200, lr=0.000137102, gnorm=0.413, loss_scale=4, train_wall=33, gb_free=6.1, wall=17700
2021-04-05 05:32:48 | INFO | train_inner | epoch 012:   1062 / 4751 loss=4.697, nll_loss=3.109, ppl=8.63, wps=88100.5, ups=3.04, wpb=29025.3, bsz=953.8, num_updates=53300, lr=0.000136973, gnorm=0.419, loss_scale=4, train_wall=33, gb_free=6.4, wall=17733
2021-04-05 05:33:21 | INFO | train_inner | epoch 012:   1162 / 4751 loss=4.704, nll_loss=3.117, ppl=8.68, wps=87330.9, ups=3.04, wpb=28721.4, bsz=955.7, num_updates=53400, lr=0.000136845, gnorm=0.409, loss_scale=4, train_wall=33, gb_free=6.3, wall=17766
2021-04-05 05:33:54 | INFO | train_inner | epoch 012:   1262 / 4751 loss=4.644, nll_loss=3.049, ppl=8.28, wps=89443.6, ups=3.06, wpb=29258, bsz=984.4, num_updates=53500, lr=0.000136717, gnorm=0.411, loss_scale=4, train_wall=33, gb_free=6, wall=17799
2021-04-05 05:34:27 | INFO | train_inner | epoch 012:   1362 / 4751 loss=4.702, nll_loss=3.115, ppl=8.67, wps=87446.8, ups=3.01, wpb=29030.3, bsz=947.9, num_updates=53600, lr=0.00013659, gnorm=0.409, loss_scale=4, train_wall=33, gb_free=6.3, wall=17832
2021-04-05 05:35:00 | INFO | train_inner | epoch 012:   1462 / 4751 loss=4.719, nll_loss=3.133, ppl=8.77, wps=88168.4, ups=3.05, wpb=28931.9, bsz=904, num_updates=53700, lr=0.000136462, gnorm=0.418, loss_scale=4, train_wall=33, gb_free=6.5, wall=17865
2021-04-05 05:35:33 | INFO | train_inner | epoch 012:   1562 / 4751 loss=4.765, nll_loss=3.186, ppl=9.1, wps=88610.8, ups=3.05, wpb=29039.3, bsz=940.1, num_updates=53800, lr=0.000136335, gnorm=0.414, loss_scale=4, train_wall=33, gb_free=6.4, wall=17898
2021-04-05 05:36:05 | INFO | train_inner | epoch 012:   1662 / 4751 loss=4.761, nll_loss=3.182, ppl=9.07, wps=87915.3, ups=3.06, wpb=28776.2, bsz=953.5, num_updates=53900, lr=0.000136209, gnorm=0.424, loss_scale=4, train_wall=33, gb_free=6.2, wall=17930
2021-04-05 05:36:38 | INFO | train_inner | epoch 012:   1762 / 4751 loss=4.756, nll_loss=3.176, ppl=9.04, wps=88168.6, ups=3.04, wpb=28966.2, bsz=935.2, num_updates=54000, lr=0.000136083, gnorm=0.414, loss_scale=4, train_wall=33, gb_free=6.3, wall=17963
2021-04-05 05:37:11 | INFO | train_inner | epoch 012:   1862 / 4751 loss=4.76, nll_loss=3.18, ppl=9.06, wps=87763.3, ups=3.03, wpb=28953.5, bsz=934.8, num_updates=54100, lr=0.000135957, gnorm=0.416, loss_scale=4, train_wall=33, gb_free=6.3, wall=17996
2021-04-05 05:37:44 | INFO | train_inner | epoch 012:   1962 / 4751 loss=4.709, nll_loss=3.123, ppl=8.71, wps=88160.1, ups=3.05, wpb=28939.1, bsz=962.2, num_updates=54200, lr=0.000135831, gnorm=0.414, loss_scale=8, train_wall=33, gb_free=6.3, wall=18029
2021-04-05 05:38:17 | INFO | train_inner | epoch 012:   2062 / 4751 loss=4.74, nll_loss=3.159, ppl=8.93, wps=88668.1, ups=3.05, wpb=29047.5, bsz=981, num_updates=54300, lr=0.000135706, gnorm=0.422, loss_scale=8, train_wall=33, gb_free=6.3, wall=18062
2021-04-05 05:38:50 | INFO | train_inner | epoch 012:   2162 / 4751 loss=4.802, nll_loss=3.229, ppl=9.38, wps=87851.9, ups=3.05, wpb=28817.2, bsz=941.2, num_updates=54400, lr=0.000135582, gnorm=0.425, loss_scale=8, train_wall=33, gb_free=6.1, wall=18095
2021-04-05 05:39:23 | INFO | train_inner | epoch 012:   2262 / 4751 loss=4.764, nll_loss=3.186, ppl=9.1, wps=87629.3, ups=3.04, wpb=28847.3, bsz=942.1, num_updates=54500, lr=0.000135457, gnorm=0.422, loss_scale=8, train_wall=33, gb_free=6.2, wall=18127
2021-04-05 05:39:56 | INFO | train_inner | epoch 012:   2362 / 4751 loss=4.767, nll_loss=3.188, ppl=9.11, wps=86972.9, ups=3.03, wpb=28680.4, bsz=921.5, num_updates=54600, lr=0.000135333, gnorm=0.415, loss_scale=8, train_wall=33, gb_free=6.2, wall=18160
2021-04-05 05:40:29 | INFO | train_inner | epoch 012:   2462 / 4751 loss=4.72, nll_loss=3.135, ppl=8.79, wps=87236.7, ups=3.03, wpb=28818.5, bsz=907.5, num_updates=54700, lr=0.000135209, gnorm=0.418, loss_scale=8, train_wall=33, gb_free=6, wall=18193
2021-04-05 05:41:02 | INFO | train_inner | epoch 012:   2562 / 4751 loss=4.745, nll_loss=3.164, ppl=8.96, wps=87793.5, ups=3.04, wpb=28849.1, bsz=960.2, num_updates=54800, lr=0.000135086, gnorm=0.411, loss_scale=8, train_wall=33, gb_free=6.3, wall=18226
2021-04-05 05:41:34 | INFO | train_inner | epoch 012:   2662 / 4751 loss=4.726, nll_loss=3.143, ppl=8.83, wps=88360.8, ups=3.05, wpb=28991.8, bsz=968.3, num_updates=54900, lr=0.000134963, gnorm=0.421, loss_scale=8, train_wall=33, gb_free=6.3, wall=18259
2021-04-05 05:42:07 | INFO | train_inner | epoch 012:   2762 / 4751 loss=4.707, nll_loss=3.121, ppl=8.7, wps=87789.2, ups=3.03, wpb=28990.3, bsz=952.5, num_updates=55000, lr=0.00013484, gnorm=0.411, loss_scale=8, train_wall=33, gb_free=6.3, wall=18292
2021-04-05 05:42:40 | INFO | train_inner | epoch 012:   2862 / 4751 loss=4.766, nll_loss=3.188, ppl=9.12, wps=89117.8, ups=3.05, wpb=29265.4, bsz=960.7, num_updates=55100, lr=0.000134718, gnorm=0.421, loss_scale=8, train_wall=33, gb_free=6.4, wall=18325
2021-04-05 05:43:13 | INFO | train_inner | epoch 012:   2962 / 4751 loss=4.717, nll_loss=3.133, ppl=8.77, wps=88762.4, ups=3.04, wpb=29153.7, bsz=980.6, num_updates=55200, lr=0.000134595, gnorm=0.407, loss_scale=8, train_wall=33, gb_free=6.5, wall=18358
2021-04-05 05:43:46 | INFO | train_inner | epoch 012:   3062 / 4751 loss=4.707, nll_loss=3.121, ppl=8.7, wps=87880.8, ups=3.03, wpb=29009.4, bsz=927, num_updates=55300, lr=0.000134474, gnorm=0.411, loss_scale=8, train_wall=33, gb_free=6.3, wall=18391
2021-04-05 05:44:19 | INFO | train_inner | epoch 012:   3162 / 4751 loss=4.792, nll_loss=3.217, ppl=9.3, wps=87572.6, ups=3.05, wpb=28736.9, bsz=921.2, num_updates=55400, lr=0.000134352, gnorm=0.421, loss_scale=8, train_wall=33, gb_free=6.2, wall=18424
2021-04-05 05:44:52 | INFO | train_inner | epoch 012:   3262 / 4751 loss=4.735, nll_loss=3.153, ppl=8.89, wps=88404.8, ups=3.05, wpb=28966.8, bsz=943.2, num_updates=55500, lr=0.000134231, gnorm=0.414, loss_scale=8, train_wall=33, gb_free=6.4, wall=18456
2021-04-05 05:45:25 | INFO | train_inner | epoch 012:   3362 / 4751 loss=4.723, nll_loss=3.139, ppl=8.81, wps=87767.1, ups=3.04, wpb=28907.8, bsz=966.6, num_updates=55600, lr=0.00013411, gnorm=0.413, loss_scale=8, train_wall=33, gb_free=6.2, wall=18489
2021-04-05 05:45:57 | INFO | train_inner | epoch 012:   3462 / 4751 loss=4.661, nll_loss=3.069, ppl=8.39, wps=88314.5, ups=3.05, wpb=28979.8, bsz=947.4, num_updates=55700, lr=0.00013399, gnorm=0.414, loss_scale=8, train_wall=33, gb_free=6.2, wall=18522
2021-04-05 05:46:30 | INFO | train_inner | epoch 012:   3562 / 4751 loss=4.709, nll_loss=3.123, ppl=8.71, wps=89217.9, ups=3.05, wpb=29276.6, bsz=940.2, num_updates=55800, lr=0.00013387, gnorm=0.41, loss_scale=8, train_wall=33, gb_free=6.3, wall=18555
2021-04-05 05:47:04 | INFO | train_inner | epoch 012:   3662 / 4751 loss=4.736, nll_loss=3.154, ppl=8.9, wps=88120.9, ups=3, wpb=29347.3, bsz=939.6, num_updates=55900, lr=0.00013375, gnorm=0.412, loss_scale=8, train_wall=33, gb_free=6.7, wall=18588
2021-04-05 05:47:37 | INFO | train_inner | epoch 012:   3762 / 4751 loss=4.71, nll_loss=3.124, ppl=8.72, wps=87421, ups=3.02, wpb=28900.6, bsz=926.2, num_updates=56000, lr=0.000133631, gnorm=0.416, loss_scale=8, train_wall=33, gb_free=6.6, wall=18621
2021-04-05 05:48:09 | INFO | train_inner | epoch 012:   3862 / 4751 loss=4.711, nll_loss=3.125, ppl=8.72, wps=88079.6, ups=3.04, wpb=28947.4, bsz=928.5, num_updates=56100, lr=0.000133511, gnorm=0.417, loss_scale=8, train_wall=33, gb_free=6, wall=18654
2021-04-05 05:48:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2021-04-05 05:48:43 | INFO | train_inner | epoch 012:   3963 / 4751 loss=4.763, nll_loss=3.185, ppl=9.09, wps=88010, ups=3.02, wpb=29186.4, bsz=926.2, num_updates=56200, lr=0.000133393, gnorm=0.42, loss_scale=4, train_wall=33, gb_free=6.2, wall=18687
2021-04-05 05:49:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-05 05:49:16 | INFO | train_inner | epoch 012:   4064 / 4751 loss=4.762, nll_loss=3.184, ppl=9.09, wps=87775.1, ups=3.01, wpb=29177.8, bsz=989.3, num_updates=56300, lr=0.000133274, gnorm=0.417, loss_scale=2, train_wall=33, gb_free=6.3, wall=18721
2021-04-05 05:49:49 | INFO | train_inner | epoch 012:   4164 / 4751 loss=4.694, nll_loss=3.107, ppl=8.61, wps=88366, ups=3.05, wpb=28962.1, bsz=964.8, num_updates=56400, lr=0.000133156, gnorm=0.414, loss_scale=2, train_wall=33, gb_free=6.3, wall=18753
2021-04-05 05:50:22 | INFO | train_inner | epoch 012:   4264 / 4751 loss=4.718, nll_loss=3.133, ppl=8.78, wps=87592.3, ups=3.04, wpb=28845, bsz=945.7, num_updates=56500, lr=0.000133038, gnorm=0.416, loss_scale=2, train_wall=33, gb_free=6.2, wall=18786
2021-04-05 05:50:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-04-05 05:50:55 | INFO | train_inner | epoch 012:   4365 / 4751 loss=4.715, nll_loss=3.131, ppl=8.76, wps=87163.6, ups=3.01, wpb=28961, bsz=946.2, num_updates=56600, lr=0.00013292, gnorm=0.413, loss_scale=1, train_wall=33, gb_free=6.5, wall=18820
2021-04-05 05:51:28 | INFO | train_inner | epoch 012:   4465 / 4751 loss=4.703, nll_loss=3.117, ppl=8.67, wps=88800.8, ups=3.04, wpb=29231.9, bsz=965.7, num_updates=56700, lr=0.000132803, gnorm=0.409, loss_scale=1, train_wall=33, gb_free=6.3, wall=18853
2021-04-05 05:52:00 | INFO | train_inner | epoch 012:   4565 / 4751 loss=4.743, nll_loss=3.162, ppl=8.95, wps=88436.6, ups=3.05, wpb=28992.9, bsz=951.3, num_updates=56800, lr=0.000132686, gnorm=0.419, loss_scale=1, train_wall=33, gb_free=6.2, wall=18885
2021-04-05 05:52:34 | INFO | train_inner | epoch 012:   4665 / 4751 loss=4.693, nll_loss=3.106, ppl=8.61, wps=85982.7, ups=2.96, wpb=29059.3, bsz=919.8, num_updates=56900, lr=0.00013257, gnorm=0.41, loss_scale=1, train_wall=34, gb_free=6.2, wall=18919
2021-04-05 05:53:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-05 05:53:04 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 4.331 | nll_loss 2.562 | ppl 5.91 | wps 205454 | wpb 10489.1 | bsz 375 | num_updates 56986 | best_loss 4.331
2021-04-05 05:53:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 56986 updates
2021-04-05 05:53:04 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 05:53:12 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 05:53:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt (epoch 12 @ 56986 updates, score 4.331) (writing took 13.458238534629345 seconds)
2021-04-05 05:53:17 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2021-04-05 05:53:17 | INFO | train | epoch 012 | loss 4.725 | nll_loss 3.141 | ppl 8.82 | wps 87115.7 | ups 3.01 | wpb 28969.2 | bsz 946.6 | num_updates 56986 | lr 0.00013247 | gnorm 0.415 | loss_scale 1 | train_wall 1556 | gb_free 6.3 | wall 18962
2021-04-05 05:53:17 | INFO | fairseq.trainer | begin training epoch 13
2021-04-05 05:53:17 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-05 05:53:23 | INFO | train_inner | epoch 013:     14 / 4751 loss=4.705, nll_loss=3.119, ppl=8.69, wps=59205.7, ups=2.05, wpb=28862.8, bsz=939.1, num_updates=57000, lr=0.000132453, gnorm=0.419, loss_scale=1, train_wall=33, gb_free=6.3, wall=18968
2021-04-05 05:53:56 | INFO | train_inner | epoch 013:    114 / 4751 loss=4.769, nll_loss=3.191, ppl=9.13, wps=88241.3, ups=3.05, wpb=28941.8, bsz=936.5, num_updates=57100, lr=0.000132337, gnorm=0.419, loss_scale=1, train_wall=33, gb_free=6.5, wall=19001
2021-04-05 05:54:28 | INFO | train_inner | epoch 013:    214 / 4751 loss=4.749, nll_loss=3.168, ppl=8.99, wps=88564.3, ups=3.07, wpb=28855.1, bsz=955.4, num_updates=57200, lr=0.000132221, gnorm=0.42, loss_scale=1, train_wall=32, gb_free=6.1, wall=19033
2021-04-05 05:55:01 | INFO | train_inner | epoch 013:    314 / 4751 loss=4.725, nll_loss=3.141, ppl=8.82, wps=87725, ups=3.04, wpb=28892.2, bsz=943.9, num_updates=57300, lr=0.000132106, gnorm=0.417, loss_scale=1, train_wall=33, gb_free=6.9, wall=19066
2021-04-05 05:55:34 | INFO | train_inner | epoch 013:    414 / 4751 loss=4.66, nll_loss=3.067, ppl=8.38, wps=87494.4, ups=3.02, wpb=28961.5, bsz=940.7, num_updates=57400, lr=0.000131991, gnorm=0.408, loss_scale=1, train_wall=33, gb_free=6.3, wall=19099
2021-04-05 05:56:07 | INFO | train_inner | epoch 013:    514 / 4751 loss=4.709, nll_loss=3.123, ppl=8.71, wps=88089.8, ups=3.06, wpb=28821.2, bsz=943.2, num_updates=57500, lr=0.000131876, gnorm=0.414, loss_scale=1, train_wall=33, gb_free=6.2, wall=19132
2021-04-05 05:56:40 | INFO | train_inner | epoch 013:    614 / 4751 loss=4.711, nll_loss=3.125, ppl=8.72, wps=88303.5, ups=3.05, wpb=28914.2, bsz=964.1, num_updates=57600, lr=0.000131762, gnorm=0.416, loss_scale=1, train_wall=33, gb_free=6.4, wall=19165
2021-04-05 05:57:13 | INFO | train_inner | epoch 013:    714 / 4751 loss=4.739, nll_loss=3.157, ppl=8.92, wps=88377, ups=3.04, wpb=29114.4, bsz=959.4, num_updates=57700, lr=0.000131647, gnorm=0.41, loss_scale=1, train_wall=33, gb_free=6.2, wall=19198
2021-04-05 05:57:46 | INFO | train_inner | epoch 013:    814 / 4751 loss=4.716, nll_loss=3.131, ppl=8.76, wps=88752.7, ups=3.05, wpb=29130.5, bsz=929.4, num_updates=57800, lr=0.000131533, gnorm=0.426, loss_scale=1, train_wall=33, gb_free=6.3, wall=19230
2021-04-05 05:58:18 | INFO | train_inner | epoch 013:    914 / 4751 loss=4.724, nll_loss=3.141, ppl=8.82, wps=87897.6, ups=3.05, wpb=28840.1, bsz=998.3, num_updates=57900, lr=0.00013142, gnorm=0.42, loss_scale=1, train_wall=33, gb_free=6.1, wall=19263
2021-04-05 05:58:51 | INFO | train_inner | epoch 013:   1014 / 4751 loss=4.729, nll_loss=3.146, ppl=8.85, wps=88635.6, ups=3.05, wpb=29024.2, bsz=941.4, num_updates=58000, lr=0.000131306, gnorm=0.413, loss_scale=1, train_wall=33, gb_free=6.2, wall=19296
2021-04-05 05:59:24 | INFO | train_inner | epoch 013:   1114 / 4751 loss=4.716, nll_loss=3.13, ppl=8.76, wps=87785.7, ups=3.03, wpb=28937.7, bsz=924.9, num_updates=58100, lr=0.000131193, gnorm=0.414, loss_scale=1, train_wall=33, gb_free=6.5, wall=19329
2021-04-05 05:59:57 | INFO | train_inner | epoch 013:   1214 / 4751 loss=4.713, nll_loss=3.128, ppl=8.74, wps=88223.5, ups=3.05, wpb=28941.4, bsz=936.7, num_updates=58200, lr=0.000131081, gnorm=0.422, loss_scale=1, train_wall=33, gb_free=6.2, wall=19362
2021-04-05 06:00:31 | INFO | train_inner | epoch 013:   1314 / 4751 loss=4.692, nll_loss=3.104, ppl=8.6, wps=86378, ups=2.98, wpb=29026, bsz=958.5, num_updates=58300, lr=0.000130968, gnorm=0.45, loss_scale=1, train_wall=33, gb_free=6.1, wall=19395
2021-04-05 06:01:03 | INFO | train_inner | epoch 013:   1414 / 4751 loss=4.738, nll_loss=3.156, ppl=8.91, wps=87142, ups=3.04, wpb=28631.6, bsz=941.7, num_updates=58400, lr=0.000130856, gnorm=0.417, loss_scale=1, train_wall=33, gb_free=6.3, wall=19428
2021-04-05 06:01:36 | INFO | train_inner | epoch 013:   1514 / 4751 loss=4.736, nll_loss=3.153, ppl=8.89, wps=88291, ups=3.05, wpb=28920.5, bsz=887.5, num_updates=58500, lr=0.000130744, gnorm=0.424, loss_scale=1, train_wall=33, gb_free=6.1, wall=19461
2021-04-05 06:02:09 | INFO | train_inner | epoch 013:   1614 / 4751 loss=4.682, nll_loss=3.093, ppl=8.53, wps=87682.6, ups=3.03, wpb=28983.1, bsz=933.5, num_updates=58600, lr=0.000130632, gnorm=0.412, loss_scale=2, train_wall=33, gb_free=6.3, wall=19494
2021-04-05 06:02:42 | INFO | train_inner | epoch 013:   1714 / 4751 loss=4.731, nll_loss=3.149, ppl=8.87, wps=88527.9, ups=3.04, wpb=29104, bsz=943, num_updates=58700, lr=0.000130521, gnorm=0.42, loss_scale=2, train_wall=33, gb_free=6.5, wall=19527
2021-04-05 06:03:15 | INFO | train_inner | epoch 013:   1814 / 4751 loss=4.719, nll_loss=3.135, ppl=8.78, wps=87766.2, ups=3.01, wpb=29164.7, bsz=958, num_updates=58800, lr=0.00013041, gnorm=0.416, loss_scale=2, train_wall=33, gb_free=6.2, wall=19560
2021-04-05 06:03:48 | INFO | train_inner | epoch 013:   1914 / 4751 loss=4.665, nll_loss=3.074, ppl=8.42, wps=87856.2, ups=3.03, wpb=29003.1, bsz=981.1, num_updates=58900, lr=0.000130299, gnorm=0.42, loss_scale=2, train_wall=33, gb_free=6.2, wall=19593
2021-04-05 06:04:21 | INFO | train_inner | epoch 013:   2014 / 4751 loss=4.651, nll_loss=3.058, ppl=8.33, wps=88766.3, ups=3.04, wpb=29222.3, bsz=955.1, num_updates=59000, lr=0.000130189, gnorm=0.412, loss_scale=2, train_wall=33, gb_free=6.1, wall=19626
2021-04-05 06:04:54 | INFO | train_inner | epoch 013:   2114 / 4751 loss=4.749, nll_loss=3.169, ppl=9, wps=88269.8, ups=3.05, wpb=28929.5, bsz=937.3, num_updates=59100, lr=0.000130079, gnorm=0.414, loss_scale=2, train_wall=33, gb_free=6.4, wall=19659
2021-04-05 06:05:27 | INFO | train_inner | epoch 013:   2214 / 4751 loss=4.694, nll_loss=3.106, ppl=8.61, wps=87976.8, ups=3.04, wpb=28923, bsz=936.5, num_updates=59200, lr=0.000129969, gnorm=0.413, loss_scale=2, train_wall=33, gb_free=6.1, wall=19692
2021-04-05 06:06:00 | INFO | train_inner | epoch 013:   2314 / 4751 loss=4.694, nll_loss=3.107, ppl=8.62, wps=87715.2, ups=3.03, wpb=28922.1, bsz=989.9, num_updates=59300, lr=0.000129859, gnorm=0.423, loss_scale=2, train_wall=33, gb_free=6.3, wall=19725
2021-04-05 06:06:33 | INFO | train_inner | epoch 013:   2414 / 4751 loss=4.733, nll_loss=3.151, ppl=8.88, wps=87615.2, ups=3.03, wpb=28939.2, bsz=933.9, num_updates=59400, lr=0.00012975, gnorm=0.415, loss_scale=2, train_wall=33, gb_free=6.2, wall=19758
2021-04-05 06:07:06 | INFO | train_inner | epoch 013:   2514 / 4751 loss=4.672, nll_loss=3.082, ppl=8.47, wps=88282.5, ups=3.04, wpb=29017.5, bsz=976.4, num_updates=59500, lr=0.000129641, gnorm=0.416, loss_scale=2, train_wall=33, gb_free=6.2, wall=19791
2021-04-05 06:07:39 | INFO | train_inner | epoch 013:   2614 / 4751 loss=4.717, nll_loss=3.133, ppl=8.77, wps=88105.1, ups=3.01, wpb=29225.4, bsz=960.9, num_updates=59600, lr=0.000129532, gnorm=0.423, loss_scale=2, train_wall=33, gb_free=6.5, wall=19824
2021-04-05 06:08:12 | INFO | train_inner | epoch 013:   2714 / 4751 loss=4.692, nll_loss=3.104, ppl=8.6, wps=87695.3, ups=3.04, wpb=28830.5, bsz=968.1, num_updates=59700, lr=0.000129423, gnorm=0.436, loss_scale=2, train_wall=33, gb_free=6.2, wall=19857
2021-04-05 06:08:45 | INFO | train_inner | epoch 013:   2814 / 4751 loss=4.633, nll_loss=3.037, ppl=8.21, wps=87473.5, ups=3.02, wpb=28956.2, bsz=982, num_updates=59800, lr=0.000129315, gnorm=0.412, loss_scale=2, train_wall=33, gb_free=6.4, wall=19890
2021-04-05 06:09:18 | INFO | train_inner | epoch 013:   2914 / 4751 loss=4.769, nll_loss=3.192, ppl=9.14, wps=88054.6, ups=3.06, wpb=28773.9, bsz=954, num_updates=59900, lr=0.000129207, gnorm=0.427, loss_scale=2, train_wall=33, gb_free=6.2, wall=19922
2021-04-05 06:09:51 | INFO | train_inner | epoch 013:   3014 / 4751 loss=4.684, nll_loss=3.095, ppl=8.54, wps=87921.5, ups=3.03, wpb=29012.5, bsz=923.5, num_updates=60000, lr=0.000129099, gnorm=0.408, loss_scale=2, train_wall=33, gb_free=6.3, wall=19955
2021-04-05 06:10:23 | INFO | train_inner | epoch 013:   3114 / 4751 loss=4.729, nll_loss=3.147, ppl=8.86, wps=89448.6, ups=3.06, wpb=29231.1, bsz=959.4, num_updates=60100, lr=0.000128992, gnorm=0.409, loss_scale=2, train_wall=33, gb_free=6, wall=19988
2021-04-05 06:10:56 | INFO | train_inner | epoch 013:   3214 / 4751 loss=4.727, nll_loss=3.144, ppl=8.84, wps=86799, ups=3.04, wpb=28522.8, bsz=918.2, num_updates=60200, lr=0.000128885, gnorm=0.44, loss_scale=2, train_wall=33, gb_free=6.1, wall=20021
2021-04-05 06:11:29 | INFO | train_inner | epoch 013:   3314 / 4751 loss=4.71, nll_loss=3.125, ppl=8.72, wps=88693.9, ups=3.02, wpb=29329.9, bsz=913.4, num_updates=60300, lr=0.000128778, gnorm=0.417, loss_scale=2, train_wall=33, gb_free=6.3, wall=20054
2021-04-05 06:12:02 | INFO | train_inner | epoch 013:   3414 / 4751 loss=4.676, nll_loss=3.086, ppl=8.49, wps=88649, ups=3.05, wpb=29043.9, bsz=909.1, num_updates=60400, lr=0.000128671, gnorm=0.416, loss_scale=2, train_wall=33, gb_free=6.3, wall=20087
2021-04-05 06:12:35 | INFO | train_inner | epoch 013:   3514 / 4751 loss=4.779, nll_loss=3.203, ppl=9.21, wps=87298.3, ups=3.03, wpb=28771.5, bsz=933.8, num_updates=60500, lr=0.000128565, gnorm=0.423, loss_scale=2, train_wall=33, gb_free=6, wall=20120
2021-04-05 06:13:08 | INFO | train_inner | epoch 013:   3614 / 4751 loss=4.702, nll_loss=3.116, ppl=8.67, wps=88585.9, ups=3.04, wpb=29155.5, bsz=954.4, num_updates=60600, lr=0.000128459, gnorm=0.416, loss_scale=2, train_wall=33, gb_free=6.3, wall=20153
2021-04-05 06:13:41 | INFO | train_inner | epoch 013:   3714 / 4751 loss=4.714, nll_loss=3.129, ppl=8.75, wps=88248, ups=3.04, wpb=29046.5, bsz=911.4, num_updates=60700, lr=0.000128353, gnorm=0.415, loss_scale=4, train_wall=33, gb_free=6.3, wall=20186
2021-04-05 06:14:14 | INFO | train_inner | epoch 013:   3814 / 4751 loss=4.724, nll_loss=3.141, ppl=8.82, wps=88562.7, ups=3.05, wpb=29077.9, bsz=964.6, num_updates=60800, lr=0.000128247, gnorm=0.409, loss_scale=4, train_wall=33, gb_free=6.3, wall=20218
2021-04-05 06:14:46 | INFO | train_inner | epoch 013:   3914 / 4751 loss=4.664, nll_loss=3.073, ppl=8.42, wps=88384.4, ups=3.05, wpb=28958.3, bsz=950.2, num_updates=60900, lr=0.000128142, gnorm=0.413, loss_scale=4, train_wall=33, gb_free=6.2, wall=20251
2021-04-05 06:15:19 | INFO | train_inner | epoch 013:   4014 / 4751 loss=4.689, nll_loss=3.101, ppl=8.58, wps=89084.4, ups=3.03, wpb=29407.8, bsz=975.4, num_updates=61000, lr=0.000128037, gnorm=0.41, loss_scale=4, train_wall=33, gb_free=6.2, wall=20284
2021-04-05 06:15:53 | INFO | train_inner | epoch 013:   4114 / 4751 loss=4.651, nll_loss=3.058, ppl=8.33, wps=86658.4, ups=3.02, wpb=28691.1, bsz=959.5, num_updates=61100, lr=0.000127932, gnorm=0.422, loss_scale=4, train_wall=33, gb_free=6, wall=20317
2021-04-05 06:16:25 | INFO | train_inner | epoch 013:   4214 / 4751 loss=4.722, nll_loss=3.139, ppl=8.81, wps=87143.7, ups=3.04, wpb=28666.5, bsz=966.2, num_updates=61200, lr=0.000127827, gnorm=0.42, loss_scale=4, train_wall=33, gb_free=6.2, wall=20350
2021-04-05 06:16:59 | INFO | train_inner | epoch 013:   4314 / 4751 loss=4.663, nll_loss=3.073, ppl=8.41, wps=88104.2, ups=3.02, wpb=29155.8, bsz=983.9, num_updates=61300, lr=0.000127723, gnorm=0.413, loss_scale=4, train_wall=33, gb_free=6.3, wall=20383
2021-04-05 06:17:32 | INFO | train_inner | epoch 013:   4414 / 4751 loss=4.669, nll_loss=3.079, ppl=8.45, wps=87942.7, ups=3.02, wpb=29084.2, bsz=953.1, num_updates=61400, lr=0.000127619, gnorm=0.415, loss_scale=4, train_wall=33, gb_free=6.3, wall=20416
2021-04-05 06:18:05 | INFO | train_inner | epoch 013:   4514 / 4751 loss=4.694, nll_loss=3.107, ppl=8.62, wps=86607.7, ups=3.02, wpb=28647.2, bsz=946.8, num_updates=61500, lr=0.000127515, gnorm=0.427, loss_scale=4, train_wall=33, gb_free=6, wall=20449
2021-04-05 06:18:38 | INFO | train_inner | epoch 013:   4614 / 4751 loss=4.721, nll_loss=3.138, ppl=8.81, wps=87849.3, ups=3.02, wpb=29089.5, bsz=941.2, num_updates=61600, lr=0.000127412, gnorm=0.42, loss_scale=4, train_wall=33, gb_free=6.1, wall=20483
2021-04-05 06:19:11 | INFO | train_inner | epoch 013:   4714 / 4751 loss=4.736, nll_loss=3.155, ppl=8.91, wps=87919.3, ups=3.04, wpb=28941.2, bsz=930.4, num_updates=61700, lr=0.000127309, gnorm=0.418, loss_scale=4, train_wall=33, gb_free=6.1, wall=20516
2021-04-05 06:19:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-05 06:19:24 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 4.309 | nll_loss 2.539 | ppl 5.81 | wps 188022 | wpb 10489.1 | bsz 375 | num_updates 61737 | best_loss 4.309
2021-04-05 06:19:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 61737 updates
2021-04-05 06:19:24 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 06:19:30 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 06:19:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt (epoch 13 @ 61737 updates, score 4.309) (writing took 13.616717882454395 seconds)
2021-04-05 06:19:37 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2021-04-05 06:19:38 | INFO | train | epoch 013 | loss 4.709 | nll_loss 3.124 | ppl 8.72 | wps 87084.5 | ups 3.01 | wpb 28968.3 | bsz 947.4 | num_updates 61737 | lr 0.00012727 | gnorm 0.418 | loss_scale 4 | train_wall 1557 | gb_free 6.5 | wall 20542
2021-04-05 06:19:38 | INFO | fairseq.trainer | begin training epoch 14
2021-04-05 06:19:38 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-05 06:20:00 | INFO | train_inner | epoch 014:     63 / 4751 loss=4.719, nll_loss=3.135, ppl=8.78, wps=58707, ups=2.04, wpb=28711.6, bsz=934.8, num_updates=61800, lr=0.000127205, gnorm=0.427, loss_scale=4, train_wall=33, gb_free=6.1, wall=20564
2021-04-05 06:20:32 | INFO | train_inner | epoch 014:    163 / 4751 loss=4.685, nll_loss=3.097, ppl=8.56, wps=88265, ups=3.04, wpb=28988.8, bsz=985.9, num_updates=61900, lr=0.000127103, gnorm=0.423, loss_scale=4, train_wall=33, gb_free=6.4, wall=20597
2021-04-05 06:21:05 | INFO | train_inner | epoch 014:    263 / 4751 loss=4.684, nll_loss=3.096, ppl=8.55, wps=88434.9, ups=3.06, wpb=28861.9, bsz=927.5, num_updates=62000, lr=0.000127, gnorm=0.422, loss_scale=4, train_wall=32, gb_free=6.4, wall=20630
2021-04-05 06:21:38 | INFO | train_inner | epoch 014:    363 / 4751 loss=4.687, nll_loss=3.099, ppl=8.57, wps=88050.6, ups=3.05, wpb=28872.1, bsz=937, num_updates=62100, lr=0.000126898, gnorm=0.416, loss_scale=4, train_wall=33, gb_free=6.2, wall=20663
2021-04-05 06:22:11 | INFO | train_inner | epoch 014:    463 / 4751 loss=4.676, nll_loss=3.087, ppl=8.49, wps=86994.6, ups=3.01, wpb=28868.6, bsz=948.3, num_updates=62200, lr=0.000126796, gnorm=0.413, loss_scale=4, train_wall=33, gb_free=6.3, wall=20696
2021-04-05 06:22:44 | INFO | train_inner | epoch 014:    563 / 4751 loss=4.667, nll_loss=3.076, ppl=8.43, wps=88577.8, ups=3.03, wpb=29224.2, bsz=952.2, num_updates=62300, lr=0.000126694, gnorm=0.418, loss_scale=4, train_wall=33, gb_free=6.3, wall=20729
2021-04-05 06:23:17 | INFO | train_inner | epoch 014:    663 / 4751 loss=4.666, nll_loss=3.075, ppl=8.43, wps=88749.9, ups=3.04, wpb=29156, bsz=974.5, num_updates=62400, lr=0.000126592, gnorm=0.415, loss_scale=4, train_wall=33, gb_free=6.2, wall=20762
2021-04-05 06:23:50 | INFO | train_inner | epoch 014:    763 / 4751 loss=4.647, nll_loss=3.053, ppl=8.3, wps=86695.7, ups=3.02, wpb=28728.1, bsz=965.4, num_updates=62500, lr=0.000126491, gnorm=0.418, loss_scale=4, train_wall=33, gb_free=6.2, wall=20795
2021-04-05 06:24:23 | INFO | train_inner | epoch 014:    863 / 4751 loss=4.626, nll_loss=3.029, ppl=8.16, wps=88031.4, ups=3.02, wpb=29171.4, bsz=960.3, num_updates=62600, lr=0.00012639, gnorm=0.414, loss_scale=4, train_wall=33, gb_free=6.1, wall=20828
2021-04-05 06:24:56 | INFO | train_inner | epoch 014:    963 / 4751 loss=4.632, nll_loss=3.037, ppl=8.21, wps=86538.3, ups=3.01, wpb=28737.9, bsz=984.9, num_updates=62700, lr=0.000126289, gnorm=0.413, loss_scale=8, train_wall=33, gb_free=6.3, wall=20861
2021-04-05 06:25:29 | INFO | train_inner | epoch 014:   1063 / 4751 loss=4.745, nll_loss=3.164, ppl=8.97, wps=88786.1, ups=3.03, wpb=29284.8, bsz=909.1, num_updates=62800, lr=0.000126189, gnorm=0.425, loss_scale=8, train_wall=33, gb_free=6.8, wall=20894
2021-04-05 06:26:02 | INFO | train_inner | epoch 014:   1163 / 4751 loss=4.737, nll_loss=3.156, ppl=8.91, wps=87666.1, ups=3.04, wpb=28841.3, bsz=922.6, num_updates=62900, lr=0.000126088, gnorm=0.429, loss_scale=8, train_wall=33, gb_free=6.7, wall=20927
2021-04-05 06:26:35 | INFO | train_inner | epoch 014:   1263 / 4751 loss=4.721, nll_loss=3.137, ppl=8.8, wps=88260.4, ups=3.04, wpb=29050, bsz=947.3, num_updates=63000, lr=0.000125988, gnorm=0.415, loss_scale=8, train_wall=33, gb_free=6.4, wall=20960
2021-04-05 06:27:08 | INFO | train_inner | epoch 014:   1363 / 4751 loss=4.714, nll_loss=3.13, ppl=8.75, wps=88633.3, ups=3.05, wpb=29077, bsz=973.5, num_updates=63100, lr=0.000125888, gnorm=0.418, loss_scale=8, train_wall=33, gb_free=6.4, wall=20993
2021-04-05 06:27:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2021-04-05 06:27:41 | INFO | train_inner | epoch 014:   1464 / 4751 loss=4.674, nll_loss=3.084, ppl=8.48, wps=87491.3, ups=3.01, wpb=29031, bsz=935.4, num_updates=63200, lr=0.000125789, gnorm=0.414, loss_scale=4, train_wall=33, gb_free=6.2, wall=21026
2021-04-05 06:28:14 | INFO | train_inner | epoch 014:   1564 / 4751 loss=4.653, nll_loss=3.06, ppl=8.34, wps=87756.6, ups=3.03, wpb=28936.5, bsz=932.3, num_updates=63300, lr=0.000125689, gnorm=0.417, loss_scale=4, train_wall=33, gb_free=6.3, wall=21059
2021-04-05 06:28:47 | INFO | train_inner | epoch 014:   1664 / 4751 loss=4.608, nll_loss=3.009, ppl=8.05, wps=88954.3, ups=3.01, wpb=29531.3, bsz=941.4, num_updates=63400, lr=0.00012559, gnorm=0.411, loss_scale=4, train_wall=33, gb_free=6.3, wall=21092
2021-04-05 06:29:20 | INFO | train_inner | epoch 014:   1764 / 4751 loss=4.706, nll_loss=3.12, ppl=8.7, wps=87805.7, ups=3.05, wpb=28743.4, bsz=954.2, num_updates=63500, lr=0.000125491, gnorm=0.42, loss_scale=4, train_wall=33, gb_free=6.3, wall=21125
2021-04-05 06:29:53 | INFO | train_inner | epoch 014:   1864 / 4751 loss=4.596, nll_loss=2.996, ppl=7.98, wps=88933.2, ups=3.04, wpb=29244.6, bsz=949.3, num_updates=63600, lr=0.000125392, gnorm=0.411, loss_scale=4, train_wall=33, gb_free=6, wall=21158
2021-04-05 06:30:26 | INFO | train_inner | epoch 014:   1964 / 4751 loss=4.676, nll_loss=3.086, ppl=8.49, wps=88043.1, ups=3.03, wpb=29062.9, bsz=973.4, num_updates=63700, lr=0.000125294, gnorm=0.418, loss_scale=4, train_wall=33, gb_free=6.3, wall=21191
2021-04-05 06:30:59 | INFO | train_inner | epoch 014:   2064 / 4751 loss=4.703, nll_loss=3.117, ppl=8.68, wps=88408.3, ups=3.03, wpb=29203.9, bsz=924.1, num_updates=63800, lr=0.000125196, gnorm=0.423, loss_scale=4, train_wall=33, gb_free=6.3, wall=21224
2021-04-05 06:31:32 | INFO | train_inner | epoch 014:   2164 / 4751 loss=4.708, nll_loss=3.123, ppl=8.71, wps=88477.6, ups=3.05, wpb=29006.8, bsz=958.4, num_updates=63900, lr=0.000125098, gnorm=0.423, loss_scale=4, train_wall=33, gb_free=6.3, wall=21257
2021-04-05 06:32:05 | INFO | train_inner | epoch 014:   2264 / 4751 loss=4.67, nll_loss=3.08, ppl=8.45, wps=86537.7, ups=2.98, wpb=29049.7, bsz=969, num_updates=64000, lr=0.000125, gnorm=0.414, loss_scale=4, train_wall=33, gb_free=6, wall=21290
2021-04-05 06:32:38 | INFO | train_inner | epoch 014:   2364 / 4751 loss=4.68, nll_loss=3.092, ppl=8.52, wps=87373.4, ups=3.02, wpb=28910, bsz=981.3, num_updates=64100, lr=0.000124902, gnorm=0.423, loss_scale=4, train_wall=33, gb_free=6.4, wall=21323
2021-04-05 06:33:11 | INFO | train_inner | epoch 014:   2464 / 4751 loss=4.781, nll_loss=3.206, ppl=9.23, wps=88397.6, ups=3.04, wpb=29046.1, bsz=967.7, num_updates=64200, lr=0.000124805, gnorm=0.429, loss_scale=4, train_wall=33, gb_free=6.2, wall=21356
2021-04-05 06:33:44 | INFO | train_inner | epoch 014:   2564 / 4751 loss=4.677, nll_loss=3.088, ppl=8.51, wps=88353.1, ups=3.05, wpb=28947, bsz=948, num_updates=64300, lr=0.000124708, gnorm=0.414, loss_scale=4, train_wall=33, gb_free=6.2, wall=21389
2021-04-05 06:34:17 | INFO | train_inner | epoch 014:   2664 / 4751 loss=4.707, nll_loss=3.122, ppl=8.71, wps=87855.3, ups=3.04, wpb=28932.6, bsz=931.3, num_updates=64400, lr=0.000124611, gnorm=0.417, loss_scale=4, train_wall=33, gb_free=6.2, wall=21422
2021-04-05 06:34:50 | INFO | train_inner | epoch 014:   2764 / 4751 loss=4.69, nll_loss=3.103, ppl=8.59, wps=87732.1, ups=3.05, wpb=28803.8, bsz=938.9, num_updates=64500, lr=0.000124515, gnorm=0.415, loss_scale=4, train_wall=33, gb_free=6.2, wall=21455
2021-04-05 06:35:23 | INFO | train_inner | epoch 014:   2864 / 4751 loss=4.763, nll_loss=3.186, ppl=9.1, wps=87506.4, ups=3.03, wpb=28848.3, bsz=963, num_updates=64600, lr=0.000124418, gnorm=0.42, loss_scale=4, train_wall=33, gb_free=6.3, wall=21488
2021-04-05 06:35:56 | INFO | train_inner | epoch 014:   2964 / 4751 loss=4.725, nll_loss=3.143, ppl=8.83, wps=87217.8, ups=3.03, wpb=28763.2, bsz=948.7, num_updates=64700, lr=0.000124322, gnorm=0.422, loss_scale=4, train_wall=33, gb_free=6.2, wall=21521
2021-04-05 06:36:29 | INFO | train_inner | epoch 014:   3064 / 4751 loss=4.744, nll_loss=3.164, ppl=8.97, wps=88154.9, ups=3.04, wpb=29041.1, bsz=924.8, num_updates=64800, lr=0.000124226, gnorm=0.418, loss_scale=4, train_wall=33, gb_free=6, wall=21554
2021-04-05 06:37:01 | INFO | train_inner | epoch 014:   3164 / 4751 loss=4.737, nll_loss=3.156, ppl=8.91, wps=88271.7, ups=3.07, wpb=28798.6, bsz=939.6, num_updates=64900, lr=0.00012413, gnorm=0.425, loss_scale=4, train_wall=32, gb_free=6.3, wall=21586
2021-04-05 06:37:34 | INFO | train_inner | epoch 014:   3264 / 4751 loss=4.711, nll_loss=3.126, ppl=8.73, wps=87655, ups=3.05, wpb=28774.7, bsz=947, num_updates=65000, lr=0.000124035, gnorm=0.421, loss_scale=4, train_wall=33, gb_free=6.2, wall=21619
2021-04-05 06:38:07 | INFO | train_inner | epoch 014:   3364 / 4751 loss=4.696, nll_loss=3.11, ppl=8.63, wps=86507.9, ups=3.01, wpb=28697.7, bsz=944.3, num_updates=65100, lr=0.000123939, gnorm=0.415, loss_scale=4, train_wall=33, gb_free=6.3, wall=21652
2021-04-05 06:38:40 | INFO | train_inner | epoch 014:   3464 / 4751 loss=4.696, nll_loss=3.11, ppl=8.64, wps=87873.2, ups=3.05, wpb=28854.2, bsz=948.4, num_updates=65200, lr=0.000123844, gnorm=0.416, loss_scale=4, train_wall=33, gb_free=6.2, wall=21685
2021-04-05 06:39:13 | INFO | train_inner | epoch 014:   3564 / 4751 loss=4.76, nll_loss=3.182, ppl=9.07, wps=87261, ups=3.06, wpb=28547.9, bsz=951.4, num_updates=65300, lr=0.000123749, gnorm=0.427, loss_scale=8, train_wall=33, gb_free=6.3, wall=21718
2021-04-05 06:39:46 | INFO | train_inner | epoch 014:   3664 / 4751 loss=4.7, nll_loss=3.114, ppl=8.66, wps=88841, ups=3.03, wpb=29303, bsz=934.1, num_updates=65400, lr=0.000123655, gnorm=0.413, loss_scale=8, train_wall=33, gb_free=6.2, wall=21751
2021-04-05 06:40:19 | INFO | train_inner | epoch 014:   3764 / 4751 loss=4.736, nll_loss=3.155, ppl=8.91, wps=88754.6, ups=3.06, wpb=29034, bsz=921.7, num_updates=65500, lr=0.00012356, gnorm=0.425, loss_scale=8, train_wall=33, gb_free=6.2, wall=21783
2021-04-05 06:40:51 | INFO | train_inner | epoch 014:   3864 / 4751 loss=4.788, nll_loss=3.214, ppl=9.28, wps=87325.5, ups=3.05, wpb=28608.4, bsz=928.2, num_updates=65600, lr=0.000123466, gnorm=0.422, loss_scale=8, train_wall=33, gb_free=6.4, wall=21816
2021-04-05 06:41:24 | INFO | train_inner | epoch 014:   3964 / 4751 loss=4.662, nll_loss=3.071, ppl=8.4, wps=88845.9, ups=3.03, wpb=29312.9, bsz=936.3, num_updates=65700, lr=0.000123372, gnorm=0.412, loss_scale=8, train_wall=33, gb_free=6.1, wall=21849
2021-04-05 06:41:57 | INFO | train_inner | epoch 014:   4064 / 4751 loss=4.661, nll_loss=3.07, ppl=8.4, wps=88217.1, ups=3.03, wpb=29162.1, bsz=963.4, num_updates=65800, lr=0.000123278, gnorm=0.411, loss_scale=8, train_wall=33, gb_free=6.2, wall=21882
2021-04-05 06:42:30 | INFO | train_inner | epoch 014:   4164 / 4751 loss=4.693, nll_loss=3.106, ppl=8.61, wps=88276.3, ups=3.05, wpb=28945, bsz=932.7, num_updates=65900, lr=0.000123185, gnorm=0.422, loss_scale=8, train_wall=33, gb_free=6.3, wall=21915
2021-04-05 06:43:03 | INFO | train_inner | epoch 014:   4264 / 4751 loss=4.741, nll_loss=3.16, ppl=8.94, wps=87546.3, ups=3.03, wpb=28923.1, bsz=912.4, num_updates=66000, lr=0.000123091, gnorm=0.421, loss_scale=8, train_wall=33, gb_free=6.6, wall=21948
2021-04-05 06:43:36 | INFO | train_inner | epoch 014:   4364 / 4751 loss=4.657, nll_loss=3.066, ppl=8.37, wps=87667.7, ups=3.02, wpb=29029.1, bsz=962, num_updates=66100, lr=0.000122998, gnorm=0.415, loss_scale=8, train_wall=33, gb_free=6.2, wall=21981
2021-04-05 06:43:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2021-04-05 06:43:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-05 06:44:10 | INFO | train_inner | epoch 014:   4466 / 4751 loss=4.703, nll_loss=3.118, ppl=8.68, wps=85992.8, ups=2.97, wpb=28947.8, bsz=952.6, num_updates=66200, lr=0.000122905, gnorm=0.427, loss_scale=2, train_wall=34, gb_free=6.6, wall=22015
2021-04-05 06:44:43 | INFO | train_inner | epoch 014:   4566 / 4751 loss=4.747, nll_loss=3.167, ppl=8.98, wps=88423.9, ups=3.06, wpb=28907.8, bsz=910, num_updates=66300, lr=0.000122813, gnorm=0.418, loss_scale=2, train_wall=33, gb_free=6.1, wall=22048
2021-04-05 06:45:15 | INFO | train_inner | epoch 014:   4666 / 4751 loss=4.703, nll_loss=3.118, ppl=8.68, wps=88599.6, ups=3.05, wpb=29021.7, bsz=926.4, num_updates=66400, lr=0.00012272, gnorm=0.419, loss_scale=2, train_wall=33, gb_free=6.2, wall=22080
2021-04-05 06:45:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-05 06:45:44 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 4.304 | nll_loss 2.533 | ppl 5.79 | wps 191198 | wpb 10489.1 | bsz 375 | num_updates 66485 | best_loss 4.304
2021-04-05 06:45:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 66485 updates
2021-04-05 06:45:44 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 06:45:51 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 06:45:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt (epoch 14 @ 66485 updates, score 4.304) (writing took 12.762072309851646 seconds)
2021-04-05 06:45:57 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2021-04-05 06:45:57 | INFO | train | epoch 014 | loss 4.695 | nll_loss 3.109 | ppl 8.63 | wps 87063.7 | ups 3.01 | wpb 28967.8 | bsz 946.6 | num_updates 66485 | lr 0.000122642 | gnorm 0.419 | loss_scale 2 | train_wall 1558 | gb_free 6.1 | wall 22122
2021-04-05 06:45:57 | INFO | fairseq.trainer | begin training epoch 15
2021-04-05 06:45:57 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-05 06:46:04 | INFO | train_inner | epoch 015:     15 / 4751 loss=4.679, nll_loss=3.09, ppl=8.51, wps=59733.7, ups=2.08, wpb=28704.4, bsz=918.5, num_updates=66500, lr=0.000122628, gnorm=0.426, loss_scale=2, train_wall=33, gb_free=6, wall=22128
2021-04-05 06:46:36 | INFO | train_inner | epoch 015:    115 / 4751 loss=4.643, nll_loss=3.049, ppl=8.28, wps=89328, ups=3.08, wpb=29041.2, bsz=961, num_updates=66600, lr=0.000122536, gnorm=0.423, loss_scale=2, train_wall=32, gb_free=6.7, wall=22161
2021-04-05 06:47:09 | INFO | train_inner | epoch 015:    215 / 4751 loss=4.68, nll_loss=3.091, ppl=8.52, wps=89113.4, ups=3.07, wpb=29041.9, bsz=961, num_updates=66700, lr=0.000122444, gnorm=0.416, loss_scale=2, train_wall=32, gb_free=6.6, wall=22193
2021-04-05 06:47:41 | INFO | train_inner | epoch 015:    315 / 4751 loss=4.696, nll_loss=3.109, ppl=8.63, wps=88595.6, ups=3.06, wpb=28946, bsz=943.7, num_updates=66800, lr=0.000122352, gnorm=0.422, loss_scale=2, train_wall=33, gb_free=6.7, wall=22226
2021-04-05 06:48:14 | INFO | train_inner | epoch 015:    415 / 4751 loss=4.718, nll_loss=3.134, ppl=8.78, wps=87281.9, ups=3.04, wpb=28691.2, bsz=953.4, num_updates=66900, lr=0.000122261, gnorm=0.423, loss_scale=2, train_wall=33, gb_free=6.4, wall=22259
2021-04-05 06:48:47 | INFO | train_inner | epoch 015:    515 / 4751 loss=4.658, nll_loss=3.067, ppl=8.38, wps=88397.4, ups=3.05, wpb=28996.3, bsz=928.7, num_updates=67000, lr=0.000122169, gnorm=0.413, loss_scale=2, train_wall=33, gb_free=6.2, wall=22292
2021-04-05 06:49:20 | INFO | train_inner | epoch 015:    615 / 4751 loss=4.649, nll_loss=3.056, ppl=8.32, wps=87955.8, ups=3.03, wpb=28992.8, bsz=923.1, num_updates=67100, lr=0.000122078, gnorm=0.413, loss_scale=2, train_wall=33, gb_free=6.5, wall=22325
2021-04-05 06:49:53 | INFO | train_inner | epoch 015:    715 / 4751 loss=4.733, nll_loss=3.151, ppl=8.88, wps=89179.4, ups=3.06, wpb=29186.2, bsz=921.4, num_updates=67200, lr=0.000121988, gnorm=0.424, loss_scale=2, train_wall=33, gb_free=6.2, wall=22357
2021-04-05 06:50:25 | INFO | train_inner | epoch 015:    815 / 4751 loss=4.637, nll_loss=3.043, ppl=8.24, wps=88276, ups=3.05, wpb=28962.3, bsz=969.8, num_updates=67300, lr=0.000121897, gnorm=0.419, loss_scale=2, train_wall=33, gb_free=6.2, wall=22390
2021-04-05 06:50:58 | INFO | train_inner | epoch 015:    915 / 4751 loss=4.691, nll_loss=3.104, ppl=8.6, wps=88103, ups=3.03, wpb=29030.8, bsz=950.6, num_updates=67400, lr=0.000121806, gnorm=0.415, loss_scale=2, train_wall=33, gb_free=6.3, wall=22423
2021-04-05 06:51:32 | INFO | train_inner | epoch 015:   1015 / 4751 loss=4.584, nll_loss=2.982, ppl=7.9, wps=87956.3, ups=3.02, wpb=29105.8, bsz=960.7, num_updates=67500, lr=0.000121716, gnorm=0.43, loss_scale=2, train_wall=33, gb_free=6, wall=22456
2021-04-05 06:52:04 | INFO | train_inner | epoch 015:   1115 / 4751 loss=4.638, nll_loss=3.044, ppl=8.25, wps=89178.6, ups=3.05, wpb=29244.2, bsz=967.8, num_updates=67600, lr=0.000121626, gnorm=0.415, loss_scale=2, train_wall=33, gb_free=6.4, wall=22489
2021-04-05 06:52:37 | INFO | train_inner | epoch 015:   1215 / 4751 loss=4.741, nll_loss=3.161, ppl=8.94, wps=87695.4, ups=3.03, wpb=28917.6, bsz=940, num_updates=67700, lr=0.000121536, gnorm=0.434, loss_scale=2, train_wall=33, gb_free=6.2, wall=22522
2021-04-05 06:53:10 | INFO | train_inner | epoch 015:   1315 / 4751 loss=4.682, nll_loss=3.094, ppl=8.54, wps=86770.2, ups=3.02, wpb=28700.3, bsz=933.4, num_updates=67800, lr=0.000121447, gnorm=0.424, loss_scale=2, train_wall=33, gb_free=6.3, wall=22555
2021-04-05 06:53:43 | INFO | train_inner | epoch 015:   1415 / 4751 loss=4.692, nll_loss=3.104, ppl=8.6, wps=87951, ups=3.04, wpb=28888.1, bsz=927.7, num_updates=67900, lr=0.000121357, gnorm=0.422, loss_scale=2, train_wall=33, gb_free=6.1, wall=22588
2021-04-05 06:54:16 | INFO | train_inner | epoch 015:   1515 / 4751 loss=4.63, nll_loss=3.035, ppl=8.2, wps=88097.4, ups=3.03, wpb=29065.5, bsz=1014.6, num_updates=68000, lr=0.000121268, gnorm=0.45, loss_scale=2, train_wall=33, gb_free=6.1, wall=22621
2021-04-05 06:54:49 | INFO | train_inner | epoch 015:   1615 / 4751 loss=4.694, nll_loss=3.108, ppl=8.62, wps=89613.8, ups=3.06, wpb=29273.7, bsz=976.6, num_updates=68100, lr=0.000121179, gnorm=0.417, loss_scale=2, train_wall=33, gb_free=6.2, wall=22654
2021-04-05 06:55:22 | INFO | train_inner | epoch 015:   1715 / 4751 loss=4.689, nll_loss=3.102, ppl=8.58, wps=87739.3, ups=3.03, wpb=28942.9, bsz=936.1, num_updates=68200, lr=0.00012109, gnorm=0.42, loss_scale=4, train_wall=33, gb_free=6.3, wall=22687
2021-04-05 06:55:55 | INFO | train_inner | epoch 015:   1815 / 4751 loss=4.675, nll_loss=3.086, ppl=8.49, wps=88916.1, ups=3.04, wpb=29232.3, bsz=930.2, num_updates=68300, lr=0.000121001, gnorm=0.415, loss_scale=4, train_wall=33, gb_free=6.2, wall=22720
2021-04-05 06:56:28 | INFO | train_inner | epoch 015:   1915 / 4751 loss=4.69, nll_loss=3.102, ppl=8.59, wps=88712.8, ups=3.05, wpb=29114.8, bsz=953.5, num_updates=68400, lr=0.000120913, gnorm=0.421, loss_scale=4, train_wall=33, gb_free=6.1, wall=22752
2021-04-05 06:57:01 | INFO | train_inner | epoch 015:   2015 / 4751 loss=4.679, nll_loss=3.09, ppl=8.51, wps=87327.3, ups=3.03, wpb=28824.5, bsz=923.8, num_updates=68500, lr=0.000120824, gnorm=0.423, loss_scale=4, train_wall=33, gb_free=6.3, wall=22785
2021-04-05 06:57:33 | INFO | train_inner | epoch 015:   2115 / 4751 loss=4.732, nll_loss=3.151, ppl=8.88, wps=88372.5, ups=3.04, wpb=29038.5, bsz=932.2, num_updates=68600, lr=0.000120736, gnorm=0.428, loss_scale=4, train_wall=33, gb_free=5.9, wall=22818
2021-04-05 06:58:06 | INFO | train_inner | epoch 015:   2215 / 4751 loss=4.706, nll_loss=3.121, ppl=8.7, wps=87599.7, ups=3.04, wpb=28832.2, bsz=929.9, num_updates=68700, lr=0.000120648, gnorm=0.419, loss_scale=4, train_wall=33, gb_free=6.4, wall=22851
2021-04-05 06:58:39 | INFO | train_inner | epoch 015:   2315 / 4751 loss=4.693, nll_loss=3.106, ppl=8.61, wps=87402.2, ups=3.02, wpb=28953.1, bsz=950.1, num_updates=68800, lr=0.000120561, gnorm=0.418, loss_scale=4, train_wall=33, gb_free=6.3, wall=22884
2021-04-05 06:59:12 | INFO | train_inner | epoch 015:   2415 / 4751 loss=4.659, nll_loss=3.068, ppl=8.39, wps=88549.8, ups=3.04, wpb=29092.3, bsz=968, num_updates=68900, lr=0.000120473, gnorm=0.421, loss_scale=4, train_wall=33, gb_free=6.2, wall=22917
2021-04-05 06:59:45 | INFO | train_inner | epoch 015:   2515 / 4751 loss=4.618, nll_loss=3.022, ppl=8.12, wps=87815.6, ups=3.04, wpb=28845.6, bsz=955.1, num_updates=69000, lr=0.000120386, gnorm=0.413, loss_scale=4, train_wall=33, gb_free=6.3, wall=22950
2021-04-05 07:00:18 | INFO | train_inner | epoch 015:   2615 / 4751 loss=4.71, nll_loss=3.126, ppl=8.73, wps=87824.1, ups=3.04, wpb=28865, bsz=962, num_updates=69100, lr=0.000120299, gnorm=0.425, loss_scale=4, train_wall=33, gb_free=6, wall=22983
2021-04-05 07:00:51 | INFO | train_inner | epoch 015:   2715 / 4751 loss=4.635, nll_loss=3.041, ppl=8.23, wps=88290.4, ups=3.02, wpb=29203.2, bsz=972.2, num_updates=69200, lr=0.000120212, gnorm=0.414, loss_scale=4, train_wall=33, gb_free=6.2, wall=23016
2021-04-05 07:00:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-05 07:01:24 | INFO | train_inner | epoch 015:   2816 / 4751 loss=4.674, nll_loss=3.085, ppl=8.49, wps=87369.8, ups=3.02, wpb=28892.6, bsz=941.9, num_updates=69300, lr=0.000120125, gnorm=0.422, loss_scale=2, train_wall=33, gb_free=6.4, wall=23049
2021-04-05 07:01:57 | INFO | train_inner | epoch 015:   2916 / 4751 loss=4.715, nll_loss=3.131, ppl=8.76, wps=87871.8, ups=3.05, wpb=28810.4, bsz=956.2, num_updates=69400, lr=0.000120038, gnorm=0.426, loss_scale=2, train_wall=33, gb_free=6.1, wall=23082
2021-04-05 07:02:30 | INFO | train_inner | epoch 015:   3016 / 4751 loss=4.689, nll_loss=3.101, ppl=8.58, wps=87782.7, ups=3.04, wpb=28893, bsz=921.9, num_updates=69500, lr=0.000119952, gnorm=0.419, loss_scale=2, train_wall=33, gb_free=6.3, wall=23115
2021-04-05 07:03:03 | INFO | train_inner | epoch 015:   3116 / 4751 loss=4.706, nll_loss=3.122, ppl=8.71, wps=88213, ups=3.04, wpb=29026.3, bsz=940.2, num_updates=69600, lr=0.000119866, gnorm=0.419, loss_scale=2, train_wall=33, gb_free=6.2, wall=23148
2021-04-05 07:03:36 | INFO | train_inner | epoch 015:   3216 / 4751 loss=4.683, nll_loss=3.095, ppl=8.54, wps=88166.8, ups=3.03, wpb=29070.9, bsz=954.9, num_updates=69700, lr=0.00011978, gnorm=0.416, loss_scale=2, train_wall=33, gb_free=6.2, wall=23181
2021-04-05 07:04:09 | INFO | train_inner | epoch 015:   3316 / 4751 loss=4.69, nll_loss=3.103, ppl=8.59, wps=88092, ups=3.04, wpb=28953.2, bsz=982.9, num_updates=69800, lr=0.000119694, gnorm=0.424, loss_scale=2, train_wall=33, gb_free=6.3, wall=23213
2021-04-05 07:04:42 | INFO | train_inner | epoch 015:   3416 / 4751 loss=4.719, nll_loss=3.136, ppl=8.79, wps=87850, ups=3.04, wpb=28922.5, bsz=939.8, num_updates=69900, lr=0.000119608, gnorm=0.427, loss_scale=2, train_wall=33, gb_free=7.1, wall=23246
2021-04-05 07:05:14 | INFO | train_inner | epoch 015:   3516 / 4751 loss=4.652, nll_loss=3.06, ppl=8.34, wps=87564, ups=3.04, wpb=28844.2, bsz=966.8, num_updates=70000, lr=0.000119523, gnorm=0.423, loss_scale=2, train_wall=33, gb_free=6.3, wall=23279
2021-04-05 07:05:47 | INFO | train_inner | epoch 015:   3616 / 4751 loss=4.709, nll_loss=3.124, ppl=8.72, wps=87639.5, ups=3.04, wpb=28832, bsz=908.3, num_updates=70100, lr=0.000119438, gnorm=0.423, loss_scale=2, train_wall=33, gb_free=6.1, wall=23312
2021-04-05 07:06:20 | INFO | train_inner | epoch 015:   3716 / 4751 loss=4.689, nll_loss=3.102, ppl=8.59, wps=86757.2, ups=3.02, wpb=28682.8, bsz=944.2, num_updates=70200, lr=0.000119352, gnorm=0.422, loss_scale=2, train_wall=33, gb_free=6, wall=23345
2021-04-05 07:06:53 | INFO | train_inner | epoch 015:   3816 / 4751 loss=4.731, nll_loss=3.149, ppl=8.87, wps=88145.2, ups=3.04, wpb=28948.6, bsz=904.3, num_updates=70300, lr=0.000119268, gnorm=0.42, loss_scale=2, train_wall=33, gb_free=6.4, wall=23378
2021-04-05 07:07:26 | INFO | train_inner | epoch 015:   3916 / 4751 loss=4.754, nll_loss=3.176, ppl=9.04, wps=88468.6, ups=3.04, wpb=29086.7, bsz=932.6, num_updates=70400, lr=0.000119183, gnorm=0.422, loss_scale=2, train_wall=33, gb_free=6.2, wall=23411
2021-04-05 07:07:59 | INFO | train_inner | epoch 015:   4016 / 4751 loss=4.648, nll_loss=3.056, ppl=8.32, wps=89272, ups=3.05, wpb=29310, bsz=938.3, num_updates=70500, lr=0.000119098, gnorm=0.412, loss_scale=2, train_wall=33, gb_free=6.2, wall=23444
2021-04-05 07:08:32 | INFO | train_inner | epoch 015:   4116 / 4751 loss=4.628, nll_loss=3.034, ppl=8.19, wps=87706, ups=3.04, wpb=28832.3, bsz=989.2, num_updates=70600, lr=0.000119014, gnorm=0.422, loss_scale=2, train_wall=33, gb_free=6.1, wall=23477
2021-04-05 07:09:05 | INFO | train_inner | epoch 015:   4216 / 4751 loss=4.701, nll_loss=3.116, ppl=8.67, wps=86334, ups=3.01, wpb=28716.3, bsz=970.2, num_updates=70700, lr=0.00011893, gnorm=0.425, loss_scale=2, train_wall=33, gb_free=6.2, wall=23510
2021-04-05 07:09:38 | INFO | train_inner | epoch 015:   4316 / 4751 loss=4.665, nll_loss=3.075, ppl=8.42, wps=88879.6, ups=3.05, wpb=29172.7, bsz=932, num_updates=70800, lr=0.000118846, gnorm=0.418, loss_scale=2, train_wall=33, gb_free=6.4, wall=23543
2021-04-05 07:10:11 | INFO | train_inner | epoch 015:   4416 / 4751 loss=4.726, nll_loss=3.144, ppl=8.84, wps=88410.9, ups=3.06, wpb=28900.5, bsz=926.6, num_updates=70900, lr=0.000118762, gnorm=0.439, loss_scale=2, train_wall=33, gb_free=6.3, wall=23575
2021-04-05 07:10:44 | INFO | train_inner | epoch 015:   4516 / 4751 loss=4.657, nll_loss=3.067, ppl=8.38, wps=87830.2, ups=3.02, wpb=29054.7, bsz=949.1, num_updates=71000, lr=0.000118678, gnorm=0.422, loss_scale=2, train_wall=33, gb_free=6.2, wall=23609
2021-04-05 07:11:17 | INFO | train_inner | epoch 015:   4616 / 4751 loss=4.699, nll_loss=3.113, ppl=8.65, wps=86714.3, ups=2.98, wpb=29101.1, bsz=952.2, num_updates=71100, lr=0.000118595, gnorm=0.421, loss_scale=2, train_wall=33, gb_free=6.2, wall=23642
2021-04-05 07:11:50 | INFO | train_inner | epoch 015:   4716 / 4751 loss=4.705, nll_loss=3.12, ppl=8.7, wps=86442.5, ups=3.02, wpb=28646.3, bsz=936.7, num_updates=71200, lr=0.000118511, gnorm=0.427, loss_scale=2, train_wall=33, gb_free=6.4, wall=23675
2021-04-05 07:12:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-05 07:12:03 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 4.273 | nll_loss 2.505 | ppl 5.68 | wps 200807 | wpb 10489.1 | bsz 375 | num_updates 71235 | best_loss 4.273
2021-04-05 07:12:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 71235 updates
2021-04-05 07:12:03 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 07:12:10 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 07:12:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt (epoch 15 @ 71235 updates, score 4.273) (writing took 13.07007372751832 seconds)
2021-04-05 07:12:16 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2021-04-05 07:12:16 | INFO | train | epoch 015 | loss 4.683 | nll_loss 3.095 | ppl 8.54 | wps 87145.1 | ups 3.01 | wpb 28968.1 | bsz 947.2 | num_updates 71235 | lr 0.000118482 | gnorm 0.422 | loss_scale 2 | train_wall 1557 | gb_free 7.6 | wall 23701
2021-04-05 07:12:16 | INFO | fairseq.trainer | begin training epoch 16
2021-04-05 07:12:16 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-05 07:12:39 | INFO | train_inner | epoch 016:     65 / 4751 loss=4.649, nll_loss=3.057, ppl=8.32, wps=59232.2, ups=2.07, wpb=28672, bsz=982.4, num_updates=71300, lr=0.000118428, gnorm=0.423, loss_scale=4, train_wall=33, gb_free=6.3, wall=23724
2021-04-05 07:13:12 | INFO | train_inner | epoch 016:    165 / 4751 loss=4.73, nll_loss=3.148, ppl=8.86, wps=88360.8, ups=3.06, wpb=28873.2, bsz=942.5, num_updates=71400, lr=0.000118345, gnorm=0.43, loss_scale=4, train_wall=33, gb_free=6.2, wall=23756
2021-04-05 07:13:45 | INFO | train_inner | epoch 016:    265 / 4751 loss=4.599, nll_loss=3, ppl=8, wps=88412.9, ups=3.03, wpb=29172.9, bsz=959.1, num_updates=71500, lr=0.000118262, gnorm=0.411, loss_scale=4, train_wall=33, gb_free=6.3, wall=23789
2021-04-05 07:14:18 | INFO | train_inner | epoch 016:    365 / 4751 loss=4.678, nll_loss=3.088, ppl=8.51, wps=86940.1, ups=3.03, wpb=28733.9, bsz=887.4, num_updates=71600, lr=0.00011818, gnorm=0.422, loss_scale=4, train_wall=33, gb_free=6.1, wall=23822
2021-04-05 07:14:50 | INFO | train_inner | epoch 016:    465 / 4751 loss=4.715, nll_loss=3.131, ppl=8.76, wps=88250.6, ups=3.06, wpb=28821.3, bsz=932, num_updates=71700, lr=0.000118097, gnorm=0.427, loss_scale=4, train_wall=33, gb_free=6.1, wall=23855
2021-04-05 07:15:23 | INFO | train_inner | epoch 016:    565 / 4751 loss=4.66, nll_loss=3.069, ppl=8.39, wps=87964.6, ups=3.02, wpb=29133.9, bsz=942.3, num_updates=71800, lr=0.000118015, gnorm=0.423, loss_scale=4, train_wall=33, gb_free=6.3, wall=23888
2021-04-05 07:15:56 | INFO | train_inner | epoch 016:    665 / 4751 loss=4.637, nll_loss=3.043, ppl=8.24, wps=86994.2, ups=3.03, wpb=28683.5, bsz=971.4, num_updates=71900, lr=0.000117933, gnorm=0.423, loss_scale=4, train_wall=33, gb_free=6, wall=23921
2021-04-05 07:16:29 | INFO | train_inner | epoch 016:    765 / 4751 loss=4.708, nll_loss=3.123, ppl=8.71, wps=88074, ups=3.05, wpb=28881.1, bsz=937, num_updates=72000, lr=0.000117851, gnorm=0.425, loss_scale=4, train_wall=33, gb_free=6.3, wall=23954
2021-04-05 07:17:02 | INFO | train_inner | epoch 016:    865 / 4751 loss=4.637, nll_loss=3.043, ppl=8.24, wps=88134.4, ups=3.04, wpb=28974, bsz=963.8, num_updates=72100, lr=0.000117769, gnorm=0.419, loss_scale=4, train_wall=33, gb_free=6.3, wall=23987
2021-04-05 07:17:35 | INFO | train_inner | epoch 016:    965 / 4751 loss=4.697, nll_loss=3.111, ppl=8.64, wps=86839.4, ups=3.03, wpb=28620.8, bsz=939.4, num_updates=72200, lr=0.000117688, gnorm=0.432, loss_scale=4, train_wall=33, gb_free=6.1, wall=24020
2021-04-05 07:18:08 | INFO | train_inner | epoch 016:   1065 / 4751 loss=4.695, nll_loss=3.108, ppl=8.62, wps=88316.5, ups=3.06, wpb=28881.5, bsz=959.4, num_updates=72300, lr=0.000117606, gnorm=0.424, loss_scale=4, train_wall=33, gb_free=6.1, wall=24052
2021-04-05 07:18:41 | INFO | train_inner | epoch 016:   1165 / 4751 loss=4.62, nll_loss=3.024, ppl=8.13, wps=88280.1, ups=3.03, wpb=29099, bsz=960.6, num_updates=72400, lr=0.000117525, gnorm=0.426, loss_scale=4, train_wall=33, gb_free=6.4, wall=24085
2021-04-05 07:19:13 | INFO | train_inner | epoch 016:   1265 / 4751 loss=4.692, nll_loss=3.105, ppl=8.61, wps=87901.2, ups=3.05, wpb=28822.6, bsz=978.6, num_updates=72500, lr=0.000117444, gnorm=0.422, loss_scale=4, train_wall=33, gb_free=6.2, wall=24118
2021-04-05 07:19:46 | INFO | train_inner | epoch 016:   1365 / 4751 loss=4.721, nll_loss=3.137, ppl=8.8, wps=87771.5, ups=3.02, wpb=29026.4, bsz=899.1, num_updates=72600, lr=0.000117363, gnorm=0.42, loss_scale=4, train_wall=33, gb_free=6.3, wall=24151
2021-04-05 07:20:19 | INFO | train_inner | epoch 016:   1465 / 4751 loss=4.633, nll_loss=3.039, ppl=8.22, wps=88484.5, ups=3.05, wpb=29019.3, bsz=972.3, num_updates=72700, lr=0.000117282, gnorm=0.423, loss_scale=4, train_wall=33, gb_free=6.2, wall=24184
2021-04-05 07:20:53 | INFO | train_inner | epoch 016:   1565 / 4751 loss=4.646, nll_loss=3.054, ppl=8.3, wps=85843, ups=2.96, wpb=28993, bsz=953.6, num_updates=72800, lr=0.000117202, gnorm=0.419, loss_scale=4, train_wall=34, gb_free=6.4, wall=24218
2021-04-05 07:21:26 | INFO | train_inner | epoch 016:   1665 / 4751 loss=4.678, nll_loss=3.089, ppl=8.51, wps=87349.7, ups=3.01, wpb=28977.3, bsz=961.9, num_updates=72900, lr=0.000117121, gnorm=0.418, loss_scale=4, train_wall=33, gb_free=6.2, wall=24251
2021-04-05 07:21:59 | INFO | train_inner | epoch 016:   1765 / 4751 loss=4.666, nll_loss=3.075, ppl=8.43, wps=89154, ups=3.05, wpb=29255.5, bsz=929.8, num_updates=73000, lr=0.000117041, gnorm=0.416, loss_scale=4, train_wall=33, gb_free=6.2, wall=24284
2021-04-05 07:22:32 | INFO | train_inner | epoch 016:   1865 / 4751 loss=4.67, nll_loss=3.08, ppl=8.46, wps=89049.6, ups=3.03, wpb=29398.1, bsz=948, num_updates=73100, lr=0.000116961, gnorm=0.425, loss_scale=4, train_wall=33, gb_free=6.2, wall=24317
2021-04-05 07:23:05 | INFO | train_inner | epoch 016:   1965 / 4751 loss=4.65, nll_loss=3.058, ppl=8.33, wps=88624.6, ups=3.04, wpb=29161.3, bsz=951.1, num_updates=73200, lr=0.000116881, gnorm=0.417, loss_scale=4, train_wall=33, gb_free=6.5, wall=24350
2021-04-05 07:23:38 | INFO | train_inner | epoch 016:   2065 / 4751 loss=4.658, nll_loss=3.067, ppl=8.38, wps=88374.1, ups=3.04, wpb=29045.6, bsz=928.2, num_updates=73300, lr=0.000116801, gnorm=0.416, loss_scale=4, train_wall=33, gb_free=6.1, wall=24383
2021-04-05 07:24:11 | INFO | train_inner | epoch 016:   2165 / 4751 loss=4.675, nll_loss=3.086, ppl=8.49, wps=88228.5, ups=3.05, wpb=28899.4, bsz=951.6, num_updates=73400, lr=0.000116722, gnorm=0.419, loss_scale=8, train_wall=33, gb_free=6.3, wall=24415
2021-04-05 07:24:44 | INFO | train_inner | epoch 016:   2265 / 4751 loss=4.707, nll_loss=3.123, ppl=8.71, wps=87189.6, ups=3.03, wpb=28766.7, bsz=946.7, num_updates=73500, lr=0.000116642, gnorm=0.431, loss_scale=8, train_wall=33, gb_free=6.2, wall=24448
2021-04-05 07:25:16 | INFO | train_inner | epoch 016:   2365 / 4751 loss=4.665, nll_loss=3.076, ppl=8.43, wps=87895.6, ups=3.05, wpb=28852.4, bsz=970.6, num_updates=73600, lr=0.000116563, gnorm=0.423, loss_scale=8, train_wall=33, gb_free=6.1, wall=24481
2021-04-05 07:25:49 | INFO | train_inner | epoch 016:   2465 / 4751 loss=4.683, nll_loss=3.095, ppl=8.54, wps=87696.6, ups=3.02, wpb=29011.9, bsz=936.4, num_updates=73700, lr=0.000116484, gnorm=0.425, loss_scale=8, train_wall=33, gb_free=6, wall=24514
2021-04-05 07:26:22 | INFO | train_inner | epoch 016:   2565 / 4751 loss=4.669, nll_loss=3.08, ppl=8.46, wps=88249.1, ups=3.05, wpb=28943.5, bsz=955.4, num_updates=73800, lr=0.000116405, gnorm=0.421, loss_scale=8, train_wall=33, gb_free=6.4, wall=24547
2021-04-05 07:26:55 | INFO | train_inner | epoch 016:   2665 / 4751 loss=4.652, nll_loss=3.06, ppl=8.34, wps=87818.6, ups=3.02, wpb=29093.3, bsz=943.8, num_updates=73900, lr=0.000116326, gnorm=0.41, loss_scale=8, train_wall=33, gb_free=6.4, wall=24580
2021-04-05 07:27:28 | INFO | train_inner | epoch 016:   2765 / 4751 loss=4.676, nll_loss=3.087, ppl=8.5, wps=87917.1, ups=3.04, wpb=28964.6, bsz=929.7, num_updates=74000, lr=0.000116248, gnorm=0.422, loss_scale=8, train_wall=33, gb_free=6.3, wall=24613
2021-04-05 07:28:01 | INFO | train_inner | epoch 016:   2865 / 4751 loss=4.668, nll_loss=3.079, ppl=8.45, wps=88480.8, ups=3.04, wpb=29077.6, bsz=945.1, num_updates=74100, lr=0.000116169, gnorm=0.425, loss_scale=8, train_wall=33, gb_free=6.2, wall=24646
2021-04-05 07:28:34 | INFO | train_inner | epoch 016:   2965 / 4751 loss=4.624, nll_loss=3.029, ppl=8.16, wps=87300.5, ups=3.02, wpb=28901, bsz=964.6, num_updates=74200, lr=0.000116091, gnorm=0.424, loss_scale=8, train_wall=33, gb_free=6.1, wall=24679
2021-04-05 07:29:07 | INFO | train_inner | epoch 016:   3065 / 4751 loss=4.706, nll_loss=3.121, ppl=8.7, wps=88138.6, ups=3.05, wpb=28881.8, bsz=906.6, num_updates=74300, lr=0.000116013, gnorm=0.429, loss_scale=8, train_wall=33, gb_free=6.4, wall=24712
2021-04-05 07:29:40 | INFO | train_inner | epoch 016:   3165 / 4751 loss=4.705, nll_loss=3.121, ppl=8.7, wps=88849.4, ups=3.05, wpb=29131.9, bsz=930.1, num_updates=74400, lr=0.000115935, gnorm=0.422, loss_scale=8, train_wall=33, gb_free=6.6, wall=24745
2021-04-05 07:30:13 | INFO | train_inner | epoch 016:   3265 / 4751 loss=4.656, nll_loss=3.065, ppl=8.37, wps=88460.2, ups=3.05, wpb=29016.7, bsz=924.1, num_updates=74500, lr=0.000115857, gnorm=0.422, loss_scale=8, train_wall=33, gb_free=6.3, wall=24777
2021-04-05 07:30:45 | INFO | train_inner | epoch 016:   3365 / 4751 loss=4.628, nll_loss=3.033, ppl=8.19, wps=88342.9, ups=3.06, wpb=28890.5, bsz=938.6, num_updates=74600, lr=0.000115779, gnorm=0.421, loss_scale=8, train_wall=33, gb_free=6.4, wall=24810
2021-04-05 07:31:18 | INFO | train_inner | epoch 016:   3465 / 4751 loss=4.684, nll_loss=3.098, ppl=8.56, wps=87079.9, ups=3.04, wpb=28683.9, bsz=965.1, num_updates=74700, lr=0.000115702, gnorm=0.423, loss_scale=8, train_wall=33, gb_free=6.2, wall=24843
2021-04-05 07:31:51 | INFO | train_inner | epoch 016:   3565 / 4751 loss=4.645, nll_loss=3.053, ppl=8.3, wps=88611.9, ups=3.05, wpb=29081.7, bsz=967.2, num_updates=74800, lr=0.000115624, gnorm=0.417, loss_scale=8, train_wall=33, gb_free=6.5, wall=24876
2021-04-05 07:32:24 | INFO | train_inner | epoch 016:   3665 / 4751 loss=4.688, nll_loss=3.101, ppl=8.58, wps=88624.7, ups=3.06, wpb=28928.3, bsz=935.8, num_updates=74900, lr=0.000115547, gnorm=0.429, loss_scale=8, train_wall=33, gb_free=6.4, wall=24909
2021-04-05 07:32:57 | INFO | train_inner | epoch 016:   3765 / 4751 loss=4.641, nll_loss=3.048, ppl=8.27, wps=86386.2, ups=3.01, wpb=28704.6, bsz=958, num_updates=75000, lr=0.00011547, gnorm=0.428, loss_scale=8, train_wall=33, gb_free=6.3, wall=24942
2021-04-05 07:33:30 | INFO | train_inner | epoch 016:   3865 / 4751 loss=4.677, nll_loss=3.089, ppl=8.51, wps=87388.2, ups=3.02, wpb=28969.7, bsz=931.8, num_updates=75100, lr=0.000115393, gnorm=0.417, loss_scale=8, train_wall=33, gb_free=6.6, wall=24975
2021-04-05 07:34:03 | INFO | train_inner | epoch 016:   3965 / 4751 loss=4.665, nll_loss=3.076, ppl=8.43, wps=87590, ups=3.04, wpb=28787.6, bsz=984.5, num_updates=75200, lr=0.000115316, gnorm=0.422, loss_scale=8, train_wall=33, gb_free=6.2, wall=25008
2021-04-05 07:34:36 | INFO | train_inner | epoch 016:   4065 / 4751 loss=4.742, nll_loss=3.162, ppl=8.95, wps=88094.2, ups=3.05, wpb=28875.4, bsz=910.5, num_updates=75300, lr=0.00011524, gnorm=0.423, loss_scale=8, train_wall=33, gb_free=6.2, wall=25041
2021-04-05 07:35:09 | INFO | train_inner | epoch 016:   4165 / 4751 loss=4.712, nll_loss=3.128, ppl=8.74, wps=88405.5, ups=3.04, wpb=29073.8, bsz=937.6, num_updates=75400, lr=0.000115163, gnorm=0.434, loss_scale=16, train_wall=33, gb_free=6.2, wall=25074
2021-04-05 07:35:42 | INFO | train_inner | epoch 016:   4265 / 4751 loss=4.725, nll_loss=3.143, ppl=8.84, wps=87432.8, ups=3.02, wpb=28960, bsz=964.2, num_updates=75500, lr=0.000115087, gnorm=0.426, loss_scale=16, train_wall=33, gb_free=6.7, wall=25107
2021-04-05 07:36:15 | INFO | train_inner | epoch 016:   4365 / 4751 loss=4.667, nll_loss=3.078, ppl=8.44, wps=87966.2, ups=3.02, wpb=29159, bsz=986.1, num_updates=75600, lr=0.000115011, gnorm=0.42, loss_scale=16, train_wall=33, gb_free=6.2, wall=25140
2021-04-05 07:36:48 | INFO | train_inner | epoch 016:   4465 / 4751 loss=4.65, nll_loss=3.059, ppl=8.33, wps=88636.9, ups=3.04, wpb=29186.2, bsz=978.7, num_updates=75700, lr=0.000114935, gnorm=0.42, loss_scale=16, train_wall=33, gb_free=6.2, wall=25173
2021-04-05 07:37:21 | INFO | train_inner | epoch 016:   4565 / 4751 loss=4.645, nll_loss=3.052, ppl=8.3, wps=88458.6, ups=3.04, wpb=29064.2, bsz=948.2, num_updates=75800, lr=0.000114859, gnorm=0.421, loss_scale=16, train_wall=33, gb_free=6.2, wall=25206
2021-04-05 07:37:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2021-04-05 07:37:54 | INFO | train_inner | epoch 016:   4666 / 4751 loss=4.66, nll_loss=3.07, ppl=8.39, wps=87499.6, ups=3.01, wpb=29104.9, bsz=926.9, num_updates=75900, lr=0.000114783, gnorm=0.423, loss_scale=8, train_wall=33, gb_free=6.2, wall=25239
2021-04-05 07:38:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-05 07:38:23 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 4.273 | nll_loss 2.501 | ppl 5.66 | wps 203051 | wpb 10489.1 | bsz 375 | num_updates 75985 | best_loss 4.273
2021-04-05 07:38:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 75985 updates
2021-04-05 07:38:23 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 07:38:29 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 07:38:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt (epoch 16 @ 75985 updates, score 4.273) (writing took 13.349165249615908 seconds)
2021-04-05 07:38:36 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2021-04-05 07:38:36 | INFO | train | epoch 016 | loss 4.672 | nll_loss 3.083 | ppl 8.47 | wps 87079.7 | ups 3.01 | wpb 28968 | bsz 947.2 | num_updates 75985 | lr 0.000114719 | gnorm 0.423 | loss_scale 8 | train_wall 1557 | gb_free 6.5 | wall 25281
2021-04-05 07:38:37 | INFO | fairseq.trainer | begin training epoch 17
2021-04-05 07:38:37 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-05 07:38:43 | INFO | train_inner | epoch 017:     15 / 4751 loss=4.702, nll_loss=3.117, ppl=8.68, wps=59595.1, ups=2.06, wpb=28936.2, bsz=908.8, num_updates=76000, lr=0.000114708, gnorm=0.429, loss_scale=8, train_wall=32, gb_free=6.2, wall=25287
2021-04-05 07:39:15 | INFO | train_inner | epoch 017:    115 / 4751 loss=4.624, nll_loss=3.028, ppl=8.16, wps=88791.5, ups=3.05, wpb=29104, bsz=970.1, num_updates=76100, lr=0.000114632, gnorm=0.416, loss_scale=8, train_wall=33, gb_free=6.2, wall=25320
2021-04-05 07:39:48 | INFO | train_inner | epoch 017:    215 / 4751 loss=4.71, nll_loss=3.125, ppl=8.73, wps=87916.5, ups=3.03, wpb=28999.2, bsz=902, num_updates=76200, lr=0.000114557, gnorm=0.433, loss_scale=8, train_wall=33, gb_free=6, wall=25353
2021-04-05 07:40:21 | INFO | train_inner | epoch 017:    315 / 4751 loss=4.615, nll_loss=3.017, ppl=8.1, wps=88867.1, ups=3.03, wpb=29289.4, bsz=950.2, num_updates=76300, lr=0.000114482, gnorm=0.422, loss_scale=8, train_wall=33, gb_free=6.3, wall=25386
2021-04-05 07:40:54 | INFO | train_inner | epoch 017:    415 / 4751 loss=4.643, nll_loss=3.049, ppl=8.28, wps=88095.4, ups=3.04, wpb=28985.4, bsz=940.6, num_updates=76400, lr=0.000114407, gnorm=0.42, loss_scale=8, train_wall=33, gb_free=6.3, wall=25419
2021-04-05 07:41:27 | INFO | train_inner | epoch 017:    515 / 4751 loss=4.631, nll_loss=3.037, ppl=8.21, wps=87286.1, ups=3.03, wpb=28822.2, bsz=950.6, num_updates=76500, lr=0.000114332, gnorm=0.421, loss_scale=8, train_wall=33, gb_free=6.1, wall=25452
2021-04-05 07:42:00 | INFO | train_inner | epoch 017:    615 / 4751 loss=4.644, nll_loss=3.051, ppl=8.29, wps=87484.3, ups=3.03, wpb=28869.4, bsz=956, num_updates=76600, lr=0.000114258, gnorm=0.42, loss_scale=8, train_wall=33, gb_free=6.6, wall=25485
2021-04-05 07:42:33 | INFO | train_inner | epoch 017:    715 / 4751 loss=4.691, nll_loss=3.104, ppl=8.6, wps=87734.1, ups=3.04, wpb=28892.5, bsz=922.6, num_updates=76700, lr=0.000114183, gnorm=0.42, loss_scale=8, train_wall=33, gb_free=6.1, wall=25518
2021-04-05 07:43:06 | INFO | train_inner | epoch 017:    815 / 4751 loss=4.64, nll_loss=3.047, ppl=8.27, wps=88077.9, ups=3.04, wpb=28962.2, bsz=957.8, num_updates=76800, lr=0.000114109, gnorm=0.425, loss_scale=8, train_wall=33, gb_free=6.2, wall=25551
2021-04-05 07:43:39 | INFO | train_inner | epoch 017:    915 / 4751 loss=4.614, nll_loss=3.017, ppl=8.1, wps=88745.1, ups=3.04, wpb=29182.3, bsz=959.8, num_updates=76900, lr=0.000114035, gnorm=0.426, loss_scale=8, train_wall=33, gb_free=6.4, wall=25584
2021-04-05 07:44:12 | INFO | train_inner | epoch 017:   1015 / 4751 loss=4.691, nll_loss=3.104, ppl=8.6, wps=88571, ups=3.04, wpb=29092, bsz=956.1, num_updates=77000, lr=0.000113961, gnorm=0.42, loss_scale=8, train_wall=33, gb_free=6.2, wall=25617
2021-04-05 07:44:45 | INFO | train_inner | epoch 017:   1115 / 4751 loss=4.712, nll_loss=3.129, ppl=8.75, wps=88742.8, ups=3.05, wpb=29082, bsz=936.3, num_updates=77100, lr=0.000113887, gnorm=0.426, loss_scale=8, train_wall=33, gb_free=6.2, wall=25649
2021-04-05 07:45:18 | INFO | train_inner | epoch 017:   1215 / 4751 loss=4.665, nll_loss=3.075, ppl=8.43, wps=86415.6, ups=2.97, wpb=29098.8, bsz=943.5, num_updates=77200, lr=0.000113813, gnorm=0.425, loss_scale=8, train_wall=34, gb_free=6.5, wall=25683
2021-04-05 07:45:51 | INFO | train_inner | epoch 017:   1315 / 4751 loss=4.721, nll_loss=3.139, ppl=8.81, wps=87924.4, ups=3.05, wpb=28832.4, bsz=946.1, num_updates=77300, lr=0.000113739, gnorm=0.435, loss_scale=8, train_wall=33, gb_free=6.3, wall=25716
2021-04-05 07:46:24 | INFO | train_inner | epoch 017:   1415 / 4751 loss=4.687, nll_loss=3.1, ppl=8.57, wps=88272.2, ups=3.04, wpb=29002.2, bsz=941.9, num_updates=77400, lr=0.000113666, gnorm=0.426, loss_scale=8, train_wall=33, gb_free=6.3, wall=25749
2021-04-05 07:46:57 | INFO | train_inner | epoch 017:   1515 / 4751 loss=4.638, nll_loss=3.044, ppl=8.25, wps=89086.8, ups=3.05, wpb=29194.5, bsz=952, num_updates=77500, lr=0.000113592, gnorm=0.419, loss_scale=8, train_wall=33, gb_free=6.1, wall=25781
2021-04-05 07:46:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2021-04-05 07:47:30 | INFO | train_inner | epoch 017:   1616 / 4751 loss=4.716, nll_loss=3.133, ppl=8.77, wps=88037.2, ups=3.02, wpb=29142.2, bsz=927.2, num_updates=77600, lr=0.000113519, gnorm=0.432, loss_scale=4, train_wall=33, gb_free=6.1, wall=25815
2021-04-05 07:48:03 | INFO | train_inner | epoch 017:   1716 / 4751 loss=4.637, nll_loss=3.043, ppl=8.24, wps=87235.6, ups=3.03, wpb=28778.4, bsz=951.4, num_updates=77700, lr=0.000113446, gnorm=0.423, loss_scale=4, train_wall=33, gb_free=6.3, wall=25848
2021-04-05 07:48:36 | INFO | train_inner | epoch 017:   1816 / 4751 loss=4.689, nll_loss=3.102, ppl=8.58, wps=86737.7, ups=3.02, wpb=28706.8, bsz=918.6, num_updates=77800, lr=0.000113373, gnorm=0.43, loss_scale=4, train_wall=33, gb_free=6.3, wall=25881
2021-04-05 07:49:09 | INFO | train_inner | epoch 017:   1916 / 4751 loss=4.688, nll_loss=3.101, ppl=8.58, wps=88365.5, ups=3.03, wpb=29122.5, bsz=936.2, num_updates=77900, lr=0.0001133, gnorm=0.429, loss_scale=4, train_wall=33, gb_free=6.2, wall=25914
2021-04-05 07:49:42 | INFO | train_inner | epoch 017:   2016 / 4751 loss=4.696, nll_loss=3.11, ppl=8.63, wps=87994.7, ups=3.04, wpb=28954.1, bsz=935.4, num_updates=78000, lr=0.000113228, gnorm=0.424, loss_scale=4, train_wall=33, gb_free=6.1, wall=25946
2021-04-05 07:50:15 | INFO | train_inner | epoch 017:   2116 / 4751 loss=4.645, nll_loss=3.052, ppl=8.29, wps=88061.8, ups=3.03, wpb=29061.1, bsz=941.1, num_updates=78100, lr=0.000113155, gnorm=0.424, loss_scale=4, train_wall=33, gb_free=6.6, wall=25979
2021-04-05 07:50:47 | INFO | train_inner | epoch 017:   2216 / 4751 loss=4.639, nll_loss=3.046, ppl=8.26, wps=87870.1, ups=3.05, wpb=28786, bsz=973.9, num_updates=78200, lr=0.000113083, gnorm=0.42, loss_scale=4, train_wall=33, gb_free=6.3, wall=26012
2021-04-05 07:51:20 | INFO | train_inner | epoch 017:   2316 / 4751 loss=4.664, nll_loss=3.074, ppl=8.42, wps=87718.4, ups=3.04, wpb=28847.8, bsz=945.6, num_updates=78300, lr=0.000113011, gnorm=0.428, loss_scale=4, train_wall=33, gb_free=6.3, wall=26045
2021-04-05 07:51:53 | INFO | train_inner | epoch 017:   2416 / 4751 loss=4.665, nll_loss=3.076, ppl=8.43, wps=88205, ups=3.04, wpb=29008.4, bsz=963.3, num_updates=78400, lr=0.000112938, gnorm=0.417, loss_scale=4, train_wall=33, gb_free=6.1, wall=26078
2021-04-05 07:52:26 | INFO | train_inner | epoch 017:   2516 / 4751 loss=4.665, nll_loss=3.075, ppl=8.43, wps=87016.7, ups=3.02, wpb=28823.8, bsz=951.5, num_updates=78500, lr=0.000112867, gnorm=0.423, loss_scale=4, train_wall=33, gb_free=6.2, wall=26111
2021-04-05 07:52:59 | INFO | train_inner | epoch 017:   2616 / 4751 loss=4.675, nll_loss=3.087, ppl=8.5, wps=88414.2, ups=3.06, wpb=28920.7, bsz=936.3, num_updates=78600, lr=0.000112795, gnorm=0.427, loss_scale=4, train_wall=33, gb_free=6.1, wall=26144
2021-04-05 07:53:32 | INFO | train_inner | epoch 017:   2716 / 4751 loss=4.688, nll_loss=3.101, ppl=8.58, wps=88435.6, ups=3.05, wpb=29030.7, bsz=933, num_updates=78700, lr=0.000112723, gnorm=0.428, loss_scale=4, train_wall=33, gb_free=6.5, wall=26177
2021-04-05 07:54:05 | INFO | train_inner | epoch 017:   2816 / 4751 loss=4.648, nll_loss=3.056, ppl=8.32, wps=86299.5, ups=2.99, wpb=28824.8, bsz=930.3, num_updates=78800, lr=0.000112651, gnorm=0.42, loss_scale=4, train_wall=33, gb_free=6.4, wall=26210
2021-04-05 07:54:38 | INFO | train_inner | epoch 017:   2916 / 4751 loss=4.608, nll_loss=3.01, ppl=8.06, wps=88653.5, ups=3.06, wpb=29005.3, bsz=962.4, num_updates=78900, lr=0.00011258, gnorm=0.419, loss_scale=4, train_wall=33, gb_free=6.1, wall=26243
2021-04-05 07:55:11 | INFO | train_inner | epoch 017:   3016 / 4751 loss=4.63, nll_loss=3.037, ppl=8.21, wps=88388.5, ups=3.04, wpb=29085.6, bsz=975.2, num_updates=79000, lr=0.000112509, gnorm=0.423, loss_scale=4, train_wall=33, gb_free=6.3, wall=26276
2021-04-05 07:55:44 | INFO | train_inner | epoch 017:   3116 / 4751 loss=4.615, nll_loss=3.019, ppl=8.11, wps=89161.2, ups=3.03, wpb=29394.6, bsz=974.3, num_updates=79100, lr=0.000112438, gnorm=0.414, loss_scale=4, train_wall=33, gb_free=6.9, wall=26309
2021-04-05 07:56:17 | INFO | train_inner | epoch 017:   3216 / 4751 loss=4.675, nll_loss=3.087, ppl=8.5, wps=88271.2, ups=3.05, wpb=28973, bsz=921.8, num_updates=79200, lr=0.000112367, gnorm=0.425, loss_scale=4, train_wall=33, gb_free=6.2, wall=26342
2021-04-05 07:56:50 | INFO | train_inner | epoch 017:   3316 / 4751 loss=4.642, nll_loss=3.049, ppl=8.28, wps=86846.6, ups=3.01, wpb=28822.9, bsz=919.8, num_updates=79300, lr=0.000112296, gnorm=0.424, loss_scale=4, train_wall=33, gb_free=6.2, wall=26375
2021-04-05 07:57:23 | INFO | train_inner | epoch 017:   3416 / 4751 loss=4.647, nll_loss=3.056, ppl=8.32, wps=88107.6, ups=3.04, wpb=29014, bsz=937.9, num_updates=79400, lr=0.000112225, gnorm=0.423, loss_scale=4, train_wall=33, gb_free=6.4, wall=26408
2021-04-05 07:57:56 | INFO | train_inner | epoch 017:   3516 / 4751 loss=4.692, nll_loss=3.106, ppl=8.61, wps=87337.4, ups=3.03, wpb=28854.4, bsz=936, num_updates=79500, lr=0.000112154, gnorm=0.425, loss_scale=4, train_wall=33, gb_free=6.7, wall=26441
2021-04-05 07:58:29 | INFO | train_inner | epoch 017:   3616 / 4751 loss=4.637, nll_loss=3.044, ppl=8.25, wps=88010.3, ups=3.03, wpb=29015.3, bsz=960.2, num_updates=79600, lr=0.000112084, gnorm=0.426, loss_scale=8, train_wall=33, gb_free=6.4, wall=26474
2021-04-05 07:59:02 | INFO | train_inner | epoch 017:   3716 / 4751 loss=4.625, nll_loss=3.031, ppl=8.17, wps=87672.2, ups=3.04, wpb=28862.3, bsz=947.6, num_updates=79700, lr=0.000112014, gnorm=0.42, loss_scale=8, train_wall=33, gb_free=6.2, wall=26507
2021-04-05 07:59:35 | INFO | train_inner | epoch 017:   3816 / 4751 loss=4.608, nll_loss=3.011, ppl=8.06, wps=88394.6, ups=3.04, wpb=29041.4, bsz=970.7, num_updates=79800, lr=0.000111943, gnorm=0.423, loss_scale=8, train_wall=33, gb_free=6.1, wall=26539
2021-04-05 08:00:08 | INFO | train_inner | epoch 017:   3916 / 4751 loss=4.66, nll_loss=3.071, ppl=8.4, wps=87398.6, ups=3.04, wpb=28782, bsz=981.6, num_updates=79900, lr=0.000111873, gnorm=0.432, loss_scale=8, train_wall=33, gb_free=6, wall=26572
2021-04-05 08:00:40 | INFO | train_inner | epoch 017:   4016 / 4751 loss=4.645, nll_loss=3.053, ppl=8.3, wps=88265, ups=3.04, wpb=28987, bsz=941, num_updates=80000, lr=0.000111803, gnorm=0.419, loss_scale=8, train_wall=33, gb_free=6.2, wall=26605
2021-04-05 08:01:13 | INFO | train_inner | epoch 017:   4116 / 4751 loss=4.643, nll_loss=3.051, ppl=8.29, wps=87187.4, ups=3.02, wpb=28884.6, bsz=949.8, num_updates=80100, lr=0.000111734, gnorm=0.421, loss_scale=8, train_wall=33, gb_free=6.2, wall=26638
2021-04-05 08:01:46 | INFO | train_inner | epoch 017:   4216 / 4751 loss=4.697, nll_loss=3.112, ppl=8.65, wps=88226.7, ups=3.06, wpb=28870.6, bsz=924.8, num_updates=80200, lr=0.000111664, gnorm=0.433, loss_scale=8, train_wall=33, gb_free=6, wall=26671
2021-04-05 08:02:19 | INFO | train_inner | epoch 017:   4316 / 4751 loss=4.688, nll_loss=3.102, ppl=8.58, wps=89433.7, ups=3.05, wpb=29356.7, bsz=937.9, num_updates=80300, lr=0.000111594, gnorm=0.422, loss_scale=8, train_wall=33, gb_free=6.3, wall=26704
2021-04-05 08:02:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2021-04-05 08:02:52 | INFO | train_inner | epoch 017:   4417 / 4751 loss=4.7, nll_loss=3.115, ppl=8.67, wps=86677.6, ups=3.02, wpb=28725.2, bsz=930.8, num_updates=80400, lr=0.000111525, gnorm=0.428, loss_scale=4, train_wall=33, gb_free=6.2, wall=26737
2021-04-05 08:03:25 | INFO | train_inner | epoch 017:   4517 / 4751 loss=4.667, nll_loss=3.078, ppl=8.45, wps=87171, ups=3.03, wpb=28787.5, bsz=973, num_updates=80500, lr=0.000111456, gnorm=0.426, loss_scale=4, train_wall=33, gb_free=6.4, wall=26770
2021-04-05 08:03:58 | INFO | train_inner | epoch 017:   4617 / 4751 loss=4.702, nll_loss=3.117, ppl=8.68, wps=88392.2, ups=3.04, wpb=29043.8, bsz=956, num_updates=80600, lr=0.000111386, gnorm=0.433, loss_scale=4, train_wall=33, gb_free=6.3, wall=26803
2021-04-05 08:04:31 | INFO | train_inner | epoch 017:   4717 / 4751 loss=4.68, nll_loss=3.093, ppl=8.53, wps=87699, ups=3.04, wpb=28848.6, bsz=985, num_updates=80700, lr=0.000111317, gnorm=0.43, loss_scale=4, train_wall=33, gb_free=6.6, wall=26836
2021-04-05 08:04:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-05 08:04:43 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 4.273 | nll_loss 2.502 | ppl 5.66 | wps 206602 | wpb 10489.1 | bsz 375 | num_updates 80734 | best_loss 4.273
2021-04-05 08:04:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 80734 updates
2021-04-05 08:04:43 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 08:04:50 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 08:04:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt (epoch 17 @ 80734 updates, score 4.273) (writing took 13.215376775711775 seconds)
2021-04-05 08:04:57 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2021-04-05 08:04:57 | INFO | train | epoch 017 | loss 4.661 | nll_loss 3.071 | ppl 8.4 | wps 87058.1 | ups 3.01 | wpb 28967.8 | bsz 946.7 | num_updates 80734 | lr 0.000111294 | gnorm 0.424 | loss_scale 4 | train_wall 1558 | gb_free 6.7 | wall 26861
2021-04-05 08:04:57 | INFO | fairseq.trainer | begin training epoch 18
2021-04-05 08:04:57 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-05 08:05:19 | INFO | train_inner | epoch 018:     66 / 4751 loss=4.62, nll_loss=3.025, ppl=8.14, wps=59907.9, ups=2.07, wpb=28960.8, bsz=965.3, num_updates=80800, lr=0.000111249, gnorm=0.43, loss_scale=4, train_wall=32, gb_free=6.4, wall=26884
2021-04-05 08:05:52 | INFO | train_inner | epoch 018:    166 / 4751 loss=4.665, nll_loss=3.075, ppl=8.43, wps=88247.8, ups=3.04, wpb=28987.3, bsz=966.2, num_updates=80900, lr=0.00011118, gnorm=0.43, loss_scale=4, train_wall=33, gb_free=6, wall=26917
2021-04-05 08:06:25 | INFO | train_inner | epoch 018:    266 / 4751 loss=4.619, nll_loss=3.023, ppl=8.13, wps=88070.4, ups=3.03, wpb=29039.6, bsz=938.9, num_updates=81000, lr=0.000111111, gnorm=0.418, loss_scale=4, train_wall=33, gb_free=6.2, wall=26950
2021-04-05 08:06:58 | INFO | train_inner | epoch 018:    366 / 4751 loss=4.606, nll_loss=3.008, ppl=8.05, wps=88843, ups=3.03, wpb=29277, bsz=971, num_updates=81100, lr=0.000111043, gnorm=0.424, loss_scale=4, train_wall=33, gb_free=6.2, wall=26983
2021-04-05 08:07:31 | INFO | train_inner | epoch 018:    466 / 4751 loss=4.628, nll_loss=3.033, ppl=8.19, wps=87114.6, ups=3.03, wpb=28716.8, bsz=917.2, num_updates=81200, lr=0.000110974, gnorm=0.421, loss_scale=4, train_wall=33, gb_free=6.2, wall=27016
2021-04-05 08:08:04 | INFO | train_inner | epoch 018:    566 / 4751 loss=4.588, nll_loss=2.988, ppl=7.94, wps=88278.5, ups=3.02, wpb=29184.4, bsz=988.7, num_updates=81300, lr=0.000110906, gnorm=0.421, loss_scale=4, train_wall=33, gb_free=6.3, wall=27049
2021-04-05 08:08:37 | INFO | train_inner | epoch 018:    666 / 4751 loss=4.562, nll_loss=2.958, ppl=7.77, wps=88306.7, ups=3.03, wpb=29137.2, bsz=974.2, num_updates=81400, lr=0.000110838, gnorm=0.427, loss_scale=4, train_wall=33, gb_free=6, wall=27082
2021-04-05 08:09:10 | INFO | train_inner | epoch 018:    766 / 4751 loss=4.691, nll_loss=3.105, ppl=8.6, wps=88716.4, ups=3.04, wpb=29179.7, bsz=928.7, num_updates=81500, lr=0.00011077, gnorm=0.43, loss_scale=4, train_wall=33, gb_free=6.2, wall=27115
2021-04-05 08:09:43 | INFO | train_inner | epoch 018:    866 / 4751 loss=4.679, nll_loss=3.091, ppl=8.52, wps=87869.1, ups=3.03, wpb=28955.6, bsz=956.4, num_updates=81600, lr=0.000110702, gnorm=0.43, loss_scale=4, train_wall=33, gb_free=6.1, wall=27148
2021-04-05 08:10:16 | INFO | train_inner | epoch 018:    966 / 4751 loss=4.717, nll_loss=3.135, ppl=8.78, wps=87466.4, ups=3.03, wpb=28906.2, bsz=948.3, num_updates=81700, lr=0.000110634, gnorm=0.433, loss_scale=4, train_wall=33, gb_free=6.2, wall=27181
2021-04-05 08:10:49 | INFO | train_inner | epoch 018:   1066 / 4751 loss=4.656, nll_loss=3.065, ppl=8.37, wps=88565.6, ups=3.04, wpb=29105, bsz=965.8, num_updates=81800, lr=0.000110566, gnorm=0.424, loss_scale=4, train_wall=33, gb_free=6.3, wall=27214
2021-04-05 08:11:22 | INFO | train_inner | epoch 018:   1166 / 4751 loss=4.669, nll_loss=3.079, ppl=8.45, wps=87976.3, ups=3.04, wpb=28977.2, bsz=946.6, num_updates=81900, lr=0.000110499, gnorm=0.422, loss_scale=4, train_wall=33, gb_free=6.4, wall=27247
2021-04-05 08:11:55 | INFO | train_inner | epoch 018:   1266 / 4751 loss=4.63, nll_loss=3.035, ppl=8.2, wps=88695.8, ups=3.04, wpb=29162, bsz=961.2, num_updates=82000, lr=0.000110432, gnorm=0.424, loss_scale=4, train_wall=33, gb_free=6.5, wall=27279
2021-04-05 08:12:27 | INFO | train_inner | epoch 018:   1366 / 4751 loss=4.656, nll_loss=3.065, ppl=8.37, wps=88478.9, ups=3.05, wpb=29021.1, bsz=942.6, num_updates=82100, lr=0.000110364, gnorm=0.423, loss_scale=4, train_wall=33, gb_free=6.3, wall=27312
2021-04-05 08:13:01 | INFO | train_inner | epoch 018:   1466 / 4751 loss=4.668, nll_loss=3.079, ppl=8.45, wps=87705.7, ups=3.02, wpb=29021.2, bsz=929.8, num_updates=82200, lr=0.000110297, gnorm=0.422, loss_scale=4, train_wall=33, gb_free=6.1, wall=27345
2021-04-05 08:13:34 | INFO | train_inner | epoch 018:   1566 / 4751 loss=4.655, nll_loss=3.064, ppl=8.36, wps=87700.4, ups=3.01, wpb=29103.1, bsz=949, num_updates=82300, lr=0.00011023, gnorm=0.419, loss_scale=4, train_wall=33, gb_free=6.2, wall=27379
2021-04-05 08:14:06 | INFO | train_inner | epoch 018:   1666 / 4751 loss=4.614, nll_loss=3.018, ppl=8.1, wps=88562.9, ups=3.05, wpb=28996.9, bsz=934.5, num_updates=82400, lr=0.000110163, gnorm=0.425, loss_scale=4, train_wall=33, gb_free=6.2, wall=27411
2021-04-05 08:14:40 | INFO | train_inner | epoch 018:   1766 / 4751 loss=4.662, nll_loss=3.072, ppl=8.41, wps=87839.8, ups=3.02, wpb=29044.7, bsz=951.4, num_updates=82500, lr=0.000110096, gnorm=0.425, loss_scale=8, train_wall=33, gb_free=6.5, wall=27444
2021-04-05 08:15:12 | INFO | train_inner | epoch 018:   1866 / 4751 loss=4.677, nll_loss=3.089, ppl=8.51, wps=87732.4, ups=3.04, wpb=28860.2, bsz=937.6, num_updates=82600, lr=0.00011003, gnorm=0.428, loss_scale=8, train_wall=33, gb_free=6.6, wall=27477
2021-04-05 08:15:45 | INFO | train_inner | epoch 018:   1966 / 4751 loss=4.672, nll_loss=3.084, ppl=8.48, wps=87519.1, ups=3.06, wpb=28641.4, bsz=946.1, num_updates=82700, lr=0.000109963, gnorm=0.431, loss_scale=8, train_wall=33, gb_free=7, wall=27510
2021-04-05 08:16:19 | INFO | train_inner | epoch 018:   2066 / 4751 loss=4.652, nll_loss=3.061, ppl=8.34, wps=85105.7, ups=2.97, wpb=28653.8, bsz=963.5, num_updates=82800, lr=0.000109897, gnorm=0.428, loss_scale=8, train_wall=34, gb_free=6.2, wall=27544
2021-04-05 08:16:52 | INFO | train_inner | epoch 018:   2166 / 4751 loss=4.641, nll_loss=3.048, ppl=8.27, wps=88026.5, ups=3.04, wpb=28954.9, bsz=931.1, num_updates=82900, lr=0.00010983, gnorm=0.423, loss_scale=8, train_wall=33, gb_free=6.3, wall=27577
2021-04-05 08:17:24 | INFO | train_inner | epoch 018:   2266 / 4751 loss=4.664, nll_loss=3.075, ppl=8.43, wps=89059.5, ups=3.05, wpb=29168.5, bsz=926.6, num_updates=83000, lr=0.000109764, gnorm=0.429, loss_scale=8, train_wall=33, gb_free=6.6, wall=27609
2021-04-05 08:17:57 | INFO | train_inner | epoch 018:   2366 / 4751 loss=4.656, nll_loss=3.066, ppl=8.37, wps=88431.9, ups=3.06, wpb=28918.3, bsz=914.1, num_updates=83100, lr=0.000109698, gnorm=0.427, loss_scale=8, train_wall=33, gb_free=6.3, wall=27642
2021-04-05 08:18:30 | INFO | train_inner | epoch 018:   2466 / 4751 loss=4.619, nll_loss=3.023, ppl=8.13, wps=88130.4, ups=3.04, wpb=28959.6, bsz=930.3, num_updates=83200, lr=0.000109632, gnorm=0.429, loss_scale=8, train_wall=33, gb_free=6.2, wall=27675
2021-04-05 08:19:03 | INFO | train_inner | epoch 018:   2566 / 4751 loss=4.625, nll_loss=3.031, ppl=8.17, wps=88434.5, ups=3.04, wpb=29089.2, bsz=955.6, num_updates=83300, lr=0.000109566, gnorm=0.427, loss_scale=8, train_wall=33, gb_free=6.3, wall=27708
2021-04-05 08:19:36 | INFO | train_inner | epoch 018:   2666 / 4751 loss=4.687, nll_loss=3.101, ppl=8.58, wps=88158, ups=3.06, wpb=28799.2, bsz=963.8, num_updates=83400, lr=0.000109501, gnorm=0.428, loss_scale=8, train_wall=33, gb_free=6.4, wall=27740
2021-04-05 08:19:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2021-04-05 08:20:09 | INFO | train_inner | epoch 018:   2767 / 4751 loss=4.684, nll_loss=3.098, ppl=8.56, wps=87091.1, ups=3.01, wpb=28904.2, bsz=950.2, num_updates=83500, lr=0.000109435, gnorm=0.432, loss_scale=4, train_wall=33, gb_free=6.5, wall=27774
2021-04-05 08:20:42 | INFO | train_inner | epoch 018:   2867 / 4751 loss=4.622, nll_loss=3.027, ppl=8.15, wps=86903.6, ups=3.01, wpb=28827.7, bsz=949.5, num_updates=83600, lr=0.00010937, gnorm=0.426, loss_scale=4, train_wall=33, gb_free=6.2, wall=27807
2021-04-05 08:21:15 | INFO | train_inner | epoch 018:   2967 / 4751 loss=4.7, nll_loss=3.116, ppl=8.67, wps=88612.4, ups=3.03, wpb=29241, bsz=970.4, num_updates=83700, lr=0.000109304, gnorm=0.431, loss_scale=4, train_wall=33, gb_free=6.4, wall=27840
2021-04-05 08:21:48 | INFO | train_inner | epoch 018:   3067 / 4751 loss=4.624, nll_loss=3.03, ppl=8.17, wps=86922.5, ups=3.03, wpb=28641.4, bsz=946.4, num_updates=83800, lr=0.000109239, gnorm=0.434, loss_scale=4, train_wall=33, gb_free=6.2, wall=27873
2021-04-05 08:22:21 | INFO | train_inner | epoch 018:   3167 / 4751 loss=4.655, nll_loss=3.065, ppl=8.37, wps=88853.7, ups=3.04, wpb=29233, bsz=971.3, num_updates=83900, lr=0.000109174, gnorm=0.428, loss_scale=4, train_wall=33, gb_free=6.2, wall=27906
2021-04-05 08:22:54 | INFO | train_inner | epoch 018:   3267 / 4751 loss=4.646, nll_loss=3.054, ppl=8.31, wps=87429.5, ups=3.01, wpb=29061.8, bsz=940.2, num_updates=84000, lr=0.000109109, gnorm=0.423, loss_scale=4, train_wall=33, gb_free=6.3, wall=27939
2021-04-05 08:23:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-05 08:23:28 | INFO | train_inner | epoch 018:   3368 / 4751 loss=4.594, nll_loss=2.996, ppl=7.98, wps=86351.8, ups=2.98, wpb=28968.1, bsz=944.8, num_updates=84100, lr=0.000109044, gnorm=0.424, loss_scale=2, train_wall=33, gb_free=6.5, wall=27972
2021-04-05 08:24:00 | INFO | train_inner | epoch 018:   3468 / 4751 loss=4.625, nll_loss=3.031, ppl=8.17, wps=89187.3, ups=3.04, wpb=29335.5, bsz=935.9, num_updates=84200, lr=0.000108979, gnorm=0.419, loss_scale=2, train_wall=33, gb_free=6.1, wall=28005
2021-04-05 08:24:33 | INFO | train_inner | epoch 018:   3568 / 4751 loss=4.678, nll_loss=3.091, ppl=8.52, wps=88580, ups=3.05, wpb=29006.2, bsz=952.5, num_updates=84300, lr=0.000108915, gnorm=0.431, loss_scale=2, train_wall=33, gb_free=6.9, wall=28038
2021-04-05 08:25:06 | INFO | train_inner | epoch 018:   3668 / 4751 loss=4.674, nll_loss=3.086, ppl=8.49, wps=88293.7, ups=3.05, wpb=28962.5, bsz=915.8, num_updates=84400, lr=0.00010885, gnorm=0.428, loss_scale=2, train_wall=33, gb_free=6.2, wall=28071
2021-04-05 08:25:39 | INFO | train_inner | epoch 018:   3768 / 4751 loss=4.693, nll_loss=3.108, ppl=8.62, wps=87772.1, ups=3.05, wpb=28779.7, bsz=899.1, num_updates=84500, lr=0.000108786, gnorm=0.434, loss_scale=2, train_wall=33, gb_free=6.2, wall=28104
2021-04-05 08:26:12 | INFO | train_inner | epoch 018:   3868 / 4751 loss=4.634, nll_loss=3.041, ppl=8.23, wps=87796.8, ups=3.03, wpb=28997.2, bsz=970.9, num_updates=84600, lr=0.000108721, gnorm=0.425, loss_scale=2, train_wall=33, gb_free=6.4, wall=28137
2021-04-05 08:26:45 | INFO | train_inner | epoch 018:   3968 / 4751 loss=4.64, nll_loss=3.048, ppl=8.27, wps=87751.9, ups=3.05, wpb=28771.4, bsz=967.7, num_updates=84700, lr=0.000108657, gnorm=0.426, loss_scale=2, train_wall=33, gb_free=6.3, wall=28169
2021-04-05 08:27:18 | INFO | train_inner | epoch 018:   4068 / 4751 loss=4.671, nll_loss=3.083, ppl=8.48, wps=87514.8, ups=3.04, wpb=28785.1, bsz=949.5, num_updates=84800, lr=0.000108593, gnorm=0.428, loss_scale=2, train_wall=33, gb_free=6.3, wall=28202
2021-04-05 08:27:50 | INFO | train_inner | epoch 018:   4168 / 4751 loss=4.65, nll_loss=3.059, ppl=8.34, wps=88030.1, ups=3.04, wpb=28960.3, bsz=958.3, num_updates=84900, lr=0.000108529, gnorm=0.424, loss_scale=2, train_wall=33, gb_free=6.3, wall=28235
2021-04-05 08:28:23 | INFO | train_inner | epoch 018:   4268 / 4751 loss=4.68, nll_loss=3.092, ppl=8.53, wps=87464.8, ups=3.03, wpb=28818.7, bsz=918.6, num_updates=85000, lr=0.000108465, gnorm=0.431, loss_scale=2, train_wall=33, gb_free=6.3, wall=28268
2021-04-05 08:28:56 | INFO | train_inner | epoch 018:   4368 / 4751 loss=4.645, nll_loss=3.054, ppl=8.3, wps=87114.4, ups=3.04, wpb=28652.7, bsz=941.6, num_updates=85100, lr=0.000108401, gnorm=0.424, loss_scale=2, train_wall=33, gb_free=6.3, wall=28301
2021-04-05 08:29:29 | INFO | train_inner | epoch 018:   4468 / 4751 loss=4.676, nll_loss=3.089, ppl=8.51, wps=88926.3, ups=3.04, wpb=29235.7, bsz=984.4, num_updates=85200, lr=0.000108338, gnorm=0.428, loss_scale=2, train_wall=33, gb_free=6.3, wall=28334
2021-04-05 08:30:02 | INFO | train_inner | epoch 018:   4568 / 4751 loss=4.665, nll_loss=3.076, ppl=8.43, wps=87631, ups=3.03, wpb=28920, bsz=939.1, num_updates=85300, lr=0.000108274, gnorm=0.429, loss_scale=2, train_wall=33, gb_free=6, wall=28367
2021-04-05 08:30:35 | INFO | train_inner | epoch 018:   4668 / 4751 loss=4.686, nll_loss=3.1, ppl=8.57, wps=87711.6, ups=3.05, wpb=28754, bsz=899.8, num_updates=85400, lr=0.000108211, gnorm=0.431, loss_scale=2, train_wall=33, gb_free=6.2, wall=28400
2021-04-05 08:31:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-05 08:31:03 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 4.257 | nll_loss 2.49 | ppl 5.62 | wps 211728 | wpb 10489.1 | bsz 375 | num_updates 85483 | best_loss 4.257
2021-04-05 08:31:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 85483 updates
2021-04-05 08:31:03 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 08:31:09 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 08:31:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt (epoch 18 @ 85483 updates, score 4.257) (writing took 13.49798583984375 seconds)
2021-04-05 08:31:17 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2021-04-05 08:31:17 | INFO | train | epoch 018 | loss 4.652 | nll_loss 3.061 | ppl 8.35 | wps 87059.4 | ups 3.01 | wpb 28968 | bsz 946.7 | num_updates 85483 | lr 0.000108158 | gnorm 0.427 | loss_scale 2 | train_wall 1557 | gb_free 6.2 | wall 28442
2021-04-05 08:31:17 | INFO | fairseq.trainer | begin training epoch 19
2021-04-05 08:31:17 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-05 08:31:24 | INFO | train_inner | epoch 019:     17 / 4751 loss=4.657, nll_loss=3.067, ppl=8.38, wps=58641.4, ups=2.06, wpb=28530.5, bsz=930.3, num_updates=85500, lr=0.000108148, gnorm=0.433, loss_scale=2, train_wall=32, gb_free=6.2, wall=28448
2021-04-05 08:31:56 | INFO | train_inner | epoch 019:    117 / 4751 loss=4.624, nll_loss=3.029, ppl=8.16, wps=87936.5, ups=3.05, wpb=28786.8, bsz=963, num_updates=85600, lr=0.000108084, gnorm=0.432, loss_scale=2, train_wall=33, gb_free=6.1, wall=28481
2021-04-05 08:32:29 | INFO | train_inner | epoch 019:    217 / 4751 loss=4.656, nll_loss=3.066, ppl=8.37, wps=88800.2, ups=3.06, wpb=29059.3, bsz=959.8, num_updates=85700, lr=0.000108021, gnorm=0.432, loss_scale=2, train_wall=33, gb_free=6.2, wall=28514
2021-04-05 08:33:02 | INFO | train_inner | epoch 019:    317 / 4751 loss=4.627, nll_loss=3.032, ppl=8.18, wps=88692, ups=3.02, wpb=29340.2, bsz=933.4, num_updates=85800, lr=0.000107958, gnorm=0.415, loss_scale=2, train_wall=33, gb_free=6.2, wall=28547
2021-04-05 08:33:35 | INFO | train_inner | epoch 019:    417 / 4751 loss=4.633, nll_loss=3.039, ppl=8.22, wps=88354.3, ups=3.04, wpb=29104.8, bsz=970.7, num_updates=85900, lr=0.000107896, gnorm=0.422, loss_scale=2, train_wall=33, gb_free=6.2, wall=28580
2021-04-05 08:34:08 | INFO | train_inner | epoch 019:    517 / 4751 loss=4.643, nll_loss=3.05, ppl=8.28, wps=89594.4, ups=3.06, wpb=29272.7, bsz=971.7, num_updates=86000, lr=0.000107833, gnorm=0.425, loss_scale=2, train_wall=33, gb_free=6.1, wall=28613
2021-04-05 08:34:41 | INFO | train_inner | epoch 019:    617 / 4751 loss=4.646, nll_loss=3.054, ppl=8.3, wps=88308, ups=3.04, wpb=29008.7, bsz=951.8, num_updates=86100, lr=0.00010777, gnorm=0.433, loss_scale=4, train_wall=33, gb_free=6, wall=28645
2021-04-05 08:35:14 | INFO | train_inner | epoch 019:    717 / 4751 loss=4.574, nll_loss=2.973, ppl=7.85, wps=88295.3, ups=3.04, wpb=29090.2, bsz=1001.4, num_updates=86200, lr=0.000107708, gnorm=0.422, loss_scale=4, train_wall=33, gb_free=6.1, wall=28678
2021-04-05 08:35:47 | INFO | train_inner | epoch 019:    817 / 4751 loss=4.59, nll_loss=2.991, ppl=7.95, wps=87676.5, ups=3.03, wpb=28917.6, bsz=938.8, num_updates=86300, lr=0.000107645, gnorm=0.431, loss_scale=4, train_wall=33, gb_free=6.2, wall=28711
2021-04-05 08:36:19 | INFO | train_inner | epoch 019:    917 / 4751 loss=4.604, nll_loss=3.007, ppl=8.04, wps=88667.5, ups=3.04, wpb=29144.6, bsz=951.2, num_updates=86400, lr=0.000107583, gnorm=0.423, loss_scale=4, train_wall=33, gb_free=6.2, wall=28744
2021-04-05 08:36:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-05 08:36:53 | INFO | train_inner | epoch 019:   1018 / 4751 loss=4.662, nll_loss=3.072, ppl=8.41, wps=86853.1, ups=3, wpb=28997.2, bsz=909.4, num_updates=86500, lr=0.000107521, gnorm=0.45, loss_scale=2, train_wall=33, gb_free=6.7, wall=28778
2021-04-05 08:37:26 | INFO | train_inner | epoch 019:   1118 / 4751 loss=4.641, nll_loss=3.049, ppl=8.27, wps=88962, ups=3.05, wpb=29193, bsz=990, num_updates=86600, lr=0.000107459, gnorm=0.437, loss_scale=2, train_wall=33, gb_free=6.3, wall=28810
2021-04-05 08:37:59 | INFO | train_inner | epoch 019:   1218 / 4751 loss=4.644, nll_loss=3.052, ppl=8.29, wps=86883, ups=3.02, wpb=28760.3, bsz=925.8, num_updates=86700, lr=0.000107397, gnorm=0.428, loss_scale=2, train_wall=33, gb_free=6.1, wall=28844
2021-04-05 08:38:32 | INFO | train_inner | epoch 019:   1318 / 4751 loss=4.645, nll_loss=3.053, ppl=8.3, wps=86280.3, ups=2.98, wpb=28988, bsz=929.7, num_updates=86800, lr=0.000107335, gnorm=0.428, loss_scale=2, train_wall=33, gb_free=6.1, wall=28877
2021-04-05 08:39:05 | INFO | train_inner | epoch 019:   1418 / 4751 loss=4.616, nll_loss=3.021, ppl=8.11, wps=88205.5, ups=3.05, wpb=28929.8, bsz=963.6, num_updates=86900, lr=0.000107273, gnorm=0.42, loss_scale=2, train_wall=33, gb_free=6.1, wall=28910
2021-04-05 08:39:38 | INFO | train_inner | epoch 019:   1518 / 4751 loss=4.666, nll_loss=3.076, ppl=8.43, wps=86725.7, ups=3.02, wpb=28742.2, bsz=950, num_updates=87000, lr=0.000107211, gnorm=0.428, loss_scale=2, train_wall=33, gb_free=6.3, wall=28943
2021-04-05 08:40:11 | INFO | train_inner | epoch 019:   1618 / 4751 loss=4.661, nll_loss=3.071, ppl=8.4, wps=87786.7, ups=3.05, wpb=28794, bsz=923.2, num_updates=87100, lr=0.00010715, gnorm=0.428, loss_scale=2, train_wall=33, gb_free=6.5, wall=28976
2021-04-05 08:40:44 | INFO | train_inner | epoch 019:   1718 / 4751 loss=4.66, nll_loss=3.071, ppl=8.4, wps=87034.4, ups=3.04, wpb=28649.9, bsz=920.2, num_updates=87200, lr=0.000107088, gnorm=0.434, loss_scale=2, train_wall=33, gb_free=6.6, wall=29009
2021-04-05 08:41:17 | INFO | train_inner | epoch 019:   1818 / 4751 loss=4.647, nll_loss=3.055, ppl=8.31, wps=88916.8, ups=3.06, wpb=29093.4, bsz=938.3, num_updates=87300, lr=0.000107027, gnorm=0.423, loss_scale=2, train_wall=33, gb_free=6, wall=29042
2021-04-05 08:41:50 | INFO | train_inner | epoch 019:   1918 / 4751 loss=4.687, nll_loss=3.101, ppl=8.58, wps=87043.8, ups=3.03, wpb=28691.5, bsz=954, num_updates=87400, lr=0.000106966, gnorm=0.433, loss_scale=2, train_wall=33, gb_free=6.4, wall=29074
2021-04-05 08:42:22 | INFO | train_inner | epoch 019:   2018 / 4751 loss=4.648, nll_loss=3.056, ppl=8.32, wps=88838.4, ups=3.06, wpb=29073.3, bsz=928.1, num_updates=87500, lr=0.000106904, gnorm=0.433, loss_scale=2, train_wall=33, gb_free=6.3, wall=29107
2021-04-05 08:42:55 | INFO | train_inner | epoch 019:   2118 / 4751 loss=4.655, nll_loss=3.064, ppl=8.36, wps=88183.1, ups=3.05, wpb=28945.3, bsz=910.7, num_updates=87600, lr=0.000106843, gnorm=0.426, loss_scale=2, train_wall=33, gb_free=6.2, wall=29140
2021-04-05 08:43:28 | INFO | train_inner | epoch 019:   2218 / 4751 loss=4.603, nll_loss=3.006, ppl=8.03, wps=89442.7, ups=3.03, wpb=29517.2, bsz=954.2, num_updates=87700, lr=0.000106783, gnorm=0.421, loss_scale=2, train_wall=33, gb_free=6.1, wall=29173
2021-04-05 08:44:01 | INFO | train_inner | epoch 019:   2318 / 4751 loss=4.691, nll_loss=3.106, ppl=8.61, wps=87905.1, ups=3.05, wpb=28836.5, bsz=950.8, num_updates=87800, lr=0.000106722, gnorm=0.434, loss_scale=2, train_wall=33, gb_free=6.3, wall=29206
2021-04-05 08:44:34 | INFO | train_inner | epoch 019:   2418 / 4751 loss=4.652, nll_loss=3.062, ppl=8.35, wps=88220.5, ups=3.03, wpb=29103.5, bsz=931.4, num_updates=87900, lr=0.000106661, gnorm=0.422, loss_scale=2, train_wall=33, gb_free=6.3, wall=29239
2021-04-05 08:45:07 | INFO | train_inner | epoch 019:   2518 / 4751 loss=4.673, nll_loss=3.086, ppl=8.49, wps=87771.5, ups=3.04, wpb=28896.7, bsz=931.1, num_updates=88000, lr=0.0001066, gnorm=0.433, loss_scale=2, train_wall=33, gb_free=6.3, wall=29272
2021-04-05 08:45:40 | INFO | train_inner | epoch 019:   2618 / 4751 loss=4.657, nll_loss=3.067, ppl=8.38, wps=86183.9, ups=3, wpb=28767.9, bsz=973, num_updates=88100, lr=0.00010654, gnorm=0.43, loss_scale=2, train_wall=33, gb_free=6.3, wall=29305
2021-04-05 08:46:13 | INFO | train_inner | epoch 019:   2718 / 4751 loss=4.667, nll_loss=3.078, ppl=8.44, wps=88460.2, ups=3.05, wpb=29043.9, bsz=959.6, num_updates=88200, lr=0.000106479, gnorm=0.43, loss_scale=2, train_wall=33, gb_free=6.2, wall=29338
2021-04-05 08:46:46 | INFO | train_inner | epoch 019:   2818 / 4751 loss=4.639, nll_loss=3.047, ppl=8.26, wps=87814.1, ups=3.03, wpb=29007.3, bsz=941.6, num_updates=88300, lr=0.000106419, gnorm=0.427, loss_scale=2, train_wall=33, gb_free=6.3, wall=29371
2021-04-05 08:47:19 | INFO | train_inner | epoch 019:   2918 / 4751 loss=4.63, nll_loss=3.036, ppl=8.2, wps=87400.7, ups=3.05, wpb=28646.9, bsz=919.4, num_updates=88400, lr=0.000106359, gnorm=0.433, loss_scale=2, train_wall=33, gb_free=6.1, wall=29404
2021-04-05 08:47:52 | INFO | train_inner | epoch 019:   3018 / 4751 loss=4.631, nll_loss=3.038, ppl=8.21, wps=87174.1, ups=3.02, wpb=28839.9, bsz=975.4, num_updates=88500, lr=0.000106299, gnorm=0.431, loss_scale=4, train_wall=33, gb_free=6.4, wall=29437
2021-04-05 08:48:25 | INFO | train_inner | epoch 019:   3118 / 4751 loss=4.642, nll_loss=3.05, ppl=8.28, wps=88638.3, ups=3.05, wpb=29089.3, bsz=943, num_updates=88600, lr=0.000106239, gnorm=0.425, loss_scale=4, train_wall=33, gb_free=6.3, wall=29470
2021-04-05 08:48:58 | INFO | train_inner | epoch 019:   3218 / 4751 loss=4.665, nll_loss=3.076, ppl=8.43, wps=88144.4, ups=3.06, wpb=28816.7, bsz=927.3, num_updates=88700, lr=0.000106179, gnorm=0.431, loss_scale=4, train_wall=33, gb_free=6.3, wall=29502
2021-04-05 08:49:30 | INFO | train_inner | epoch 019:   3318 / 4751 loss=4.667, nll_loss=3.078, ppl=8.44, wps=89168.9, ups=3.05, wpb=29204.6, bsz=936.2, num_updates=88800, lr=0.000106119, gnorm=0.423, loss_scale=4, train_wall=33, gb_free=6.5, wall=29535
2021-04-05 08:50:03 | INFO | train_inner | epoch 019:   3418 / 4751 loss=4.605, nll_loss=3.008, ppl=8.04, wps=89574, ups=3.04, wpb=29437.5, bsz=956.6, num_updates=88900, lr=0.000106059, gnorm=0.422, loss_scale=4, train_wall=33, gb_free=6.2, wall=29568
2021-04-05 08:50:36 | INFO | train_inner | epoch 019:   3518 / 4751 loss=4.623, nll_loss=3.029, ppl=8.16, wps=88559.6, ups=3.05, wpb=29047.5, bsz=942, num_updates=89000, lr=0.000106, gnorm=0.429, loss_scale=4, train_wall=33, gb_free=6.2, wall=29601
2021-04-05 08:51:09 | INFO | train_inner | epoch 019:   3618 / 4751 loss=4.664, nll_loss=3.075, ppl=8.43, wps=87477.6, ups=3.05, wpb=28659.6, bsz=993.5, num_updates=89100, lr=0.00010594, gnorm=0.426, loss_scale=4, train_wall=33, gb_free=6.3, wall=29634
2021-04-05 08:51:42 | INFO | train_inner | epoch 019:   3718 / 4751 loss=4.658, nll_loss=3.068, ppl=8.39, wps=87526.7, ups=3.03, wpb=28906.3, bsz=924.1, num_updates=89200, lr=0.000105881, gnorm=0.431, loss_scale=4, train_wall=33, gb_free=6.3, wall=29667
2021-04-05 08:52:15 | INFO | train_inner | epoch 019:   3818 / 4751 loss=4.595, nll_loss=2.998, ppl=7.99, wps=87057.6, ups=3.03, wpb=28766.5, bsz=954.2, num_updates=89300, lr=0.000105822, gnorm=0.427, loss_scale=4, train_wall=33, gb_free=6.2, wall=29700
2021-04-05 08:52:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-05 08:52:48 | INFO | train_inner | epoch 019:   3919 / 4751 loss=4.623, nll_loss=3.029, ppl=8.16, wps=88061.2, ups=3, wpb=29338, bsz=964.1, num_updates=89400, lr=0.000105762, gnorm=0.426, loss_scale=2, train_wall=33, gb_free=6.3, wall=29733
2021-04-05 08:53:21 | INFO | train_inner | epoch 019:   4019 / 4751 loss=4.632, nll_loss=3.039, ppl=8.22, wps=88555.2, ups=3.05, wpb=29048.9, bsz=970.5, num_updates=89500, lr=0.000105703, gnorm=0.427, loss_scale=2, train_wall=33, gb_free=6.2, wall=29766
2021-04-05 08:53:54 | INFO | train_inner | epoch 019:   4119 / 4751 loss=4.665, nll_loss=3.076, ppl=8.43, wps=88348.8, ups=3.03, wpb=29182.5, bsz=942.6, num_updates=89600, lr=0.000105644, gnorm=0.421, loss_scale=2, train_wall=33, gb_free=6.4, wall=29799
2021-04-05 08:54:27 | INFO | train_inner | epoch 019:   4219 / 4751 loss=4.725, nll_loss=3.145, ppl=8.85, wps=87873, ups=3.06, wpb=28759.2, bsz=932.3, num_updates=89700, lr=0.000105585, gnorm=0.435, loss_scale=2, train_wall=33, gb_free=6.2, wall=29831
2021-04-05 08:55:00 | INFO | train_inner | epoch 019:   4319 / 4751 loss=4.668, nll_loss=3.08, ppl=8.46, wps=87515.6, ups=3.03, wpb=28871.6, bsz=931.5, num_updates=89800, lr=0.000105527, gnorm=0.428, loss_scale=2, train_wall=33, gb_free=6, wall=29864
2021-04-05 08:55:33 | INFO | train_inner | epoch 019:   4419 / 4751 loss=4.718, nll_loss=3.136, ppl=8.79, wps=86765.6, ups=3.04, wpb=28511.6, bsz=895.5, num_updates=89900, lr=0.000105468, gnorm=0.435, loss_scale=2, train_wall=33, gb_free=6.3, wall=29897
2021-04-05 08:56:06 | INFO | train_inner | epoch 019:   4519 / 4751 loss=4.614, nll_loss=3.019, ppl=8.11, wps=87308.9, ups=3.02, wpb=28956.1, bsz=968.1, num_updates=90000, lr=0.000105409, gnorm=0.443, loss_scale=2, train_wall=33, gb_free=6.1, wall=29930
2021-04-05 08:56:39 | INFO | train_inner | epoch 019:   4619 / 4751 loss=4.569, nll_loss=2.967, ppl=7.82, wps=87416.7, ups=3.01, wpb=29014.8, bsz=951.5, num_updates=90100, lr=0.000105351, gnorm=0.419, loss_scale=2, train_wall=33, gb_free=6.3, wall=29964
2021-04-05 08:57:12 | INFO | train_inner | epoch 019:   4719 / 4751 loss=4.624, nll_loss=3.03, ppl=8.17, wps=87849.8, ups=3.03, wpb=28967.3, bsz=947.8, num_updates=90200, lr=0.000105292, gnorm=0.424, loss_scale=2, train_wall=33, gb_free=6.2, wall=29997
2021-04-05 08:57:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-05 08:57:23 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 4.261 | nll_loss 2.485 | ppl 5.6 | wps 192364 | wpb 10489.1 | bsz 375 | num_updates 90232 | best_loss 4.257
2021-04-05 08:57:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 90232 updates
2021-04-05 08:57:23 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-05 08:57:30 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-05 08:57:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt (epoch 19 @ 90232 updates, score 4.261) (writing took 6.1910813972353935 seconds)
2021-04-05 08:57:30 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2021-04-05 08:57:30 | INFO | train | epoch 019 | loss 4.643 | nll_loss 3.052 | ppl 8.29 | wps 87458.3 | ups 3.02 | wpb 28967.8 | bsz 946.8 | num_updates 90232 | lr 0.000105274 | gnorm 0.429 | loss_scale 2 | train_wall 1558 | gb_free 6.7 | wall 30015
2021-04-05 08:57:30 | INFO | fairseq.trainer | begin training epoch 20
2021-04-05 08:57:30 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-05 08:57:53 | INFO | train_inner | epoch 020:     68 / 4751 loss=4.71, nll_loss=3.127, ppl=8.74, wps=69358.9, ups=2.43, wpb=28571.5, bsz=931.9, num_updates=90300, lr=0.000105234, gnorm=0.432, loss_scale=2, train_wall=32, gb_free=6.1, wall=30038
2021-04-05 08:58:26 | INFO | train_inner | epoch 020:    168 / 4751 loss=4.625, nll_loss=3.031, ppl=8.17, wps=87236.2, ups=3.05, wpb=28580.1, bsz=928.1, num_updates=90400, lr=0.000105176, gnorm=0.44, loss_scale=2, train_wall=33, gb_free=6.4, wall=30071
2021-04-05 08:58:59 | INFO | train_inner | epoch 020:    268 / 4751 loss=4.66, nll_loss=3.07, ppl=8.4, wps=88341.8, ups=3.05, wpb=28943.4, bsz=961.3, num_updates=90500, lr=0.000105118, gnorm=0.432, loss_scale=2, train_wall=33, gb_free=6.2, wall=30103
2021-04-05 08:59:31 | INFO | train_inner | epoch 020:    368 / 4751 loss=4.625, nll_loss=3.03, ppl=8.17, wps=89051.8, ups=3.05, wpb=29241.5, bsz=958.1, num_updates=90600, lr=0.00010506, gnorm=0.429, loss_scale=2, train_wall=33, gb_free=6, wall=30136
2021-04-05 09:00:04 | INFO | train_inner | epoch 020:    468 / 4751 loss=4.625, nll_loss=3.031, ppl=8.17, wps=88640.8, ups=3.04, wpb=29140, bsz=943, num_updates=90700, lr=0.000105002, gnorm=0.428, loss_scale=2, train_wall=33, gb_free=6.1, wall=30169
2021-04-05 09:00:37 | INFO | train_inner | epoch 020:    568 / 4751 loss=4.586, nll_loss=2.986, ppl=7.93, wps=88517.2, ups=3.04, wpb=29145.3, bsz=980.4, num_updates=90800, lr=0.000104944, gnorm=0.425, loss_scale=2, train_wall=33, gb_free=6.2, wall=30202
2021-04-05 09:01:10 | INFO | train_inner | epoch 020:    668 / 4751 loss=4.637, nll_loss=3.044, ppl=8.25, wps=87316.8, ups=3.03, wpb=28774, bsz=926.6, num_updates=90900, lr=0.000104886, gnorm=0.429, loss_scale=2, train_wall=33, gb_free=6.3, wall=30235
2021-04-05 09:01:43 | INFO | train_inner | epoch 020:    768 / 4751 loss=4.646, nll_loss=3.054, ppl=8.31, wps=87895.5, ups=3.03, wpb=28981.7, bsz=936.2, num_updates=91000, lr=0.000104828, gnorm=0.436, loss_scale=2, train_wall=33, gb_free=6.1, wall=30268
2021-04-05 09:02:16 | INFO | train_inner | epoch 020:    868 / 4751 loss=4.615, nll_loss=3.019, ppl=8.1, wps=88193.3, ups=3.04, wpb=29014.9, bsz=934.7, num_updates=91100, lr=0.000104771, gnorm=0.426, loss_scale=2, train_wall=33, gb_free=6.1, wall=30301
2021-04-05 09:02:49 | INFO | train_inner | epoch 020:    968 / 4751 loss=4.656, nll_loss=3.066, ppl=8.37, wps=88601.6, ups=3.05, wpb=29050, bsz=922.4, num_updates=91200, lr=0.000104713, gnorm=0.423, loss_scale=2, train_wall=33, gb_free=6, wall=30334
2021-04-05 09:03:22 | INFO | train_inner | epoch 020:   1068 / 4751 loss=4.601, nll_loss=3.004, ppl=8.02, wps=87115.1, ups=3.01, wpb=28904.9, bsz=972.4, num_updates=91300, lr=0.000104656, gnorm=0.425, loss_scale=2, train_wall=33, gb_free=6.4, wall=30367
2021-04-05 09:03:56 | INFO | train_inner | epoch 020:   1168 / 4751 loss=4.576, nll_loss=2.975, ppl=7.86, wps=86638.4, ups=2.98, wpb=29113, bsz=933.2, num_updates=91400, lr=0.000104599, gnorm=0.421, loss_scale=4, train_wall=33, gb_free=6.4, wall=30400
2021-04-05 09:04:28 | INFO | train_inner | epoch 020:   1268 / 4751 loss=4.721, nll_loss=3.139, ppl=8.81, wps=89423, ups=3.07, wpb=29115.7, bsz=920.2, num_updates=91500, lr=0.000104542, gnorm=0.434, loss_scale=4, train_wall=32, gb_free=6.1, wall=30433
2021-04-05 09:05:01 | INFO | train_inner | epoch 020:   1368 / 4751 loss=4.61, nll_loss=3.014, ppl=8.08, wps=88189.1, ups=3.03, wpb=29072.3, bsz=982.5, num_updates=91600, lr=0.000104485, gnorm=0.426, loss_scale=4, train_wall=33, gb_free=6.4, wall=30466
2021-04-05 09:05:34 | INFO | train_inner | epoch 020:   1468 / 4751 loss=4.637, nll_loss=3.044, ppl=8.25, wps=88128.2, ups=3.06, wpb=28802.3, bsz=928.2, num_updates=91700, lr=0.000104428, gnorm=0.437, loss_scale=4, train_wall=33, gb_free=6.1, wall=30499
2021-04-05 09:06:07 | INFO | train_inner | epoch 020:   1568 / 4751 loss=4.603, nll_loss=3.006, ppl=8.03, wps=87695.5, ups=3.03, wpb=28920.9, bsz=933.4, num_updates=91800, lr=0.000104371, gnorm=0.433, loss_scale=4, train_wall=33, gb_free=6.3, wall=30532
2021-04-05 09:06:40 | INFO | train_inner | epoch 020:   1668 / 4751 loss=4.602, nll_loss=3.004, ppl=8.02, wps=88086.2, ups=3.02, wpb=29148, bsz=937, num_updates=91900, lr=0.000104314, gnorm=0.425, loss_scale=4, train_wall=33, gb_free=6.2, wall=30565
2021-04-05 09:07:13 | INFO | train_inner | epoch 020:   1768 / 4751 loss=4.617, nll_loss=3.023, ppl=8.13, wps=87346.5, ups=3.02, wpb=28904.1, bsz=960.7, num_updates=92000, lr=0.000104257, gnorm=0.432, loss_scale=4, train_wall=33, gb_free=6.2, wall=30598
2021-04-05 09:07:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-05 09:07:46 | INFO | train_inner | epoch 020:   1869 / 4751 loss=4.562, nll_loss=2.959, ppl=7.78, wps=86856.5, ups=3, wpb=28921.1, bsz=959.2, num_updates=92100, lr=0.000104201, gnorm=0.423, loss_scale=2, train_wall=33, gb_free=6.3, wall=30631
2021-04-05 09:08:19 | INFO | train_inner | epoch 020:   1969 / 4751 loss=4.608, nll_loss=3.011, ppl=8.06, wps=87439.1, ups=3.03, wpb=28813, bsz=952.2, num_updates=92200, lr=0.000104144, gnorm=0.432, loss_scale=2, train_wall=33, gb_free=6.2, wall=30664
2021-04-05 09:08:52 | INFO | train_inner | epoch 020:   2069 / 4751 loss=4.657, nll_loss=3.067, ppl=8.38, wps=87654.6, ups=3.03, wpb=28932.6, bsz=934.7, num_updates=92300, lr=0.000104088, gnorm=0.438, loss_scale=2, train_wall=33, gb_free=6.2, wall=30697
2021-04-05 09:09:25 | INFO | train_inner | epoch 020:   2169 / 4751 loss=4.689, nll_loss=3.103, ppl=8.59, wps=87986.7, ups=3.03, wpb=29037.4, bsz=956.8, num_updates=92400, lr=0.000104031, gnorm=0.435, loss_scale=2, train_wall=33, gb_free=6.3, wall=30730
2021-04-05 09:09:58 | INFO | train_inner | epoch 020:   2269 / 4751 loss=4.673, nll_loss=3.086, ppl=8.49, wps=88004.2, ups=3.03, wpb=29004.9, bsz=935.9, num_updates=92500, lr=0.000103975, gnorm=0.428, loss_scale=2, train_wall=33, gb_free=6.5, wall=30763
2021-04-05 09:10:31 | INFO | train_inner | epoch 020:   2369 / 4751 loss=4.669, nll_loss=3.081, ppl=8.46, wps=87566, ups=3.05, wpb=28679.3, bsz=937, num_updates=92600, lr=0.000103919, gnorm=0.434, loss_scale=2, train_wall=33, gb_free=6.1, wall=30796
2021-04-05 09:11:04 | INFO | train_inner | epoch 020:   2469 / 4751 loss=4.619, nll_loss=3.025, ppl=8.14, wps=88611.3, ups=3.02, wpb=29304.8, bsz=966.8, num_updates=92700, lr=0.000103863, gnorm=0.422, loss_scale=2, train_wall=33, gb_free=6.4, wall=30829
2021-04-05 09:11:37 | INFO | train_inner | epoch 020:   2569 / 4751 loss=4.676, nll_loss=3.088, ppl=8.5, wps=87422.3, ups=3.03, wpb=28816.1, bsz=938.2, num_updates=92800, lr=0.000103807, gnorm=0.432, loss_scale=2, train_wall=33, gb_free=6.2, wall=30862
2021-04-05 09:12:10 | INFO | train_inner | epoch 020:   2669 / 4751 loss=4.611, nll_loss=3.014, ppl=8.08, wps=88199.5, ups=3.05, wpb=28936.9, bsz=939.4, num_updates=92900, lr=0.000103751, gnorm=0.425, loss_scale=2, train_wall=33, gb_free=6.3, wall=30895
2021-04-05 09:12:43 | INFO | train_inner | epoch 020:   2769 / 4751 loss=4.62, nll_loss=3.025, ppl=8.14, wps=88566.9, ups=3.04, wpb=29155.9, bsz=921, num_updates=93000, lr=0.000103695, gnorm=0.428, loss_scale=2, train_wall=33, gb_free=6.2, wall=30928
2021-04-05 09:13:16 | INFO | train_inner | epoch 020:   2869 / 4751 loss=4.65, nll_loss=3.059, ppl=8.33, wps=87878, ups=3.04, wpb=28882.7, bsz=961.7, num_updates=93100, lr=0.000103639, gnorm=0.437, loss_scale=2, train_wall=33, gb_free=6.3, wall=30960
2021-04-05 09:13:49 | INFO | train_inner | epoch 020:   2969 / 4751 loss=4.639, nll_loss=3.046, ppl=8.26, wps=87694.6, ups=3.03, wpb=28983.9, bsz=933.7, num_updates=93200, lr=0.000103584, gnorm=0.425, loss_scale=2, train_wall=33, gb_free=6.2, wall=30993
2021-04-05 09:14:21 | INFO | train_inner | epoch 020:   3069 / 4751 loss=4.66, nll_loss=3.071, ppl=8.4, wps=87682.3, ups=3.05, wpb=28711.9, bsz=944.9, num_updates=93300, lr=0.000103528, gnorm=0.434, loss_scale=2, train_wall=33, gb_free=6.3, wall=31026
2021-04-05 09:14:54 | INFO | train_inner | epoch 020:   3169 / 4751 loss=4.667, nll_loss=3.079, ppl=8.45, wps=88350.4, ups=3.04, wpb=29017.4, bsz=958.3, num_updates=93400, lr=0.000103473, gnorm=0.424, loss_scale=2, train_wall=33, gb_free=6.2, wall=31059
2021-04-05 09:15:27 | INFO | train_inner | epoch 020:   3269 / 4751 loss=4.682, nll_loss=3.096, ppl=8.55, wps=88810.1, ups=3.05, wpb=29140.2, bsz=977.9, num_updates=93500, lr=0.000103418, gnorm=0.426, loss_scale=2, train_wall=33, gb_free=6.4, wall=31092
2021-04-05 09:16:00 | INFO | train_inner | epoch 020:   3369 / 4751 loss=4.621, nll_loss=3.026, ppl=8.15, wps=88437.1, ups=3.05, wpb=29006.3, bsz=952.2, num_updates=93600, lr=0.000103362, gnorm=0.432, loss_scale=2, train_wall=33, gb_free=6.1, wall=31125
2021-04-05 09:16:33 | INFO | train_inner | epoch 020:   3469 / 4751 loss=4.627, nll_loss=3.034, ppl=8.19, wps=87717.6, ups=3.01, wpb=29137.5, bsz=951.1, num_updates=93700, lr=0.000103307, gnorm=0.426, loss_scale=2, train_wall=33, gb_free=6.4, wall=31158
2021-04-05 09:17:06 | INFO | train_inner | epoch 020:   3569 / 4751 loss=4.542, nll_loss=2.937, ppl=7.66, wps=88376.1, ups=3.04, wpb=29109.3, bsz=946.8, num_updates=93800, lr=0.000103252, gnorm=0.42, loss_scale=2, train_wall=33, gb_free=6.2, wall=31191
2021-04-05 09:17:39 | INFO | train_inner | epoch 020:   3669 / 4751 loss=4.656, nll_loss=3.066, ppl=8.37, wps=88206.3, ups=3.04, wpb=29009, bsz=953.9, num_updates=93900, lr=0.000103197, gnorm=0.429, loss_scale=2, train_wall=33, gb_free=6.2, wall=31224
2021-04-05 09:18:12 | INFO | train_inner | epoch 020:   3769 / 4751 loss=4.685, nll_loss=3.099, ppl=8.57, wps=88195.5, ups=3.04, wpb=28979.9, bsz=933, num_updates=94000, lr=0.000103142, gnorm=0.433, loss_scale=2, train_wall=33, gb_free=7.1, wall=31257
2021-04-05 09:18:45 | INFO | train_inner | epoch 020:   3869 / 4751 loss=4.638, nll_loss=3.046, ppl=8.26, wps=88256.4, ups=3.04, wpb=29036.4, bsz=970.4, num_updates=94100, lr=0.000103087, gnorm=0.428, loss_scale=2, train_wall=33, gb_free=6, wall=31289
2021-04-05 09:19:18 | INFO | train_inner | epoch 020:   3969 / 4751 loss=4.591, nll_loss=2.993, ppl=7.96, wps=88014.8, ups=3.04, wpb=28964.1, bsz=958.2, num_updates=94200, lr=0.000103033, gnorm=0.447, loss_scale=4, train_wall=33, gb_free=6.4, wall=31322
2021-04-05 09:19:50 | INFO | train_inner | epoch 020:   4069 / 4751 loss=4.634, nll_loss=3.041, ppl=8.23, wps=87662.6, ups=3.04, wpb=28838, bsz=927.8, num_updates=94300, lr=0.000102978, gnorm=0.438, loss_scale=4, train_wall=33, gb_free=6.9, wall=31355
2021-04-05 09:20:23 | INFO | train_inner | epoch 020:   4169 / 4751 loss=4.646, nll_loss=3.055, ppl=8.31, wps=88765.8, ups=3.06, wpb=29041.1, bsz=971.1, num_updates=94400, lr=0.000102923, gnorm=0.423, loss_scale=4, train_wall=33, gb_free=6.1, wall=31388
2021-04-05 09:20:56 | INFO | train_inner | epoch 020:   4269 / 4751 loss=4.663, nll_loss=3.074, ppl=8.42, wps=87884, ups=3.05, wpb=28818.9, bsz=934.5, num_updates=94500, lr=0.000102869, gnorm=0.437, loss_scale=4, train_wall=33, gb_free=6.3, wall=31421
2021-04-05 09:21:29 | INFO | train_inner | epoch 020:   4369 / 4751 loss=4.631, nll_loss=3.038, ppl=8.21, wps=87085.3, ups=3.04, wpb=28605.6, bsz=939.4, num_updates=94600, lr=0.000102815, gnorm=0.446, loss_scale=4, train_wall=33, gb_free=6.7, wall=31454
2021-04-05 09:22:02 | INFO | train_inner | epoch 020:   4469 / 4751 loss=4.631, nll_loss=3.038, ppl=8.22, wps=87576.1, ups=3.03, wpb=28870.7, bsz=917.3, num_updates=94700, lr=0.00010276, gnorm=0.429, loss_scale=4, train_wall=33, gb_free=6.4, wall=31487
2021-04-05 09:22:35 | INFO | train_inner | epoch 020:   4569 / 4751 loss=4.649, nll_loss=3.058, ppl=8.33, wps=87819.3, ups=3.05, wpb=28812.3, bsz=968.3, num_updates=94800, lr=0.000102706, gnorm=0.43, loss_scale=4, train_wall=33, gb_free=6.4, wall=31519
2021-04-05 09:23:07 | INFO | train_inner | epoch 020:   4669 / 4751 loss=4.628, nll_loss=3.034, ppl=8.19, wps=88850, ups=3.05, wpb=29123.9, bsz=937.8, num_updates=94900, lr=0.000102652, gnorm=0.427, loss_scale=4, train_wall=33, gb_free=6.3, wall=31552
2021-04-05 09:23:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-05 09:23:35 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 4.258 | nll_loss 2.487 | ppl 5.61 | wps 194919 | wpb 10489.1 | bsz 375 | num_updates 94982 | best_loss 4.257
2021-04-05 09:23:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 94982 updates
2021-04-05 09:23:35 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-05 09:23:42 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-05 09:23:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt (epoch 20 @ 94982 updates, score 4.258) (writing took 6.206923637539148 seconds)
2021-04-05 09:23:42 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2021-04-05 09:23:42 | INFO | train | epoch 020 | loss 4.635 | nll_loss 3.043 | ppl 8.24 | wps 87539.2 | ups 3.02 | wpb 28967.9 | bsz 947 | num_updates 94982 | lr 0.000102608 | gnorm 0.43 | loss_scale 4 | train_wall 1556 | gb_free 6.5 | wall 31586
2021-04-05 09:23:42 | INFO | fairseq.trainer | begin training epoch 21
2021-04-05 09:23:42 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-05 09:23:49 | INFO | train_inner | epoch 021:     18 / 4751 loss=4.644, nll_loss=3.053, ppl=8.3, wps=70253.1, ups=2.42, wpb=29040, bsz=958.1, num_updates=95000, lr=0.000102598, gnorm=0.43, loss_scale=4, train_wall=32, gb_free=6.2, wall=31593
2021-04-05 09:24:21 | INFO | train_inner | epoch 021:    118 / 4751 loss=4.602, nll_loss=3.004, ppl=8.02, wps=88848.5, ups=3.07, wpb=28980, bsz=944.5, num_updates=95100, lr=0.000102544, gnorm=0.426, loss_scale=4, train_wall=32, gb_free=6.2, wall=31626
2021-04-05 09:24:54 | INFO | train_inner | epoch 021:    218 / 4751 loss=4.612, nll_loss=3.017, ppl=8.09, wps=86986.4, ups=3.01, wpb=28858.5, bsz=960.6, num_updates=95200, lr=0.00010249, gnorm=0.435, loss_scale=4, train_wall=33, gb_free=6.3, wall=31659
2021-04-05 09:25:27 | INFO | train_inner | epoch 021:    318 / 4751 loss=4.581, nll_loss=2.981, ppl=7.89, wps=88144.4, ups=3.04, wpb=28992.5, bsz=993.3, num_updates=95300, lr=0.000102436, gnorm=0.431, loss_scale=4, train_wall=33, gb_free=6.3, wall=31692
2021-04-05 09:26:00 | INFO | train_inner | epoch 021:    418 / 4751 loss=4.614, nll_loss=3.018, ppl=8.1, wps=87105.5, ups=3.03, wpb=28762, bsz=909, num_updates=95400, lr=0.000102383, gnorm=0.429, loss_scale=4, train_wall=33, gb_free=6.1, wall=31725
2021-04-05 09:26:33 | INFO | train_inner | epoch 021:    518 / 4751 loss=4.657, nll_loss=3.067, ppl=8.38, wps=88478.9, ups=3.05, wpb=28996.4, bsz=968.5, num_updates=95500, lr=0.000102329, gnorm=0.436, loss_scale=4, train_wall=33, gb_free=6.2, wall=31758
2021-04-05 09:27:06 | INFO | train_inner | epoch 021:    618 / 4751 loss=4.641, nll_loss=3.048, ppl=8.27, wps=87774.3, ups=3.02, wpb=29026.6, bsz=916.1, num_updates=95600, lr=0.000102275, gnorm=0.429, loss_scale=4, train_wall=33, gb_free=6.2, wall=31791
2021-04-05 09:27:39 | INFO | train_inner | epoch 021:    718 / 4751 loss=4.618, nll_loss=3.023, ppl=8.13, wps=88716.3, ups=3.05, wpb=29043, bsz=931.4, num_updates=95700, lr=0.000102222, gnorm=0.428, loss_scale=4, train_wall=33, gb_free=6.3, wall=31824
2021-04-05 09:28:12 | INFO | train_inner | epoch 021:    818 / 4751 loss=4.657, nll_loss=3.067, ppl=8.38, wps=89309.6, ups=3.03, wpb=29437.2, bsz=968.6, num_updates=95800, lr=0.000102169, gnorm=0.426, loss_scale=4, train_wall=33, gb_free=6, wall=31857
2021-04-05 09:28:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-05 09:28:45 | INFO | train_inner | epoch 021:    919 / 4751 loss=4.62, nll_loss=3.024, ppl=8.14, wps=87546.2, ups=3.01, wpb=29048.6, bsz=943.9, num_updates=95900, lr=0.000102115, gnorm=0.435, loss_scale=2, train_wall=33, gb_free=6.1, wall=31890
2021-04-05 09:29:18 | INFO | train_inner | epoch 021:   1019 / 4751 loss=4.628, nll_loss=3.035, ppl=8.19, wps=88751.8, ups=3.06, wpb=29020.8, bsz=939.9, num_updates=96000, lr=0.000102062, gnorm=0.43, loss_scale=2, train_wall=33, gb_free=6.3, wall=31923
2021-04-05 09:29:51 | INFO | train_inner | epoch 021:   1119 / 4751 loss=4.626, nll_loss=3.031, ppl=8.18, wps=88212.6, ups=3.04, wpb=29006.9, bsz=939, num_updates=96100, lr=0.000102009, gnorm=0.437, loss_scale=2, train_wall=33, gb_free=6.1, wall=31956
2021-04-05 09:30:24 | INFO | train_inner | epoch 021:   1219 / 4751 loss=4.573, nll_loss=2.972, ppl=7.85, wps=87949.1, ups=3.03, wpb=28989.9, bsz=959.4, num_updates=96200, lr=0.000101956, gnorm=0.426, loss_scale=2, train_wall=33, gb_free=6.2, wall=31988
2021-04-05 09:30:56 | INFO | train_inner | epoch 021:   1319 / 4751 loss=4.644, nll_loss=3.052, ppl=8.3, wps=87842.7, ups=3.05, wpb=28806.2, bsz=937.5, num_updates=96300, lr=0.000101903, gnorm=0.43, loss_scale=2, train_wall=33, gb_free=6.3, wall=32021
2021-04-05 09:31:29 | INFO | train_inner | epoch 021:   1419 / 4751 loss=4.63, nll_loss=3.037, ppl=8.21, wps=88427.4, ups=3.04, wpb=29073.3, bsz=948.8, num_updates=96400, lr=0.00010185, gnorm=0.428, loss_scale=2, train_wall=33, gb_free=6.8, wall=32054
2021-04-05 09:32:02 | INFO | train_inner | epoch 021:   1519 / 4751 loss=4.652, nll_loss=3.061, ppl=8.35, wps=88013.8, ups=3.05, wpb=28834.1, bsz=970.2, num_updates=96500, lr=0.000101797, gnorm=0.447, loss_scale=2, train_wall=33, gb_free=6.3, wall=32087
2021-04-05 09:32:36 | INFO | train_inner | epoch 021:   1619 / 4751 loss=4.616, nll_loss=3.021, ppl=8.12, wps=85742.7, ups=2.98, wpb=28756.4, bsz=948.7, num_updates=96600, lr=0.000101745, gnorm=0.435, loss_scale=2, train_wall=33, gb_free=6.2, wall=32120
2021-04-05 09:33:08 | INFO | train_inner | epoch 021:   1719 / 4751 loss=4.672, nll_loss=3.083, ppl=8.48, wps=88146.3, ups=3.05, wpb=28903.8, bsz=932.7, num_updates=96700, lr=0.000101692, gnorm=0.439, loss_scale=2, train_wall=33, gb_free=6.2, wall=32153
2021-04-05 09:33:41 | INFO | train_inner | epoch 021:   1819 / 4751 loss=4.608, nll_loss=3.011, ppl=8.06, wps=88335.6, ups=3.04, wpb=29060.3, bsz=940.2, num_updates=96800, lr=0.000101639, gnorm=0.431, loss_scale=2, train_wall=33, gb_free=6.2, wall=32186
2021-04-05 09:34:14 | INFO | train_inner | epoch 021:   1919 / 4751 loss=4.559, nll_loss=2.956, ppl=7.76, wps=87735.6, ups=3.03, wpb=28975.5, bsz=975.7, num_updates=96900, lr=0.000101587, gnorm=0.421, loss_scale=2, train_wall=33, gb_free=6.2, wall=32219
2021-04-05 09:34:47 | INFO | train_inner | epoch 021:   2019 / 4751 loss=4.66, nll_loss=3.071, ppl=8.4, wps=87596.8, ups=3.02, wpb=28959.6, bsz=941.8, num_updates=97000, lr=0.000101535, gnorm=0.436, loss_scale=2, train_wall=33, gb_free=6.1, wall=32252
2021-04-05 09:35:20 | INFO | train_inner | epoch 021:   2119 / 4751 loss=4.631, nll_loss=3.038, ppl=8.21, wps=87431.3, ups=3.05, wpb=28671.4, bsz=934.4, num_updates=97100, lr=0.000101482, gnorm=0.43, loss_scale=2, train_wall=33, gb_free=6.1, wall=32285
2021-04-05 09:35:53 | INFO | train_inner | epoch 021:   2219 / 4751 loss=4.604, nll_loss=3.007, ppl=8.04, wps=88657.6, ups=3.04, wpb=29119.4, bsz=950.9, num_updates=97200, lr=0.00010143, gnorm=0.431, loss_scale=2, train_wall=33, gb_free=6.3, wall=32318
2021-04-05 09:36:26 | INFO | train_inner | epoch 021:   2319 / 4751 loss=4.627, nll_loss=3.034, ppl=8.19, wps=87692.6, ups=3.02, wpb=29016.7, bsz=968.1, num_updates=97300, lr=0.000101378, gnorm=0.438, loss_scale=2, train_wall=33, gb_free=6.2, wall=32351
2021-04-05 09:36:59 | INFO | train_inner | epoch 021:   2419 / 4751 loss=4.655, nll_loss=3.065, ppl=8.37, wps=88932.9, ups=3.04, wpb=29237.5, bsz=936.4, num_updates=97400, lr=0.000101326, gnorm=0.432, loss_scale=2, train_wall=33, gb_free=6.2, wall=32384
2021-04-05 09:37:32 | INFO | train_inner | epoch 021:   2519 / 4751 loss=4.67, nll_loss=3.083, ppl=8.47, wps=88817.5, ups=3.06, wpb=29018.3, bsz=943.8, num_updates=97500, lr=0.000101274, gnorm=0.429, loss_scale=2, train_wall=33, gb_free=6.3, wall=32416
2021-04-05 09:38:05 | INFO | train_inner | epoch 021:   2619 / 4751 loss=4.63, nll_loss=3.037, ppl=8.21, wps=87845.9, ups=3.04, wpb=28849.9, bsz=967.8, num_updates=97600, lr=0.000101222, gnorm=0.426, loss_scale=2, train_wall=33, gb_free=6.6, wall=32449
2021-04-05 09:38:37 | INFO | train_inner | epoch 021:   2719 / 4751 loss=4.533, nll_loss=2.927, ppl=7.61, wps=88673.2, ups=3.03, wpb=29226.5, bsz=963.6, num_updates=97700, lr=0.00010117, gnorm=0.427, loss_scale=2, train_wall=33, gb_free=6.2, wall=32482
2021-04-05 09:39:10 | INFO | train_inner | epoch 021:   2819 / 4751 loss=4.616, nll_loss=3.022, ppl=8.12, wps=88106.9, ups=3.04, wpb=28967, bsz=966.6, num_updates=97800, lr=0.000101118, gnorm=0.43, loss_scale=2, train_wall=33, gb_free=6.4, wall=32515
2021-04-05 09:39:43 | INFO | train_inner | epoch 021:   2919 / 4751 loss=4.593, nll_loss=2.995, ppl=7.97, wps=88042, ups=3.03, wpb=29080.7, bsz=933.6, num_updates=97900, lr=0.000101067, gnorm=0.429, loss_scale=4, train_wall=33, gb_free=6.1, wall=32548
2021-04-05 09:40:16 | INFO | train_inner | epoch 021:   3019 / 4751 loss=4.621, nll_loss=3.027, ppl=8.15, wps=87056.2, ups=3.03, wpb=28760.1, bsz=946.1, num_updates=98000, lr=0.000101015, gnorm=0.433, loss_scale=4, train_wall=33, gb_free=6.3, wall=32581
2021-04-05 09:40:49 | INFO | train_inner | epoch 021:   3119 / 4751 loss=4.667, nll_loss=3.079, ppl=8.45, wps=88027.4, ups=3.06, wpb=28804.4, bsz=936.2, num_updates=98100, lr=0.000100964, gnorm=0.431, loss_scale=4, train_wall=33, gb_free=6.8, wall=32614
2021-04-05 09:41:22 | INFO | train_inner | epoch 021:   3219 / 4751 loss=4.633, nll_loss=3.04, ppl=8.23, wps=87135, ups=3.03, wpb=28792.3, bsz=961.3, num_updates=98200, lr=0.000100912, gnorm=0.438, loss_scale=4, train_wall=33, gb_free=6.5, wall=32647
2021-04-05 09:41:55 | INFO | train_inner | epoch 021:   3319 / 4751 loss=4.593, nll_loss=2.995, ppl=7.97, wps=88389.5, ups=3.04, wpb=29037.8, bsz=966.3, num_updates=98300, lr=0.000100861, gnorm=0.424, loss_scale=4, train_wall=33, gb_free=6.5, wall=32680
2021-04-05 09:42:28 | INFO | train_inner | epoch 021:   3419 / 4751 loss=4.649, nll_loss=3.059, ppl=8.33, wps=86873.9, ups=3, wpb=28982.7, bsz=927.8, num_updates=98400, lr=0.00010081, gnorm=0.429, loss_scale=4, train_wall=33, gb_free=6.2, wall=32713
2021-04-05 09:43:01 | INFO | train_inner | epoch 021:   3519 / 4751 loss=4.673, nll_loss=3.086, ppl=8.49, wps=87882.9, ups=3.04, wpb=28863.4, bsz=939.4, num_updates=98500, lr=0.000100759, gnorm=0.435, loss_scale=4, train_wall=33, gb_free=6.3, wall=32746
2021-04-05 09:43:34 | INFO | train_inner | epoch 021:   3619 / 4751 loss=4.642, nll_loss=3.051, ppl=8.29, wps=88448.9, ups=3.04, wpb=29061.8, bsz=940.6, num_updates=98600, lr=0.000100707, gnorm=0.436, loss_scale=4, train_wall=33, gb_free=6.1, wall=32779
2021-04-05 09:44:07 | INFO | train_inner | epoch 021:   3719 / 4751 loss=4.674, nll_loss=3.087, ppl=8.5, wps=87024.2, ups=3.04, wpb=28653.5, bsz=946.5, num_updates=98700, lr=0.000100656, gnorm=0.442, loss_scale=4, train_wall=33, gb_free=6.2, wall=32812
2021-04-05 09:44:40 | INFO | train_inner | epoch 021:   3819 / 4751 loss=4.703, nll_loss=3.12, ppl=8.69, wps=88222.2, ups=3.04, wpb=28984.7, bsz=936.7, num_updates=98800, lr=0.000100605, gnorm=0.441, loss_scale=4, train_wall=33, gb_free=6.4, wall=32845
2021-04-05 09:45:13 | INFO | train_inner | epoch 021:   3919 / 4751 loss=4.581, nll_loss=2.982, ppl=7.9, wps=87075.8, ups=3.03, wpb=28767.6, bsz=971.5, num_updates=98900, lr=0.000100555, gnorm=0.433, loss_scale=4, train_wall=33, gb_free=6.3, wall=32878
2021-04-05 09:45:46 | INFO | train_inner | epoch 021:   4019 / 4751 loss=4.635, nll_loss=3.042, ppl=8.24, wps=88787.3, ups=3.04, wpb=29242.9, bsz=936.6, num_updates=99000, lr=0.000100504, gnorm=0.426, loss_scale=4, train_wall=33, gb_free=6.3, wall=32911
2021-04-05 09:46:19 | INFO | train_inner | epoch 021:   4119 / 4751 loss=4.664, nll_loss=3.076, ppl=8.43, wps=88737.3, ups=3.06, wpb=29029.5, bsz=939.2, num_updates=99100, lr=0.000100453, gnorm=0.428, loss_scale=4, train_wall=33, gb_free=6.2, wall=32943
2021-04-05 09:46:52 | INFO | train_inner | epoch 021:   4219 / 4751 loss=4.62, nll_loss=3.026, ppl=8.14, wps=87500.2, ups=3.03, wpb=28831.2, bsz=921, num_updates=99200, lr=0.000100402, gnorm=0.434, loss_scale=4, train_wall=33, gb_free=6.3, wall=32976
2021-04-05 09:47:25 | INFO | train_inner | epoch 021:   4319 / 4751 loss=4.623, nll_loss=3.03, ppl=8.17, wps=88969.9, ups=3.02, wpb=29446.8, bsz=948.5, num_updates=99300, lr=0.000100352, gnorm=0.419, loss_scale=4, train_wall=33, gb_free=6.2, wall=33009
2021-04-05 09:47:57 | INFO | train_inner | epoch 021:   4419 / 4751 loss=4.601, nll_loss=3.005, ppl=8.03, wps=88217.4, ups=3.05, wpb=28961.3, bsz=966.2, num_updates=99400, lr=0.000100301, gnorm=0.426, loss_scale=4, train_wall=33, gb_free=6.2, wall=33042
2021-04-05 09:48:30 | INFO | train_inner | epoch 021:   4519 / 4751 loss=4.645, nll_loss=3.054, ppl=8.31, wps=88504, ups=3.04, wpb=29158.6, bsz=948.4, num_updates=99500, lr=0.000100251, gnorm=0.43, loss_scale=4, train_wall=33, gb_free=6.1, wall=33075
2021-04-05 09:49:03 | INFO | train_inner | epoch 021:   4619 / 4751 loss=4.667, nll_loss=3.079, ppl=8.45, wps=87501.8, ups=3.03, wpb=28869.1, bsz=952.9, num_updates=99600, lr=0.000100201, gnorm=0.44, loss_scale=4, train_wall=33, gb_free=6.3, wall=33108
2021-04-05 09:49:36 | INFO | train_inner | epoch 021:   4719 / 4751 loss=4.608, nll_loss=3.012, ppl=8.07, wps=87171.3, ups=3.04, wpb=28718.2, bsz=926.1, num_updates=99700, lr=0.00010015, gnorm=0.43, loss_scale=4, train_wall=33, gb_free=6.2, wall=33141
2021-04-05 09:49:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-05 09:49:48 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 4.232 | nll_loss 2.465 | ppl 5.52 | wps 180355 | wpb 10489.1 | bsz 375 | num_updates 99732 | best_loss 4.232
2021-04-05 09:49:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 99732 updates
2021-04-05 09:49:48 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 09:49:55 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 09:50:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt (epoch 21 @ 99732 updates, score 4.232) (writing took 13.512405455112457 seconds)
2021-04-05 09:50:01 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2021-04-05 09:50:01 | INFO | train | epoch 021 | loss 4.628 | nll_loss 3.034 | ppl 8.19 | wps 87093.7 | ups 3.01 | wpb 28968.6 | bsz 947.2 | num_updates 99732 | lr 0.000100134 | gnorm 0.431 | loss_scale 4 | train_wall 1557 | gb_free 6.3 | wall 33166
2021-04-05 09:50:02 | INFO | fairseq.trainer | begin training epoch 22
2021-04-05 09:50:02 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-05 09:50:25 | INFO | train_inner | epoch 022:     68 / 4751 loss=4.637, nll_loss=3.044, ppl=8.25, wps=58857.8, ups=2.05, wpb=28678.3, bsz=931.1, num_updates=99800, lr=0.0001001, gnorm=0.428, loss_scale=4, train_wall=33, gb_free=6.2, wall=33190
2021-04-05 09:50:58 | INFO | train_inner | epoch 022:    168 / 4751 loss=4.626, nll_loss=3.032, ppl=8.18, wps=87980.8, ups=3.03, wpb=29001, bsz=920.6, num_updates=99900, lr=0.00010005, gnorm=0.433, loss_scale=4, train_wall=33, gb_free=7, wall=33223
2021-04-05 09:51:31 | INFO | train_inner | epoch 022:    268 / 4751 loss=4.616, nll_loss=3.02, ppl=8.11, wps=87868.2, ups=3.03, wpb=28959, bsz=956.4, num_updates=100000, lr=0.0001, gnorm=0.434, loss_scale=8, train_wall=33, gb_free=6.1, wall=33256
2021-04-05 09:52:04 | INFO | train_inner | epoch 022:    368 / 4751 loss=4.625, nll_loss=3.031, ppl=8.17, wps=87672.2, ups=3.03, wpb=28918.2, bsz=972.2, num_updates=100100, lr=9.995e-05, gnorm=0.436, loss_scale=8, train_wall=33, gb_free=6.3, wall=33289
2021-04-05 09:52:37 | INFO | train_inner | epoch 022:    468 / 4751 loss=4.567, nll_loss=2.966, ppl=7.81, wps=88376.6, ups=3.04, wpb=29116.6, bsz=969.3, num_updates=100200, lr=9.99001e-05, gnorm=0.431, loss_scale=8, train_wall=33, gb_free=6.4, wall=33322
2021-04-05 09:53:10 | INFO | train_inner | epoch 022:    568 / 4751 loss=4.639, nll_loss=3.047, ppl=8.26, wps=88443.8, ups=3.04, wpb=29096, bsz=969.4, num_updates=100300, lr=9.98503e-05, gnorm=0.432, loss_scale=8, train_wall=33, gb_free=6, wall=33355
2021-04-05 09:53:43 | INFO | train_inner | epoch 022:    668 / 4751 loss=4.665, nll_loss=3.077, ppl=8.44, wps=87406.7, ups=3.05, wpb=28666.2, bsz=954.6, num_updates=100400, lr=9.98006e-05, gnorm=0.441, loss_scale=8, train_wall=33, gb_free=6.6, wall=33387
2021-04-05 09:54:16 | INFO | train_inner | epoch 022:    768 / 4751 loss=4.677, nll_loss=3.09, ppl=8.51, wps=87769.6, ups=3.03, wpb=28924.5, bsz=942.8, num_updates=100500, lr=9.97509e-05, gnorm=0.439, loss_scale=8, train_wall=33, gb_free=6.5, wall=33420
2021-04-05 09:54:48 | INFO | train_inner | epoch 022:    868 / 4751 loss=4.587, nll_loss=2.989, ppl=7.94, wps=87558.3, ups=3.05, wpb=28725.1, bsz=964.2, num_updates=100600, lr=9.97013e-05, gnorm=0.428, loss_scale=8, train_wall=33, gb_free=6.3, wall=33453
2021-04-05 09:55:21 | INFO | train_inner | epoch 022:    968 / 4751 loss=4.561, nll_loss=2.959, ppl=7.77, wps=88014, ups=3.04, wpb=28972.3, bsz=935, num_updates=100700, lr=9.96518e-05, gnorm=0.431, loss_scale=8, train_wall=33, gb_free=6.4, wall=33486
2021-04-05 09:55:54 | INFO | train_inner | epoch 022:   1068 / 4751 loss=4.605, nll_loss=3.009, ppl=8.05, wps=88292.3, ups=3.04, wpb=29017.5, bsz=952.6, num_updates=100800, lr=9.96024e-05, gnorm=0.429, loss_scale=8, train_wall=33, gb_free=6.2, wall=33519
2021-04-05 09:56:27 | INFO | train_inner | epoch 022:   1168 / 4751 loss=4.622, nll_loss=3.028, ppl=8.15, wps=87951.9, ups=3.02, wpb=29130.6, bsz=959.9, num_updates=100900, lr=9.9553e-05, gnorm=0.429, loss_scale=8, train_wall=33, gb_free=6.2, wall=33552
2021-04-05 09:57:00 | INFO | train_inner | epoch 022:   1268 / 4751 loss=4.656, nll_loss=3.066, ppl=8.37, wps=86913.7, ups=3.01, wpb=28849.8, bsz=930.1, num_updates=101000, lr=9.95037e-05, gnorm=0.438, loss_scale=8, train_wall=33, gb_free=6.3, wall=33585
2021-04-05 09:57:33 | INFO | train_inner | epoch 022:   1368 / 4751 loss=4.628, nll_loss=3.035, ppl=8.2, wps=88086, ups=3.04, wpb=29015.8, bsz=905, num_updates=101100, lr=9.94545e-05, gnorm=0.432, loss_scale=8, train_wall=33, gb_free=6.3, wall=33618
2021-04-05 09:58:06 | INFO | train_inner | epoch 022:   1468 / 4751 loss=4.611, nll_loss=3.015, ppl=8.08, wps=87805.6, ups=3.04, wpb=28893.4, bsz=966.1, num_updates=101200, lr=9.94053e-05, gnorm=0.433, loss_scale=8, train_wall=33, gb_free=6.2, wall=33651
2021-04-05 09:58:39 | INFO | train_inner | epoch 022:   1568 / 4751 loss=4.597, nll_loss=2.999, ppl=8, wps=88031.1, ups=3.02, wpb=29151.7, bsz=982.2, num_updates=101300, lr=9.93563e-05, gnorm=0.432, loss_scale=8, train_wall=33, gb_free=6.4, wall=33684
2021-04-05 09:59:12 | INFO | train_inner | epoch 022:   1668 / 4751 loss=4.618, nll_loss=3.023, ppl=8.13, wps=88796.1, ups=3.06, wpb=29044.8, bsz=955.8, num_updates=101400, lr=9.93073e-05, gnorm=0.432, loss_scale=8, train_wall=33, gb_free=6.2, wall=33717
2021-04-05 09:59:45 | INFO | train_inner | epoch 022:   1768 / 4751 loss=4.594, nll_loss=2.996, ppl=7.98, wps=88582.7, ups=3.05, wpb=29070.2, bsz=951.4, num_updates=101500, lr=9.92583e-05, gnorm=0.43, loss_scale=8, train_wall=33, gb_free=6.3, wall=33750
2021-04-05 10:00:18 | INFO | train_inner | epoch 022:   1868 / 4751 loss=4.584, nll_loss=2.984, ppl=7.91, wps=87472, ups=3.04, wpb=28777.4, bsz=924.6, num_updates=101600, lr=9.92095e-05, gnorm=0.429, loss_scale=8, train_wall=33, gb_free=6.2, wall=33783
2021-04-05 10:00:51 | INFO | train_inner | epoch 022:   1968 / 4751 loss=4.601, nll_loss=3.004, ppl=8.02, wps=89011.2, ups=3.05, wpb=29201.2, bsz=933.8, num_updates=101700, lr=9.91607e-05, gnorm=0.433, loss_scale=8, train_wall=33, gb_free=6, wall=33815
2021-04-05 10:01:23 | INFO | train_inner | epoch 022:   2068 / 4751 loss=4.683, nll_loss=3.097, ppl=8.56, wps=87854.1, ups=3.06, wpb=28729.4, bsz=925.1, num_updates=101800, lr=9.9112e-05, gnorm=0.439, loss_scale=8, train_wall=33, gb_free=6.2, wall=33848
2021-04-05 10:01:56 | INFO | train_inner | epoch 022:   2168 / 4751 loss=4.62, nll_loss=3.026, ppl=8.14, wps=87420.8, ups=3.03, wpb=28817.6, bsz=932.4, num_updates=101900, lr=9.90633e-05, gnorm=0.425, loss_scale=8, train_wall=33, gb_free=6.3, wall=33881
2021-04-05 10:02:29 | INFO | train_inner | epoch 022:   2268 / 4751 loss=4.652, nll_loss=3.062, ppl=8.35, wps=88287.1, ups=3.05, wpb=28955.5, bsz=951.7, num_updates=102000, lr=9.90148e-05, gnorm=0.439, loss_scale=16, train_wall=33, gb_free=6.1, wall=33914
2021-04-05 10:03:02 | INFO | train_inner | epoch 022:   2368 / 4751 loss=4.637, nll_loss=3.044, ppl=8.25, wps=86720.4, ups=3.01, wpb=28857, bsz=920.4, num_updates=102100, lr=9.89663e-05, gnorm=0.442, loss_scale=16, train_wall=33, gb_free=6.1, wall=33947
2021-04-05 10:03:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2021-04-05 10:03:36 | INFO | train_inner | epoch 022:   2469 / 4751 loss=4.586, nll_loss=2.988, ppl=7.93, wps=86969, ups=3.02, wpb=28826.2, bsz=937.3, num_updates=102200, lr=9.89178e-05, gnorm=0.43, loss_scale=8, train_wall=33, gb_free=6.3, wall=33980
2021-04-05 10:04:08 | INFO | train_inner | epoch 022:   2569 / 4751 loss=4.62, nll_loss=3.026, ppl=8.15, wps=87354, ups=3.04, wpb=28778.1, bsz=957.5, num_updates=102300, lr=9.88695e-05, gnorm=0.432, loss_scale=8, train_wall=33, gb_free=6.3, wall=34013
2021-04-05 10:04:42 | INFO | train_inner | epoch 022:   2669 / 4751 loss=4.594, nll_loss=2.996, ppl=7.98, wps=87960.5, ups=3.02, wpb=29127.8, bsz=951.1, num_updates=102400, lr=9.88212e-05, gnorm=0.427, loss_scale=8, train_wall=33, gb_free=6.3, wall=34046
2021-04-05 10:05:15 | INFO | train_inner | epoch 022:   2769 / 4751 loss=4.647, nll_loss=3.056, ppl=8.32, wps=87793.2, ups=3.04, wpb=28888.1, bsz=940.2, num_updates=102500, lr=9.8773e-05, gnorm=0.433, loss_scale=8, train_wall=33, gb_free=6.2, wall=34079
2021-04-05 10:05:48 | INFO | train_inner | epoch 022:   2869 / 4751 loss=4.619, nll_loss=3.025, ppl=8.14, wps=87811.3, ups=3.02, wpb=29039, bsz=931.9, num_updates=102600, lr=9.87248e-05, gnorm=0.432, loss_scale=8, train_wall=33, gb_free=6.2, wall=34112
2021-04-05 10:06:21 | INFO | train_inner | epoch 022:   2969 / 4751 loss=4.634, nll_loss=3.042, ppl=8.23, wps=87595.6, ups=3.02, wpb=28958.9, bsz=928.3, num_updates=102700, lr=9.86767e-05, gnorm=0.429, loss_scale=8, train_wall=33, gb_free=6.3, wall=34145
2021-04-05 10:06:54 | INFO | train_inner | epoch 022:   3069 / 4751 loss=4.571, nll_loss=2.97, ppl=7.84, wps=87545.4, ups=3.02, wpb=28969.3, bsz=939.3, num_updates=102800, lr=9.86287e-05, gnorm=0.433, loss_scale=8, train_wall=33, gb_free=6.5, wall=34179
2021-04-05 10:07:27 | INFO | train_inner | epoch 022:   3169 / 4751 loss=4.6, nll_loss=3.003, ppl=8.02, wps=87667.6, ups=3.03, wpb=28889, bsz=939, num_updates=102900, lr=9.85808e-05, gnorm=0.432, loss_scale=8, train_wall=33, gb_free=6.2, wall=34212
2021-04-05 10:08:00 | INFO | train_inner | epoch 022:   3269 / 4751 loss=4.607, nll_loss=3.011, ppl=8.06, wps=87518.6, ups=3.03, wpb=28864.3, bsz=976.7, num_updates=103000, lr=9.85329e-05, gnorm=0.435, loss_scale=8, train_wall=33, gb_free=6.3, wall=34244
2021-04-05 10:08:32 | INFO | train_inner | epoch 022:   3369 / 4751 loss=4.693, nll_loss=3.108, ppl=8.62, wps=89047.1, ups=3.07, wpb=29027, bsz=933.9, num_updates=103100, lr=9.84851e-05, gnorm=0.436, loss_scale=8, train_wall=32, gb_free=6.4, wall=34277
2021-04-05 10:09:05 | INFO | train_inner | epoch 022:   3469 / 4751 loss=4.63, nll_loss=3.037, ppl=8.21, wps=88450.2, ups=3.03, wpb=29214.3, bsz=945.5, num_updates=103200, lr=9.84374e-05, gnorm=0.426, loss_scale=8, train_wall=33, gb_free=6.2, wall=34310
2021-04-05 10:09:38 | INFO | train_inner | epoch 022:   3569 / 4751 loss=4.649, nll_loss=3.059, ppl=8.34, wps=88840.4, ups=3.06, wpb=29073.5, bsz=952.2, num_updates=103300, lr=9.83897e-05, gnorm=0.437, loss_scale=8, train_wall=33, gb_free=6.1, wall=34343
2021-04-05 10:10:11 | INFO | train_inner | epoch 022:   3669 / 4751 loss=4.619, nll_loss=3.025, ppl=8.14, wps=87082.9, ups=3.02, wpb=28829.9, bsz=944.7, num_updates=103400, lr=9.83422e-05, gnorm=0.432, loss_scale=8, train_wall=33, gb_free=6.3, wall=34376
2021-04-05 10:10:44 | INFO | train_inner | epoch 022:   3769 / 4751 loss=4.632, nll_loss=3.039, ppl=8.22, wps=87939.9, ups=3.03, wpb=29044.8, bsz=963.7, num_updates=103500, lr=9.82946e-05, gnorm=0.442, loss_scale=8, train_wall=33, gb_free=6.4, wall=34409
2021-04-05 10:11:18 | INFO | train_inner | epoch 022:   3869 / 4751 loss=4.583, nll_loss=2.984, ppl=7.91, wps=85897.9, ups=2.96, wpb=28983.7, bsz=971.9, num_updates=103600, lr=9.82472e-05, gnorm=0.431, loss_scale=8, train_wall=34, gb_free=6.8, wall=34443
2021-04-05 10:11:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2021-04-05 10:11:51 | INFO | train_inner | epoch 022:   3970 / 4751 loss=4.677, nll_loss=3.091, ppl=8.52, wps=87961.4, ups=3.01, wpb=29197.2, bsz=958.6, num_updates=103700, lr=9.81998e-05, gnorm=0.432, loss_scale=4, train_wall=33, gb_free=6.7, wall=34476
2021-04-05 10:11:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-05 10:12:24 | INFO | train_inner | epoch 022:   4071 / 4751 loss=4.675, nll_loss=3.089, ppl=8.51, wps=87720.4, ups=3.02, wpb=29052.1, bsz=902.6, num_updates=103800, lr=9.81525e-05, gnorm=0.433, loss_scale=2, train_wall=33, gb_free=6.4, wall=34509
2021-04-05 10:12:57 | INFO | train_inner | epoch 022:   4171 / 4751 loss=4.552, nll_loss=2.949, ppl=7.72, wps=87635.6, ups=3.03, wpb=28953.3, bsz=951.9, num_updates=103900, lr=9.81052e-05, gnorm=0.425, loss_scale=2, train_wall=33, gb_free=6, wall=34542
2021-04-05 10:13:30 | INFO | train_inner | epoch 022:   4271 / 4751 loss=4.583, nll_loss=2.984, ppl=7.91, wps=88631.8, ups=3.03, wpb=29212.2, bsz=1001.2, num_updates=104000, lr=9.80581e-05, gnorm=0.425, loss_scale=2, train_wall=33, gb_free=6.3, wall=34575
2021-04-05 10:14:03 | INFO | train_inner | epoch 022:   4371 / 4751 loss=4.651, nll_loss=3.061, ppl=8.35, wps=88760.8, ups=3.05, wpb=29070.1, bsz=945.2, num_updates=104100, lr=9.8011e-05, gnorm=0.449, loss_scale=2, train_wall=33, gb_free=6.1, wall=34608
2021-04-05 10:14:36 | INFO | train_inner | epoch 022:   4471 / 4751 loss=4.599, nll_loss=3.003, ppl=8.01, wps=88147.6, ups=3.03, wpb=29128, bsz=930.1, num_updates=104200, lr=9.79639e-05, gnorm=0.426, loss_scale=2, train_wall=33, gb_free=6.3, wall=34641
2021-04-05 10:15:09 | INFO | train_inner | epoch 022:   4571 / 4751 loss=4.603, nll_loss=3.007, ppl=8.04, wps=87533.4, ups=3.04, wpb=28768.3, bsz=940.2, num_updates=104300, lr=9.79169e-05, gnorm=0.437, loss_scale=2, train_wall=33, gb_free=6, wall=34674
2021-04-05 10:15:42 | INFO | train_inner | epoch 022:   4671 / 4751 loss=4.644, nll_loss=3.053, ppl=8.3, wps=88506, ups=3.05, wpb=28990.6, bsz=945.4, num_updates=104400, lr=9.787e-05, gnorm=0.432, loss_scale=2, train_wall=33, gb_free=5.9, wall=34706
2021-04-05 10:16:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-05 10:16:09 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 4.231 | nll_loss 2.459 | ppl 5.5 | wps 214528 | wpb 10489.1 | bsz 375 | num_updates 104480 | best_loss 4.231
2021-04-05 10:16:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 104480 updates
2021-04-05 10:16:09 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 10:16:15 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 10:16:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt (epoch 22 @ 104480 updates, score 4.231) (writing took 13.291982997208834 seconds)
2021-04-05 10:16:22 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2021-04-05 10:16:22 | INFO | train | epoch 022 | loss 4.621 | nll_loss 3.027 | ppl 8.15 | wps 86998.8 | ups 3 | wpb 28967.6 | bsz 946.7 | num_updates 104480 | lr 9.78326e-05 | gnorm 0.433 | loss_scale 2 | train_wall 1558 | gb_free 6.3 | wall 34747
2021-04-05 10:16:22 | INFO | fairseq.trainer | begin training epoch 23
2021-04-05 10:16:22 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-05 10:16:30 | INFO | train_inner | epoch 023:     20 / 4751 loss=4.63, nll_loss=3.037, ppl=8.21, wps=59232, ups=2.06, wpb=28779.5, bsz=933, num_updates=104500, lr=9.78232e-05, gnorm=0.434, loss_scale=2, train_wall=33, gb_free=6.4, wall=34755
2021-04-05 10:17:03 | INFO | train_inner | epoch 023:    120 / 4751 loss=4.62, nll_loss=3.025, ppl=8.14, wps=88588.9, ups=3.03, wpb=29236.4, bsz=961.4, num_updates=104600, lr=9.77764e-05, gnorm=0.428, loss_scale=2, train_wall=33, gb_free=6.2, wall=34788
2021-04-05 10:17:36 | INFO | train_inner | epoch 023:    220 / 4751 loss=4.648, nll_loss=3.057, ppl=8.32, wps=88338.9, ups=3.05, wpb=28933.4, bsz=905.3, num_updates=104700, lr=9.77297e-05, gnorm=0.441, loss_scale=2, train_wall=33, gb_free=6.3, wall=34821
2021-04-05 10:18:09 | INFO | train_inner | epoch 023:    320 / 4751 loss=4.585, nll_loss=2.986, ppl=7.92, wps=88133.5, ups=3.03, wpb=29098.1, bsz=950.1, num_updates=104800, lr=9.76831e-05, gnorm=0.431, loss_scale=2, train_wall=33, gb_free=6.2, wall=34854
2021-04-05 10:18:42 | INFO | train_inner | epoch 023:    420 / 4751 loss=4.605, nll_loss=3.009, ppl=8.05, wps=88334.3, ups=3.04, wpb=29071.6, bsz=992.9, num_updates=104900, lr=9.76365e-05, gnorm=0.433, loss_scale=2, train_wall=33, gb_free=6.4, wall=34887
2021-04-05 10:19:15 | INFO | train_inner | epoch 023:    520 / 4751 loss=4.61, nll_loss=3.014, ppl=8.08, wps=89150.7, ups=3.06, wpb=29137.8, bsz=955.4, num_updates=105000, lr=9.759e-05, gnorm=0.43, loss_scale=2, train_wall=33, gb_free=6.2, wall=34919
2021-04-05 10:19:48 | INFO | train_inner | epoch 023:    620 / 4751 loss=4.592, nll_loss=2.994, ppl=7.96, wps=88547.3, ups=3.03, wpb=29237.3, bsz=964.7, num_updates=105100, lr=9.75436e-05, gnorm=0.432, loss_scale=2, train_wall=33, gb_free=6.1, wall=34952
2021-04-05 10:20:21 | INFO | train_inner | epoch 023:    720 / 4751 loss=4.602, nll_loss=3.005, ppl=8.03, wps=87654.4, ups=3.01, wpb=29077.5, bsz=931.8, num_updates=105200, lr=9.74972e-05, gnorm=0.435, loss_scale=2, train_wall=33, gb_free=6.3, wall=34986
2021-04-05 10:20:54 | INFO | train_inner | epoch 023:    820 / 4751 loss=4.605, nll_loss=3.009, ppl=8.05, wps=88395, ups=3.04, wpb=29044.1, bsz=934, num_updates=105300, lr=9.74509e-05, gnorm=0.429, loss_scale=2, train_wall=33, gb_free=6.2, wall=35018
2021-04-05 10:21:27 | INFO | train_inner | epoch 023:    920 / 4751 loss=4.629, nll_loss=3.036, ppl=8.2, wps=88058.2, ups=3.04, wpb=28979.9, bsz=934.4, num_updates=105400, lr=9.74047e-05, gnorm=0.433, loss_scale=2, train_wall=33, gb_free=6.2, wall=35051
2021-04-05 10:21:59 | INFO | train_inner | epoch 023:   1020 / 4751 loss=4.599, nll_loss=3.002, ppl=8.01, wps=88084.9, ups=3.04, wpb=28972.7, bsz=940.6, num_updates=105500, lr=9.73585e-05, gnorm=0.438, loss_scale=2, train_wall=33, gb_free=6.1, wall=35084
2021-04-05 10:22:32 | INFO | train_inner | epoch 023:   1120 / 4751 loss=4.615, nll_loss=3.02, ppl=8.11, wps=87804.2, ups=3.04, wpb=28925.3, bsz=917.1, num_updates=105600, lr=9.73124e-05, gnorm=0.434, loss_scale=2, train_wall=33, gb_free=6, wall=35117
2021-04-05 10:23:05 | INFO | train_inner | epoch 023:   1220 / 4751 loss=4.639, nll_loss=3.047, ppl=8.27, wps=87794.2, ups=3.06, wpb=28716.3, bsz=923.3, num_updates=105700, lr=9.72663e-05, gnorm=0.437, loss_scale=2, train_wall=33, gb_free=6.1, wall=35150
2021-04-05 10:23:38 | INFO | train_inner | epoch 023:   1320 / 4751 loss=4.638, nll_loss=3.046, ppl=8.26, wps=88044.3, ups=3.06, wpb=28810.8, bsz=928.6, num_updates=105800, lr=9.72203e-05, gnorm=0.433, loss_scale=4, train_wall=33, gb_free=6.4, wall=35183
2021-04-05 10:24:11 | INFO | train_inner | epoch 023:   1420 / 4751 loss=4.631, nll_loss=3.038, ppl=8.21, wps=88367.1, ups=3.04, wpb=29088.8, bsz=942.2, num_updates=105900, lr=9.71744e-05, gnorm=0.435, loss_scale=4, train_wall=33, gb_free=6.4, wall=35216
2021-04-05 10:24:43 | INFO | train_inner | epoch 023:   1520 / 4751 loss=4.642, nll_loss=3.051, ppl=8.29, wps=88312.5, ups=3.07, wpb=28759.4, bsz=921.6, num_updates=106000, lr=9.71286e-05, gnorm=0.444, loss_scale=4, train_wall=32, gb_free=6.2, wall=35248
2021-04-05 10:25:16 | INFO | train_inner | epoch 023:   1620 / 4751 loss=4.58, nll_loss=2.98, ppl=7.89, wps=88726.3, ups=3.05, wpb=29137.2, bsz=940.4, num_updates=106100, lr=9.70828e-05, gnorm=0.429, loss_scale=4, train_wall=33, gb_free=6.4, wall=35281
2021-04-05 10:25:49 | INFO | train_inner | epoch 023:   1720 / 4751 loss=4.584, nll_loss=2.985, ppl=7.92, wps=86803.8, ups=3.01, wpb=28797.8, bsz=965.3, num_updates=106200, lr=9.70371e-05, gnorm=0.443, loss_scale=4, train_wall=33, gb_free=6.3, wall=35314
2021-04-05 10:26:22 | INFO | train_inner | epoch 023:   1820 / 4751 loss=4.532, nll_loss=2.926, ppl=7.6, wps=88276.5, ups=3.04, wpb=29040.2, bsz=956.1, num_updates=106300, lr=9.69914e-05, gnorm=0.429, loss_scale=4, train_wall=33, gb_free=6.4, wall=35347
2021-04-05 10:26:55 | INFO | train_inner | epoch 023:   1920 / 4751 loss=4.661, nll_loss=3.072, ppl=8.41, wps=86873.4, ups=3.03, wpb=28624.5, bsz=906.2, num_updates=106400, lr=9.69458e-05, gnorm=0.437, loss_scale=4, train_wall=33, gb_free=6.1, wall=35380
2021-04-05 10:27:28 | INFO | train_inner | epoch 023:   2020 / 4751 loss=4.61, nll_loss=3.015, ppl=8.09, wps=87712.6, ups=3.03, wpb=28927.6, bsz=979.9, num_updates=106500, lr=9.69003e-05, gnorm=0.447, loss_scale=4, train_wall=33, gb_free=6.1, wall=35413
2021-04-05 10:28:01 | INFO | train_inner | epoch 023:   2120 / 4751 loss=4.64, nll_loss=3.049, ppl=8.27, wps=88426.1, ups=3.04, wpb=29039.8, bsz=951.9, num_updates=106600, lr=9.68549e-05, gnorm=0.437, loss_scale=4, train_wall=33, gb_free=6.3, wall=35446
2021-04-05 10:28:34 | INFO | train_inner | epoch 023:   2220 / 4751 loss=4.639, nll_loss=3.047, ppl=8.26, wps=87819.2, ups=3.05, wpb=28819, bsz=950, num_updates=106700, lr=9.68095e-05, gnorm=0.439, loss_scale=4, train_wall=33, gb_free=6.7, wall=35479
2021-04-05 10:29:07 | INFO | train_inner | epoch 023:   2320 / 4751 loss=4.636, nll_loss=3.044, ppl=8.25, wps=87123.2, ups=3.04, wpb=28632.6, bsz=968.7, num_updates=106800, lr=9.67641e-05, gnorm=0.445, loss_scale=4, train_wall=33, gb_free=6.7, wall=35511
2021-04-05 10:29:40 | INFO | train_inner | epoch 023:   2420 / 4751 loss=4.555, nll_loss=2.952, ppl=7.74, wps=88587.1, ups=3.04, wpb=29151.4, bsz=942.6, num_updates=106900, lr=9.67189e-05, gnorm=0.428, loss_scale=4, train_wall=33, gb_free=6.1, wall=35544
2021-04-05 10:30:12 | INFO | train_inner | epoch 023:   2520 / 4751 loss=4.658, nll_loss=3.069, ppl=8.39, wps=87747.1, ups=3.05, wpb=28803.3, bsz=934.2, num_updates=107000, lr=9.66736e-05, gnorm=0.441, loss_scale=4, train_wall=33, gb_free=6.4, wall=35577
2021-04-05 10:30:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-05 10:30:46 | INFO | train_inner | epoch 023:   2621 / 4751 loss=4.558, nll_loss=2.955, ppl=7.76, wps=85947.6, ups=3, wpb=28636, bsz=959.5, num_updates=107100, lr=9.66285e-05, gnorm=0.433, loss_scale=2, train_wall=33, gb_free=6.3, wall=35611
2021-04-05 10:31:19 | INFO | train_inner | epoch 023:   2721 / 4751 loss=4.556, nll_loss=2.954, ppl=7.75, wps=87962.1, ups=3.03, wpb=28997.1, bsz=984.6, num_updates=107200, lr=9.65834e-05, gnorm=0.438, loss_scale=2, train_wall=33, gb_free=6.2, wall=35643
2021-04-05 10:31:52 | INFO | train_inner | epoch 023:   2821 / 4751 loss=4.636, nll_loss=3.044, ppl=8.25, wps=86193.8, ups=3, wpb=28710.7, bsz=918.2, num_updates=107300, lr=9.65384e-05, gnorm=0.436, loss_scale=2, train_wall=33, gb_free=6.1, wall=35677
2021-04-05 10:32:25 | INFO | train_inner | epoch 023:   2921 / 4751 loss=4.61, nll_loss=3.015, ppl=8.08, wps=88492, ups=3.03, wpb=29178.6, bsz=980.5, num_updates=107400, lr=9.64935e-05, gnorm=0.43, loss_scale=2, train_wall=33, gb_free=6.1, wall=35710
2021-04-05 10:32:58 | INFO | train_inner | epoch 023:   3021 / 4751 loss=4.635, nll_loss=3.043, ppl=8.24, wps=88520.1, ups=3.03, wpb=29173.1, bsz=961.4, num_updates=107500, lr=9.64486e-05, gnorm=0.43, loss_scale=2, train_wall=33, gb_free=6.4, wall=35743
2021-04-05 10:33:31 | INFO | train_inner | epoch 023:   3121 / 4751 loss=4.622, nll_loss=3.029, ppl=8.16, wps=87487.6, ups=3.02, wpb=28927.5, bsz=936.7, num_updates=107600, lr=9.64037e-05, gnorm=0.435, loss_scale=2, train_wall=33, gb_free=6, wall=35776
2021-04-05 10:34:04 | INFO | train_inner | epoch 023:   3221 / 4751 loss=4.615, nll_loss=3.02, ppl=8.11, wps=87852.8, ups=3.03, wpb=28951.3, bsz=974.4, num_updates=107700, lr=9.6359e-05, gnorm=0.435, loss_scale=2, train_wall=33, gb_free=6.7, wall=35809
2021-04-05 10:34:37 | INFO | train_inner | epoch 023:   3321 / 4751 loss=4.599, nll_loss=3.002, ppl=8.01, wps=87912.8, ups=3.04, wpb=28899, bsz=967.6, num_updates=107800, lr=9.63143e-05, gnorm=0.442, loss_scale=2, train_wall=33, gb_free=6.2, wall=35842
2021-04-05 10:35:10 | INFO | train_inner | epoch 023:   3421 / 4751 loss=4.559, nll_loss=2.957, ppl=7.77, wps=87792.6, ups=3.02, wpb=29115.5, bsz=923, num_updates=107900, lr=9.62696e-05, gnorm=0.437, loss_scale=2, train_wall=33, gb_free=6.3, wall=35875
2021-04-05 10:35:43 | INFO | train_inner | epoch 023:   3521 / 4751 loss=4.671, nll_loss=3.083, ppl=8.48, wps=87608.6, ups=3.03, wpb=28891, bsz=951.9, num_updates=108000, lr=9.6225e-05, gnorm=0.443, loss_scale=2, train_wall=33, gb_free=6.1, wall=35908
2021-04-05 10:36:17 | INFO | train_inner | epoch 023:   3621 / 4751 loss=4.593, nll_loss=2.995, ppl=7.97, wps=85712.4, ups=2.97, wpb=28852.3, bsz=956.1, num_updates=108100, lr=9.61805e-05, gnorm=0.432, loss_scale=2, train_wall=34, gb_free=6.2, wall=35941
2021-04-05 10:36:50 | INFO | train_inner | epoch 023:   3721 / 4751 loss=4.688, nll_loss=3.104, ppl=8.6, wps=87482.3, ups=3.03, wpb=28876.6, bsz=940.2, num_updates=108200, lr=9.61361e-05, gnorm=0.438, loss_scale=2, train_wall=33, gb_free=6.3, wall=35974
2021-04-05 10:37:23 | INFO | train_inner | epoch 023:   3821 / 4751 loss=4.608, nll_loss=3.013, ppl=8.07, wps=87694.5, ups=3.02, wpb=29031.6, bsz=967, num_updates=108300, lr=9.60917e-05, gnorm=0.436, loss_scale=2, train_wall=33, gb_free=6.2, wall=36008
2021-04-05 10:37:56 | INFO | train_inner | epoch 023:   3921 / 4751 loss=4.614, nll_loss=3.019, ppl=8.11, wps=88674.9, ups=3.04, wpb=29210, bsz=919.5, num_updates=108400, lr=9.60473e-05, gnorm=0.437, loss_scale=2, train_wall=33, gb_free=6.4, wall=36040
2021-04-05 10:38:29 | INFO | train_inner | epoch 023:   4021 / 4751 loss=4.594, nll_loss=2.997, ppl=7.98, wps=86843.7, ups=3.03, wpb=28685.4, bsz=954.7, num_updates=108500, lr=9.60031e-05, gnorm=0.438, loss_scale=2, train_wall=33, gb_free=6.2, wall=36074
2021-04-05 10:39:01 | INFO | train_inner | epoch 023:   4121 / 4751 loss=4.667, nll_loss=3.08, ppl=8.45, wps=88672.6, ups=3.05, wpb=29040.6, bsz=931.8, num_updates=108600, lr=9.59589e-05, gnorm=0.442, loss_scale=2, train_wall=33, gb_free=6, wall=36106
2021-04-05 10:39:34 | INFO | train_inner | epoch 023:   4221 / 4751 loss=4.634, nll_loss=3.042, ppl=8.23, wps=87652.7, ups=3.03, wpb=28953, bsz=945.4, num_updates=108700, lr=9.59147e-05, gnorm=0.44, loss_scale=2, train_wall=33, gb_free=6.2, wall=36139
2021-04-05 10:40:07 | INFO | train_inner | epoch 023:   4321 / 4751 loss=4.632, nll_loss=3.039, ppl=8.22, wps=89060.9, ups=3.06, wpb=29107.4, bsz=946.2, num_updates=108800, lr=9.58706e-05, gnorm=0.433, loss_scale=2, train_wall=33, gb_free=6.1, wall=36172
2021-04-05 10:40:40 | INFO | train_inner | epoch 023:   4421 / 4751 loss=4.58, nll_loss=2.981, ppl=7.89, wps=88443, ups=3.03, wpb=29218.5, bsz=973.3, num_updates=108900, lr=9.58266e-05, gnorm=0.428, loss_scale=2, train_wall=33, gb_free=6.4, wall=36205
2021-04-05 10:41:13 | INFO | train_inner | epoch 023:   4521 / 4751 loss=4.637, nll_loss=3.044, ppl=8.25, wps=87557.3, ups=3.03, wpb=28902.5, bsz=905.8, num_updates=109000, lr=9.57826e-05, gnorm=0.439, loss_scale=2, train_wall=33, gb_free=6.3, wall=36238
2021-04-05 10:41:46 | INFO | train_inner | epoch 023:   4621 / 4751 loss=4.602, nll_loss=3.007, ppl=8.04, wps=88497.5, ups=3.04, wpb=29128.8, bsz=965.2, num_updates=109100, lr=9.57387e-05, gnorm=0.436, loss_scale=2, train_wall=33, gb_free=6.2, wall=36271
2021-04-05 10:42:19 | INFO | train_inner | epoch 023:   4721 / 4751 loss=4.605, nll_loss=3.009, ppl=8.05, wps=88203.6, ups=3.04, wpb=29012.5, bsz=962.1, num_updates=109200, lr=9.56949e-05, gnorm=0.434, loss_scale=4, train_wall=33, gb_free=6.2, wall=36304
2021-04-05 10:42:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-05 10:42:30 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 4.228 | nll_loss 2.458 | ppl 5.49 | wps 194355 | wpb 10489.1 | bsz 375 | num_updates 109230 | best_loss 4.228
2021-04-05 10:42:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 109230 updates
2021-04-05 10:42:30 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 10:42:36 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 10:42:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt (epoch 23 @ 109230 updates, score 4.228) (writing took 12.889346309006214 seconds)
2021-04-05 10:42:43 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2021-04-05 10:42:43 | INFO | train | epoch 023 | loss 4.614 | nll_loss 3.019 | ppl 8.11 | wps 87054.7 | ups 3.01 | wpb 28968.3 | bsz 947.3 | num_updates 109230 | lr 9.56817e-05 | gnorm 0.436 | loss_scale 4 | train_wall 1558 | gb_free 6.5 | wall 36328
2021-04-05 10:42:43 | INFO | fairseq.trainer | begin training epoch 24
2021-04-05 10:42:43 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-05 10:43:07 | INFO | train_inner | epoch 024:     70 / 4751 loss=4.618, nll_loss=3.024, ppl=8.13, wps=60200.8, ups=2.08, wpb=28939.6, bsz=934.7, num_updates=109300, lr=9.56511e-05, gnorm=0.431, loss_scale=4, train_wall=33, gb_free=6.2, wall=36352
2021-04-05 10:43:40 | INFO | train_inner | epoch 024:    170 / 4751 loss=4.577, nll_loss=2.977, ppl=7.87, wps=88170.3, ups=3.04, wpb=28957.3, bsz=936.9, num_updates=109400, lr=9.56074e-05, gnorm=0.433, loss_scale=4, train_wall=33, gb_free=5.8, wall=36385
2021-04-05 10:43:42 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-05 10:44:13 | INFO | train_inner | epoch 024:    271 / 4751 loss=4.609, nll_loss=3.013, ppl=8.07, wps=87087, ups=3.01, wpb=28977.6, bsz=971.4, num_updates=109500, lr=9.55637e-05, gnorm=0.44, loss_scale=2, train_wall=33, gb_free=6.3, wall=36418
2021-04-05 10:44:46 | INFO | train_inner | epoch 024:    371 / 4751 loss=4.642, nll_loss=3.051, ppl=8.29, wps=87555.4, ups=3.03, wpb=28919.3, bsz=955.3, num_updates=109600, lr=9.55201e-05, gnorm=0.438, loss_scale=2, train_wall=33, gb_free=6.3, wall=36451
2021-04-05 10:45:19 | INFO | train_inner | epoch 024:    471 / 4751 loss=4.626, nll_loss=3.033, ppl=8.18, wps=87489, ups=3.04, wpb=28802.8, bsz=958.9, num_updates=109700, lr=9.54765e-05, gnorm=0.436, loss_scale=2, train_wall=33, gb_free=6.3, wall=36484
2021-04-05 10:45:52 | INFO | train_inner | epoch 024:    571 / 4751 loss=4.616, nll_loss=3.021, ppl=8.12, wps=88892.1, ups=3.04, wpb=29198.3, bsz=939.8, num_updates=109800, lr=9.54331e-05, gnorm=0.45, loss_scale=2, train_wall=33, gb_free=6.1, wall=36517
2021-04-05 10:46:25 | INFO | train_inner | epoch 024:    671 / 4751 loss=4.616, nll_loss=3.021, ppl=8.12, wps=86759.4, ups=3.02, wpb=28745.7, bsz=937.7, num_updates=109900, lr=9.53896e-05, gnorm=0.438, loss_scale=2, train_wall=33, gb_free=6.3, wall=36550
2021-04-05 10:46:58 | INFO | train_inner | epoch 024:    771 / 4751 loss=4.58, nll_loss=2.981, ppl=7.89, wps=87139.9, ups=3.02, wpb=28837.2, bsz=975.6, num_updates=110000, lr=9.53463e-05, gnorm=0.445, loss_scale=2, train_wall=33, gb_free=6.2, wall=36583
2021-04-05 10:47:31 | INFO | train_inner | epoch 024:    871 / 4751 loss=4.622, nll_loss=3.028, ppl=8.16, wps=87990.4, ups=3.04, wpb=28970, bsz=948.9, num_updates=110100, lr=9.53029e-05, gnorm=0.437, loss_scale=2, train_wall=33, gb_free=6.2, wall=36616
2021-04-05 10:48:04 | INFO | train_inner | epoch 024:    971 / 4751 loss=4.596, nll_loss=2.998, ppl=7.99, wps=88196.4, ups=3.03, wpb=29116.8, bsz=961.6, num_updates=110200, lr=9.52597e-05, gnorm=0.437, loss_scale=2, train_wall=33, gb_free=6.4, wall=36649
2021-04-05 10:48:37 | INFO | train_inner | epoch 024:   1071 / 4751 loss=4.585, nll_loss=2.987, ppl=7.93, wps=89053.6, ups=3.04, wpb=29266.2, bsz=959.2, num_updates=110300, lr=9.52165e-05, gnorm=0.432, loss_scale=2, train_wall=33, gb_free=6.2, wall=36682
2021-04-05 10:49:10 | INFO | train_inner | epoch 024:   1171 / 4751 loss=4.588, nll_loss=2.99, ppl=7.94, wps=88584, ups=3.04, wpb=29119.8, bsz=936.7, num_updates=110400, lr=9.51734e-05, gnorm=0.426, loss_scale=2, train_wall=33, gb_free=6.3, wall=36715
2021-04-05 10:49:43 | INFO | train_inner | epoch 024:   1271 / 4751 loss=4.641, nll_loss=3.049, ppl=8.28, wps=87963.7, ups=3.05, wpb=28850.4, bsz=948.2, num_updates=110500, lr=9.51303e-05, gnorm=0.442, loss_scale=2, train_wall=33, gb_free=6.3, wall=36748
2021-04-05 10:50:16 | INFO | train_inner | epoch 024:   1371 / 4751 loss=4.603, nll_loss=3.007, ppl=8.04, wps=88538.4, ups=3.04, wpb=29146.1, bsz=958.8, num_updates=110600, lr=9.50873e-05, gnorm=0.441, loss_scale=2, train_wall=33, gb_free=6.3, wall=36780
2021-04-05 10:50:49 | INFO | train_inner | epoch 024:   1471 / 4751 loss=4.552, nll_loss=2.949, ppl=7.72, wps=85886.3, ups=2.97, wpb=28943.5, bsz=986.3, num_updates=110700, lr=9.50443e-05, gnorm=0.43, loss_scale=2, train_wall=34, gb_free=6.2, wall=36814
2021-04-05 10:51:22 | INFO | train_inner | epoch 024:   1571 / 4751 loss=4.509, nll_loss=2.9, ppl=7.47, wps=88664.7, ups=3.03, wpb=29242.6, bsz=961.1, num_updates=110800, lr=9.50014e-05, gnorm=0.423, loss_scale=2, train_wall=33, gb_free=6.1, wall=36847
2021-04-05 10:51:55 | INFO | train_inner | epoch 024:   1671 / 4751 loss=4.662, nll_loss=3.074, ppl=8.42, wps=88959.8, ups=3.04, wpb=29266.5, bsz=943.5, num_updates=110900, lr=9.49586e-05, gnorm=0.431, loss_scale=2, train_wall=33, gb_free=6.6, wall=36880
2021-04-05 10:52:28 | INFO | train_inner | epoch 024:   1771 / 4751 loss=4.574, nll_loss=2.973, ppl=7.85, wps=89394.5, ups=3.05, wpb=29291.7, bsz=927.4, num_updates=111000, lr=9.49158e-05, gnorm=0.438, loss_scale=2, train_wall=33, gb_free=6, wall=36913
2021-04-05 10:53:01 | INFO | train_inner | epoch 024:   1871 / 4751 loss=4.582, nll_loss=2.983, ppl=7.91, wps=87913.6, ups=3.03, wpb=28976.1, bsz=955.5, num_updates=111100, lr=9.48731e-05, gnorm=0.432, loss_scale=2, train_wall=33, gb_free=6.3, wall=36946
2021-04-05 10:53:34 | INFO | train_inner | epoch 024:   1971 / 4751 loss=4.624, nll_loss=3.031, ppl=8.17, wps=88104.6, ups=3.03, wpb=29047.7, bsz=914.7, num_updates=111200, lr=9.48304e-05, gnorm=0.429, loss_scale=2, train_wall=33, gb_free=6.2, wall=36979
2021-04-05 10:54:07 | INFO | train_inner | epoch 024:   2071 / 4751 loss=4.548, nll_loss=2.944, ppl=7.69, wps=88554.2, ups=3.03, wpb=29231.7, bsz=958.8, num_updates=111300, lr=9.47878e-05, gnorm=0.463, loss_scale=2, train_wall=33, gb_free=6.2, wall=37012
2021-04-05 10:54:40 | INFO | train_inner | epoch 024:   2171 / 4751 loss=4.583, nll_loss=2.984, ppl=7.91, wps=87676.2, ups=3.03, wpb=28947.2, bsz=922.2, num_updates=111400, lr=9.47452e-05, gnorm=0.437, loss_scale=2, train_wall=33, gb_free=6, wall=37045
2021-04-05 10:55:13 | INFO | train_inner | epoch 024:   2271 / 4751 loss=4.628, nll_loss=3.035, ppl=8.2, wps=88380.4, ups=3.05, wpb=29014.4, bsz=926.7, num_updates=111500, lr=9.47027e-05, gnorm=0.433, loss_scale=4, train_wall=33, gb_free=6, wall=37078
2021-04-05 10:55:46 | INFO | train_inner | epoch 024:   2371 / 4751 loss=4.607, nll_loss=3.012, ppl=8.07, wps=88194.4, ups=3.04, wpb=29023.6, bsz=952.4, num_updates=111600, lr=9.46603e-05, gnorm=0.432, loss_scale=4, train_wall=33, gb_free=6.1, wall=37110
2021-04-05 10:56:19 | INFO | train_inner | epoch 024:   2471 / 4751 loss=4.618, nll_loss=3.024, ppl=8.13, wps=88345, ups=3.04, wpb=29039.5, bsz=942.4, num_updates=111700, lr=9.46179e-05, gnorm=0.437, loss_scale=4, train_wall=33, gb_free=6.1, wall=37143
2021-04-05 10:56:51 | INFO | train_inner | epoch 024:   2571 / 4751 loss=4.586, nll_loss=2.989, ppl=7.94, wps=88097.3, ups=3.04, wpb=29003.3, bsz=963.4, num_updates=111800, lr=9.45756e-05, gnorm=0.438, loss_scale=4, train_wall=33, gb_free=6.3, wall=37176
2021-04-05 10:57:24 | INFO | train_inner | epoch 024:   2671 / 4751 loss=4.579, nll_loss=2.98, ppl=7.89, wps=87928.7, ups=3.03, wpb=28989.1, bsz=936.9, num_updates=111900, lr=9.45333e-05, gnorm=0.438, loss_scale=4, train_wall=33, gb_free=6, wall=37209
2021-04-05 10:57:57 | INFO | train_inner | epoch 024:   2771 / 4751 loss=4.601, nll_loss=3.005, ppl=8.03, wps=87815.5, ups=3.04, wpb=28885.9, bsz=949.4, num_updates=112000, lr=9.44911e-05, gnorm=0.436, loss_scale=4, train_wall=33, gb_free=6.2, wall=37242
2021-04-05 10:58:30 | INFO | train_inner | epoch 024:   2871 / 4751 loss=4.594, nll_loss=2.996, ppl=7.98, wps=88319.6, ups=3.04, wpb=29053.9, bsz=930.4, num_updates=112100, lr=9.4449e-05, gnorm=0.439, loss_scale=4, train_wall=33, gb_free=6.6, wall=37275
2021-04-05 10:59:03 | INFO | train_inner | epoch 024:   2971 / 4751 loss=4.607, nll_loss=3.011, ppl=8.06, wps=88017, ups=3.03, wpb=29092.8, bsz=946.8, num_updates=112200, lr=9.44069e-05, gnorm=0.438, loss_scale=4, train_wall=33, gb_free=6.1, wall=37308
2021-04-05 10:59:36 | INFO | train_inner | epoch 024:   3071 / 4751 loss=4.636, nll_loss=3.043, ppl=8.24, wps=87307.7, ups=3.03, wpb=28800.3, bsz=905.8, num_updates=112300, lr=9.43648e-05, gnorm=0.437, loss_scale=4, train_wall=33, gb_free=6.2, wall=37341
2021-04-05 11:00:09 | INFO | train_inner | epoch 024:   3171 / 4751 loss=4.586, nll_loss=2.988, ppl=7.93, wps=88700.9, ups=3.04, wpb=29149.5, bsz=974.7, num_updates=112400, lr=9.43228e-05, gnorm=0.431, loss_scale=4, train_wall=33, gb_free=6.3, wall=37374
2021-04-05 11:00:42 | INFO | train_inner | epoch 024:   3271 / 4751 loss=4.586, nll_loss=2.988, ppl=7.93, wps=87841, ups=3.03, wpb=28943.8, bsz=946.6, num_updates=112500, lr=9.42809e-05, gnorm=0.434, loss_scale=4, train_wall=33, gb_free=6.3, wall=37407
2021-04-05 11:01:15 | INFO | train_inner | epoch 024:   3371 / 4751 loss=4.648, nll_loss=3.058, ppl=8.33, wps=87954.2, ups=3.05, wpb=28858.2, bsz=931.3, num_updates=112600, lr=9.4239e-05, gnorm=0.442, loss_scale=4, train_wall=33, gb_free=6.1, wall=37440
2021-04-05 11:01:48 | INFO | train_inner | epoch 024:   3471 / 4751 loss=4.594, nll_loss=2.997, ppl=7.98, wps=86484.1, ups=3.02, wpb=28679.3, bsz=985.9, num_updates=112700, lr=9.41972e-05, gnorm=0.44, loss_scale=4, train_wall=33, gb_free=6.2, wall=37473
2021-04-05 11:02:21 | INFO | train_inner | epoch 024:   3571 / 4751 loss=4.608, nll_loss=3.012, ppl=8.07, wps=87154.8, ups=3.02, wpb=28845.9, bsz=952.8, num_updates=112800, lr=9.41554e-05, gnorm=0.441, loss_scale=4, train_wall=33, gb_free=6.4, wall=37506
2021-04-05 11:02:54 | INFO | train_inner | epoch 024:   3671 / 4751 loss=4.562, nll_loss=2.96, ppl=7.78, wps=87241.1, ups=3.01, wpb=28945.9, bsz=938.9, num_updates=112900, lr=9.41137e-05, gnorm=0.434, loss_scale=4, train_wall=33, gb_free=6.2, wall=37539
2021-04-05 11:03:27 | INFO | train_inner | epoch 024:   3771 / 4751 loss=4.664, nll_loss=3.076, ppl=8.43, wps=87470.4, ups=3.04, wpb=28749.9, bsz=938.5, num_updates=113000, lr=9.40721e-05, gnorm=0.448, loss_scale=4, train_wall=33, gb_free=6.3, wall=37572
2021-04-05 11:04:00 | INFO | train_inner | epoch 024:   3871 / 4751 loss=4.641, nll_loss=3.049, ppl=8.28, wps=88294.4, ups=3.04, wpb=29081.2, bsz=924.6, num_updates=113100, lr=9.40305e-05, gnorm=0.433, loss_scale=4, train_wall=33, gb_free=6.2, wall=37605
2021-04-05 11:04:33 | INFO | train_inner | epoch 024:   3971 / 4751 loss=4.567, nll_loss=2.967, ppl=7.82, wps=87918.6, ups=3.01, wpb=29250.7, bsz=997.8, num_updates=113200, lr=9.39889e-05, gnorm=0.433, loss_scale=4, train_wall=33, gb_free=6.1, wall=37638
2021-04-05 11:05:06 | INFO | train_inner | epoch 024:   4071 / 4751 loss=4.635, nll_loss=3.044, ppl=8.25, wps=87908.7, ups=3.04, wpb=28926.3, bsz=917, num_updates=113300, lr=9.39475e-05, gnorm=0.436, loss_scale=4, train_wall=33, gb_free=6.3, wall=37671
2021-04-05 11:05:39 | INFO | train_inner | epoch 024:   4171 / 4751 loss=4.614, nll_loss=3.02, ppl=8.11, wps=87614.5, ups=3.03, wpb=28894.8, bsz=951.2, num_updates=113400, lr=9.3906e-05, gnorm=0.436, loss_scale=4, train_wall=33, gb_free=6.3, wall=37704
2021-04-05 11:06:12 | INFO | train_inner | epoch 024:   4271 / 4751 loss=4.652, nll_loss=3.063, ppl=8.36, wps=86909.5, ups=3.03, wpb=28710.5, bsz=971.5, num_updates=113500, lr=9.38647e-05, gnorm=0.441, loss_scale=4, train_wall=33, gb_free=6.2, wall=37737
2021-04-05 11:06:45 | INFO | train_inner | epoch 024:   4371 / 4751 loss=4.672, nll_loss=3.086, ppl=8.49, wps=87759.2, ups=3.05, wpb=28759.6, bsz=950, num_updates=113600, lr=9.38233e-05, gnorm=0.439, loss_scale=8, train_wall=33, gb_free=6.1, wall=37770
2021-04-05 11:07:18 | INFO | train_inner | epoch 024:   4471 / 4751 loss=4.647, nll_loss=3.057, ppl=8.32, wps=85746.9, ups=3, wpb=28545.2, bsz=901, num_updates=113700, lr=9.37821e-05, gnorm=0.447, loss_scale=8, train_wall=33, gb_free=6.6, wall=37803
2021-04-05 11:07:51 | INFO | train_inner | epoch 024:   4571 / 4751 loss=4.662, nll_loss=3.074, ppl=8.42, wps=88276.9, ups=3.05, wpb=28952.5, bsz=942.2, num_updates=113800, lr=9.37408e-05, gnorm=0.438, loss_scale=8, train_wall=33, gb_free=6.1, wall=37836
2021-04-05 11:08:24 | INFO | train_inner | epoch 024:   4671 / 4751 loss=4.611, nll_loss=3.017, ppl=8.1, wps=87718.7, ups=3.05, wpb=28789.3, bsz=965.5, num_updates=113900, lr=9.36997e-05, gnorm=0.437, loss_scale=8, train_wall=33, gb_free=6.4, wall=37869
2021-04-05 11:08:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-05 11:08:52 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 4.216 | nll_loss 2.45 | ppl 5.46 | wps 169104 | wpb 10489.1 | bsz 375 | num_updates 113980 | best_loss 4.216
2021-04-05 11:08:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 113980 updates
2021-04-05 11:08:52 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 11:08:58 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 11:09:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt (epoch 24 @ 113980 updates, score 4.216) (writing took 13.31210870668292 seconds)
2021-04-05 11:09:05 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2021-04-05 11:09:05 | INFO | train | epoch 024 | loss 4.609 | nll_loss 3.013 | ppl 8.07 | wps 86979.7 | ups 3 | wpb 28968.6 | bsz 947.3 | num_updates 113980 | lr 9.36668e-05 | gnorm 0.437 | loss_scale 8 | train_wall 1559 | gb_free 6.7 | wall 37910
2021-04-05 11:09:05 | INFO | fairseq.trainer | begin training epoch 25
2021-04-05 11:09:05 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-05 11:09:13 | INFO | train_inner | epoch 025:     20 / 4751 loss=4.622, nll_loss=3.029, ppl=8.16, wps=59010.4, ups=2.05, wpb=28808, bsz=934.6, num_updates=114000, lr=9.36586e-05, gnorm=0.437, loss_scale=8, train_wall=33, gb_free=5.9, wall=37918
2021-04-05 11:09:46 | INFO | train_inner | epoch 025:    120 / 4751 loss=4.576, nll_loss=2.976, ppl=7.87, wps=87724.8, ups=3.05, wpb=28804.9, bsz=946.3, num_updates=114100, lr=9.36175e-05, gnorm=0.439, loss_scale=8, train_wall=33, gb_free=6.3, wall=37950
2021-04-05 11:10:18 | INFO | train_inner | epoch 025:    220 / 4751 loss=4.609, nll_loss=3.013, ppl=8.07, wps=88365.2, ups=3.05, wpb=28981.5, bsz=949.8, num_updates=114200, lr=9.35765e-05, gnorm=0.435, loss_scale=8, train_wall=33, gb_free=6.3, wall=37983
2021-04-05 11:10:52 | INFO | train_inner | epoch 025:    320 / 4751 loss=4.547, nll_loss=2.943, ppl=7.69, wps=87479.7, ups=3.01, wpb=29032.1, bsz=975.6, num_updates=114300, lr=9.35356e-05, gnorm=0.43, loss_scale=8, train_wall=33, gb_free=6.2, wall=38016
2021-04-05 11:11:25 | INFO | train_inner | epoch 025:    420 / 4751 loss=4.569, nll_loss=2.969, ppl=7.83, wps=87779.6, ups=3.03, wpb=28947, bsz=976.1, num_updates=114400, lr=9.34947e-05, gnorm=0.447, loss_scale=8, train_wall=33, gb_free=6.1, wall=38049
2021-04-05 11:11:58 | INFO | train_inner | epoch 025:    520 / 4751 loss=4.648, nll_loss=3.058, ppl=8.33, wps=87447.9, ups=3.03, wpb=28875.9, bsz=916, num_updates=114500, lr=9.34539e-05, gnorm=0.444, loss_scale=8, train_wall=33, gb_free=6.3, wall=38082
2021-04-05 11:12:31 | INFO | train_inner | epoch 025:    620 / 4751 loss=4.621, nll_loss=3.027, ppl=8.15, wps=86909, ups=3.04, wpb=28597.7, bsz=922.4, num_updates=114600, lr=9.34131e-05, gnorm=0.442, loss_scale=8, train_wall=33, gb_free=6.4, wall=38115
2021-04-05 11:13:04 | INFO | train_inner | epoch 025:    720 / 4751 loss=4.595, nll_loss=2.998, ppl=7.99, wps=87860.3, ups=3.02, wpb=29094, bsz=983.4, num_updates=114700, lr=9.33724e-05, gnorm=0.436, loss_scale=8, train_wall=33, gb_free=6.4, wall=38148
2021-04-05 11:13:36 | INFO | train_inner | epoch 025:    820 / 4751 loss=4.583, nll_loss=2.984, ppl=7.91, wps=88058.6, ups=3.05, wpb=28864.2, bsz=947, num_updates=114800, lr=9.33317e-05, gnorm=0.436, loss_scale=8, train_wall=33, gb_free=6.9, wall=38181
2021-04-05 11:14:09 | INFO | train_inner | epoch 025:    920 / 4751 loss=4.681, nll_loss=3.095, ppl=8.54, wps=87346.7, ups=3.03, wpb=28850.6, bsz=931.7, num_updates=114900, lr=9.32911e-05, gnorm=0.44, loss_scale=8, train_wall=33, gb_free=6.4, wall=38214
2021-04-05 11:14:43 | INFO | train_inner | epoch 025:   1020 / 4751 loss=4.631, nll_loss=3.039, ppl=8.22, wps=88204.1, ups=3.02, wpb=29198.9, bsz=955.5, num_updates=115000, lr=9.32505e-05, gnorm=0.438, loss_scale=8, train_wall=33, gb_free=6.3, wall=38247
2021-04-05 11:15:15 | INFO | train_inner | epoch 025:   1120 / 4751 loss=4.593, nll_loss=2.995, ppl=7.97, wps=87852.8, ups=3.04, wpb=28924.1, bsz=946.6, num_updates=115100, lr=9.321e-05, gnorm=0.435, loss_scale=8, train_wall=33, gb_free=6.4, wall=38280
2021-04-05 11:15:48 | INFO | train_inner | epoch 025:   1220 / 4751 loss=4.634, nll_loss=3.041, ppl=8.23, wps=88923.2, ups=3.05, wpb=29134.8, bsz=950.3, num_updates=115200, lr=9.31695e-05, gnorm=0.437, loss_scale=8, train_wall=33, gb_free=6.2, wall=38313
2021-04-05 11:16:21 | INFO | train_inner | epoch 025:   1320 / 4751 loss=4.586, nll_loss=2.987, ppl=7.93, wps=88525.6, ups=3.01, wpb=29376.9, bsz=957.4, num_updates=115300, lr=9.31291e-05, gnorm=0.431, loss_scale=8, train_wall=33, gb_free=6.2, wall=38346
2021-04-05 11:16:54 | INFO | train_inner | epoch 025:   1420 / 4751 loss=4.602, nll_loss=3.005, ppl=8.03, wps=88335.2, ups=3.05, wpb=28920.1, bsz=965.1, num_updates=115400, lr=9.30887e-05, gnorm=0.438, loss_scale=8, train_wall=33, gb_free=6.2, wall=38379
2021-04-05 11:17:27 | INFO | train_inner | epoch 025:   1520 / 4751 loss=4.592, nll_loss=2.994, ppl=7.97, wps=87361.4, ups=3.03, wpb=28789.5, bsz=956.4, num_updates=115500, lr=9.30484e-05, gnorm=0.445, loss_scale=8, train_wall=33, gb_free=6.8, wall=38412
2021-04-05 11:18:00 | INFO | train_inner | epoch 025:   1620 / 4751 loss=4.571, nll_loss=2.97, ppl=7.84, wps=88073.1, ups=3.05, wpb=28896.5, bsz=911.4, num_updates=115600, lr=9.30082e-05, gnorm=0.438, loss_scale=16, train_wall=33, gb_free=6.8, wall=38445
2021-04-05 11:18:33 | INFO | train_inner | epoch 025:   1720 / 4751 loss=4.651, nll_loss=3.061, ppl=8.35, wps=86248.7, ups=3.02, wpb=28550, bsz=948.2, num_updates=115700, lr=9.2968e-05, gnorm=0.447, loss_scale=16, train_wall=33, gb_free=6.1, wall=38478
2021-04-05 11:19:06 | INFO | train_inner | epoch 025:   1820 / 4751 loss=4.597, nll_loss=3, ppl=8, wps=88098.3, ups=3.04, wpb=28933.1, bsz=933.1, num_updates=115800, lr=9.29278e-05, gnorm=0.432, loss_scale=16, train_wall=33, gb_free=6.2, wall=38511
2021-04-05 11:19:39 | INFO | train_inner | epoch 025:   1920 / 4751 loss=4.612, nll_loss=3.017, ppl=8.09, wps=86854, ups=3.03, wpb=28635.4, bsz=921.8, num_updates=115900, lr=9.28877e-05, gnorm=0.441, loss_scale=16, train_wall=33, gb_free=6.2, wall=38544
2021-04-05 11:20:12 | INFO | train_inner | epoch 025:   2020 / 4751 loss=4.627, nll_loss=3.034, ppl=8.19, wps=88137.9, ups=3.05, wpb=28942.7, bsz=909.5, num_updates=116000, lr=9.28477e-05, gnorm=0.44, loss_scale=16, train_wall=33, gb_free=6.2, wall=38577
2021-04-05 11:20:45 | INFO | train_inner | epoch 025:   2120 / 4751 loss=4.561, nll_loss=2.959, ppl=7.78, wps=87401, ups=3.03, wpb=28833, bsz=927.8, num_updates=116100, lr=9.28077e-05, gnorm=0.438, loss_scale=16, train_wall=33, gb_free=6.2, wall=38610
2021-04-05 11:21:18 | INFO | train_inner | epoch 025:   2220 / 4751 loss=4.601, nll_loss=3.004, ppl=8.02, wps=87826.6, ups=3.03, wpb=29005.9, bsz=928.2, num_updates=116200, lr=9.27677e-05, gnorm=0.437, loss_scale=16, train_wall=33, gb_free=6.2, wall=38643
2021-04-05 11:21:51 | INFO | train_inner | epoch 025:   2320 / 4751 loss=4.588, nll_loss=2.99, ppl=7.94, wps=88688.4, ups=3.04, wpb=29216.1, bsz=961.4, num_updates=116300, lr=9.27278e-05, gnorm=0.437, loss_scale=16, train_wall=33, gb_free=6.2, wall=38675
2021-04-05 11:22:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2021-04-05 11:22:24 | INFO | train_inner | epoch 025:   2421 / 4751 loss=4.628, nll_loss=3.036, ppl=8.2, wps=87683.4, ups=3, wpb=29187.1, bsz=961.8, num_updates=116400, lr=9.2688e-05, gnorm=0.436, loss_scale=8, train_wall=33, gb_free=6.4, wall=38709
2021-04-05 11:22:57 | INFO | train_inner | epoch 025:   2521 / 4751 loss=4.613, nll_loss=3.019, ppl=8.11, wps=88776.6, ups=3.04, wpb=29183.5, bsz=989.1, num_updates=116500, lr=9.26482e-05, gnorm=0.447, loss_scale=8, train_wall=33, gb_free=6.2, wall=38742
2021-04-05 11:23:30 | INFO | train_inner | epoch 025:   2621 / 4751 loss=4.614, nll_loss=3.019, ppl=8.11, wps=88349.8, ups=3.03, wpb=29177.6, bsz=938.5, num_updates=116600, lr=9.26085e-05, gnorm=0.434, loss_scale=8, train_wall=33, gb_free=6.2, wall=38775
2021-04-05 11:24:03 | INFO | train_inner | epoch 025:   2721 / 4751 loss=4.59, nll_loss=2.993, ppl=7.96, wps=88473, ups=3.05, wpb=29020.8, bsz=1003.3, num_updates=116700, lr=9.25688e-05, gnorm=0.437, loss_scale=8, train_wall=33, gb_free=6.4, wall=38807
2021-04-05 11:24:36 | INFO | train_inner | epoch 025:   2821 / 4751 loss=4.598, nll_loss=3.001, ppl=8, wps=89288.6, ups=3.04, wpb=29368.6, bsz=930.6, num_updates=116800, lr=9.25292e-05, gnorm=0.436, loss_scale=8, train_wall=33, gb_free=6.1, wall=38840
2021-04-05 11:25:09 | INFO | train_inner | epoch 025:   2921 / 4751 loss=4.544, nll_loss=2.941, ppl=7.68, wps=87421.9, ups=3.03, wpb=28872, bsz=947.5, num_updates=116900, lr=9.24896e-05, gnorm=0.432, loss_scale=8, train_wall=33, gb_free=6.3, wall=38873
2021-04-05 11:25:41 | INFO | train_inner | epoch 025:   3021 / 4751 loss=4.664, nll_loss=3.077, ppl=8.44, wps=87965.4, ups=3.04, wpb=28942.5, bsz=931.9, num_updates=117000, lr=9.245e-05, gnorm=0.447, loss_scale=8, train_wall=33, gb_free=6.5, wall=38906
2021-04-05 11:25:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2021-04-05 11:26:15 | INFO | train_inner | epoch 025:   3122 / 4751 loss=4.629, nll_loss=3.036, ppl=8.2, wps=87373.6, ups=3.01, wpb=29037, bsz=936.4, num_updates=117100, lr=9.24105e-05, gnorm=0.44, loss_scale=4, train_wall=33, gb_free=6.3, wall=38940
2021-04-05 11:26:48 | INFO | train_inner | epoch 025:   3222 / 4751 loss=4.578, nll_loss=2.979, ppl=7.88, wps=88183.9, ups=3.05, wpb=28954.7, bsz=974.3, num_updates=117200, lr=9.23711e-05, gnorm=0.445, loss_scale=4, train_wall=33, gb_free=5.8, wall=38972
2021-04-05 11:27:20 | INFO | train_inner | epoch 025:   3322 / 4751 loss=4.634, nll_loss=3.041, ppl=8.23, wps=88632.4, ups=3.04, wpb=29165.2, bsz=895.1, num_updates=117300, lr=9.23317e-05, gnorm=0.435, loss_scale=4, train_wall=33, gb_free=6.3, wall=39005
2021-04-05 11:27:54 | INFO | train_inner | epoch 025:   3422 / 4751 loss=4.603, nll_loss=3.007, ppl=8.04, wps=86435.4, ups=3, wpb=28818.3, bsz=910.6, num_updates=117400, lr=9.22924e-05, gnorm=0.434, loss_scale=4, train_wall=33, gb_free=6.1, wall=39039
2021-04-05 11:28:27 | INFO | train_inner | epoch 025:   3522 / 4751 loss=4.601, nll_loss=3.005, ppl=8.03, wps=88316.7, ups=3.05, wpb=28976.7, bsz=917.8, num_updates=117500, lr=9.22531e-05, gnorm=0.432, loss_scale=4, train_wall=33, gb_free=6.1, wall=39071
2021-04-05 11:29:00 | INFO | train_inner | epoch 025:   3622 / 4751 loss=4.624, nll_loss=3.031, ppl=8.17, wps=85800.4, ups=2.99, wpb=28736.6, bsz=942.7, num_updates=117600, lr=9.22139e-05, gnorm=0.437, loss_scale=4, train_wall=33, gb_free=6.1, wall=39105
2021-04-05 11:29:33 | INFO | train_inner | epoch 025:   3722 / 4751 loss=4.604, nll_loss=3.009, ppl=8.05, wps=87178.4, ups=3.05, wpb=28584.9, bsz=965.1, num_updates=117700, lr=9.21747e-05, gnorm=0.441, loss_scale=4, train_wall=33, gb_free=6.2, wall=39138
2021-04-05 11:30:06 | INFO | train_inner | epoch 025:   3822 / 4751 loss=4.52, nll_loss=2.914, ppl=7.54, wps=88100.9, ups=3.03, wpb=29073.8, bsz=1001.6, num_updates=117800, lr=9.21356e-05, gnorm=0.434, loss_scale=4, train_wall=33, gb_free=6.1, wall=39171
2021-04-05 11:30:39 | INFO | train_inner | epoch 025:   3922 / 4751 loss=4.588, nll_loss=2.99, ppl=7.95, wps=88126.1, ups=3.02, wpb=29211.2, bsz=957.7, num_updates=117900, lr=9.20965e-05, gnorm=0.433, loss_scale=4, train_wall=33, gb_free=6.4, wall=39204
2021-04-05 11:31:12 | INFO | train_inner | epoch 025:   4022 / 4751 loss=4.624, nll_loss=3.031, ppl=8.17, wps=88352.5, ups=3.03, wpb=29142.6, bsz=953.8, num_updates=118000, lr=9.20575e-05, gnorm=0.441, loss_scale=4, train_wall=33, gb_free=6.3, wall=39237
2021-04-05 11:31:45 | INFO | train_inner | epoch 025:   4122 / 4751 loss=4.659, nll_loss=3.071, ppl=8.4, wps=88837.9, ups=3.06, wpb=29026.8, bsz=912.6, num_updates=118100, lr=9.20185e-05, gnorm=0.443, loss_scale=4, train_wall=33, gb_free=6.1, wall=39270
2021-04-05 11:32:18 | INFO | train_inner | epoch 025:   4222 / 4751 loss=4.58, nll_loss=2.982, ppl=7.9, wps=87519.8, ups=3.02, wpb=28948.3, bsz=965.4, num_updates=118200, lr=9.19795e-05, gnorm=0.436, loss_scale=4, train_wall=33, gb_free=6.5, wall=39303
2021-04-05 11:32:51 | INFO | train_inner | epoch 025:   4322 / 4751 loss=4.588, nll_loss=2.991, ppl=7.95, wps=88552.4, ups=3.05, wpb=29080.9, bsz=925.1, num_updates=118300, lr=9.19407e-05, gnorm=0.431, loss_scale=4, train_wall=33, gb_free=6.2, wall=39335
2021-04-05 11:32:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-05 11:33:24 | INFO | train_inner | epoch 025:   4423 / 4751 loss=4.609, nll_loss=3.015, ppl=8.08, wps=86632.4, ups=3, wpb=28855.5, bsz=958.2, num_updates=118400, lr=9.19018e-05, gnorm=0.437, loss_scale=2, train_wall=33, gb_free=6.2, wall=39369
2021-04-05 11:33:57 | INFO | train_inner | epoch 025:   4523 / 4751 loss=4.594, nll_loss=2.997, ppl=7.99, wps=87397.8, ups=3.02, wpb=28967, bsz=968.5, num_updates=118500, lr=9.1863e-05, gnorm=0.436, loss_scale=2, train_wall=33, gb_free=6, wall=39402
2021-04-05 11:34:30 | INFO | train_inner | epoch 025:   4623 / 4751 loss=4.605, nll_loss=3.01, ppl=8.05, wps=87519.3, ups=3.03, wpb=28872.2, bsz=941.4, num_updates=118600, lr=9.18243e-05, gnorm=0.437, loss_scale=2, train_wall=33, gb_free=6.3, wall=39435
2021-04-05 11:35:03 | INFO | train_inner | epoch 025:   4723 / 4751 loss=4.583, nll_loss=2.985, ppl=7.92, wps=88204.9, ups=3.05, wpb=28949.2, bsz=949.6, num_updates=118700, lr=9.17856e-05, gnorm=0.438, loss_scale=2, train_wall=33, gb_free=6.2, wall=39468
2021-04-05 11:35:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-05 11:35:13 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 4.215 | nll_loss 2.449 | ppl 5.46 | wps 189958 | wpb 10489.1 | bsz 375 | num_updates 118728 | best_loss 4.215
2021-04-05 11:35:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 118728 updates
2021-04-05 11:35:13 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 11:35:20 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 11:35:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt (epoch 25 @ 118728 updates, score 4.215) (writing took 13.39990808814764 seconds)
2021-04-05 11:35:27 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2021-04-05 11:35:27 | INFO | train | epoch 025 | loss 4.603 | nll_loss 3.007 | ppl 8.04 | wps 86953.1 | ups 3 | wpb 28967.6 | bsz 946.5 | num_updates 118728 | lr 9.17748e-05 | gnorm 0.438 | loss_scale 2 | train_wall 1559 | gb_free 6.3 | wall 39492
2021-04-05 11:35:27 | INFO | fairseq.trainer | begin training epoch 26
2021-04-05 11:35:27 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-05 11:35:52 | INFO | train_inner | epoch 026:     72 / 4751 loss=4.619, nll_loss=3.025, ppl=8.14, wps=58239.1, ups=2.05, wpb=28477.9, bsz=939, num_updates=118800, lr=9.1747e-05, gnorm=0.44, loss_scale=2, train_wall=33, gb_free=6.2, wall=39517
2021-04-05 11:36:25 | INFO | train_inner | epoch 026:    172 / 4751 loss=4.632, nll_loss=3.039, ppl=8.22, wps=87970.3, ups=3.05, wpb=28805.2, bsz=926.4, num_updates=118900, lr=9.17084e-05, gnorm=0.443, loss_scale=2, train_wall=33, gb_free=6.2, wall=39549
2021-04-05 11:36:58 | INFO | train_inner | epoch 026:    272 / 4751 loss=4.643, nll_loss=3.051, ppl=8.29, wps=86915.4, ups=3.03, wpb=28681, bsz=935.4, num_updates=119000, lr=9.16698e-05, gnorm=0.444, loss_scale=2, train_wall=33, gb_free=6.2, wall=39582
2021-04-05 11:37:30 | INFO | train_inner | epoch 026:    372 / 4751 loss=4.558, nll_loss=2.956, ppl=7.76, wps=87953.6, ups=3.05, wpb=28857.8, bsz=949.9, num_updates=119100, lr=9.16314e-05, gnorm=0.435, loss_scale=2, train_wall=33, gb_free=6.2, wall=39615
2021-04-05 11:38:04 | INFO | train_inner | epoch 026:    472 / 4751 loss=4.564, nll_loss=2.963, ppl=7.8, wps=86716.9, ups=2.99, wpb=29019.5, bsz=935.4, num_updates=119200, lr=9.15929e-05, gnorm=0.439, loss_scale=2, train_wall=33, gb_free=6.2, wall=39649
2021-04-05 11:38:37 | INFO | train_inner | epoch 026:    572 / 4751 loss=4.56, nll_loss=2.958, ppl=7.77, wps=88443.3, ups=3.02, wpb=29257, bsz=955.8, num_updates=119300, lr=9.15545e-05, gnorm=0.439, loss_scale=2, train_wall=33, gb_free=6.1, wall=39682
2021-04-05 11:39:10 | INFO | train_inner | epoch 026:    672 / 4751 loss=4.619, nll_loss=3.025, ppl=8.14, wps=87892.1, ups=3.05, wpb=28848, bsz=929.2, num_updates=119400, lr=9.15162e-05, gnorm=0.443, loss_scale=2, train_wall=33, gb_free=6.3, wall=39715
2021-04-05 11:39:43 | INFO | train_inner | epoch 026:    772 / 4751 loss=4.519, nll_loss=2.912, ppl=7.53, wps=88723.8, ups=3.02, wpb=29403.8, bsz=1005.1, num_updates=119500, lr=9.14779e-05, gnorm=0.43, loss_scale=2, train_wall=33, gb_free=6.2, wall=39748
2021-04-05 11:40:16 | INFO | train_inner | epoch 026:    872 / 4751 loss=4.603, nll_loss=3.006, ppl=8.03, wps=87925.5, ups=3.04, wpb=28963.3, bsz=943.9, num_updates=119600, lr=9.14396e-05, gnorm=0.441, loss_scale=2, train_wall=33, gb_free=6.3, wall=39781
2021-04-05 11:40:49 | INFO | train_inner | epoch 026:    972 / 4751 loss=4.616, nll_loss=3.021, ppl=8.12, wps=88976.8, ups=3.05, wpb=29153.6, bsz=911, num_updates=119700, lr=9.14014e-05, gnorm=0.439, loss_scale=2, train_wall=33, gb_free=6.2, wall=39813
2021-04-05 11:41:21 | INFO | train_inner | epoch 026:   1072 / 4751 loss=4.539, nll_loss=2.935, ppl=7.65, wps=88012, ups=3.04, wpb=28987.2, bsz=964.6, num_updates=119800, lr=9.13633e-05, gnorm=0.438, loss_scale=2, train_wall=33, gb_free=6.3, wall=39846
2021-04-05 11:41:54 | INFO | train_inner | epoch 026:   1172 / 4751 loss=4.593, nll_loss=2.996, ppl=7.98, wps=88002.1, ups=3.03, wpb=29022.4, bsz=961.8, num_updates=119900, lr=9.13252e-05, gnorm=0.439, loss_scale=2, train_wall=33, gb_free=6.2, wall=39879
2021-04-05 11:42:27 | INFO | train_inner | epoch 026:   1272 / 4751 loss=4.591, nll_loss=2.994, ppl=7.97, wps=87613.5, ups=3.03, wpb=28898.8, bsz=976.3, num_updates=120000, lr=9.12871e-05, gnorm=0.457, loss_scale=2, train_wall=33, gb_free=6.1, wall=39912
2021-04-05 11:43:00 | INFO | train_inner | epoch 026:   1372 / 4751 loss=4.626, nll_loss=3.033, ppl=8.19, wps=88574.4, ups=3.03, wpb=29208, bsz=961.7, num_updates=120100, lr=9.12491e-05, gnorm=0.438, loss_scale=2, train_wall=33, gb_free=6.3, wall=39945
2021-04-05 11:43:33 | INFO | train_inner | epoch 026:   1472 / 4751 loss=4.603, nll_loss=3.007, ppl=8.04, wps=87230.3, ups=3.04, wpb=28729.8, bsz=930.4, num_updates=120200, lr=9.12111e-05, gnorm=0.444, loss_scale=2, train_wall=33, gb_free=6, wall=39978
2021-04-05 11:44:06 | INFO | train_inner | epoch 026:   1572 / 4751 loss=4.632, nll_loss=3.04, ppl=8.22, wps=87600.9, ups=3.04, wpb=28854.8, bsz=917.2, num_updates=120300, lr=9.11732e-05, gnorm=0.44, loss_scale=2, train_wall=33, gb_free=6.2, wall=40011
2021-04-05 11:44:39 | INFO | train_inner | epoch 026:   1672 / 4751 loss=4.634, nll_loss=3.042, ppl=8.24, wps=87980, ups=3.04, wpb=28966.2, bsz=955.8, num_updates=120400, lr=9.11353e-05, gnorm=0.438, loss_scale=4, train_wall=33, gb_free=6.4, wall=40044
2021-04-05 11:45:12 | INFO | train_inner | epoch 026:   1772 / 4751 loss=4.609, nll_loss=3.014, ppl=8.08, wps=88830.1, ups=3.06, wpb=29071.5, bsz=940, num_updates=120500, lr=9.10975e-05, gnorm=0.435, loss_scale=4, train_wall=33, gb_free=6.1, wall=40077
2021-04-05 11:45:45 | INFO | train_inner | epoch 026:   1872 / 4751 loss=4.576, nll_loss=2.977, ppl=7.87, wps=87189, ups=3.03, wpb=28771.4, bsz=934.6, num_updates=120600, lr=9.10597e-05, gnorm=0.439, loss_scale=4, train_wall=33, gb_free=6.1, wall=40110
2021-04-05 11:46:18 | INFO | train_inner | epoch 026:   1972 / 4751 loss=4.662, nll_loss=3.073, ppl=8.42, wps=87367, ups=3.03, wpb=28796.7, bsz=940, num_updates=120700, lr=9.1022e-05, gnorm=0.445, loss_scale=4, train_wall=33, gb_free=6.2, wall=40143
2021-04-05 11:46:51 | INFO | train_inner | epoch 026:   2072 / 4751 loss=4.566, nll_loss=2.965, ppl=7.81, wps=88230, ups=3.02, wpb=29172.6, bsz=934.4, num_updates=120800, lr=9.09843e-05, gnorm=0.431, loss_scale=4, train_wall=33, gb_free=6.4, wall=40176
2021-04-05 11:47:24 | INFO | train_inner | epoch 026:   2172 / 4751 loss=4.609, nll_loss=3.014, ppl=8.08, wps=87436.8, ups=3.03, wpb=28843.1, bsz=955.8, num_updates=120900, lr=9.09467e-05, gnorm=0.443, loss_scale=4, train_wall=33, gb_free=6.4, wall=40209
2021-04-05 11:47:57 | INFO | train_inner | epoch 026:   2272 / 4751 loss=4.583, nll_loss=2.984, ppl=7.91, wps=87576, ups=3.03, wpb=28886.2, bsz=935.3, num_updates=121000, lr=9.09091e-05, gnorm=0.433, loss_scale=4, train_wall=33, gb_free=6.5, wall=40242
2021-04-05 11:48:30 | INFO | train_inner | epoch 026:   2372 / 4751 loss=4.61, nll_loss=3.015, ppl=8.09, wps=88047.1, ups=3.04, wpb=28973.6, bsz=982.1, num_updates=121100, lr=9.08715e-05, gnorm=0.444, loss_scale=4, train_wall=33, gb_free=6.2, wall=40275
2021-04-05 11:49:03 | INFO | train_inner | epoch 026:   2472 / 4751 loss=4.601, nll_loss=3.006, ppl=8.03, wps=87674, ups=3.03, wpb=28921.4, bsz=969.2, num_updates=121200, lr=9.08341e-05, gnorm=0.435, loss_scale=4, train_wall=33, gb_free=6.1, wall=40308
2021-04-05 11:49:36 | INFO | train_inner | epoch 026:   2572 / 4751 loss=4.606, nll_loss=3.011, ppl=8.06, wps=87544.2, ups=3.04, wpb=28761.8, bsz=925, num_updates=121300, lr=9.07966e-05, gnorm=0.444, loss_scale=4, train_wall=33, gb_free=6.2, wall=40341
2021-04-05 11:50:09 | INFO | train_inner | epoch 026:   2672 / 4751 loss=4.661, nll_loss=3.073, ppl=8.41, wps=87937.4, ups=3.02, wpb=29080.2, bsz=932.7, num_updates=121400, lr=9.07592e-05, gnorm=0.444, loss_scale=4, train_wall=33, gb_free=5.9, wall=40374
2021-04-05 11:50:42 | INFO | train_inner | epoch 026:   2772 / 4751 loss=4.583, nll_loss=2.984, ppl=7.91, wps=88587, ups=3.03, wpb=29196, bsz=966.3, num_updates=121500, lr=9.07218e-05, gnorm=0.445, loss_scale=4, train_wall=33, gb_free=6.3, wall=40407
2021-04-05 11:51:15 | INFO | train_inner | epoch 026:   2872 / 4751 loss=4.554, nll_loss=2.952, ppl=7.74, wps=87229.7, ups=3.01, wpb=28998.1, bsz=967.4, num_updates=121600, lr=9.06845e-05, gnorm=0.441, loss_scale=4, train_wall=33, gb_free=6.3, wall=40440
2021-04-05 11:51:48 | INFO | train_inner | epoch 026:   2972 / 4751 loss=4.592, nll_loss=2.995, ppl=7.97, wps=88805.2, ups=3.04, wpb=29198.4, bsz=967.8, num_updates=121700, lr=9.06473e-05, gnorm=0.436, loss_scale=4, train_wall=33, gb_free=6.1, wall=40473
2021-04-05 11:52:21 | INFO | train_inner | epoch 026:   3072 / 4751 loss=4.583, nll_loss=2.984, ppl=7.91, wps=87629.1, ups=3.02, wpb=28982, bsz=949.1, num_updates=121800, lr=9.061e-05, gnorm=0.442, loss_scale=4, train_wall=33, gb_free=6.5, wall=40506
2021-04-05 11:52:54 | INFO | train_inner | epoch 026:   3172 / 4751 loss=4.587, nll_loss=2.989, ppl=7.94, wps=86607.4, ups=3.04, wpb=28517, bsz=934.3, num_updates=121900, lr=9.05729e-05, gnorm=0.44, loss_scale=4, train_wall=33, gb_free=6.5, wall=40539
2021-04-05 11:53:27 | INFO | train_inner | epoch 026:   3272 / 4751 loss=4.594, nll_loss=2.997, ppl=7.98, wps=88290.7, ups=3.03, wpb=29116, bsz=962.7, num_updates=122000, lr=9.05357e-05, gnorm=0.437, loss_scale=4, train_wall=33, gb_free=6.1, wall=40572
2021-04-05 11:54:00 | INFO | train_inner | epoch 026:   3372 / 4751 loss=4.605, nll_loss=3.01, ppl=8.06, wps=88453.5, ups=3.04, wpb=29070.2, bsz=935.9, num_updates=122100, lr=9.04987e-05, gnorm=0.435, loss_scale=4, train_wall=33, gb_free=6.5, wall=40604
2021-04-05 11:54:33 | INFO | train_inner | epoch 026:   3472 / 4751 loss=4.558, nll_loss=2.957, ppl=7.76, wps=89195.7, ups=3.03, wpb=29444.8, bsz=991.8, num_updates=122200, lr=9.04616e-05, gnorm=0.429, loss_scale=4, train_wall=33, gb_free=6.1, wall=40638
2021-04-05 11:54:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-05 11:55:06 | INFO | train_inner | epoch 026:   3573 / 4751 loss=4.587, nll_loss=2.989, ppl=7.94, wps=86841.1, ups=3.02, wpb=28769.1, bsz=926.3, num_updates=122300, lr=9.04246e-05, gnorm=0.451, loss_scale=2, train_wall=33, gb_free=6.3, wall=40671
2021-04-05 11:55:39 | INFO | train_inner | epoch 026:   3673 / 4751 loss=4.635, nll_loss=3.044, ppl=8.25, wps=88687.4, ups=3.06, wpb=29004.5, bsz=926.3, num_updates=122400, lr=9.03877e-05, gnorm=0.448, loss_scale=2, train_wall=33, gb_free=6.2, wall=40703
2021-04-05 11:56:11 | INFO | train_inner | epoch 026:   3773 / 4751 loss=4.565, nll_loss=2.964, ppl=7.8, wps=87936.4, ups=3.04, wpb=28941, bsz=912.6, num_updates=122500, lr=9.03508e-05, gnorm=0.436, loss_scale=2, train_wall=33, gb_free=6.3, wall=40736
2021-04-05 11:56:44 | INFO | train_inner | epoch 026:   3873 / 4751 loss=4.562, nll_loss=2.961, ppl=7.79, wps=88606.9, ups=3.04, wpb=29158.8, bsz=950, num_updates=122600, lr=9.03139e-05, gnorm=0.435, loss_scale=2, train_wall=33, gb_free=6.1, wall=40769
2021-04-05 11:57:17 | INFO | train_inner | epoch 026:   3973 / 4751 loss=4.619, nll_loss=3.026, ppl=8.14, wps=87971.4, ups=3.04, wpb=28972.2, bsz=925, num_updates=122700, lr=9.02771e-05, gnorm=0.448, loss_scale=2, train_wall=33, gb_free=6.3, wall=40802
2021-04-05 11:57:51 | INFO | train_inner | epoch 026:   4073 / 4751 loss=4.559, nll_loss=2.958, ppl=7.77, wps=85653.6, ups=2.96, wpb=28951.3, bsz=930.8, num_updates=122800, lr=9.02404e-05, gnorm=0.437, loss_scale=2, train_wall=34, gb_free=6.2, wall=40836
2021-04-05 11:58:24 | INFO | train_inner | epoch 026:   4173 / 4751 loss=4.597, nll_loss=3.001, ppl=8, wps=87307.2, ups=3.02, wpb=28881.6, bsz=971.7, num_updates=122900, lr=9.02036e-05, gnorm=0.442, loss_scale=2, train_wall=33, gb_free=6.3, wall=40869
2021-04-05 11:58:57 | INFO | train_inner | epoch 026:   4273 / 4751 loss=4.587, nll_loss=2.989, ppl=7.94, wps=89202.2, ups=3.06, wpb=29196.2, bsz=935, num_updates=123000, lr=9.0167e-05, gnorm=0.44, loss_scale=2, train_wall=33, gb_free=6.3, wall=40902
2021-04-05 11:59:30 | INFO | train_inner | epoch 026:   4373 / 4751 loss=4.611, nll_loss=3.017, ppl=8.09, wps=86625.8, ups=3.02, wpb=28671.8, bsz=956.5, num_updates=123100, lr=9.01303e-05, gnorm=0.443, loss_scale=2, train_wall=33, gb_free=6.6, wall=40935
2021-04-05 12:00:03 | INFO | train_inner | epoch 026:   4473 / 4751 loss=4.579, nll_loss=2.98, ppl=7.89, wps=88367.4, ups=3.05, wpb=28993.5, bsz=932.1, num_updates=123200, lr=9.00937e-05, gnorm=0.432, loss_scale=2, train_wall=33, gb_free=6.2, wall=40968
2021-04-05 12:00:36 | INFO | train_inner | epoch 026:   4573 / 4751 loss=4.637, nll_loss=3.046, ppl=8.26, wps=87265.2, ups=3.03, wpb=28827.5, bsz=948.2, num_updates=123300, lr=9.00572e-05, gnorm=0.438, loss_scale=2, train_wall=33, gb_free=5.9, wall=41001
2021-04-05 12:01:09 | INFO | train_inner | epoch 026:   4673 / 4751 loss=4.643, nll_loss=3.053, ppl=8.3, wps=88152.6, ups=3.04, wpb=29028.7, bsz=930.4, num_updates=123400, lr=9.00207e-05, gnorm=0.44, loss_scale=2, train_wall=33, gb_free=6.2, wall=41034
2021-04-05 12:01:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-05 12:01:36 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 4.215 | nll_loss 2.444 | ppl 5.44 | wps 182164 | wpb 10489.1 | bsz 375 | num_updates 123478 | best_loss 4.215
2021-04-05 12:01:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 123478 updates
2021-04-05 12:01:36 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 12:01:42 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 12:01:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt (epoch 26 @ 123478 updates, score 4.215) (writing took 12.834506165236235 seconds)
2021-04-05 12:01:48 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2021-04-05 12:01:48 | INFO | train | epoch 026 | loss 4.597 | nll_loss 3.001 | ppl 8 | wps 86997.8 | ups 3 | wpb 28968.2 | bsz 946.9 | num_updates 123478 | lr 8.99923e-05 | gnorm 0.44 | loss_scale 2 | train_wall 1559 | gb_free 6.6 | wall 41073
2021-04-05 12:01:48 | INFO | fairseq.trainer | begin training epoch 27
2021-04-05 12:01:48 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-05 12:01:57 | INFO | train_inner | epoch 027:     22 / 4751 loss=4.599, nll_loss=3.003, ppl=8.02, wps=60045.3, ups=2.08, wpb=28882.2, bsz=965.3, num_updates=123500, lr=8.99843e-05, gnorm=0.439, loss_scale=2, train_wall=33, gb_free=6.4, wall=41082
2021-04-05 12:02:30 | INFO | train_inner | epoch 027:    122 / 4751 loss=4.578, nll_loss=2.979, ppl=7.88, wps=89434.4, ups=3.05, wpb=29306.5, bsz=922.1, num_updates=123600, lr=8.99478e-05, gnorm=0.436, loss_scale=2, train_wall=33, gb_free=6.1, wall=41114
2021-04-05 12:03:03 | INFO | train_inner | epoch 027:    222 / 4751 loss=4.552, nll_loss=2.948, ppl=7.72, wps=87767.6, ups=3.02, wpb=29084, bsz=932, num_updates=123700, lr=8.99115e-05, gnorm=0.439, loss_scale=2, train_wall=33, gb_free=6.4, wall=41148
2021-04-05 12:03:36 | INFO | train_inner | epoch 027:    322 / 4751 loss=4.593, nll_loss=2.996, ppl=7.98, wps=86878.5, ups=3.01, wpb=28856.9, bsz=956.7, num_updates=123800, lr=8.98752e-05, gnorm=0.441, loss_scale=2, train_wall=33, gb_free=6.3, wall=41181
2021-04-05 12:04:09 | INFO | train_inner | epoch 027:    422 / 4751 loss=4.567, nll_loss=2.967, ppl=7.82, wps=88640.8, ups=3.04, wpb=29141, bsz=996.4, num_updates=123900, lr=8.98389e-05, gnorm=0.438, loss_scale=2, train_wall=33, gb_free=6.3, wall=41214
2021-04-05 12:04:42 | INFO | train_inner | epoch 027:    522 / 4751 loss=4.595, nll_loss=2.998, ppl=7.99, wps=87487.7, ups=3.01, wpb=29028.9, bsz=927.9, num_updates=124000, lr=8.98027e-05, gnorm=0.437, loss_scale=2, train_wall=33, gb_free=6.2, wall=41247
2021-04-05 12:05:15 | INFO | train_inner | epoch 027:    622 / 4751 loss=4.592, nll_loss=2.994, ppl=7.97, wps=88125.8, ups=3.03, wpb=29082.8, bsz=956.9, num_updates=124100, lr=8.97665e-05, gnorm=0.439, loss_scale=2, train_wall=33, gb_free=6.4, wall=41280
2021-04-05 12:05:48 | INFO | train_inner | epoch 027:    722 / 4751 loss=4.577, nll_loss=2.978, ppl=7.88, wps=88218.9, ups=3.05, wpb=28954.4, bsz=941.5, num_updates=124200, lr=8.97303e-05, gnorm=0.441, loss_scale=2, train_wall=33, gb_free=6.1, wall=41313
2021-04-05 12:06:21 | INFO | train_inner | epoch 027:    822 / 4751 loss=4.6, nll_loss=3.003, ppl=8.02, wps=87352.5, ups=3.03, wpb=28862.1, bsz=927.4, num_updates=124300, lr=8.96942e-05, gnorm=0.443, loss_scale=4, train_wall=33, gb_free=6.1, wall=41346
2021-04-05 12:06:54 | INFO | train_inner | epoch 027:    922 / 4751 loss=4.585, nll_loss=2.986, ppl=7.92, wps=88863.8, ups=3.04, wpb=29222.5, bsz=948.3, num_updates=124400, lr=8.96582e-05, gnorm=0.436, loss_scale=4, train_wall=33, gb_free=6.1, wall=41379
2021-04-05 12:07:27 | INFO | train_inner | epoch 027:   1022 / 4751 loss=4.593, nll_loss=2.996, ppl=7.98, wps=88111.8, ups=3.05, wpb=28847.1, bsz=972.2, num_updates=124500, lr=8.96221e-05, gnorm=0.442, loss_scale=4, train_wall=33, gb_free=6.2, wall=41411
2021-04-05 12:08:00 | INFO | train_inner | epoch 027:   1122 / 4751 loss=4.553, nll_loss=2.95, ppl=7.73, wps=86537.4, ups=3.01, wpb=28712.9, bsz=931.3, num_updates=124600, lr=8.95862e-05, gnorm=0.444, loss_scale=4, train_wall=33, gb_free=6.2, wall=41445
2021-04-05 12:08:33 | INFO | train_inner | epoch 027:   1222 / 4751 loss=4.573, nll_loss=2.973, ppl=7.85, wps=88215.4, ups=3.04, wpb=29028.3, bsz=954.3, num_updates=124700, lr=8.95502e-05, gnorm=0.442, loss_scale=4, train_wall=33, gb_free=6.5, wall=41477
2021-04-05 12:09:06 | INFO | train_inner | epoch 027:   1322 / 4751 loss=4.591, nll_loss=2.994, ppl=7.97, wps=87005.4, ups=3.03, wpb=28750.8, bsz=952.8, num_updates=124800, lr=8.95144e-05, gnorm=0.441, loss_scale=4, train_wall=33, gb_free=6.2, wall=41510
2021-04-05 12:09:38 | INFO | train_inner | epoch 027:   1422 / 4751 loss=4.649, nll_loss=3.06, ppl=8.34, wps=87980.8, ups=3.06, wpb=28777.8, bsz=956.5, num_updates=124900, lr=8.94785e-05, gnorm=0.447, loss_scale=4, train_wall=33, gb_free=6.1, wall=41543
2021-04-05 12:10:11 | INFO | train_inner | epoch 027:   1522 / 4751 loss=4.571, nll_loss=2.971, ppl=7.84, wps=87641.9, ups=3.03, wpb=28963.1, bsz=962.2, num_updates=125000, lr=8.94427e-05, gnorm=0.439, loss_scale=4, train_wall=33, gb_free=6.2, wall=41576
2021-04-05 12:10:44 | INFO | train_inner | epoch 027:   1622 / 4751 loss=4.594, nll_loss=2.997, ppl=7.98, wps=88665.6, ups=3.05, wpb=29075.5, bsz=951.4, num_updates=125100, lr=8.9407e-05, gnorm=0.439, loss_scale=4, train_wall=33, gb_free=6.3, wall=41609
2021-04-05 12:11:17 | INFO | train_inner | epoch 027:   1722 / 4751 loss=4.576, nll_loss=2.977, ppl=7.87, wps=87507.9, ups=3.03, wpb=28858.1, bsz=941.4, num_updates=125200, lr=8.93713e-05, gnorm=0.44, loss_scale=4, train_wall=33, gb_free=6.1, wall=41642
2021-04-05 12:11:50 | INFO | train_inner | epoch 027:   1822 / 4751 loss=4.617, nll_loss=3.024, ppl=8.13, wps=87787.8, ups=3.03, wpb=29004.3, bsz=961.8, num_updates=125300, lr=8.93356e-05, gnorm=0.451, loss_scale=4, train_wall=33, gb_free=6.2, wall=41675
2021-04-05 12:12:23 | INFO | train_inner | epoch 027:   1922 / 4751 loss=4.56, nll_loss=2.959, ppl=7.77, wps=87961.5, ups=3.02, wpb=29139.5, bsz=960.8, num_updates=125400, lr=8.93e-05, gnorm=0.445, loss_scale=4, train_wall=33, gb_free=6.4, wall=41708
2021-04-05 12:12:56 | INFO | train_inner | epoch 027:   2022 / 4751 loss=4.537, nll_loss=2.932, ppl=7.63, wps=89052.6, ups=3.03, wpb=29351.5, bsz=966.9, num_updates=125500, lr=8.92644e-05, gnorm=0.432, loss_scale=4, train_wall=33, gb_free=6.2, wall=41741
2021-04-05 12:13:29 | INFO | train_inner | epoch 027:   2122 / 4751 loss=4.581, nll_loss=2.982, ppl=7.9, wps=87825, ups=3.04, wpb=28919, bsz=935.3, num_updates=125600, lr=8.92288e-05, gnorm=0.443, loss_scale=4, train_wall=33, gb_free=6.3, wall=41774
2021-04-05 12:14:02 | INFO | train_inner | epoch 027:   2222 / 4751 loss=4.556, nll_loss=2.954, ppl=7.75, wps=87987.3, ups=3.02, wpb=29145.5, bsz=925.4, num_updates=125700, lr=8.91933e-05, gnorm=0.436, loss_scale=4, train_wall=33, gb_free=6.5, wall=41807
2021-04-05 12:14:36 | INFO | train_inner | epoch 027:   2322 / 4751 loss=4.691, nll_loss=3.106, ppl=8.61, wps=85644.9, ups=2.97, wpb=28852.4, bsz=895.9, num_updates=125800, lr=8.91579e-05, gnorm=0.451, loss_scale=4, train_wall=34, gb_free=6.2, wall=41841
2021-04-05 12:15:09 | INFO | train_inner | epoch 027:   2422 / 4751 loss=4.529, nll_loss=2.924, ppl=7.59, wps=88422.5, ups=3.04, wpb=29128.5, bsz=979.8, num_updates=125900, lr=8.91225e-05, gnorm=0.434, loss_scale=4, train_wall=33, gb_free=6.3, wall=41874
2021-04-05 12:15:42 | INFO | train_inner | epoch 027:   2522 / 4751 loss=4.641, nll_loss=3.05, ppl=8.28, wps=87977.4, ups=3.04, wpb=28964.5, bsz=924.6, num_updates=126000, lr=8.90871e-05, gnorm=0.446, loss_scale=4, train_wall=33, gb_free=6.6, wall=41907
2021-04-05 12:16:15 | INFO | train_inner | epoch 027:   2622 / 4751 loss=4.601, nll_loss=3.005, ppl=8.03, wps=87809.5, ups=3.02, wpb=29064.7, bsz=917.5, num_updates=126100, lr=8.90517e-05, gnorm=0.441, loss_scale=4, train_wall=33, gb_free=6.2, wall=41940
2021-04-05 12:16:48 | INFO | train_inner | epoch 027:   2722 / 4751 loss=4.574, nll_loss=2.974, ppl=7.86, wps=88108.6, ups=3.04, wpb=28985.5, bsz=941.8, num_updates=126200, lr=8.90165e-05, gnorm=0.439, loss_scale=4, train_wall=33, gb_free=6.3, wall=41973
2021-04-05 12:17:21 | INFO | train_inner | epoch 027:   2822 / 4751 loss=4.617, nll_loss=3.023, ppl=8.13, wps=87173.8, ups=3.03, wpb=28744.3, bsz=926.4, num_updates=126300, lr=8.89812e-05, gnorm=0.442, loss_scale=4, train_wall=33, gb_free=6.4, wall=42006
2021-04-05 12:17:54 | INFO | train_inner | epoch 027:   2922 / 4751 loss=4.598, nll_loss=3.002, ppl=8.01, wps=89062.7, ups=3.03, wpb=29381.5, bsz=975.4, num_updates=126400, lr=8.8946e-05, gnorm=0.446, loss_scale=8, train_wall=33, gb_free=6.6, wall=42039
2021-04-05 12:18:27 | INFO | train_inner | epoch 027:   3022 / 4751 loss=4.56, nll_loss=2.958, ppl=7.77, wps=87852.9, ups=3.03, wpb=28960.2, bsz=926.3, num_updates=126500, lr=8.89108e-05, gnorm=0.438, loss_scale=8, train_wall=33, gb_free=6, wall=42072
2021-04-05 12:18:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2021-04-05 12:19:00 | INFO | train_inner | epoch 027:   3123 / 4751 loss=4.579, nll_loss=2.98, ppl=7.89, wps=85784.4, ups=3, wpb=28593.5, bsz=945.2, num_updates=126600, lr=8.88757e-05, gnorm=0.444, loss_scale=4, train_wall=33, gb_free=6.1, wall=42105
2021-04-05 12:19:33 | INFO | train_inner | epoch 027:   3223 / 4751 loss=4.59, nll_loss=2.992, ppl=7.96, wps=87575.1, ups=3.01, wpb=29058.5, bsz=951.7, num_updates=126700, lr=8.88406e-05, gnorm=0.451, loss_scale=4, train_wall=33, gb_free=6.1, wall=42138
2021-04-05 12:20:06 | INFO | train_inner | epoch 027:   3323 / 4751 loss=4.623, nll_loss=3.03, ppl=8.17, wps=88211.1, ups=3.06, wpb=28846.9, bsz=943.7, num_updates=126800, lr=8.88056e-05, gnorm=0.449, loss_scale=4, train_wall=33, gb_free=6.2, wall=42171
2021-04-05 12:20:39 | INFO | train_inner | epoch 027:   3423 / 4751 loss=4.602, nll_loss=3.006, ppl=8.03, wps=87603.6, ups=3.02, wpb=29005.6, bsz=959, num_updates=126900, lr=8.87706e-05, gnorm=0.444, loss_scale=4, train_wall=33, gb_free=6.2, wall=42204
2021-04-05 12:21:12 | INFO | train_inner | epoch 027:   3523 / 4751 loss=4.597, nll_loss=3.001, ppl=8, wps=87061.7, ups=3.04, wpb=28651.8, bsz=965, num_updates=127000, lr=8.87357e-05, gnorm=0.451, loss_scale=4, train_wall=33, gb_free=6.7, wall=42237
2021-04-05 12:21:45 | INFO | train_inner | epoch 027:   3623 / 4751 loss=4.607, nll_loss=3.012, ppl=8.07, wps=88497.6, ups=3.04, wpb=29115, bsz=949.2, num_updates=127100, lr=8.87007e-05, gnorm=0.437, loss_scale=4, train_wall=33, gb_free=6.2, wall=42270
2021-04-05 12:22:18 | INFO | train_inner | epoch 027:   3723 / 4751 loss=4.612, nll_loss=3.017, ppl=8.1, wps=87908.5, ups=3.03, wpb=29005, bsz=954.7, num_updates=127200, lr=8.86659e-05, gnorm=0.432, loss_scale=4, train_wall=33, gb_free=6.4, wall=42303
2021-04-05 12:22:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-05 12:22:51 | INFO | train_inner | epoch 027:   3824 / 4751 loss=4.578, nll_loss=2.98, ppl=7.89, wps=86044.2, ups=3, wpb=28713.1, bsz=936.2, num_updates=127300, lr=8.8631e-05, gnorm=0.447, loss_scale=2, train_wall=33, gb_free=6.5, wall=42336
2021-04-05 12:23:24 | INFO | train_inner | epoch 027:   3924 / 4751 loss=4.575, nll_loss=2.976, ppl=7.87, wps=87758.5, ups=3.04, wpb=28848.4, bsz=959, num_updates=127400, lr=8.85962e-05, gnorm=0.439, loss_scale=2, train_wall=33, gb_free=6.3, wall=42369
2021-04-05 12:23:57 | INFO | train_inner | epoch 027:   4024 / 4751 loss=4.565, nll_loss=2.965, ppl=7.81, wps=87414.3, ups=3.02, wpb=28951.2, bsz=945, num_updates=127500, lr=8.85615e-05, gnorm=0.441, loss_scale=2, train_wall=33, gb_free=6.1, wall=42402
2021-04-05 12:24:30 | INFO | train_inner | epoch 027:   4124 / 4751 loss=4.582, nll_loss=2.984, ppl=7.91, wps=88845.4, ups=3.05, wpb=29147.4, bsz=941, num_updates=127600, lr=8.85268e-05, gnorm=0.44, loss_scale=2, train_wall=33, gb_free=6.4, wall=42435
2021-04-05 12:25:03 | INFO | train_inner | epoch 027:   4224 / 4751 loss=4.66, nll_loss=3.072, ppl=8.41, wps=87558.3, ups=3.04, wpb=28824.2, bsz=926.2, num_updates=127700, lr=8.84921e-05, gnorm=0.447, loss_scale=2, train_wall=33, gb_free=6.2, wall=42468
2021-04-05 12:25:36 | INFO | train_inner | epoch 027:   4324 / 4751 loss=4.575, nll_loss=2.975, ppl=7.87, wps=88326.4, ups=3.06, wpb=28909.8, bsz=947.8, num_updates=127800, lr=8.84575e-05, gnorm=0.437, loss_scale=2, train_wall=33, gb_free=6.2, wall=42501
2021-04-05 12:26:08 | INFO | train_inner | epoch 027:   4424 / 4751 loss=4.676, nll_loss=3.09, ppl=8.52, wps=89291.1, ups=3.07, wpb=29040.9, bsz=924.4, num_updates=127900, lr=8.84229e-05, gnorm=0.455, loss_scale=2, train_wall=32, gb_free=6.1, wall=42533
2021-04-05 12:26:41 | INFO | train_inner | epoch 027:   4524 / 4751 loss=4.595, nll_loss=2.998, ppl=7.99, wps=88113.3, ups=3.04, wpb=29006.6, bsz=959.4, num_updates=128000, lr=8.83883e-05, gnorm=0.442, loss_scale=2, train_wall=33, gb_free=6.2, wall=42566
2021-04-05 12:27:14 | INFO | train_inner | epoch 027:   4624 / 4751 loss=4.62, nll_loss=3.028, ppl=8.15, wps=87749.5, ups=3.04, wpb=28868, bsz=948.6, num_updates=128100, lr=8.83538e-05, gnorm=0.443, loss_scale=2, train_wall=33, gb_free=6.2, wall=42599
2021-04-05 12:27:47 | INFO | train_inner | epoch 027:   4724 / 4751 loss=4.616, nll_loss=3.023, ppl=8.13, wps=87574.5, ups=3.03, wpb=28873.8, bsz=975.6, num_updates=128200, lr=8.83194e-05, gnorm=0.461, loss_scale=2, train_wall=33, gb_free=6.1, wall=42632
2021-04-05 12:27:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-05 12:27:57 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 4.203 | nll_loss 2.428 | ppl 5.38 | wps 199544 | wpb 10489.1 | bsz 375 | num_updates 128227 | best_loss 4.203
2021-04-05 12:27:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 128227 updates
2021-04-05 12:27:57 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 12:28:04 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 12:28:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt (epoch 27 @ 128227 updates, score 4.203) (writing took 13.18798702955246 seconds)
2021-04-05 12:28:10 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2021-04-05 12:28:10 | INFO | train | epoch 027 | loss 4.592 | nll_loss 2.995 | ppl 7.97 | wps 86966.1 | ups 3 | wpb 28968.8 | bsz 946.7 | num_updates 128227 | lr 8.83101e-05 | gnorm 0.442 | loss_scale 2 | train_wall 1559 | gb_free 6.3 | wall 42655
2021-04-05 12:28:10 | INFO | fairseq.trainer | begin training epoch 28
2021-04-05 12:28:10 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-05 12:28:35 | INFO | train_inner | epoch 028:     73 / 4751 loss=4.561, nll_loss=2.959, ppl=7.78, wps=60211.1, ups=2.07, wpb=29086.2, bsz=932.5, num_updates=128300, lr=8.82849e-05, gnorm=0.44, loss_scale=2, train_wall=32, gb_free=6.1, wall=42680
2021-04-05 12:29:09 | INFO | train_inner | epoch 028:    173 / 4751 loss=4.631, nll_loss=3.039, ppl=8.22, wps=87211.6, ups=3.02, wpb=28859.4, bsz=948.3, num_updates=128400, lr=8.82506e-05, gnorm=0.445, loss_scale=2, train_wall=33, gb_free=6.5, wall=42713
2021-04-05 12:29:42 | INFO | train_inner | epoch 028:    273 / 4751 loss=4.566, nll_loss=2.965, ppl=7.81, wps=87757.4, ups=3.03, wpb=28963.6, bsz=936.1, num_updates=128500, lr=8.82162e-05, gnorm=0.441, loss_scale=2, train_wall=33, gb_free=6.3, wall=42746
2021-04-05 12:30:14 | INFO | train_inner | epoch 028:    373 / 4751 loss=4.585, nll_loss=2.987, ppl=7.93, wps=87937.2, ups=3.05, wpb=28855.7, bsz=918.6, num_updates=128600, lr=8.81819e-05, gnorm=0.444, loss_scale=2, train_wall=33, gb_free=6.3, wall=42779
2021-04-05 12:30:47 | INFO | train_inner | epoch 028:    473 / 4751 loss=4.516, nll_loss=2.908, ppl=7.51, wps=88742.3, ups=3.04, wpb=29195.6, bsz=969.2, num_updates=128700, lr=8.81476e-05, gnorm=0.432, loss_scale=2, train_wall=33, gb_free=6.3, wall=42812
2021-04-05 12:31:20 | INFO | train_inner | epoch 028:    573 / 4751 loss=4.611, nll_loss=3.016, ppl=8.09, wps=88382.4, ups=3.04, wpb=29119.6, bsz=962, num_updates=128800, lr=8.81134e-05, gnorm=0.442, loss_scale=2, train_wall=33, gb_free=6.3, wall=42845
2021-04-05 12:31:53 | INFO | train_inner | epoch 028:    673 / 4751 loss=4.578, nll_loss=2.979, ppl=7.89, wps=88776.6, ups=3.05, wpb=29112.7, bsz=952.5, num_updates=128900, lr=8.80792e-05, gnorm=0.441, loss_scale=2, train_wall=33, gb_free=6.1, wall=42878
2021-04-05 12:32:26 | INFO | train_inner | epoch 028:    773 / 4751 loss=4.56, nll_loss=2.958, ppl=7.77, wps=87618.8, ups=3, wpb=29176.8, bsz=946.2, num_updates=129000, lr=8.80451e-05, gnorm=0.438, loss_scale=2, train_wall=33, gb_free=6.1, wall=42911
2021-04-05 12:32:59 | INFO | train_inner | epoch 028:    873 / 4751 loss=4.61, nll_loss=3.015, ppl=8.09, wps=88478.8, ups=3.05, wpb=29006.5, bsz=915.4, num_updates=129100, lr=8.8011e-05, gnorm=0.443, loss_scale=2, train_wall=33, gb_free=6.7, wall=42944
2021-04-05 12:33:32 | INFO | train_inner | epoch 028:    973 / 4751 loss=4.613, nll_loss=3.018, ppl=8.1, wps=88739.8, ups=3.04, wpb=29143.8, bsz=967.7, num_updates=129200, lr=8.79769e-05, gnorm=0.45, loss_scale=2, train_wall=33, gb_free=6.2, wall=42977
2021-04-05 12:34:05 | INFO | train_inner | epoch 028:   1073 / 4751 loss=4.595, nll_loss=2.998, ppl=7.99, wps=87985.6, ups=3.03, wpb=29043.2, bsz=927.6, num_updates=129300, lr=8.79429e-05, gnorm=0.445, loss_scale=4, train_wall=33, gb_free=6.2, wall=43010
2021-04-05 12:34:38 | INFO | train_inner | epoch 028:   1173 / 4751 loss=4.604, nll_loss=3.008, ppl=8.05, wps=87672.4, ups=3.05, wpb=28717.5, bsz=938.5, num_updates=129400, lr=8.79089e-05, gnorm=0.449, loss_scale=4, train_wall=33, gb_free=6.1, wall=43042
2021-04-05 12:35:11 | INFO | train_inner | epoch 028:   1273 / 4751 loss=4.579, nll_loss=2.98, ppl=7.89, wps=88003.4, ups=3.03, wpb=29045, bsz=977.6, num_updates=129500, lr=8.7875e-05, gnorm=0.442, loss_scale=4, train_wall=33, gb_free=6.1, wall=43075
2021-04-05 12:35:44 | INFO | train_inner | epoch 028:   1373 / 4751 loss=4.6, nll_loss=3.004, ppl=8.02, wps=86546.5, ups=3.02, wpb=28687.1, bsz=951, num_updates=129600, lr=8.7841e-05, gnorm=0.446, loss_scale=4, train_wall=33, gb_free=6.4, wall=43109
2021-04-05 12:36:17 | INFO | train_inner | epoch 028:   1473 / 4751 loss=4.559, nll_loss=2.958, ppl=7.77, wps=88748.2, ups=3.03, wpb=29247.7, bsz=959.1, num_updates=129700, lr=8.78072e-05, gnorm=0.44, loss_scale=4, train_wall=33, gb_free=6.2, wall=43142
2021-04-05 12:36:50 | INFO | train_inner | epoch 028:   1573 / 4751 loss=4.576, nll_loss=2.977, ppl=7.87, wps=88156.5, ups=3.04, wpb=29000.5, bsz=953.7, num_updates=129800, lr=8.77733e-05, gnorm=0.436, loss_scale=4, train_wall=33, gb_free=6.2, wall=43174
2021-04-05 12:37:22 | INFO | train_inner | epoch 028:   1673 / 4751 loss=4.565, nll_loss=2.965, ppl=7.81, wps=88349, ups=3.06, wpb=28908.4, bsz=935.3, num_updates=129900, lr=8.77396e-05, gnorm=0.439, loss_scale=4, train_wall=33, gb_free=6.1, wall=43207
2021-04-05 12:37:55 | INFO | train_inner | epoch 028:   1773 / 4751 loss=4.582, nll_loss=2.984, ppl=7.91, wps=88735.1, ups=3.03, wpb=29279.1, bsz=967.8, num_updates=130000, lr=8.77058e-05, gnorm=0.442, loss_scale=4, train_wall=33, gb_free=6.1, wall=43240
2021-04-05 12:38:28 | INFO | train_inner | epoch 028:   1873 / 4751 loss=4.667, nll_loss=3.08, ppl=8.46, wps=88450.5, ups=3.04, wpb=29085.2, bsz=963.7, num_updates=130100, lr=8.76721e-05, gnorm=0.443, loss_scale=4, train_wall=33, gb_free=5.9, wall=43273
2021-04-05 12:39:01 | INFO | train_inner | epoch 028:   1973 / 4751 loss=4.542, nll_loss=2.938, ppl=7.67, wps=87976.9, ups=3.01, wpb=29233.9, bsz=941.8, num_updates=130200, lr=8.76384e-05, gnorm=0.433, loss_scale=4, train_wall=33, gb_free=6.1, wall=43306
2021-04-05 12:39:05 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-05 12:39:35 | INFO | train_inner | epoch 028:   2074 / 4751 loss=4.623, nll_loss=3.03, ppl=8.17, wps=86784.1, ups=3.02, wpb=28752.3, bsz=928.4, num_updates=130300, lr=8.76048e-05, gnorm=0.448, loss_scale=2, train_wall=33, gb_free=6.3, wall=43339
2021-04-05 12:40:08 | INFO | train_inner | epoch 028:   2174 / 4751 loss=4.568, nll_loss=2.968, ppl=7.83, wps=87440.3, ups=3.02, wpb=28915.7, bsz=969.9, num_updates=130400, lr=8.75712e-05, gnorm=0.443, loss_scale=2, train_wall=33, gb_free=6.2, wall=43373
2021-04-05 12:40:41 | INFO | train_inner | epoch 028:   2274 / 4751 loss=4.587, nll_loss=2.99, ppl=7.94, wps=88843.3, ups=3.04, wpb=29249.8, bsz=968.5, num_updates=130500, lr=8.75376e-05, gnorm=0.443, loss_scale=2, train_wall=33, gb_free=6.4, wall=43405
2021-04-05 12:41:14 | INFO | train_inner | epoch 028:   2374 / 4751 loss=4.598, nll_loss=3.002, ppl=8.01, wps=87907.2, ups=3.03, wpb=28997.4, bsz=948.1, num_updates=130600, lr=8.75041e-05, gnorm=0.439, loss_scale=2, train_wall=33, gb_free=6.3, wall=43438
2021-04-05 12:41:46 | INFO | train_inner | epoch 028:   2474 / 4751 loss=4.605, nll_loss=3.01, ppl=8.06, wps=87697.3, ups=3.05, wpb=28748.2, bsz=941.1, num_updates=130700, lr=8.74706e-05, gnorm=0.458, loss_scale=2, train_wall=33, gb_free=6.4, wall=43471
2021-04-05 12:42:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-04-05 12:42:20 | INFO | train_inner | epoch 028:   2575 / 4751 loss=4.561, nll_loss=2.959, ppl=7.78, wps=86698.9, ups=3, wpb=28924.9, bsz=934.4, num_updates=130800, lr=8.74372e-05, gnorm=0.44, loss_scale=1, train_wall=33, gb_free=6.2, wall=43505
2021-04-05 12:42:53 | INFO | train_inner | epoch 028:   2675 / 4751 loss=4.621, nll_loss=3.029, ppl=8.16, wps=85353.1, ups=2.98, wpb=28606.3, bsz=950.3, num_updates=130900, lr=8.74038e-05, gnorm=0.449, loss_scale=1, train_wall=33, gb_free=6.3, wall=43538
2021-04-05 12:43:26 | INFO | train_inner | epoch 028:   2775 / 4751 loss=4.578, nll_loss=2.979, ppl=7.89, wps=87518.3, ups=3.04, wpb=28776.1, bsz=960.6, num_updates=131000, lr=8.73704e-05, gnorm=0.444, loss_scale=1, train_wall=33, gb_free=6.2, wall=43571
2021-04-05 12:43:59 | INFO | train_inner | epoch 028:   2875 / 4751 loss=4.601, nll_loss=3.006, ppl=8.03, wps=87644, ups=3.05, wpb=28690.7, bsz=975.6, num_updates=131100, lr=8.73371e-05, gnorm=0.448, loss_scale=1, train_wall=33, gb_free=6.2, wall=43604
2021-04-05 12:44:32 | INFO | train_inner | epoch 028:   2975 / 4751 loss=4.639, nll_loss=3.047, ppl=8.27, wps=87964, ups=3.03, wpb=29063.6, bsz=906.3, num_updates=131200, lr=8.73038e-05, gnorm=0.444, loss_scale=1, train_wall=33, gb_free=5.9, wall=43637
2021-04-05 12:45:05 | INFO | train_inner | epoch 028:   3075 / 4751 loss=4.563, nll_loss=2.963, ppl=7.8, wps=87684.4, ups=3.05, wpb=28778.4, bsz=965.3, num_updates=131300, lr=8.72705e-05, gnorm=0.446, loss_scale=1, train_wall=33, gb_free=6.6, wall=43670
2021-04-05 12:45:37 | INFO | train_inner | epoch 028:   3175 / 4751 loss=4.607, nll_loss=3.012, ppl=8.06, wps=88350.2, ups=3.05, wpb=28920.7, bsz=946.6, num_updates=131400, lr=8.72373e-05, gnorm=0.443, loss_scale=1, train_wall=33, gb_free=6.4, wall=43702
2021-04-05 12:46:11 | INFO | train_inner | epoch 028:   3275 / 4751 loss=4.601, nll_loss=3.006, ppl=8.03, wps=87646, ups=3.02, wpb=29020.2, bsz=968.6, num_updates=131500, lr=8.72041e-05, gnorm=0.442, loss_scale=1, train_wall=33, gb_free=6.4, wall=43735
2021-04-05 12:46:44 | INFO | train_inner | epoch 028:   3375 / 4751 loss=4.598, nll_loss=3.002, ppl=8.01, wps=87950.3, ups=3.03, wpb=29010.9, bsz=953.9, num_updates=131600, lr=8.7171e-05, gnorm=0.45, loss_scale=1, train_wall=33, gb_free=6.1, wall=43768
2021-04-05 12:47:17 | INFO | train_inner | epoch 028:   3475 / 4751 loss=4.594, nll_loss=2.998, ppl=7.99, wps=87696.3, ups=3.03, wpb=28931.1, bsz=939.8, num_updates=131700, lr=8.71379e-05, gnorm=0.437, loss_scale=1, train_wall=33, gb_free=6.5, wall=43801
2021-04-05 12:47:49 | INFO | train_inner | epoch 028:   3575 / 4751 loss=4.638, nll_loss=3.047, ppl=8.26, wps=88398.8, ups=3.06, wpb=28899.5, bsz=907, num_updates=131800, lr=8.71048e-05, gnorm=0.449, loss_scale=1, train_wall=33, gb_free=6.2, wall=43834
2021-04-05 12:48:22 | INFO | train_inner | epoch 028:   3675 / 4751 loss=4.595, nll_loss=2.999, ppl=7.99, wps=88816.2, ups=3.04, wpb=29218.8, bsz=955.5, num_updates=131900, lr=8.70718e-05, gnorm=0.438, loss_scale=1, train_wall=33, gb_free=6.1, wall=43867
2021-04-05 12:48:55 | INFO | train_inner | epoch 028:   3775 / 4751 loss=4.526, nll_loss=2.921, ppl=7.57, wps=87490.7, ups=3.01, wpb=29079.5, bsz=960.5, num_updates=132000, lr=8.70388e-05, gnorm=0.438, loss_scale=1, train_wall=33, gb_free=6.2, wall=43900
2021-04-05 12:49:28 | INFO | train_inner | epoch 028:   3875 / 4751 loss=4.618, nll_loss=3.024, ppl=8.13, wps=88628.5, ups=3.05, wpb=29098.2, bsz=928.4, num_updates=132100, lr=8.70059e-05, gnorm=0.443, loss_scale=1, train_wall=33, gb_free=6.3, wall=43933
2021-04-05 12:50:01 | INFO | train_inner | epoch 028:   3975 / 4751 loss=4.652, nll_loss=3.063, ppl=8.36, wps=88235.3, ups=3.05, wpb=28913.4, bsz=919.8, num_updates=132200, lr=8.6973e-05, gnorm=0.447, loss_scale=1, train_wall=33, gb_free=6, wall=43966
2021-04-05 12:50:34 | INFO | train_inner | epoch 028:   4075 / 4751 loss=4.559, nll_loss=2.958, ppl=7.77, wps=87977, ups=3.02, wpb=29088.4, bsz=970.7, num_updates=132300, lr=8.69401e-05, gnorm=0.435, loss_scale=1, train_wall=33, gb_free=6.3, wall=43999
2021-04-05 12:51:07 | INFO | train_inner | epoch 028:   4175 / 4751 loss=4.547, nll_loss=2.944, ppl=7.7, wps=88046.6, ups=3.03, wpb=29013.3, bsz=946.2, num_updates=132400, lr=8.69072e-05, gnorm=0.441, loss_scale=1, train_wall=33, gb_free=6.3, wall=44032
2021-04-05 12:51:40 | INFO | train_inner | epoch 028:   4275 / 4751 loss=4.559, nll_loss=2.958, ppl=7.77, wps=87681.2, ups=3.03, wpb=28941.6, bsz=937.2, num_updates=132500, lr=8.68744e-05, gnorm=0.437, loss_scale=1, train_wall=33, gb_free=6.2, wall=44065
2021-04-05 12:52:13 | INFO | train_inner | epoch 028:   4375 / 4751 loss=4.549, nll_loss=2.947, ppl=7.71, wps=87442, ups=3.03, wpb=28816.5, bsz=913.1, num_updates=132600, lr=8.68417e-05, gnorm=0.447, loss_scale=1, train_wall=33, gb_free=6.7, wall=44098
2021-04-05 12:52:46 | INFO | train_inner | epoch 028:   4475 / 4751 loss=4.572, nll_loss=2.972, ppl=7.85, wps=87328.5, ups=3.04, wpb=28695.1, bsz=951.7, num_updates=132700, lr=8.6809e-05, gnorm=0.447, loss_scale=1, train_wall=33, gb_free=6.4, wall=44131
2021-04-05 12:53:19 | INFO | train_inner | epoch 028:   4575 / 4751 loss=4.591, nll_loss=2.994, ppl=7.97, wps=87846.5, ups=3.04, wpb=28872.5, bsz=932.5, num_updates=132800, lr=8.67763e-05, gnorm=0.439, loss_scale=1, train_wall=33, gb_free=6.7, wall=44164
2021-04-05 12:53:52 | INFO | train_inner | epoch 028:   4675 / 4751 loss=4.584, nll_loss=2.987, ppl=7.93, wps=87788.7, ups=3.04, wpb=28897.2, bsz=933.1, num_updates=132900, lr=8.67436e-05, gnorm=0.447, loss_scale=2, train_wall=33, gb_free=6.3, wall=44196
2021-04-05 12:54:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-05 12:54:18 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 4.203 | nll_loss 2.437 | ppl 5.41 | wps 197847 | wpb 10489.1 | bsz 375 | num_updates 132976 | best_loss 4.203
2021-04-05 12:54:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 132976 updates
2021-04-05 12:54:18 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 12:54:24 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 12:54:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt (epoch 28 @ 132976 updates, score 4.203) (writing took 13.56629080325365 seconds)
2021-04-05 12:54:31 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2021-04-05 12:54:31 | INFO | train | epoch 028 | loss 4.587 | nll_loss 2.99 | ppl 7.94 | wps 87007.9 | ups 3 | wpb 28968.1 | bsz 946.7 | num_updates 132976 | lr 8.67188e-05 | gnorm 0.443 | loss_scale 2 | train_wall 1558 | gb_free 6.5 | wall 44236
2021-04-05 12:54:32 | INFO | fairseq.trainer | begin training epoch 29
2021-04-05 12:54:32 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-05 12:54:41 | INFO | train_inner | epoch 029:     24 / 4751 loss=4.57, nll_loss=2.97, ppl=7.84, wps=58698.4, ups=2.04, wpb=28748.5, bsz=950.4, num_updates=133000, lr=8.6711e-05, gnorm=0.441, loss_scale=2, train_wall=33, gb_free=6.2, wall=44245
2021-04-05 12:55:13 | INFO | train_inner | epoch 029:    124 / 4751 loss=4.583, nll_loss=2.984, ppl=7.91, wps=89595, ups=3.05, wpb=29395.9, bsz=955.9, num_updates=133100, lr=8.66784e-05, gnorm=0.444, loss_scale=2, train_wall=33, gb_free=6.4, wall=44278
2021-04-05 12:55:46 | INFO | train_inner | epoch 029:    224 / 4751 loss=4.553, nll_loss=2.951, ppl=7.73, wps=87912.2, ups=3.04, wpb=28965.8, bsz=961.1, num_updates=133200, lr=8.66459e-05, gnorm=0.442, loss_scale=2, train_wall=33, gb_free=6.3, wall=44311
2021-04-05 12:56:19 | INFO | train_inner | epoch 029:    324 / 4751 loss=4.621, nll_loss=3.027, ppl=8.15, wps=88752.2, ups=3.05, wpb=29063.1, bsz=932.9, num_updates=133300, lr=8.66134e-05, gnorm=0.445, loss_scale=2, train_wall=33, gb_free=6.1, wall=44344
2021-04-05 12:56:52 | INFO | train_inner | epoch 029:    424 / 4751 loss=4.642, nll_loss=3.051, ppl=8.29, wps=87401.4, ups=3.05, wpb=28641.6, bsz=947.7, num_updates=133400, lr=8.65809e-05, gnorm=0.453, loss_scale=2, train_wall=33, gb_free=6, wall=44377
2021-04-05 12:57:25 | INFO | train_inner | epoch 029:    524 / 4751 loss=4.539, nll_loss=2.935, ppl=7.65, wps=86650.6, ups=3.02, wpb=28680.4, bsz=951.2, num_updates=133500, lr=8.65485e-05, gnorm=0.442, loss_scale=2, train_wall=33, gb_free=6.2, wall=44410
2021-04-05 12:57:58 | INFO | train_inner | epoch 029:    624 / 4751 loss=4.629, nll_loss=3.037, ppl=8.21, wps=87643.5, ups=3.03, wpb=28895.3, bsz=960.2, num_updates=133600, lr=8.65161e-05, gnorm=0.448, loss_scale=2, train_wall=33, gb_free=6.9, wall=44443
2021-04-05 12:58:31 | INFO | train_inner | epoch 029:    724 / 4751 loss=4.597, nll_loss=3.001, ppl=8, wps=88179.1, ups=3.03, wpb=29136.1, bsz=936.5, num_updates=133700, lr=8.64837e-05, gnorm=0.437, loss_scale=2, train_wall=33, gb_free=6.3, wall=44476
2021-04-05 12:59:04 | INFO | train_inner | epoch 029:    824 / 4751 loss=4.553, nll_loss=2.951, ppl=7.73, wps=87772.8, ups=3.03, wpb=28956.6, bsz=924.3, num_updates=133800, lr=8.64514e-05, gnorm=0.445, loss_scale=2, train_wall=33, gb_free=6.2, wall=44509
2021-04-05 12:59:37 | INFO | train_inner | epoch 029:    924 / 4751 loss=4.53, nll_loss=2.924, ppl=7.59, wps=87961.7, ups=3.03, wpb=29020.8, bsz=951.4, num_updates=133900, lr=8.64191e-05, gnorm=0.437, loss_scale=2, train_wall=33, gb_free=6.2, wall=44542
2021-04-05 13:00:10 | INFO | train_inner | epoch 029:   1024 / 4751 loss=4.605, nll_loss=3.01, ppl=8.05, wps=89174.9, ups=3.06, wpb=29188.9, bsz=958, num_updates=134000, lr=8.63868e-05, gnorm=0.437, loss_scale=2, train_wall=33, gb_free=6.2, wall=44575
2021-04-05 13:00:43 | INFO | train_inner | epoch 029:   1124 / 4751 loss=4.566, nll_loss=2.966, ppl=7.81, wps=87152.4, ups=3.01, wpb=28911.8, bsz=954.2, num_updates=134100, lr=8.63546e-05, gnorm=0.443, loss_scale=2, train_wall=33, gb_free=6.4, wall=44608
2021-04-05 13:01:16 | INFO | train_inner | epoch 029:   1224 / 4751 loss=4.514, nll_loss=2.907, ppl=7.5, wps=88482.3, ups=3.03, wpb=29213.5, bsz=966.7, num_updates=134200, lr=8.63224e-05, gnorm=0.447, loss_scale=2, train_wall=33, gb_free=6.2, wall=44641
2021-04-05 13:01:49 | INFO | train_inner | epoch 029:   1324 / 4751 loss=4.552, nll_loss=2.95, ppl=7.73, wps=87127, ups=3.01, wpb=28984.4, bsz=917.9, num_updates=134300, lr=8.62903e-05, gnorm=0.441, loss_scale=2, train_wall=33, gb_free=5.9, wall=44674
2021-04-05 13:02:22 | INFO | train_inner | epoch 029:   1424 / 4751 loss=4.537, nll_loss=2.934, ppl=7.64, wps=87673.2, ups=3.02, wpb=28985.4, bsz=986.2, num_updates=134400, lr=8.62582e-05, gnorm=0.441, loss_scale=2, train_wall=33, gb_free=6.2, wall=44707
2021-04-05 13:02:55 | INFO | train_inner | epoch 029:   1524 / 4751 loss=4.665, nll_loss=3.077, ppl=8.44, wps=86753.9, ups=3.04, wpb=28525.2, bsz=933.1, num_updates=134500, lr=8.62261e-05, gnorm=0.461, loss_scale=2, train_wall=33, gb_free=6.1, wall=44740
2021-04-05 13:03:28 | INFO | train_inner | epoch 029:   1624 / 4751 loss=4.624, nll_loss=3.031, ppl=8.17, wps=89161.8, ups=3.05, wpb=29232, bsz=914.5, num_updates=134600, lr=8.61941e-05, gnorm=0.437, loss_scale=2, train_wall=33, gb_free=6.1, wall=44773
2021-04-05 13:04:01 | INFO | train_inner | epoch 029:   1724 / 4751 loss=4.501, nll_loss=2.892, ppl=7.42, wps=88990.9, ups=3.04, wpb=29232.1, bsz=980.5, num_updates=134700, lr=8.61621e-05, gnorm=0.449, loss_scale=2, train_wall=33, gb_free=6.8, wall=44806
2021-04-05 13:04:34 | INFO | train_inner | epoch 029:   1824 / 4751 loss=4.573, nll_loss=2.973, ppl=7.85, wps=86633, ups=3.04, wpb=28501.3, bsz=935.1, num_updates=134800, lr=8.61301e-05, gnorm=0.445, loss_scale=2, train_wall=33, gb_free=6.1, wall=44838
2021-04-05 13:05:07 | INFO | train_inner | epoch 029:   1924 / 4751 loss=4.567, nll_loss=2.967, ppl=7.82, wps=88833.6, ups=3.04, wpb=29200.9, bsz=965, num_updates=134900, lr=8.60982e-05, gnorm=0.44, loss_scale=4, train_wall=33, gb_free=6.1, wall=44871
2021-04-05 13:05:39 | INFO | train_inner | epoch 029:   2024 / 4751 loss=4.567, nll_loss=2.966, ppl=7.82, wps=87892.7, ups=3.03, wpb=28967.4, bsz=943.6, num_updates=135000, lr=8.60663e-05, gnorm=0.443, loss_scale=4, train_wall=33, gb_free=6.6, wall=44904
2021-04-05 13:06:12 | INFO | train_inner | epoch 029:   2124 / 4751 loss=4.594, nll_loss=2.998, ppl=7.99, wps=87045.2, ups=3.03, wpb=28705.1, bsz=954.3, num_updates=135100, lr=8.60344e-05, gnorm=0.447, loss_scale=4, train_wall=33, gb_free=6.2, wall=44937
2021-04-05 13:06:45 | INFO | train_inner | epoch 029:   2224 / 4751 loss=4.567, nll_loss=2.967, ppl=7.82, wps=86973.2, ups=3.03, wpb=28683.8, bsz=936.9, num_updates=135200, lr=8.60026e-05, gnorm=0.443, loss_scale=4, train_wall=33, gb_free=6.2, wall=44970
2021-04-05 13:07:18 | INFO | train_inner | epoch 029:   2324 / 4751 loss=4.573, nll_loss=2.975, ppl=7.86, wps=87517.7, ups=3.03, wpb=28873.1, bsz=971.4, num_updates=135300, lr=8.59708e-05, gnorm=0.448, loss_scale=4, train_wall=33, gb_free=6.2, wall=45003
2021-04-05 13:07:51 | INFO | train_inner | epoch 029:   2424 / 4751 loss=4.615, nll_loss=3.022, ppl=8.12, wps=87604.9, ups=3.02, wpb=28963, bsz=935.4, num_updates=135400, lr=8.59391e-05, gnorm=0.444, loss_scale=4, train_wall=33, gb_free=6.4, wall=45036
2021-04-05 13:08:24 | INFO | train_inner | epoch 029:   2524 / 4751 loss=4.554, nll_loss=2.952, ppl=7.74, wps=88196.1, ups=3.05, wpb=28939.8, bsz=950.7, num_updates=135500, lr=8.59074e-05, gnorm=0.444, loss_scale=4, train_wall=33, gb_free=6.2, wall=45069
2021-04-05 13:08:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-05 13:08:58 | INFO | train_inner | epoch 029:   2625 / 4751 loss=4.627, nll_loss=3.034, ppl=8.19, wps=85960.4, ups=2.99, wpb=28745.6, bsz=908.2, num_updates=135600, lr=8.58757e-05, gnorm=0.449, loss_scale=2, train_wall=33, gb_free=6.3, wall=45103
2021-04-05 13:09:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-04-05 13:09:31 | INFO | train_inner | epoch 029:   2726 / 4751 loss=4.621, nll_loss=3.028, ppl=8.16, wps=87096.7, ups=3, wpb=29021.5, bsz=986.2, num_updates=135700, lr=8.5844e-05, gnorm=0.442, loss_scale=1, train_wall=33, gb_free=6.1, wall=45136
2021-04-05 13:10:04 | INFO | train_inner | epoch 029:   2826 / 4751 loss=4.541, nll_loss=2.937, ppl=7.66, wps=88515.2, ups=3.04, wpb=29161, bsz=937.4, num_updates=135800, lr=8.58124e-05, gnorm=0.435, loss_scale=1, train_wall=33, gb_free=6.3, wall=45169
2021-04-05 13:10:37 | INFO | train_inner | epoch 029:   2926 / 4751 loss=4.607, nll_loss=3.013, ppl=8.07, wps=88390.8, ups=3.05, wpb=29020, bsz=945.7, num_updates=135900, lr=8.57808e-05, gnorm=0.449, loss_scale=1, train_wall=33, gb_free=6.2, wall=45202
2021-04-05 13:11:10 | INFO | train_inner | epoch 029:   3026 / 4751 loss=4.567, nll_loss=2.967, ppl=7.82, wps=88008.8, ups=3.02, wpb=29128.9, bsz=930.4, num_updates=136000, lr=8.57493e-05, gnorm=0.441, loss_scale=1, train_wall=33, gb_free=6.1, wall=45235
2021-04-05 13:11:43 | INFO | train_inner | epoch 029:   3126 / 4751 loss=4.634, nll_loss=3.043, ppl=8.24, wps=87912.3, ups=3.05, wpb=28837.2, bsz=945.6, num_updates=136100, lr=8.57178e-05, gnorm=0.446, loss_scale=1, train_wall=33, gb_free=6.4, wall=45268
2021-04-05 13:12:16 | INFO | train_inner | epoch 029:   3226 / 4751 loss=4.56, nll_loss=2.959, ppl=7.78, wps=88132.6, ups=3.03, wpb=29065.2, bsz=964.7, num_updates=136200, lr=8.56863e-05, gnorm=0.451, loss_scale=1, train_wall=33, gb_free=6.3, wall=45301
2021-04-05 13:12:49 | INFO | train_inner | epoch 029:   3326 / 4751 loss=4.602, nll_loss=3.006, ppl=8.04, wps=87912.2, ups=3.03, wpb=28991.2, bsz=931.2, num_updates=136300, lr=8.56549e-05, gnorm=0.442, loss_scale=1, train_wall=33, gb_free=6.3, wall=45334
2021-04-05 13:13:21 | INFO | train_inner | epoch 029:   3426 / 4751 loss=4.565, nll_loss=2.965, ppl=7.81, wps=88628.9, ups=3.05, wpb=29083.6, bsz=958.9, num_updates=136400, lr=8.56235e-05, gnorm=0.447, loss_scale=1, train_wall=33, gb_free=6.1, wall=45366
2021-04-05 13:13:54 | INFO | train_inner | epoch 029:   3526 / 4751 loss=4.556, nll_loss=2.954, ppl=7.75, wps=88366, ups=3.05, wpb=29018.9, bsz=937, num_updates=136500, lr=8.55921e-05, gnorm=0.438, loss_scale=1, train_wall=33, gb_free=6.1, wall=45399
2021-04-05 13:14:27 | INFO | train_inner | epoch 029:   3626 / 4751 loss=4.612, nll_loss=3.018, ppl=8.1, wps=87676.6, ups=3.04, wpb=28870.5, bsz=934.6, num_updates=136600, lr=8.55608e-05, gnorm=0.447, loss_scale=1, train_wall=33, gb_free=6.1, wall=45432
2021-04-05 13:15:00 | INFO | train_inner | epoch 029:   3726 / 4751 loss=4.578, nll_loss=2.98, ppl=7.89, wps=87173.7, ups=3.04, wpb=28720, bsz=927.2, num_updates=136700, lr=8.55295e-05, gnorm=0.442, loss_scale=1, train_wall=33, gb_free=6.2, wall=45465
2021-04-05 13:15:33 | INFO | train_inner | epoch 029:   3826 / 4751 loss=4.563, nll_loss=2.962, ppl=7.79, wps=88022.8, ups=3.03, wpb=29012.4, bsz=949.3, num_updates=136800, lr=8.54982e-05, gnorm=0.444, loss_scale=1, train_wall=33, gb_free=6.5, wall=45498
2021-04-05 13:16:06 | INFO | train_inner | epoch 029:   3926 / 4751 loss=4.567, nll_loss=2.967, ppl=7.82, wps=88477.2, ups=3.03, wpb=29172.4, bsz=943.6, num_updates=136900, lr=8.5467e-05, gnorm=0.445, loss_scale=1, train_wall=33, gb_free=6.4, wall=45531
2021-04-05 13:16:39 | INFO | train_inner | epoch 029:   4026 / 4751 loss=4.634, nll_loss=3.043, ppl=8.24, wps=87622.2, ups=3.04, wpb=28782.2, bsz=928.4, num_updates=137000, lr=8.54358e-05, gnorm=0.446, loss_scale=1, train_wall=33, gb_free=6.4, wall=45564
2021-04-05 13:17:12 | INFO | train_inner | epoch 029:   4126 / 4751 loss=4.606, nll_loss=3.011, ppl=8.06, wps=88408.5, ups=3.05, wpb=28964, bsz=937.3, num_updates=137100, lr=8.54046e-05, gnorm=0.449, loss_scale=1, train_wall=33, gb_free=6.6, wall=45597
2021-04-05 13:17:45 | INFO | train_inner | epoch 029:   4226 / 4751 loss=4.598, nll_loss=3.003, ppl=8.02, wps=88148, ups=3.04, wpb=28948.4, bsz=959.4, num_updates=137200, lr=8.53735e-05, gnorm=0.45, loss_scale=1, train_wall=33, gb_free=6, wall=45629
2021-04-05 13:18:18 | INFO | train_inner | epoch 029:   4326 / 4751 loss=4.562, nll_loss=2.962, ppl=7.79, wps=87165.2, ups=2.96, wpb=29410.4, bsz=962.8, num_updates=137300, lr=8.53424e-05, gnorm=0.445, loss_scale=1, train_wall=34, gb_free=6.1, wall=45663
2021-04-05 13:18:51 | INFO | train_inner | epoch 029:   4426 / 4751 loss=4.587, nll_loss=2.99, ppl=7.95, wps=87924.8, ups=3.04, wpb=28961.2, bsz=960.4, num_updates=137400, lr=8.53113e-05, gnorm=0.444, loss_scale=1, train_wall=33, gb_free=6.2, wall=45696
2021-04-05 13:19:24 | INFO | train_inner | epoch 029:   4526 / 4751 loss=4.583, nll_loss=2.986, ppl=7.92, wps=87886, ups=3.04, wpb=28903.5, bsz=934.9, num_updates=137500, lr=8.52803e-05, gnorm=0.441, loss_scale=1, train_wall=33, gb_free=7.3, wall=45729
2021-04-05 13:19:57 | INFO | train_inner | epoch 029:   4626 / 4751 loss=4.604, nll_loss=3.009, ppl=8.05, wps=87881.7, ups=3.02, wpb=29145.7, bsz=926.6, num_updates=137600, lr=8.52493e-05, gnorm=0.438, loss_scale=1, train_wall=33, gb_free=6.3, wall=45762
2021-04-05 13:20:30 | INFO | train_inner | epoch 029:   4726 / 4751 loss=4.622, nll_loss=3.029, ppl=8.16, wps=87492.4, ups=3.04, wpb=28797.8, bsz=953.1, num_updates=137700, lr=8.52183e-05, gnorm=0.453, loss_scale=2, train_wall=33, gb_free=6.8, wall=45795
2021-04-05 13:20:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-05 13:20:40 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 4.2 | nll_loss 2.434 | ppl 5.4 | wps 193309 | wpb 10489.1 | bsz 375 | num_updates 137725 | best_loss 4.2
2021-04-05 13:20:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 137725 updates
2021-04-05 13:20:40 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 13:20:46 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 13:20:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt (epoch 29 @ 137725 updates, score 4.2) (writing took 12.812069665640593 seconds)
2021-04-05 13:20:52 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2021-04-05 13:20:52 | INFO | train | epoch 029 | loss 4.583 | nll_loss 2.985 | ppl 7.92 | wps 87012.9 | ups 3 | wpb 28968 | bsz 946.7 | num_updates 137725 | lr 8.52106e-05 | gnorm 0.444 | loss_scale 2 | train_wall 1559 | gb_free 6.3 | wall 45817
2021-04-05 13:20:53 | INFO | fairseq.trainer | begin training epoch 30
2021-04-05 13:20:53 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-05 13:21:18 | INFO | train_inner | epoch 030:     75 / 4751 loss=4.548, nll_loss=2.946, ppl=7.71, wps=59890.9, ups=2.08, wpb=28780.2, bsz=979.4, num_updates=137800, lr=8.51874e-05, gnorm=0.448, loss_scale=2, train_wall=33, gb_free=6.1, wall=45843
2021-04-05 13:21:52 | INFO | train_inner | epoch 030:    175 / 4751 loss=4.52, nll_loss=2.913, ppl=7.53, wps=87223.2, ups=3, wpb=29071.7, bsz=927.8, num_updates=137900, lr=8.51565e-05, gnorm=0.438, loss_scale=2, train_wall=33, gb_free=6.2, wall=45876
2021-04-05 13:22:24 | INFO | train_inner | epoch 030:    275 / 4751 loss=4.607, nll_loss=3.011, ppl=8.06, wps=88054.9, ups=3.05, wpb=28870, bsz=912.9, num_updates=138000, lr=8.51257e-05, gnorm=0.444, loss_scale=2, train_wall=33, gb_free=6.5, wall=45909
2021-04-05 13:22:57 | INFO | train_inner | epoch 030:    375 / 4751 loss=4.592, nll_loss=2.995, ppl=7.97, wps=88119.4, ups=3.03, wpb=29057.1, bsz=925.5, num_updates=138100, lr=8.50948e-05, gnorm=0.446, loss_scale=2, train_wall=33, gb_free=6.4, wall=45942
2021-04-05 13:23:30 | INFO | train_inner | epoch 030:    475 / 4751 loss=4.56, nll_loss=2.959, ppl=7.78, wps=87444.5, ups=3.03, wpb=28845.6, bsz=942.1, num_updates=138200, lr=8.5064e-05, gnorm=0.443, loss_scale=2, train_wall=33, gb_free=6.3, wall=45975
2021-04-05 13:24:03 | INFO | train_inner | epoch 030:    575 / 4751 loss=4.552, nll_loss=2.95, ppl=7.73, wps=87999.7, ups=3.04, wpb=28952.1, bsz=935.7, num_updates=138300, lr=8.50333e-05, gnorm=0.446, loss_scale=2, train_wall=33, gb_free=6.3, wall=46008
2021-04-05 13:24:36 | INFO | train_inner | epoch 030:    675 / 4751 loss=4.613, nll_loss=3.019, ppl=8.11, wps=88266.1, ups=3.06, wpb=28810, bsz=966, num_updates=138400, lr=8.50026e-05, gnorm=0.45, loss_scale=2, train_wall=32, gb_free=6.2, wall=46041
2021-04-05 13:25:09 | INFO | train_inner | epoch 030:    775 / 4751 loss=4.537, nll_loss=2.932, ppl=7.63, wps=87213.6, ups=3.02, wpb=28831, bsz=944.6, num_updates=138500, lr=8.49719e-05, gnorm=0.442, loss_scale=2, train_wall=33, gb_free=6, wall=46074
2021-04-05 13:25:42 | INFO | train_inner | epoch 030:    875 / 4751 loss=4.584, nll_loss=2.986, ppl=7.93, wps=87515.5, ups=3.03, wpb=28878, bsz=945.8, num_updates=138600, lr=8.49412e-05, gnorm=0.452, loss_scale=2, train_wall=33, gb_free=6.2, wall=46107
2021-04-05 13:26:15 | INFO | train_inner | epoch 030:    975 / 4751 loss=4.52, nll_loss=2.914, ppl=7.54, wps=88075.5, ups=3.03, wpb=29074.5, bsz=972.8, num_updates=138700, lr=8.49106e-05, gnorm=0.441, loss_scale=2, train_wall=33, gb_free=6.4, wall=46140
2021-04-05 13:26:24 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-04-05 13:26:48 | INFO | train_inner | epoch 030:   1076 / 4751 loss=4.616, nll_loss=3.021, ppl=8.12, wps=85919.4, ups=2.99, wpb=28705, bsz=923.6, num_updates=138800, lr=8.488e-05, gnorm=0.452, loss_scale=1, train_wall=33, gb_free=6.6, wall=46173
2021-04-05 13:27:21 | INFO | train_inner | epoch 030:   1176 / 4751 loss=4.601, nll_loss=3.005, ppl=8.03, wps=89275.3, ups=3.06, wpb=29183.2, bsz=919.2, num_updates=138900, lr=8.48494e-05, gnorm=0.447, loss_scale=1, train_wall=33, gb_free=6.2, wall=46206
2021-04-05 13:27:54 | INFO | train_inner | epoch 030:   1276 / 4751 loss=4.584, nll_loss=2.986, ppl=7.92, wps=88676.4, ups=3.05, wpb=29094.6, bsz=936.9, num_updates=139000, lr=8.48189e-05, gnorm=0.445, loss_scale=1, train_wall=33, gb_free=6.4, wall=46239
2021-04-05 13:28:27 | INFO | train_inner | epoch 030:   1376 / 4751 loss=4.602, nll_loss=3.007, ppl=8.04, wps=87381.5, ups=3.02, wpb=28907.2, bsz=928.3, num_updates=139100, lr=8.47884e-05, gnorm=0.437, loss_scale=1, train_wall=33, gb_free=6.3, wall=46272
2021-04-05 13:29:00 | INFO | train_inner | epoch 030:   1476 / 4751 loss=4.52, nll_loss=2.914, ppl=7.54, wps=88163.5, ups=3.04, wpb=29012.5, bsz=977.5, num_updates=139200, lr=8.47579e-05, gnorm=0.446, loss_scale=1, train_wall=33, gb_free=6.1, wall=46305
2021-04-05 13:29:33 | INFO | train_inner | epoch 030:   1576 / 4751 loss=4.622, nll_loss=3.029, ppl=8.16, wps=88305.5, ups=3.06, wpb=28883.5, bsz=957, num_updates=139300, lr=8.47275e-05, gnorm=0.446, loss_scale=1, train_wall=33, gb_free=6.2, wall=46337
2021-04-05 13:30:06 | INFO | train_inner | epoch 030:   1676 / 4751 loss=4.568, nll_loss=2.968, ppl=7.83, wps=88102, ups=3.02, wpb=29142.2, bsz=965.3, num_updates=139400, lr=8.46971e-05, gnorm=0.443, loss_scale=1, train_wall=33, gb_free=6.1, wall=46370
2021-04-05 13:30:39 | INFO | train_inner | epoch 030:   1776 / 4751 loss=4.583, nll_loss=2.986, ppl=7.92, wps=87967, ups=3.03, wpb=29051.9, bsz=968.3, num_updates=139500, lr=8.46668e-05, gnorm=0.444, loss_scale=1, train_wall=33, gb_free=6.3, wall=46404
2021-04-05 13:31:12 | INFO | train_inner | epoch 030:   1876 / 4751 loss=4.524, nll_loss=2.918, ppl=7.56, wps=88661.2, ups=3.03, wpb=29259.5, bsz=935.1, num_updates=139600, lr=8.46364e-05, gnorm=0.439, loss_scale=1, train_wall=33, gb_free=6.3, wall=46437
2021-04-05 13:31:45 | INFO | train_inner | epoch 030:   1976 / 4751 loss=4.588, nll_loss=2.99, ppl=7.95, wps=88348, ups=3.03, wpb=29147.5, bsz=984.7, num_updates=139700, lr=8.46061e-05, gnorm=0.442, loss_scale=1, train_wall=33, gb_free=6.1, wall=46470
2021-04-05 13:32:18 | INFO | train_inner | epoch 030:   2076 / 4751 loss=4.506, nll_loss=2.898, ppl=7.46, wps=88716.6, ups=3.04, wpb=29147.3, bsz=980.8, num_updates=139800, lr=8.45759e-05, gnorm=0.448, loss_scale=1, train_wall=33, gb_free=6.4, wall=46502
2021-04-05 13:32:50 | INFO | train_inner | epoch 030:   2176 / 4751 loss=4.61, nll_loss=3.015, ppl=8.09, wps=87839.6, ups=3.05, wpb=28781, bsz=925.4, num_updates=139900, lr=8.45456e-05, gnorm=0.447, loss_scale=1, train_wall=33, gb_free=6, wall=46535
2021-04-05 13:33:24 | INFO | train_inner | epoch 030:   2276 / 4751 loss=4.596, nll_loss=3, ppl=8, wps=86013.9, ups=2.99, wpb=28797.9, bsz=943.3, num_updates=140000, lr=8.45154e-05, gnorm=0.446, loss_scale=1, train_wall=33, gb_free=6, wall=46569
2021-04-05 13:33:57 | INFO | train_inner | epoch 030:   2376 / 4751 loss=4.559, nll_loss=2.958, ppl=7.77, wps=86481.2, ups=3.01, wpb=28685.2, bsz=928.6, num_updates=140100, lr=8.44853e-05, gnorm=0.453, loss_scale=1, train_wall=33, gb_free=6.3, wall=46602
2021-04-05 13:34:30 | INFO | train_inner | epoch 030:   2476 / 4751 loss=4.637, nll_loss=3.046, ppl=8.26, wps=87832.1, ups=3.04, wpb=28923.1, bsz=939.4, num_updates=140200, lr=8.44551e-05, gnorm=0.45, loss_scale=1, train_wall=33, gb_free=6.3, wall=46635
2021-04-05 13:35:03 | INFO | train_inner | epoch 030:   2576 / 4751 loss=4.65, nll_loss=3.06, ppl=8.34, wps=87936, ups=3.04, wpb=28948.6, bsz=938.1, num_updates=140300, lr=8.4425e-05, gnorm=0.443, loss_scale=1, train_wall=33, gb_free=6.2, wall=46668
2021-04-05 13:35:36 | INFO | train_inner | epoch 030:   2676 / 4751 loss=4.581, nll_loss=2.983, ppl=7.9, wps=88626.2, ups=3.05, wpb=29093.8, bsz=950.7, num_updates=140400, lr=8.43949e-05, gnorm=0.44, loss_scale=1, train_wall=33, gb_free=6.3, wall=46700
2021-04-05 13:36:09 | INFO | train_inner | epoch 030:   2776 / 4751 loss=4.541, nll_loss=2.938, ppl=7.66, wps=88516.4, ups=3.04, wpb=29104.6, bsz=980.4, num_updates=140500, lr=8.43649e-05, gnorm=0.443, loss_scale=1, train_wall=33, gb_free=6.3, wall=46733
2021-04-05 13:36:42 | INFO | train_inner | epoch 030:   2876 / 4751 loss=4.568, nll_loss=2.969, ppl=7.83, wps=87764, ups=3.03, wpb=29001.8, bsz=937.4, num_updates=140600, lr=8.43349e-05, gnorm=0.447, loss_scale=1, train_wall=33, gb_free=6.2, wall=46766
2021-04-05 13:37:14 | INFO | train_inner | epoch 030:   2976 / 4751 loss=4.624, nll_loss=3.032, ppl=8.18, wps=88418.3, ups=3.05, wpb=28990.7, bsz=966.5, num_updates=140700, lr=8.43049e-05, gnorm=0.469, loss_scale=1, train_wall=33, gb_free=6.1, wall=46799
2021-04-05 13:37:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-04-05 13:37:47 | INFO | train_inner | epoch 030:   3077 / 4751 loss=4.605, nll_loss=3.011, ppl=8.06, wps=87895.5, ups=3.02, wpb=29105.6, bsz=939.8, num_updates=140800, lr=8.4275e-05, gnorm=0.456, loss_scale=1, train_wall=33, gb_free=6.2, wall=46832
2021-04-05 13:38:21 | INFO | train_inner | epoch 030:   3177 / 4751 loss=4.555, nll_loss=2.953, ppl=7.75, wps=87686.6, ups=3.02, wpb=29017.9, bsz=938.1, num_updates=140900, lr=8.42451e-05, gnorm=0.441, loss_scale=1, train_wall=33, gb_free=6.3, wall=46865
2021-04-05 13:38:53 | INFO | train_inner | epoch 030:   3277 / 4751 loss=4.585, nll_loss=2.987, ppl=7.93, wps=88369.9, ups=3.04, wpb=29104.6, bsz=929.1, num_updates=141000, lr=8.42152e-05, gnorm=0.453, loss_scale=1, train_wall=33, gb_free=6.4, wall=46898
2021-04-05 13:39:26 | INFO | train_inner | epoch 030:   3377 / 4751 loss=4.612, nll_loss=3.018, ppl=8.1, wps=87579.2, ups=3.07, wpb=28551.9, bsz=953.9, num_updates=141100, lr=8.41853e-05, gnorm=0.456, loss_scale=1, train_wall=32, gb_free=6.3, wall=46931
2021-04-05 13:39:59 | INFO | train_inner | epoch 030:   3477 / 4751 loss=4.599, nll_loss=3.003, ppl=8.01, wps=87752.4, ups=3.02, wpb=29042.3, bsz=921.4, num_updates=141200, lr=8.41555e-05, gnorm=0.445, loss_scale=1, train_wall=33, gb_free=6.2, wall=46964
2021-04-05 13:40:32 | INFO | train_inner | epoch 030:   3577 / 4751 loss=4.543, nll_loss=2.94, ppl=7.67, wps=88804.9, ups=3.04, wpb=29235.6, bsz=955, num_updates=141300, lr=8.41257e-05, gnorm=0.441, loss_scale=1, train_wall=33, gb_free=6.2, wall=46997
2021-04-05 13:41:05 | INFO | train_inner | epoch 030:   3677 / 4751 loss=4.549, nll_loss=2.947, ppl=7.71, wps=87482.1, ups=3.03, wpb=28862.7, bsz=934.3, num_updates=141400, lr=8.4096e-05, gnorm=0.441, loss_scale=1, train_wall=33, gb_free=6.1, wall=47030
2021-04-05 13:41:38 | INFO | train_inner | epoch 030:   3777 / 4751 loss=4.607, nll_loss=3.013, ppl=8.07, wps=86970.3, ups=3.02, wpb=28790.7, bsz=936.1, num_updates=141500, lr=8.40663e-05, gnorm=0.449, loss_scale=1, train_wall=33, gb_free=6, wall=47063
2021-04-05 13:42:11 | INFO | train_inner | epoch 030:   3877 / 4751 loss=4.538, nll_loss=2.935, ppl=7.65, wps=88643.6, ups=3.04, wpb=29111.5, bsz=970.6, num_updates=141600, lr=8.40366e-05, gnorm=0.441, loss_scale=1, train_wall=33, gb_free=6.4, wall=47096
2021-04-05 13:42:44 | INFO | train_inner | epoch 030:   3977 / 4751 loss=4.582, nll_loss=2.984, ppl=7.91, wps=86977.7, ups=3.01, wpb=28854.5, bsz=996.3, num_updates=141700, lr=8.40069e-05, gnorm=0.453, loss_scale=1, train_wall=33, gb_free=6.1, wall=47129
2021-04-05 13:43:17 | INFO | train_inner | epoch 030:   4077 / 4751 loss=4.558, nll_loss=2.957, ppl=7.77, wps=87847.2, ups=3.04, wpb=28878.4, bsz=919.8, num_updates=141800, lr=8.39773e-05, gnorm=0.446, loss_scale=1, train_wall=33, gb_free=6.3, wall=47162
2021-04-05 13:43:50 | INFO | train_inner | epoch 030:   4177 / 4751 loss=4.541, nll_loss=2.938, ppl=7.67, wps=88227.4, ups=3.04, wpb=29057.2, bsz=946.2, num_updates=141900, lr=8.39477e-05, gnorm=0.437, loss_scale=1, train_wall=33, gb_free=6.2, wall=47195
2021-04-05 13:44:23 | INFO | train_inner | epoch 030:   4277 / 4751 loss=4.586, nll_loss=2.989, ppl=7.94, wps=88062.5, ups=3.04, wpb=28967.3, bsz=979.3, num_updates=142000, lr=8.39181e-05, gnorm=0.449, loss_scale=1, train_wall=33, gb_free=6.3, wall=47228
2021-04-05 13:44:56 | INFO | train_inner | epoch 030:   4377 / 4751 loss=4.625, nll_loss=3.033, ppl=8.18, wps=87248.2, ups=3.03, wpb=28803.6, bsz=932.1, num_updates=142100, lr=8.38886e-05, gnorm=0.467, loss_scale=1, train_wall=33, gb_free=6.3, wall=47261
2021-04-05 13:45:29 | INFO | train_inner | epoch 030:   4477 / 4751 loss=4.595, nll_loss=2.999, ppl=8, wps=87211.7, ups=3.02, wpb=28904, bsz=936.2, num_updates=142200, lr=8.38591e-05, gnorm=0.448, loss_scale=1, train_wall=33, gb_free=6.3, wall=47294
2021-04-05 13:46:02 | INFO | train_inner | epoch 030:   4577 / 4751 loss=4.525, nll_loss=2.92, ppl=7.57, wps=89154.6, ups=3.03, wpb=29415.1, bsz=944, num_updates=142300, lr=8.38296e-05, gnorm=0.43, loss_scale=1, train_wall=33, gb_free=6.1, wall=47327
2021-04-05 13:46:35 | INFO | train_inner | epoch 030:   4677 / 4751 loss=4.694, nll_loss=3.111, ppl=8.64, wps=88189.3, ups=3.06, wpb=28849.7, bsz=941.6, num_updates=142400, lr=8.38002e-05, gnorm=0.453, loss_scale=1, train_wall=33, gb_free=6, wall=47360
2021-04-05 13:46:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-05 13:47:00 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 4.19 | nll_loss 2.419 | ppl 5.35 | wps 186037 | wpb 10489.1 | bsz 375 | num_updates 142474 | best_loss 4.19
2021-04-05 13:47:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 142474 updates
2021-04-05 13:47:00 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 13:47:07 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 13:47:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt (epoch 30 @ 142474 updates, score 4.19) (writing took 12.975960470736027 seconds)
2021-04-05 13:47:13 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2021-04-05 13:47:13 | INFO | train | epoch 030 | loss 4.579 | nll_loss 2.98 | ppl 7.89 | wps 87019.2 | ups 3 | wpb 28968.3 | bsz 946.9 | num_updates 142474 | lr 8.37784e-05 | gnorm 0.446 | loss_scale 1 | train_wall 1559 | gb_free 6.3 | wall 47398
2021-04-05 13:47:13 | INFO | fairseq.trainer | begin training epoch 31
2021-04-05 13:47:13 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-05 13:47:23 | INFO | train_inner | epoch 031:     26 / 4751 loss=4.539, nll_loss=2.936, ppl=7.65, wps=59515.3, ups=2.07, wpb=28807.5, bsz=956.6, num_updates=142500, lr=8.37708e-05, gnorm=0.448, loss_scale=1, train_wall=33, gb_free=6.5, wall=47408
2021-04-05 13:47:56 | INFO | train_inner | epoch 031:    126 / 4751 loss=4.557, nll_loss=2.956, ppl=7.76, wps=87946.9, ups=3.06, wpb=28722.3, bsz=996.6, num_updates=142600, lr=8.37414e-05, gnorm=0.442, loss_scale=1, train_wall=33, gb_free=6.1, wall=47441
2021-04-05 13:48:29 | INFO | train_inner | epoch 031:    226 / 4751 loss=4.55, nll_loss=2.948, ppl=7.72, wps=89111.3, ups=3.05, wpb=29212.5, bsz=953.8, num_updates=142700, lr=8.37121e-05, gnorm=0.44, loss_scale=1, train_wall=33, gb_free=6, wall=47473
2021-04-05 13:49:02 | INFO | train_inner | epoch 031:    326 / 4751 loss=4.644, nll_loss=3.054, ppl=8.3, wps=87005.5, ups=3.03, wpb=28675.5, bsz=961.9, num_updates=142800, lr=8.36827e-05, gnorm=0.459, loss_scale=1, train_wall=33, gb_free=6.3, wall=47506
2021-04-05 13:49:35 | INFO | train_inner | epoch 031:    426 / 4751 loss=4.514, nll_loss=2.907, ppl=7.5, wps=86787.6, ups=3.02, wpb=28731.9, bsz=937.8, num_updates=142900, lr=8.36535e-05, gnorm=0.46, loss_scale=2, train_wall=33, gb_free=6.2, wall=47540
2021-04-05 13:50:08 | INFO | train_inner | epoch 031:    526 / 4751 loss=4.581, nll_loss=2.982, ppl=7.9, wps=88866.9, ups=3.05, wpb=29149.6, bsz=942.9, num_updates=143000, lr=8.36242e-05, gnorm=0.447, loss_scale=2, train_wall=33, gb_free=6.1, wall=47572
2021-04-05 13:50:40 | INFO | train_inner | epoch 031:    626 / 4751 loss=4.616, nll_loss=3.022, ppl=8.12, wps=87824, ups=3.03, wpb=28962.4, bsz=933.7, num_updates=143100, lr=8.3595e-05, gnorm=0.455, loss_scale=2, train_wall=33, gb_free=6.1, wall=47605
2021-04-05 13:51:13 | INFO | train_inner | epoch 031:    726 / 4751 loss=4.569, nll_loss=2.969, ppl=7.83, wps=87555.7, ups=3.03, wpb=28892.5, bsz=953.7, num_updates=143200, lr=8.35658e-05, gnorm=0.445, loss_scale=2, train_wall=33, gb_free=6.3, wall=47638
2021-04-05 13:51:46 | INFO | train_inner | epoch 031:    826 / 4751 loss=4.547, nll_loss=2.943, ppl=7.69, wps=89507.6, ups=3.05, wpb=29354, bsz=947.5, num_updates=143300, lr=8.35366e-05, gnorm=0.437, loss_scale=2, train_wall=33, gb_free=6.4, wall=47671
2021-04-05 13:52:19 | INFO | train_inner | epoch 031:    926 / 4751 loss=4.555, nll_loss=2.954, ppl=7.75, wps=89234, ups=3.04, wpb=29335.1, bsz=939.8, num_updates=143400, lr=8.35075e-05, gnorm=0.446, loss_scale=2, train_wall=33, gb_free=6.1, wall=47704
2021-04-05 13:52:52 | INFO | train_inner | epoch 031:   1026 / 4751 loss=4.574, nll_loss=2.975, ppl=7.86, wps=89179.5, ups=3.04, wpb=29367.2, bsz=933.8, num_updates=143500, lr=8.34784e-05, gnorm=0.441, loss_scale=2, train_wall=33, gb_free=6, wall=47737
2021-04-05 13:53:25 | INFO | train_inner | epoch 031:   1126 / 4751 loss=4.61, nll_loss=3.016, ppl=8.09, wps=87970.8, ups=3.04, wpb=28908.4, bsz=941.4, num_updates=143600, lr=8.34493e-05, gnorm=0.454, loss_scale=2, train_wall=33, gb_free=6.1, wall=47770
2021-04-05 13:53:58 | INFO | train_inner | epoch 031:   1226 / 4751 loss=4.578, nll_loss=2.98, ppl=7.89, wps=87671, ups=3.05, wpb=28763.8, bsz=915, num_updates=143700, lr=8.34203e-05, gnorm=0.447, loss_scale=2, train_wall=33, gb_free=6, wall=47803
2021-04-05 13:54:31 | INFO | train_inner | epoch 031:   1326 / 4751 loss=4.556, nll_loss=2.955, ppl=7.75, wps=88020.8, ups=3.03, wpb=29031.4, bsz=949.7, num_updates=143800, lr=8.33913e-05, gnorm=0.456, loss_scale=2, train_wall=33, gb_free=6.2, wall=47836
2021-04-05 13:55:04 | INFO | train_inner | epoch 031:   1426 / 4751 loss=4.542, nll_loss=2.939, ppl=7.67, wps=88851.9, ups=3.04, wpb=29191.9, bsz=977.2, num_updates=143900, lr=8.33623e-05, gnorm=0.444, loss_scale=2, train_wall=33, gb_free=6.2, wall=47868
2021-04-05 13:55:36 | INFO | train_inner | epoch 031:   1526 / 4751 loss=4.559, nll_loss=2.958, ppl=7.77, wps=87165.8, ups=3.05, wpb=28603.1, bsz=927.1, num_updates=144000, lr=8.33333e-05, gnorm=0.448, loss_scale=2, train_wall=33, gb_free=6.2, wall=47901
2021-04-05 13:56:10 | INFO | train_inner | epoch 031:   1626 / 4751 loss=4.565, nll_loss=2.964, ppl=7.81, wps=87082.5, ups=3.02, wpb=28878.5, bsz=938.9, num_updates=144100, lr=8.33044e-05, gnorm=0.448, loss_scale=2, train_wall=33, gb_free=5.8, wall=47934
2021-04-05 13:56:42 | INFO | train_inner | epoch 031:   1726 / 4751 loss=4.613, nll_loss=3.019, ppl=8.11, wps=88322.5, ups=3.04, wpb=29067, bsz=951, num_updates=144200, lr=8.32755e-05, gnorm=0.448, loss_scale=2, train_wall=33, gb_free=6.1, wall=47967
2021-04-05 13:57:16 | INFO | train_inner | epoch 031:   1826 / 4751 loss=4.585, nll_loss=2.988, ppl=7.93, wps=87094.8, ups=3.02, wpb=28828.3, bsz=950.9, num_updates=144300, lr=8.32467e-05, gnorm=0.445, loss_scale=2, train_wall=33, gb_free=5.8, wall=48000
2021-04-05 13:57:48 | INFO | train_inner | epoch 031:   1926 / 4751 loss=4.647, nll_loss=3.057, ppl=8.32, wps=87845.4, ups=3.05, wpb=28798.1, bsz=927.3, num_updates=144400, lr=8.32178e-05, gnorm=0.451, loss_scale=2, train_wall=33, gb_free=6.1, wall=48033
2021-04-05 13:58:21 | INFO | train_inner | epoch 031:   2026 / 4751 loss=4.565, nll_loss=2.964, ppl=7.8, wps=86985.7, ups=3.04, wpb=28654.4, bsz=925.8, num_updates=144500, lr=8.3189e-05, gnorm=0.443, loss_scale=2, train_wall=33, gb_free=6.1, wall=48066
2021-04-05 13:58:55 | INFO | train_inner | epoch 031:   2126 / 4751 loss=4.544, nll_loss=2.941, ppl=7.68, wps=85587.5, ups=2.95, wpb=28978.4, bsz=964.5, num_updates=144600, lr=8.31603e-05, gnorm=0.457, loss_scale=2, train_wall=34, gb_free=6.2, wall=48100
2021-04-05 13:59:28 | INFO | train_inner | epoch 031:   2226 / 4751 loss=4.555, nll_loss=2.953, ppl=7.75, wps=88986.2, ups=3.04, wpb=29263.3, bsz=929.5, num_updates=144700, lr=8.31315e-05, gnorm=0.449, loss_scale=2, train_wall=33, gb_free=7.1, wall=48133
2021-04-05 14:00:01 | INFO | train_inner | epoch 031:   2326 / 4751 loss=4.595, nll_loss=2.998, ppl=7.99, wps=88067.1, ups=3.05, wpb=28889.1, bsz=942.6, num_updates=144800, lr=8.31028e-05, gnorm=0.445, loss_scale=2, train_wall=33, gb_free=6.3, wall=48166
2021-04-05 14:00:34 | INFO | train_inner | epoch 031:   2426 / 4751 loss=4.543, nll_loss=2.94, ppl=7.67, wps=87619.8, ups=3.02, wpb=28973.1, bsz=974.4, num_updates=144900, lr=8.30741e-05, gnorm=0.447, loss_scale=4, train_wall=33, gb_free=6.2, wall=48199
2021-04-05 14:01:07 | INFO | train_inner | epoch 031:   2526 / 4751 loss=4.54, nll_loss=2.937, ppl=7.66, wps=88327.6, ups=3.04, wpb=29037.8, bsz=955.3, num_updates=145000, lr=8.30455e-05, gnorm=0.443, loss_scale=4, train_wall=33, gb_free=6.3, wall=48232
2021-04-05 14:01:40 | INFO | train_inner | epoch 031:   2626 / 4751 loss=4.52, nll_loss=2.914, ppl=7.54, wps=88534.9, ups=3.04, wpb=29143.4, bsz=936.2, num_updates=145100, lr=8.30169e-05, gnorm=0.446, loss_scale=4, train_wall=33, gb_free=6.2, wall=48265
2021-04-05 14:02:13 | INFO | train_inner | epoch 031:   2726 / 4751 loss=4.553, nll_loss=2.952, ppl=7.74, wps=87939.9, ups=3.03, wpb=28981.8, bsz=952.3, num_updates=145200, lr=8.29883e-05, gnorm=0.452, loss_scale=4, train_wall=33, gb_free=6.2, wall=48297
2021-04-05 14:02:46 | INFO | train_inner | epoch 031:   2826 / 4751 loss=4.542, nll_loss=2.939, ppl=7.67, wps=87942.5, ups=3.03, wpb=29034.7, bsz=955.8, num_updates=145300, lr=8.29597e-05, gnorm=0.441, loss_scale=4, train_wall=33, gb_free=6.3, wall=48331
2021-04-05 14:03:19 | INFO | train_inner | epoch 031:   2926 / 4751 loss=4.656, nll_loss=3.068, ppl=8.39, wps=87618.5, ups=3.04, wpb=28789.6, bsz=913.9, num_updates=145400, lr=8.29312e-05, gnorm=0.452, loss_scale=4, train_wall=33, gb_free=6.3, wall=48363
2021-04-05 14:03:51 | INFO | train_inner | epoch 031:   3026 / 4751 loss=4.567, nll_loss=2.967, ppl=7.82, wps=87391.7, ups=3.04, wpb=28764, bsz=927.3, num_updates=145500, lr=8.29027e-05, gnorm=0.46, loss_scale=4, train_wall=33, gb_free=6, wall=48396
2021-04-05 14:04:24 | INFO | train_inner | epoch 031:   3126 / 4751 loss=4.618, nll_loss=3.025, ppl=8.14, wps=87874.7, ups=3.05, wpb=28802.6, bsz=890.2, num_updates=145600, lr=8.28742e-05, gnorm=0.45, loss_scale=4, train_wall=33, gb_free=6.9, wall=48429
2021-04-05 14:04:58 | INFO | train_inner | epoch 031:   3226 / 4751 loss=4.515, nll_loss=2.908, ppl=7.51, wps=87641.1, ups=3, wpb=29199.5, bsz=966.6, num_updates=145700, lr=8.28457e-05, gnorm=0.439, loss_scale=4, train_wall=33, gb_free=6.1, wall=48462
2021-04-05 14:05:31 | INFO | train_inner | epoch 031:   3326 / 4751 loss=4.571, nll_loss=2.971, ppl=7.84, wps=88213, ups=3.02, wpb=29247.6, bsz=930.8, num_updates=145800, lr=8.28173e-05, gnorm=0.44, loss_scale=4, train_wall=33, gb_free=6.2, wall=48496
2021-04-05 14:06:04 | INFO | train_inner | epoch 031:   3426 / 4751 loss=4.611, nll_loss=3.018, ppl=8.1, wps=87632.3, ups=3.04, wpb=28798.1, bsz=944.8, num_updates=145900, lr=8.27889e-05, gnorm=0.462, loss_scale=4, train_wall=33, gb_free=6.9, wall=48528
2021-04-05 14:06:36 | INFO | train_inner | epoch 031:   3526 / 4751 loss=4.608, nll_loss=3.014, ppl=8.08, wps=88140.1, ups=3.05, wpb=28858.3, bsz=955, num_updates=146000, lr=8.27606e-05, gnorm=0.458, loss_scale=4, train_wall=33, gb_free=6.7, wall=48561
2021-04-05 14:07:10 | INFO | train_inner | epoch 031:   3626 / 4751 loss=4.584, nll_loss=2.987, ppl=7.93, wps=87325.8, ups=3.01, wpb=29032.2, bsz=969, num_updates=146100, lr=8.27323e-05, gnorm=0.446, loss_scale=4, train_wall=33, gb_free=6.2, wall=48594
2021-04-05 14:07:43 | INFO | train_inner | epoch 031:   3726 / 4751 loss=4.585, nll_loss=2.988, ppl=7.93, wps=87926.3, ups=3.03, wpb=29010, bsz=968.7, num_updates=146200, lr=8.2704e-05, gnorm=0.442, loss_scale=4, train_wall=33, gb_free=6.4, wall=48627
2021-04-05 14:08:15 | INFO | train_inner | epoch 031:   3826 / 4751 loss=4.599, nll_loss=3.004, ppl=8.02, wps=87179.2, ups=3.04, wpb=28709.3, bsz=945.8, num_updates=146300, lr=8.26757e-05, gnorm=0.447, loss_scale=4, train_wall=33, gb_free=6.4, wall=48660
2021-04-05 14:08:48 | INFO | train_inner | epoch 031:   3926 / 4751 loss=4.591, nll_loss=2.995, ppl=7.97, wps=87866.5, ups=3.04, wpb=28899.5, bsz=933.8, num_updates=146400, lr=8.26475e-05, gnorm=0.443, loss_scale=4, train_wall=33, gb_free=6.2, wall=48693
2021-04-05 14:09:21 | INFO | train_inner | epoch 031:   4026 / 4751 loss=4.591, nll_loss=2.995, ppl=7.97, wps=88178.9, ups=3.06, wpb=28832.5, bsz=969, num_updates=146500, lr=8.26192e-05, gnorm=0.451, loss_scale=4, train_wall=33, gb_free=6.1, wall=48726
2021-04-05 14:09:54 | INFO | train_inner | epoch 031:   4126 / 4751 loss=4.537, nll_loss=2.933, ppl=7.64, wps=88384.2, ups=3.03, wpb=29178, bsz=961.2, num_updates=146600, lr=8.25911e-05, gnorm=0.44, loss_scale=4, train_wall=33, gb_free=6.2, wall=48759
2021-04-05 14:10:27 | INFO | train_inner | epoch 031:   4226 / 4751 loss=4.529, nll_loss=2.925, ppl=7.6, wps=87772.1, ups=3.03, wpb=28986.8, bsz=971.3, num_updates=146700, lr=8.25629e-05, gnorm=0.457, loss_scale=4, train_wall=33, gb_free=6.2, wall=48792
2021-04-05 14:11:00 | INFO | train_inner | epoch 031:   4326 / 4751 loss=4.583, nll_loss=2.986, ppl=7.92, wps=87755.1, ups=3.05, wpb=28779.9, bsz=946.5, num_updates=146800, lr=8.25348e-05, gnorm=0.452, loss_scale=4, train_wall=33, gb_free=6.2, wall=48825
2021-04-05 14:11:33 | INFO | train_inner | epoch 031:   4426 / 4751 loss=4.564, nll_loss=2.964, ppl=7.8, wps=89359.1, ups=3.03, wpb=29451.6, bsz=947, num_updates=146900, lr=8.25067e-05, gnorm=0.437, loss_scale=4, train_wall=33, gb_free=6.4, wall=48858
2021-04-05 14:12:06 | INFO | train_inner | epoch 031:   4526 / 4751 loss=4.621, nll_loss=3.029, ppl=8.16, wps=87858.6, ups=3.05, wpb=28766.9, bsz=941, num_updates=147000, lr=8.24786e-05, gnorm=0.455, loss_scale=8, train_wall=33, gb_free=6.5, wall=48890
2021-04-05 14:12:38 | INFO | train_inner | epoch 031:   4626 / 4751 loss=4.603, nll_loss=3.009, ppl=8.05, wps=88091.6, ups=3.05, wpb=28920.9, bsz=941.7, num_updates=147100, lr=8.24506e-05, gnorm=0.451, loss_scale=8, train_wall=33, gb_free=6, wall=48923
2021-04-05 14:12:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2021-04-05 14:13:12 | INFO | train_inner | epoch 031:   4727 / 4751 loss=4.553, nll_loss=2.951, ppl=7.73, wps=87730.3, ups=3.01, wpb=29194.3, bsz=971.9, num_updates=147200, lr=8.24226e-05, gnorm=0.449, loss_scale=4, train_wall=33, gb_free=6.3, wall=48957
2021-04-05 14:13:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-05 14:13:21 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 4.199 | nll_loss 2.428 | ppl 5.38 | wps 191270 | wpb 10489.1 | bsz 375 | num_updates 147224 | best_loss 4.19
2021-04-05 14:13:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 147224 updates
2021-04-05 14:13:21 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-05 14:13:27 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-05 14:13:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt (epoch 31 @ 147224 updates, score 4.199) (writing took 6.406333409249783 seconds)
2021-04-05 14:13:27 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2021-04-05 14:13:27 | INFO | train | epoch 031 | loss 4.574 | nll_loss 2.976 | ppl 7.87 | wps 87433.4 | ups 3.02 | wpb 28968.3 | bsz 947 | num_updates 147224 | lr 8.24158e-05 | gnorm 0.448 | loss_scale 4 | train_wall 1558 | gb_free 6.9 | wall 48972
2021-04-05 14:13:27 | INFO | fairseq.trainer | begin training epoch 32
2021-04-05 14:13:27 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-05 14:13:53 | INFO | train_inner | epoch 032:     76 / 4751 loss=4.564, nll_loss=2.964, ppl=7.8, wps=69453.7, ups=2.4, wpb=28926.2, bsz=925.8, num_updates=147300, lr=8.23946e-05, gnorm=0.446, loss_scale=4, train_wall=33, gb_free=6.3, wall=48998
2021-04-05 14:14:26 | INFO | train_inner | epoch 032:    176 / 4751 loss=4.57, nll_loss=2.97, ppl=7.84, wps=87997.9, ups=3.03, wpb=29011.7, bsz=937.3, num_updates=147400, lr=8.23666e-05, gnorm=0.448, loss_scale=4, train_wall=33, gb_free=6.5, wall=49031
2021-04-05 14:14:59 | INFO | train_inner | epoch 032:    276 / 4751 loss=4.536, nll_loss=2.932, ppl=7.63, wps=89214.1, ups=3.04, wpb=29341.2, bsz=967.4, num_updates=147500, lr=8.23387e-05, gnorm=0.447, loss_scale=4, train_wall=33, gb_free=6.5, wall=49064
2021-04-05 14:15:32 | INFO | train_inner | epoch 032:    376 / 4751 loss=4.63, nll_loss=3.038, ppl=8.21, wps=87475.7, ups=3.06, wpb=28576.5, bsz=917.5, num_updates=147600, lr=8.23108e-05, gnorm=0.462, loss_scale=4, train_wall=33, gb_free=6.1, wall=49097
2021-04-05 14:16:05 | INFO | train_inner | epoch 032:    476 / 4751 loss=4.601, nll_loss=3.005, ppl=8.03, wps=88635.7, ups=3.04, wpb=29130.9, bsz=967.6, num_updates=147700, lr=8.22829e-05, gnorm=0.443, loss_scale=4, train_wall=33, gb_free=6.3, wall=49130
2021-04-05 14:16:38 | INFO | train_inner | epoch 032:    576 / 4751 loss=4.534, nll_loss=2.93, ppl=7.62, wps=87698.1, ups=3.05, wpb=28716.2, bsz=955.9, num_updates=147800, lr=8.22551e-05, gnorm=0.455, loss_scale=4, train_wall=33, gb_free=6, wall=49162
2021-04-05 14:17:10 | INFO | train_inner | epoch 032:    676 / 4751 loss=4.608, nll_loss=3.012, ppl=8.07, wps=89248, ups=3.05, wpb=29296.5, bsz=905.5, num_updates=147900, lr=8.22273e-05, gnorm=0.445, loss_scale=4, train_wall=33, gb_free=6.2, wall=49195
2021-04-05 14:17:43 | INFO | train_inner | epoch 032:    776 / 4751 loss=4.583, nll_loss=2.986, ppl=7.92, wps=88107.6, ups=3.06, wpb=28800, bsz=947.8, num_updates=148000, lr=8.21995e-05, gnorm=0.451, loss_scale=4, train_wall=33, gb_free=6.2, wall=49228
2021-04-05 14:18:16 | INFO | train_inner | epoch 032:    876 / 4751 loss=4.562, nll_loss=2.961, ppl=7.79, wps=87665.6, ups=3.03, wpb=28933.2, bsz=959.2, num_updates=148100, lr=8.21717e-05, gnorm=0.445, loss_scale=4, train_wall=33, gb_free=6.5, wall=49261
2021-04-05 14:18:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-05 14:18:49 | INFO | train_inner | epoch 032:    977 / 4751 loss=4.55, nll_loss=2.947, ppl=7.71, wps=86412.7, ups=3, wpb=28817.2, bsz=925.2, num_updates=148200, lr=8.2144e-05, gnorm=0.452, loss_scale=2, train_wall=33, gb_free=6.2, wall=49294
2021-04-05 14:19:22 | INFO | train_inner | epoch 032:   1077 / 4751 loss=4.564, nll_loss=2.964, ppl=7.8, wps=88448.6, ups=3.03, wpb=29193, bsz=940.2, num_updates=148300, lr=8.21163e-05, gnorm=0.444, loss_scale=2, train_wall=33, gb_free=6.5, wall=49327
2021-04-05 14:19:55 | INFO | train_inner | epoch 032:   1177 / 4751 loss=4.608, nll_loss=3.014, ppl=8.08, wps=87781.6, ups=3.04, wpb=28899.4, bsz=944.3, num_updates=148400, lr=8.20886e-05, gnorm=0.455, loss_scale=2, train_wall=33, gb_free=6.2, wall=49360
2021-04-05 14:20:28 | INFO | train_inner | epoch 032:   1277 / 4751 loss=4.559, nll_loss=2.958, ppl=7.77, wps=88315.1, ups=3.04, wpb=29078.2, bsz=951.6, num_updates=148500, lr=8.2061e-05, gnorm=0.449, loss_scale=2, train_wall=33, gb_free=6.3, wall=49393
2021-04-05 14:21:01 | INFO | train_inner | epoch 032:   1377 / 4751 loss=4.593, nll_loss=2.996, ppl=7.98, wps=88411.8, ups=3.04, wpb=29067.1, bsz=941.5, num_updates=148600, lr=8.20334e-05, gnorm=0.449, loss_scale=2, train_wall=33, gb_free=6.1, wall=49426
2021-04-05 14:21:34 | INFO | train_inner | epoch 032:   1477 / 4751 loss=4.55, nll_loss=2.948, ppl=7.71, wps=88248.1, ups=3.04, wpb=28997.1, bsz=955, num_updates=148700, lr=8.20058e-05, gnorm=0.445, loss_scale=2, train_wall=33, gb_free=5.8, wall=49459
2021-04-05 14:22:07 | INFO | train_inner | epoch 032:   1577 / 4751 loss=4.5, nll_loss=2.892, ppl=7.42, wps=88681.2, ups=3.02, wpb=29372.8, bsz=953, num_updates=148800, lr=8.19782e-05, gnorm=0.444, loss_scale=2, train_wall=33, gb_free=6, wall=49492
2021-04-05 14:22:40 | INFO | train_inner | epoch 032:   1677 / 4751 loss=4.571, nll_loss=2.972, ppl=7.84, wps=87936.8, ups=3.03, wpb=29016.6, bsz=939.4, num_updates=148900, lr=8.19507e-05, gnorm=0.449, loss_scale=2, train_wall=33, gb_free=6.1, wall=49525
2021-04-05 14:23:13 | INFO | train_inner | epoch 032:   1777 / 4751 loss=4.625, nll_loss=3.032, ppl=8.18, wps=87764.3, ups=3.04, wpb=28829.3, bsz=899.2, num_updates=149000, lr=8.19232e-05, gnorm=0.452, loss_scale=2, train_wall=33, gb_free=6.3, wall=49558
2021-04-05 14:23:46 | INFO | train_inner | epoch 032:   1877 / 4751 loss=4.541, nll_loss=2.938, ppl=7.67, wps=87303.6, ups=3.03, wpb=28847.1, bsz=982.7, num_updates=149100, lr=8.18957e-05, gnorm=0.447, loss_scale=2, train_wall=33, gb_free=6.2, wall=49591
2021-04-05 14:24:19 | INFO | train_inner | epoch 032:   1977 / 4751 loss=4.558, nll_loss=2.957, ppl=7.76, wps=89455.1, ups=3.04, wpb=29391.4, bsz=955.7, num_updates=149200, lr=8.18683e-05, gnorm=0.444, loss_scale=2, train_wall=33, gb_free=6.3, wall=49624
2021-04-05 14:24:52 | INFO | train_inner | epoch 032:   2077 / 4751 loss=4.538, nll_loss=2.935, ppl=7.65, wps=87561.5, ups=3.03, wpb=28858.8, bsz=965.7, num_updates=149300, lr=8.18408e-05, gnorm=0.448, loss_scale=2, train_wall=33, gb_free=6.1, wall=49657
2021-04-05 14:25:25 | INFO | train_inner | epoch 032:   2177 / 4751 loss=4.589, nll_loss=2.992, ppl=7.96, wps=87369.5, ups=3.04, wpb=28782.5, bsz=920.9, num_updates=149400, lr=8.18134e-05, gnorm=0.454, loss_scale=2, train_wall=33, gb_free=6.2, wall=49690
2021-04-05 14:25:57 | INFO | train_inner | epoch 032:   2277 / 4751 loss=4.592, nll_loss=2.996, ppl=7.98, wps=88419.5, ups=3.06, wpb=28853.1, bsz=944.5, num_updates=149500, lr=8.17861e-05, gnorm=0.449, loss_scale=2, train_wall=32, gb_free=6.2, wall=49722
2021-04-05 14:26:30 | INFO | train_inner | epoch 032:   2377 / 4751 loss=4.547, nll_loss=2.944, ppl=7.7, wps=88075.2, ups=3.03, wpb=29075.6, bsz=961.9, num_updates=149600, lr=8.17587e-05, gnorm=0.454, loss_scale=2, train_wall=33, gb_free=6, wall=49755
2021-04-05 14:27:03 | INFO | train_inner | epoch 032:   2477 / 4751 loss=4.587, nll_loss=2.99, ppl=7.94, wps=87325.9, ups=3.03, wpb=28864.9, bsz=924.5, num_updates=149700, lr=8.17314e-05, gnorm=0.445, loss_scale=2, train_wall=33, gb_free=6.1, wall=49788
2021-04-05 14:27:36 | INFO | train_inner | epoch 032:   2577 / 4751 loss=4.557, nll_loss=2.957, ppl=7.76, wps=87171.3, ups=3.03, wpb=28803.9, bsz=944.4, num_updates=149800, lr=8.17041e-05, gnorm=0.472, loss_scale=2, train_wall=33, gb_free=6.4, wall=49821
2021-04-05 14:28:09 | INFO | train_inner | epoch 032:   2677 / 4751 loss=4.553, nll_loss=2.952, ppl=7.74, wps=88403.7, ups=3.04, wpb=29049, bsz=988.4, num_updates=149900, lr=8.16769e-05, gnorm=0.454, loss_scale=2, train_wall=33, gb_free=6.3, wall=49854
2021-04-05 14:28:42 | INFO | train_inner | epoch 032:   2777 / 4751 loss=4.565, nll_loss=2.965, ppl=7.81, wps=88115.9, ups=3.04, wpb=28965, bsz=924.9, num_updates=150000, lr=8.16497e-05, gnorm=0.447, loss_scale=2, train_wall=33, gb_free=6.2, wall=49887
2021-04-05 14:29:15 | INFO | train_inner | epoch 032:   2877 / 4751 loss=4.616, nll_loss=3.023, ppl=8.13, wps=88361.9, ups=3.05, wpb=28998.4, bsz=969.4, num_updates=150100, lr=8.16225e-05, gnorm=0.45, loss_scale=2, train_wall=33, gb_free=6.3, wall=49920
2021-04-05 14:29:48 | INFO | train_inner | epoch 032:   2977 / 4751 loss=4.484, nll_loss=2.874, ppl=7.33, wps=87641.5, ups=3.03, wpb=28947.2, bsz=1002.9, num_updates=150200, lr=8.15953e-05, gnorm=0.441, loss_scale=4, train_wall=33, gb_free=6.2, wall=49953
2021-04-05 14:30:21 | INFO | train_inner | epoch 032:   3077 / 4751 loss=4.604, nll_loss=3.009, ppl=8.05, wps=88303.7, ups=3.04, wpb=29066.2, bsz=953.4, num_updates=150300, lr=8.15681e-05, gnorm=0.45, loss_scale=4, train_wall=33, gb_free=6.2, wall=49986
2021-04-05 14:30:54 | INFO | train_inner | epoch 032:   3177 / 4751 loss=4.543, nll_loss=2.941, ppl=7.68, wps=87815.3, ups=3.02, wpb=29041.6, bsz=963.2, num_updates=150400, lr=8.1541e-05, gnorm=0.446, loss_scale=4, train_wall=33, gb_free=6.1, wall=50019
2021-04-05 14:31:27 | INFO | train_inner | epoch 032:   3277 / 4751 loss=4.629, nll_loss=3.038, ppl=8.21, wps=88613.1, ups=3.05, wpb=29064, bsz=914.8, num_updates=150500, lr=8.15139e-05, gnorm=0.452, loss_scale=4, train_wall=33, gb_free=6.3, wall=50052
2021-04-05 14:32:00 | INFO | train_inner | epoch 032:   3377 / 4751 loss=4.581, nll_loss=2.984, ppl=7.91, wps=87619.4, ups=3.03, wpb=28884.5, bsz=985.6, num_updates=150600, lr=8.14868e-05, gnorm=0.458, loss_scale=4, train_wall=33, gb_free=6.4, wall=50085
2021-04-05 14:32:33 | INFO | train_inner | epoch 032:   3477 / 4751 loss=4.543, nll_loss=2.94, ppl=7.68, wps=88903.1, ups=3.05, wpb=29133.5, bsz=974.9, num_updates=150700, lr=8.14598e-05, gnorm=0.445, loss_scale=4, train_wall=33, gb_free=6.3, wall=50117
2021-04-05 14:33:06 | INFO | train_inner | epoch 032:   3577 / 4751 loss=4.539, nll_loss=2.936, ppl=7.65, wps=87600.3, ups=3.02, wpb=29013, bsz=956, num_updates=150800, lr=8.14328e-05, gnorm=0.451, loss_scale=4, train_wall=33, gb_free=6.3, wall=50151
2021-04-05 14:33:39 | INFO | train_inner | epoch 032:   3677 / 4751 loss=4.582, nll_loss=2.984, ppl=7.91, wps=87672.7, ups=3.04, wpb=28855.6, bsz=943.9, num_updates=150900, lr=8.14058e-05, gnorm=0.448, loss_scale=4, train_wall=33, gb_free=6.1, wall=50183
2021-04-05 14:34:11 | INFO | train_inner | epoch 032:   3777 / 4751 loss=4.608, nll_loss=3.014, ppl=8.08, wps=88087.6, ups=3.04, wpb=28951.7, bsz=919.6, num_updates=151000, lr=8.13788e-05, gnorm=0.452, loss_scale=4, train_wall=33, gb_free=6.1, wall=50216
2021-04-05 14:34:44 | INFO | train_inner | epoch 032:   3877 / 4751 loss=4.566, nll_loss=2.966, ppl=7.81, wps=88699, ups=3.05, wpb=29100.5, bsz=967.7, num_updates=151100, lr=8.13519e-05, gnorm=0.452, loss_scale=4, train_wall=33, gb_free=6.9, wall=50249
2021-04-05 14:35:17 | INFO | train_inner | epoch 032:   3977 / 4751 loss=4.62, nll_loss=3.027, ppl=8.15, wps=89195.5, ups=3.07, wpb=29087.9, bsz=921, num_updates=151200, lr=8.1325e-05, gnorm=0.448, loss_scale=4, train_wall=32, gb_free=6, wall=50282
2021-04-05 14:35:51 | INFO | train_inner | epoch 032:   4077 / 4751 loss=4.565, nll_loss=2.965, ppl=7.81, wps=85218.8, ups=2.97, wpb=28672.7, bsz=937.2, num_updates=151300, lr=8.12981e-05, gnorm=0.448, loss_scale=4, train_wall=34, gb_free=6.2, wall=50315
2021-04-05 14:36:23 | INFO | train_inner | epoch 032:   4177 / 4751 loss=4.626, nll_loss=3.035, ppl=8.19, wps=87260.1, ups=3.04, wpb=28715.4, bsz=944.9, num_updates=151400, lr=8.12713e-05, gnorm=0.45, loss_scale=4, train_wall=33, gb_free=6.3, wall=50348
2021-04-05 14:36:56 | INFO | train_inner | epoch 032:   4277 / 4751 loss=4.571, nll_loss=2.972, ppl=7.85, wps=87672.7, ups=3.04, wpb=28814.7, bsz=920.9, num_updates=151500, lr=8.12444e-05, gnorm=0.45, loss_scale=4, train_wall=33, gb_free=6.6, wall=50381
2021-04-05 14:37:29 | INFO | train_inner | epoch 032:   4377 / 4751 loss=4.575, nll_loss=2.978, ppl=7.88, wps=88396.6, ups=3.06, wpb=28886.3, bsz=968.8, num_updates=151600, lr=8.12176e-05, gnorm=0.448, loss_scale=4, train_wall=33, gb_free=6.3, wall=50414
2021-04-05 14:38:02 | INFO | train_inner | epoch 032:   4477 / 4751 loss=4.53, nll_loss=2.926, ppl=7.6, wps=87967.5, ups=3.04, wpb=28944.1, bsz=942.4, num_updates=151700, lr=8.11909e-05, gnorm=0.441, loss_scale=4, train_wall=33, gb_free=6.1, wall=50447
2021-04-05 14:38:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-05 14:38:35 | INFO | train_inner | epoch 032:   4578 / 4751 loss=4.544, nll_loss=2.942, ppl=7.68, wps=86437.9, ups=2.99, wpb=28922.4, bsz=955.7, num_updates=151800, lr=8.11641e-05, gnorm=0.446, loss_scale=2, train_wall=33, gb_free=6.1, wall=50480
2021-04-05 14:39:09 | INFO | train_inner | epoch 032:   4678 / 4751 loss=4.549, nll_loss=2.947, ppl=7.71, wps=86523.6, ups=3.01, wpb=28748.6, bsz=928.7, num_updates=151900, lr=8.11374e-05, gnorm=0.442, loss_scale=2, train_wall=33, gb_free=6.2, wall=50513
2021-04-05 14:39:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-05 14:39:34 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 4.189 | nll_loss 2.419 | ppl 5.35 | wps 198464 | wpb 10489.1 | bsz 375 | num_updates 151973 | best_loss 4.189
2021-04-05 14:39:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 151973 updates
2021-04-05 14:39:34 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 14:39:40 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 14:39:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt (epoch 32 @ 151973 updates, score 4.189) (writing took 12.946263678371906 seconds)
2021-04-05 14:39:47 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2021-04-05 14:39:47 | INFO | train | epoch 032 | loss 4.57 | nll_loss 2.971 | ppl 7.84 | wps 87091.3 | ups 3.01 | wpb 28968.2 | bsz 946.9 | num_updates 151973 | lr 8.11179e-05 | gnorm 0.449 | loss_scale 2 | train_wall 1557 | gb_free 7.9 | wall 50552
2021-04-05 14:39:47 | INFO | fairseq.trainer | begin training epoch 33
2021-04-05 14:39:47 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-05 14:39:57 | INFO | train_inner | epoch 033:     27 / 4751 loss=4.564, nll_loss=2.964, ppl=7.8, wps=59901.9, ups=2.07, wpb=28975.5, bsz=934.5, num_updates=152000, lr=8.11107e-05, gnorm=0.447, loss_scale=2, train_wall=33, gb_free=6.2, wall=50562
2021-04-05 14:40:30 | INFO | train_inner | epoch 033:    127 / 4751 loss=4.583, nll_loss=2.985, ppl=7.92, wps=87201.8, ups=3.05, wpb=28583.4, bsz=951.1, num_updates=152100, lr=8.1084e-05, gnorm=0.456, loss_scale=2, train_wall=33, gb_free=6.4, wall=50595
2021-04-05 14:41:02 | INFO | train_inner | epoch 033:    227 / 4751 loss=4.583, nll_loss=2.985, ppl=7.92, wps=88768.8, ups=3.06, wpb=29026.7, bsz=937, num_updates=152200, lr=8.10574e-05, gnorm=0.455, loss_scale=2, train_wall=33, gb_free=6.1, wall=50627
2021-04-05 14:41:35 | INFO | train_inner | epoch 033:    327 / 4751 loss=4.579, nll_loss=2.981, ppl=7.89, wps=88211.5, ups=3.05, wpb=28919, bsz=930.4, num_updates=152300, lr=8.10308e-05, gnorm=0.45, loss_scale=2, train_wall=33, gb_free=6.2, wall=50660
2021-04-05 14:42:08 | INFO | train_inner | epoch 033:    427 / 4751 loss=4.584, nll_loss=2.986, ppl=7.92, wps=88011.1, ups=3.05, wpb=28864, bsz=950.6, num_updates=152400, lr=8.10042e-05, gnorm=0.451, loss_scale=2, train_wall=33, gb_free=6, wall=50693
2021-04-05 14:42:41 | INFO | train_inner | epoch 033:    527 / 4751 loss=4.563, nll_loss=2.963, ppl=7.8, wps=88396.7, ups=3.07, wpb=28836.2, bsz=941.5, num_updates=152500, lr=8.09776e-05, gnorm=0.456, loss_scale=2, train_wall=32, gb_free=6.2, wall=50725
2021-04-05 14:43:14 | INFO | train_inner | epoch 033:    627 / 4751 loss=4.528, nll_loss=2.923, ppl=7.58, wps=88220.2, ups=3.04, wpb=28997.7, bsz=938.6, num_updates=152600, lr=8.09511e-05, gnorm=0.448, loss_scale=2, train_wall=33, gb_free=6.3, wall=50758
2021-04-05 14:43:46 | INFO | train_inner | epoch 033:    727 / 4751 loss=4.572, nll_loss=2.973, ppl=7.85, wps=88507.3, ups=3.05, wpb=28985.3, bsz=906.2, num_updates=152700, lr=8.09246e-05, gnorm=0.457, loss_scale=2, train_wall=33, gb_free=6.1, wall=50791
2021-04-05 14:44:19 | INFO | train_inner | epoch 033:    827 / 4751 loss=4.584, nll_loss=2.987, ppl=7.93, wps=86770.6, ups=3.02, wpb=28688.9, bsz=959.3, num_updates=152800, lr=8.08981e-05, gnorm=0.451, loss_scale=2, train_wall=33, gb_free=6.3, wall=50824
2021-04-05 14:44:52 | INFO | train_inner | epoch 033:    927 / 4751 loss=4.61, nll_loss=3.016, ppl=8.09, wps=88761.5, ups=3.05, wpb=29110.4, bsz=926.1, num_updates=152900, lr=8.08716e-05, gnorm=0.448, loss_scale=2, train_wall=33, gb_free=6.3, wall=50857
2021-04-05 14:45:25 | INFO | train_inner | epoch 033:   1027 / 4751 loss=4.53, nll_loss=2.926, ppl=7.6, wps=87764, ups=3.04, wpb=28900.3, bsz=933.2, num_updates=153000, lr=8.08452e-05, gnorm=0.447, loss_scale=2, train_wall=33, gb_free=6.9, wall=50890
2021-04-05 14:45:58 | INFO | train_inner | epoch 033:   1127 / 4751 loss=4.594, nll_loss=2.998, ppl=7.99, wps=87671.7, ups=3.04, wpb=28870.7, bsz=934.2, num_updates=153100, lr=8.08188e-05, gnorm=0.452, loss_scale=2, train_wall=33, gb_free=6.2, wall=50923
2021-04-05 14:46:31 | INFO | train_inner | epoch 033:   1227 / 4751 loss=4.584, nll_loss=2.986, ppl=7.92, wps=88592.7, ups=3.04, wpb=29107.2, bsz=940.5, num_updates=153200, lr=8.07924e-05, gnorm=0.442, loss_scale=2, train_wall=33, gb_free=6.1, wall=50956
2021-04-05 14:47:04 | INFO | train_inner | epoch 033:   1327 / 4751 loss=4.543, nll_loss=2.94, ppl=7.67, wps=88287.8, ups=3.03, wpb=29150.3, bsz=927.5, num_updates=153300, lr=8.07661e-05, gnorm=0.445, loss_scale=2, train_wall=33, gb_free=6.8, wall=50989
2021-04-05 14:47:37 | INFO | train_inner | epoch 033:   1427 / 4751 loss=4.592, nll_loss=2.995, ppl=7.97, wps=88224.6, ups=3.04, wpb=29027.1, bsz=913.6, num_updates=153400, lr=8.07397e-05, gnorm=0.449, loss_scale=2, train_wall=33, gb_free=6.2, wall=51022
2021-04-05 14:48:10 | INFO | train_inner | epoch 033:   1527 / 4751 loss=4.517, nll_loss=2.911, ppl=7.52, wps=88709.7, ups=3.04, wpb=29155.2, bsz=995.5, num_updates=153500, lr=8.07134e-05, gnorm=0.453, loss_scale=2, train_wall=33, gb_free=6, wall=51054
2021-04-05 14:48:43 | INFO | train_inner | epoch 033:   1627 / 4751 loss=4.583, nll_loss=2.985, ppl=7.92, wps=87235.3, ups=3.02, wpb=28886.8, bsz=944.9, num_updates=153600, lr=8.06872e-05, gnorm=0.45, loss_scale=2, train_wall=33, gb_free=6.2, wall=51088
2021-04-05 14:49:15 | INFO | train_inner | epoch 033:   1727 / 4751 loss=4.57, nll_loss=2.972, ppl=7.84, wps=88633.8, ups=3.06, wpb=28995.3, bsz=978.9, num_updates=153700, lr=8.06609e-05, gnorm=0.447, loss_scale=2, train_wall=33, gb_free=6.3, wall=51120
2021-04-05 14:49:49 | INFO | train_inner | epoch 033:   1827 / 4751 loss=4.581, nll_loss=2.984, ppl=7.91, wps=87971.9, ups=3.03, wpb=29072, bsz=929.1, num_updates=153800, lr=8.06347e-05, gnorm=0.448, loss_scale=4, train_wall=33, gb_free=6.2, wall=51153
2021-04-05 14:50:21 | INFO | train_inner | epoch 033:   1927 / 4751 loss=4.594, nll_loss=2.997, ppl=7.98, wps=88279.4, ups=3.04, wpb=29031.4, bsz=946.9, num_updates=153900, lr=8.06085e-05, gnorm=0.452, loss_scale=4, train_wall=33, gb_free=6.1, wall=51186
2021-04-05 14:50:54 | INFO | train_inner | epoch 033:   2027 / 4751 loss=4.575, nll_loss=2.976, ppl=7.87, wps=87034.4, ups=3.04, wpb=28661.3, bsz=941.9, num_updates=154000, lr=8.05823e-05, gnorm=0.451, loss_scale=4, train_wall=33, gb_free=6.2, wall=51219
2021-04-05 14:51:27 | INFO | train_inner | epoch 033:   2127 / 4751 loss=4.591, nll_loss=2.994, ppl=7.97, wps=88232.8, ups=3.05, wpb=28936.8, bsz=941.4, num_updates=154100, lr=8.05561e-05, gnorm=0.462, loss_scale=4, train_wall=33, gb_free=6.3, wall=51252
2021-04-05 14:52:00 | INFO | train_inner | epoch 033:   2227 / 4751 loss=4.531, nll_loss=2.926, ppl=7.6, wps=88364.6, ups=3.01, wpb=29343.2, bsz=935.2, num_updates=154200, lr=8.053e-05, gnorm=0.442, loss_scale=4, train_wall=33, gb_free=6.2, wall=51285
2021-04-05 14:52:33 | INFO | train_inner | epoch 033:   2327 / 4751 loss=4.577, nll_loss=2.979, ppl=7.88, wps=87935.9, ups=3.04, wpb=28911.7, bsz=923.8, num_updates=154300, lr=8.05039e-05, gnorm=0.456, loss_scale=4, train_wall=33, gb_free=6.2, wall=51318
2021-04-05 14:53:06 | INFO | train_inner | epoch 033:   2427 / 4751 loss=4.547, nll_loss=2.945, ppl=7.7, wps=87699.6, ups=3.04, wpb=28830.5, bsz=940.8, num_updates=154400, lr=8.04778e-05, gnorm=0.452, loss_scale=4, train_wall=33, gb_free=6.5, wall=51351
2021-04-05 14:53:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-05 14:53:39 | INFO | train_inner | epoch 033:   2528 / 4751 loss=4.559, nll_loss=2.959, ppl=7.78, wps=87898.6, ups=3, wpb=29347.8, bsz=970.6, num_updates=154500, lr=8.04518e-05, gnorm=0.455, loss_scale=2, train_wall=33, gb_free=6.3, wall=51384
2021-04-05 14:54:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-04-05 14:54:13 | INFO | train_inner | epoch 033:   2629 / 4751 loss=4.614, nll_loss=3.02, ppl=8.11, wps=86603.1, ups=3.01, wpb=28758.4, bsz=902.4, num_updates=154600, lr=8.04258e-05, gnorm=0.458, loss_scale=1, train_wall=33, gb_free=6.4, wall=51417
2021-04-05 14:54:46 | INFO | train_inner | epoch 033:   2729 / 4751 loss=4.542, nll_loss=2.94, ppl=7.67, wps=85342.8, ups=2.97, wpb=28724.4, bsz=949.2, num_updates=154700, lr=8.03998e-05, gnorm=0.452, loss_scale=1, train_wall=34, gb_free=6.3, wall=51451
2021-04-05 14:55:19 | INFO | train_inner | epoch 033:   2829 / 4751 loss=4.565, nll_loss=2.965, ppl=7.81, wps=88261.2, ups=3.05, wpb=28966.9, bsz=951.8, num_updates=154800, lr=8.03738e-05, gnorm=0.453, loss_scale=1, train_wall=33, gb_free=6.2, wall=51484
2021-04-05 14:55:52 | INFO | train_inner | epoch 033:   2929 / 4751 loss=4.576, nll_loss=2.978, ppl=7.88, wps=88499.4, ups=3.05, wpb=29058.2, bsz=1000, num_updates=154900, lr=8.03479e-05, gnorm=0.452, loss_scale=1, train_wall=33, gb_free=6.3, wall=51517
2021-04-05 14:56:25 | INFO | train_inner | epoch 033:   3029 / 4751 loss=4.524, nll_loss=2.919, ppl=7.56, wps=87829, ups=3.04, wpb=28880.4, bsz=964.6, num_updates=155000, lr=8.03219e-05, gnorm=0.449, loss_scale=1, train_wall=33, gb_free=6.1, wall=51550
2021-04-05 14:56:58 | INFO | train_inner | epoch 033:   3129 / 4751 loss=4.562, nll_loss=2.963, ppl=7.8, wps=89721.4, ups=3.05, wpb=29412, bsz=944.9, num_updates=155100, lr=8.0296e-05, gnorm=0.448, loss_scale=1, train_wall=33, gb_free=6.4, wall=51582
2021-04-05 14:57:30 | INFO | train_inner | epoch 033:   3229 / 4751 loss=4.617, nll_loss=3.025, ppl=8.14, wps=88162.2, ups=3.05, wpb=28874, bsz=939.8, num_updates=155200, lr=8.02702e-05, gnorm=0.46, loss_scale=1, train_wall=33, gb_free=6.3, wall=51615
2021-04-05 14:58:03 | INFO | train_inner | epoch 033:   3329 / 4751 loss=4.576, nll_loss=2.978, ppl=7.88, wps=87286.1, ups=3.03, wpb=28827.1, bsz=950.2, num_updates=155300, lr=8.02443e-05, gnorm=0.453, loss_scale=1, train_wall=33, gb_free=6.2, wall=51648
2021-04-05 14:58:36 | INFO | train_inner | epoch 033:   3429 / 4751 loss=4.484, nll_loss=2.873, ppl=7.33, wps=89853.4, ups=3.04, wpb=29542.6, bsz=973, num_updates=155400, lr=8.02185e-05, gnorm=0.44, loss_scale=1, train_wall=33, gb_free=6.1, wall=51681
2021-04-05 14:59:09 | INFO | train_inner | epoch 033:   3529 / 4751 loss=4.531, nll_loss=2.927, ppl=7.6, wps=88663.4, ups=3.03, wpb=29284.5, bsz=947, num_updates=155500, lr=8.01927e-05, gnorm=0.44, loss_scale=1, train_wall=33, gb_free=5.9, wall=51714
2021-04-05 14:59:42 | INFO | train_inner | epoch 033:   3629 / 4751 loss=4.542, nll_loss=2.939, ppl=7.67, wps=88670.5, ups=3.05, wpb=29027, bsz=955.1, num_updates=155600, lr=8.01669e-05, gnorm=0.454, loss_scale=1, train_wall=33, gb_free=6.3, wall=51747
2021-04-05 15:00:15 | INFO | train_inner | epoch 033:   3729 / 4751 loss=4.535, nll_loss=2.932, ppl=7.63, wps=88264.1, ups=3.03, wpb=29097.9, bsz=968.2, num_updates=155700, lr=8.01412e-05, gnorm=0.451, loss_scale=1, train_wall=33, gb_free=6.6, wall=51780
2021-04-05 15:00:48 | INFO | train_inner | epoch 033:   3829 / 4751 loss=4.619, nll_loss=3.027, ppl=8.15, wps=87444.1, ups=3.05, wpb=28668.7, bsz=944.5, num_updates=155800, lr=8.01154e-05, gnorm=0.454, loss_scale=1, train_wall=33, gb_free=6.2, wall=51813
2021-04-05 15:01:21 | INFO | train_inner | epoch 033:   3929 / 4751 loss=4.582, nll_loss=2.985, ppl=7.91, wps=88400.6, ups=3.04, wpb=29064.5, bsz=961.8, num_updates=155900, lr=8.00898e-05, gnorm=0.45, loss_scale=1, train_wall=33, gb_free=5.9, wall=51846
2021-04-05 15:01:53 | INFO | train_inner | epoch 033:   4029 / 4751 loss=4.561, nll_loss=2.96, ppl=7.78, wps=88662.6, ups=3.05, wpb=29072.5, bsz=935.8, num_updates=156000, lr=8.00641e-05, gnorm=0.45, loss_scale=1, train_wall=33, gb_free=6.2, wall=51878
2021-04-05 15:02:26 | INFO | train_inner | epoch 033:   4129 / 4751 loss=4.548, nll_loss=2.946, ppl=7.71, wps=87859.7, ups=3.04, wpb=28916.2, bsz=943.8, num_updates=156100, lr=8.00384e-05, gnorm=0.453, loss_scale=1, train_wall=33, gb_free=6.1, wall=51911
2021-04-05 15:02:59 | INFO | train_inner | epoch 033:   4229 / 4751 loss=4.582, nll_loss=2.985, ppl=7.92, wps=87521.1, ups=3.04, wpb=28836.7, bsz=957.7, num_updates=156200, lr=8.00128e-05, gnorm=0.455, loss_scale=1, train_wall=33, gb_free=6.5, wall=51944
2021-04-05 15:03:33 | INFO | train_inner | epoch 033:   4329 / 4751 loss=4.587, nll_loss=2.99, ppl=7.95, wps=86490.9, ups=3.02, wpb=28671.3, bsz=911, num_updates=156300, lr=7.99872e-05, gnorm=0.456, loss_scale=1, train_wall=33, gb_free=6.3, wall=51977
2021-04-05 15:04:05 | INFO | train_inner | epoch 033:   4429 / 4751 loss=4.542, nll_loss=2.94, ppl=7.68, wps=87030.7, ups=3.03, wpb=28699.2, bsz=982.9, num_updates=156400, lr=7.99616e-05, gnorm=0.456, loss_scale=1, train_wall=33, gb_free=6.3, wall=52010
2021-04-05 15:04:38 | INFO | train_inner | epoch 033:   4529 / 4751 loss=4.632, nll_loss=3.041, ppl=8.23, wps=87796.6, ups=3.05, wpb=28810.8, bsz=927, num_updates=156500, lr=7.99361e-05, gnorm=0.451, loss_scale=1, train_wall=33, gb_free=6.2, wall=52043
2021-04-05 15:05:11 | INFO | train_inner | epoch 033:   4629 / 4751 loss=4.525, nll_loss=2.921, ppl=7.57, wps=88057.8, ups=3.03, wpb=29024.6, bsz=947.3, num_updates=156600, lr=7.99106e-05, gnorm=0.448, loss_scale=1, train_wall=33, gb_free=6.2, wall=52076
2021-04-05 15:05:44 | INFO | train_inner | epoch 033:   4729 / 4751 loss=4.551, nll_loss=2.95, ppl=7.73, wps=88715.4, ups=3.04, wpb=29137.2, bsz=971.4, num_updates=156700, lr=7.9885e-05, gnorm=0.446, loss_scale=2, train_wall=33, gb_free=6.2, wall=52109
2021-04-05 15:05:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-05 15:05:53 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 4.188 | nll_loss 2.413 | ppl 5.33 | wps 189436 | wpb 10489.1 | bsz 375 | num_updates 156722 | best_loss 4.188
2021-04-05 15:05:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 156722 updates
2021-04-05 15:05:53 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 15:05:59 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 15:06:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt (epoch 33 @ 156722 updates, score 4.188) (writing took 13.43570128083229 seconds)
2021-04-05 15:06:06 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2021-04-05 15:06:06 | INFO | train | epoch 033 | loss 4.567 | nll_loss 2.967 | ppl 7.82 | wps 87110.9 | ups 3.01 | wpb 28968.9 | bsz 946.7 | num_updates 156722 | lr 7.98794e-05 | gnorm 0.451 | loss_scale 2 | train_wall 1557 | gb_free 6.3 | wall 52131
2021-04-05 15:06:06 | INFO | fairseq.trainer | begin training epoch 34
2021-04-05 15:06:06 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-05 15:06:33 | INFO | train_inner | epoch 034:     78 / 4751 loss=4.58, nll_loss=2.982, ppl=7.9, wps=58796.2, ups=2.06, wpb=28585.4, bsz=981.8, num_updates=156800, lr=7.98596e-05, gnorm=0.453, loss_scale=2, train_wall=32, gb_free=6.1, wall=52158
2021-04-05 15:07:06 | INFO | train_inner | epoch 034:    178 / 4751 loss=4.523, nll_loss=2.918, ppl=7.56, wps=86096.5, ups=2.98, wpb=28896.2, bsz=933.2, num_updates=156900, lr=7.98341e-05, gnorm=0.451, loss_scale=2, train_wall=33, gb_free=6.1, wall=52191
2021-04-05 15:07:39 | INFO | train_inner | epoch 034:    278 / 4751 loss=4.593, nll_loss=2.996, ppl=7.98, wps=88303.5, ups=3.04, wpb=29026.1, bsz=954.7, num_updates=157000, lr=7.98087e-05, gnorm=0.456, loss_scale=2, train_wall=33, gb_free=6.3, wall=52224
2021-04-05 15:08:12 | INFO | train_inner | epoch 034:    378 / 4751 loss=4.583, nll_loss=2.985, ppl=7.92, wps=88167.9, ups=3.05, wpb=28908.8, bsz=951.7, num_updates=157100, lr=7.97833e-05, gnorm=0.457, loss_scale=2, train_wall=33, gb_free=6.2, wall=52257
2021-04-05 15:08:45 | INFO | train_inner | epoch 034:    478 / 4751 loss=4.546, nll_loss=2.943, ppl=7.69, wps=88478, ups=3.03, wpb=29204, bsz=956.6, num_updates=157200, lr=7.97579e-05, gnorm=0.456, loss_scale=2, train_wall=33, gb_free=6.2, wall=52290
2021-04-05 15:09:18 | INFO | train_inner | epoch 034:    578 / 4751 loss=4.594, nll_loss=2.997, ppl=7.99, wps=88673.2, ups=3.07, wpb=28921.9, bsz=956.5, num_updates=157300, lr=7.97325e-05, gnorm=0.45, loss_scale=2, train_wall=32, gb_free=6.1, wall=52322
2021-04-05 15:09:50 | INFO | train_inner | epoch 034:    678 / 4751 loss=4.568, nll_loss=2.969, ppl=7.83, wps=87694.7, ups=3.06, wpb=28688.6, bsz=958.2, num_updates=157400, lr=7.97072e-05, gnorm=0.45, loss_scale=2, train_wall=33, gb_free=6.2, wall=52355
2021-04-05 15:10:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-04-05 15:10:23 | INFO | train_inner | epoch 034:    779 / 4751 loss=4.562, nll_loss=2.961, ppl=7.79, wps=87304.6, ups=3.03, wpb=28843, bsz=949.7, num_updates=157500, lr=7.96819e-05, gnorm=0.451, loss_scale=1, train_wall=33, gb_free=6.3, wall=52388
2021-04-05 15:10:56 | INFO | train_inner | epoch 034:    879 / 4751 loss=4.582, nll_loss=2.984, ppl=7.91, wps=88330.5, ups=3.03, wpb=29146.5, bsz=934.2, num_updates=157600, lr=7.96566e-05, gnorm=0.447, loss_scale=1, train_wall=33, gb_free=6.5, wall=52421
2021-04-05 15:11:29 | INFO | train_inner | epoch 034:    979 / 4751 loss=4.542, nll_loss=2.939, ppl=7.67, wps=88351, ups=3.04, wpb=29019, bsz=947, num_updates=157700, lr=7.96314e-05, gnorm=0.455, loss_scale=1, train_wall=33, gb_free=6.2, wall=52454
2021-04-05 15:12:02 | INFO | train_inner | epoch 034:   1079 / 4751 loss=4.509, nll_loss=2.901, ppl=7.47, wps=87138.2, ups=3.03, wpb=28762, bsz=959.4, num_updates=157800, lr=7.96061e-05, gnorm=0.45, loss_scale=1, train_wall=33, gb_free=6.3, wall=52487
2021-04-05 15:12:35 | INFO | train_inner | epoch 034:   1179 / 4751 loss=4.53, nll_loss=2.926, ppl=7.6, wps=88352, ups=3.02, wpb=29299.1, bsz=989, num_updates=157900, lr=7.95809e-05, gnorm=0.446, loss_scale=1, train_wall=33, gb_free=6.2, wall=52520
2021-04-05 15:13:08 | INFO | train_inner | epoch 034:   1279 / 4751 loss=4.581, nll_loss=2.983, ppl=7.91, wps=88679.8, ups=3.04, wpb=29126.9, bsz=946.2, num_updates=158000, lr=7.95557e-05, gnorm=0.446, loss_scale=1, train_wall=33, gb_free=6.5, wall=52553
2021-04-05 15:13:41 | INFO | train_inner | epoch 034:   1379 / 4751 loss=4.58, nll_loss=2.983, ppl=7.9, wps=88375.5, ups=3.06, wpb=28923.7, bsz=965.7, num_updates=158100, lr=7.95306e-05, gnorm=0.458, loss_scale=1, train_wall=33, gb_free=6.7, wall=52586
2021-04-05 15:14:14 | INFO | train_inner | epoch 034:   1479 / 4751 loss=4.559, nll_loss=2.958, ppl=7.77, wps=87764.8, ups=3.06, wpb=28712.9, bsz=968.2, num_updates=158200, lr=7.95054e-05, gnorm=0.45, loss_scale=1, train_wall=33, gb_free=5.9, wall=52618
2021-04-05 15:14:47 | INFO | train_inner | epoch 034:   1579 / 4751 loss=4.555, nll_loss=2.954, ppl=7.75, wps=87355.1, ups=3.01, wpb=29013.5, bsz=966.2, num_updates=158300, lr=7.94803e-05, gnorm=0.461, loss_scale=1, train_wall=33, gb_free=6.1, wall=52652
2021-04-05 15:15:20 | INFO | train_inner | epoch 034:   1679 / 4751 loss=4.537, nll_loss=2.934, ppl=7.64, wps=87382.7, ups=3, wpb=29090.5, bsz=928.5, num_updates=158400, lr=7.94552e-05, gnorm=0.454, loss_scale=1, train_wall=33, gb_free=6.3, wall=52685
2021-04-05 15:15:53 | INFO | train_inner | epoch 034:   1779 / 4751 loss=4.509, nll_loss=2.901, ppl=7.47, wps=88582.3, ups=3.03, wpb=29190.8, bsz=948.9, num_updates=158500, lr=7.94301e-05, gnorm=0.439, loss_scale=1, train_wall=33, gb_free=5.8, wall=52718
2021-04-05 15:16:26 | INFO | train_inner | epoch 034:   1879 / 4751 loss=4.507, nll_loss=2.9, ppl=7.46, wps=89083.4, ups=3.05, wpb=29199.5, bsz=985.1, num_updates=158600, lr=7.94051e-05, gnorm=0.484, loss_scale=1, train_wall=33, gb_free=6.2, wall=52751
2021-04-05 15:16:59 | INFO | train_inner | epoch 034:   1979 / 4751 loss=4.558, nll_loss=2.958, ppl=7.77, wps=87316.1, ups=3.04, wpb=28725, bsz=935.5, num_updates=158700, lr=7.93801e-05, gnorm=0.471, loss_scale=1, train_wall=33, gb_free=6.2, wall=52784
2021-04-05 15:17:32 | INFO | train_inner | epoch 034:   2079 / 4751 loss=4.571, nll_loss=2.972, ppl=7.85, wps=87941, ups=3.04, wpb=28972.3, bsz=957, num_updates=158800, lr=7.93551e-05, gnorm=0.448, loss_scale=1, train_wall=33, gb_free=6.5, wall=52817
2021-04-05 15:18:05 | INFO | train_inner | epoch 034:   2179 / 4751 loss=4.539, nll_loss=2.935, ppl=7.65, wps=89182.2, ups=3.05, wpb=29280.4, bsz=945, num_updates=158900, lr=7.93301e-05, gnorm=0.443, loss_scale=1, train_wall=33, gb_free=6.1, wall=52849
2021-04-05 15:18:37 | INFO | train_inner | epoch 034:   2279 / 4751 loss=4.559, nll_loss=2.959, ppl=7.78, wps=88722.5, ups=3.04, wpb=29179.4, bsz=929.8, num_updates=159000, lr=7.93052e-05, gnorm=0.458, loss_scale=1, train_wall=33, gb_free=6.1, wall=52882
2021-04-05 15:19:10 | INFO | train_inner | epoch 034:   2379 / 4751 loss=4.579, nll_loss=2.981, ppl=7.9, wps=87448.4, ups=3.05, wpb=28652.5, bsz=927.1, num_updates=159100, lr=7.92802e-05, gnorm=0.457, loss_scale=1, train_wall=33, gb_free=6.4, wall=52915
2021-04-05 15:19:43 | INFO | train_inner | epoch 034:   2479 / 4751 loss=4.581, nll_loss=2.983, ppl=7.91, wps=88814.3, ups=3.05, wpb=29136.3, bsz=938.4, num_updates=159200, lr=7.92553e-05, gnorm=0.449, loss_scale=1, train_wall=33, gb_free=6.1, wall=52948
2021-04-05 15:20:16 | INFO | train_inner | epoch 034:   2579 / 4751 loss=4.557, nll_loss=2.956, ppl=7.76, wps=87905.8, ups=3.05, wpb=28813.8, bsz=938.6, num_updates=159300, lr=7.92304e-05, gnorm=0.452, loss_scale=1, train_wall=33, gb_free=6.2, wall=52981
2021-04-05 15:20:49 | INFO | train_inner | epoch 034:   2679 / 4751 loss=4.626, nll_loss=3.034, ppl=8.19, wps=89140, ups=3.04, wpb=29285.9, bsz=944.6, num_updates=159400, lr=7.92056e-05, gnorm=0.456, loss_scale=1, train_wall=33, gb_free=6.1, wall=53013
2021-04-05 15:21:21 | INFO | train_inner | epoch 034:   2779 / 4751 loss=4.545, nll_loss=2.943, ppl=7.69, wps=88478, ups=3.05, wpb=29021.6, bsz=931.4, num_updates=159500, lr=7.91808e-05, gnorm=0.452, loss_scale=1, train_wall=33, gb_free=6.3, wall=53046
2021-04-05 15:21:54 | INFO | train_inner | epoch 034:   2879 / 4751 loss=4.628, nll_loss=3.036, ppl=8.2, wps=87692.6, ups=3.05, wpb=28737.9, bsz=919.1, num_updates=159600, lr=7.91559e-05, gnorm=0.455, loss_scale=2, train_wall=33, gb_free=6.6, wall=53079
2021-04-05 15:22:27 | INFO | train_inner | epoch 034:   2979 / 4751 loss=4.58, nll_loss=2.982, ppl=7.9, wps=88050.2, ups=3.04, wpb=28972.2, bsz=945.4, num_updates=159700, lr=7.91312e-05, gnorm=0.454, loss_scale=2, train_wall=33, gb_free=6.4, wall=53112
2021-04-05 15:23:00 | INFO | train_inner | epoch 034:   3079 / 4751 loss=4.618, nll_loss=3.025, ppl=8.14, wps=87371.8, ups=3.03, wpb=28789.3, bsz=928.5, num_updates=159800, lr=7.91064e-05, gnorm=0.456, loss_scale=2, train_wall=33, gb_free=6.3, wall=53145
2021-04-05 15:23:33 | INFO | train_inner | epoch 034:   3179 / 4751 loss=4.589, nll_loss=2.992, ppl=7.96, wps=88268, ups=3.06, wpb=28848.5, bsz=926.8, num_updates=159900, lr=7.90817e-05, gnorm=0.454, loss_scale=2, train_wall=33, gb_free=6.3, wall=53178
2021-04-05 15:24:06 | INFO | train_inner | epoch 034:   3279 / 4751 loss=4.52, nll_loss=2.915, ppl=7.54, wps=87933, ups=3.01, wpb=29177.4, bsz=962.5, num_updates=160000, lr=7.90569e-05, gnorm=0.445, loss_scale=2, train_wall=33, gb_free=6.4, wall=53211
2021-04-05 15:24:39 | INFO | train_inner | epoch 034:   3379 / 4751 loss=4.567, nll_loss=2.968, ppl=7.83, wps=88244.6, ups=3.04, wpb=28997.1, bsz=922.7, num_updates=160100, lr=7.90322e-05, gnorm=0.449, loss_scale=2, train_wall=33, gb_free=6.1, wall=53244
2021-04-05 15:25:12 | INFO | train_inner | epoch 034:   3479 / 4751 loss=4.58, nll_loss=2.982, ppl=7.9, wps=86863.6, ups=3.03, wpb=28697.2, bsz=918.1, num_updates=160200, lr=7.90076e-05, gnorm=0.456, loss_scale=2, train_wall=33, gb_free=6.3, wall=53277
2021-04-05 15:25:45 | INFO | train_inner | epoch 034:   3579 / 4751 loss=4.566, nll_loss=2.967, ppl=7.82, wps=89542.6, ups=3.06, wpb=29282.6, bsz=940.7, num_updates=160300, lr=7.89829e-05, gnorm=0.449, loss_scale=2, train_wall=33, gb_free=6.2, wall=53309
2021-04-05 15:26:17 | INFO | train_inner | epoch 034:   3679 / 4751 loss=4.61, nll_loss=3.017, ppl=8.09, wps=87866.4, ups=3.05, wpb=28814.5, bsz=953, num_updates=160400, lr=7.89583e-05, gnorm=0.453, loss_scale=2, train_wall=33, gb_free=6.1, wall=53342
2021-04-05 15:26:50 | INFO | train_inner | epoch 034:   3779 / 4751 loss=4.585, nll_loss=2.988, ppl=7.94, wps=87133.8, ups=3.03, wpb=28761.9, bsz=933.4, num_updates=160500, lr=7.89337e-05, gnorm=0.459, loss_scale=2, train_wall=33, gb_free=6.2, wall=53375
2021-04-05 15:27:23 | INFO | train_inner | epoch 034:   3879 / 4751 loss=4.605, nll_loss=3.01, ppl=8.06, wps=88326.5, ups=3.07, wpb=28817.6, bsz=919.5, num_updates=160600, lr=7.89091e-05, gnorm=0.453, loss_scale=2, train_wall=32, gb_free=6.2, wall=53408
2021-04-05 15:27:56 | INFO | train_inner | epoch 034:   3979 / 4751 loss=4.501, nll_loss=2.893, ppl=7.43, wps=88276, ups=3.04, wpb=29027.7, bsz=962.2, num_updates=160700, lr=7.88846e-05, gnorm=0.45, loss_scale=2, train_wall=33, gb_free=6.4, wall=53441
2021-04-05 15:28:29 | INFO | train_inner | epoch 034:   4079 / 4751 loss=4.618, nll_loss=3.026, ppl=8.15, wps=87523, ups=3.05, wpb=28701.7, bsz=927.9, num_updates=160800, lr=7.886e-05, gnorm=0.457, loss_scale=2, train_wall=33, gb_free=6.1, wall=53473
2021-04-05 15:29:02 | INFO | train_inner | epoch 034:   4179 / 4751 loss=4.545, nll_loss=2.943, ppl=7.69, wps=88530.1, ups=3.04, wpb=29117.2, bsz=957, num_updates=160900, lr=7.88355e-05, gnorm=0.449, loss_scale=2, train_wall=33, gb_free=6.2, wall=53506
2021-04-05 15:29:35 | INFO | train_inner | epoch 034:   4279 / 4751 loss=4.485, nll_loss=2.875, ppl=7.34, wps=87491.4, ups=3.03, wpb=28903.8, bsz=956.8, num_updates=161000, lr=7.8811e-05, gnorm=0.452, loss_scale=2, train_wall=33, gb_free=6.2, wall=53539
2021-04-05 15:30:07 | INFO | train_inner | epoch 034:   4379 / 4751 loss=4.555, nll_loss=2.954, ppl=7.75, wps=88499.9, ups=3.04, wpb=29129.8, bsz=971.2, num_updates=161100, lr=7.87866e-05, gnorm=0.445, loss_scale=2, train_wall=33, gb_free=6.2, wall=53572
2021-04-05 15:30:41 | INFO | train_inner | epoch 034:   4479 / 4751 loss=4.55, nll_loss=2.948, ppl=7.72, wps=87291.3, ups=3.01, wpb=29045.8, bsz=945.8, num_updates=161200, lr=7.87621e-05, gnorm=0.45, loss_scale=2, train_wall=33, gb_free=6.6, wall=53606
2021-04-05 15:31:13 | INFO | train_inner | epoch 034:   4579 / 4751 loss=4.565, nll_loss=2.966, ppl=7.82, wps=88275.2, ups=3.05, wpb=28899.5, bsz=967, num_updates=161300, lr=7.87377e-05, gnorm=0.454, loss_scale=2, train_wall=33, gb_free=6.4, wall=53638
2021-04-05 15:31:46 | INFO | train_inner | epoch 034:   4679 / 4751 loss=4.575, nll_loss=2.976, ppl=7.87, wps=88817.1, ups=3.04, wpb=29251.9, bsz=937.5, num_updates=161400, lr=7.87133e-05, gnorm=0.452, loss_scale=2, train_wall=33, gb_free=6.2, wall=53671
2021-04-05 15:32:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-05 15:32:11 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 4.203 | nll_loss 2.43 | ppl 5.39 | wps 201257 | wpb 10489.1 | bsz 375 | num_updates 161472 | best_loss 4.188
2021-04-05 15:32:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 161472 updates
2021-04-05 15:32:11 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-05 15:32:17 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-05 15:32:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt (epoch 34 @ 161472 updates, score 4.203) (writing took 6.0448451936244965 seconds)
2021-04-05 15:32:17 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2021-04-05 15:32:17 | INFO | train | epoch 034 | loss 4.563 | nll_loss 2.963 | ppl 7.8 | wps 87574.9 | ups 3.02 | wpb 28968.1 | bsz 947.2 | num_updates 161472 | lr 7.86958e-05 | gnorm 0.453 | loss_scale 2 | train_wall 1556 | gb_free 6.2 | wall 53702
2021-04-05 15:32:17 | INFO | fairseq.trainer | begin training epoch 35
2021-04-05 15:32:17 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-05 15:32:28 | INFO | train_inner | epoch 035:     28 / 4751 loss=4.528, nll_loss=2.924, ppl=7.59, wps=70084.1, ups=2.43, wpb=28889.5, bsz=951.8, num_updates=161500, lr=7.86889e-05, gnorm=0.454, loss_scale=2, train_wall=32, gb_free=6.2, wall=53712
2021-04-05 15:33:01 | INFO | train_inner | epoch 035:    128 / 4751 loss=4.515, nll_loss=2.908, ppl=7.5, wps=86989.8, ups=3.04, wpb=28598.1, bsz=938, num_updates=161600, lr=7.86646e-05, gnorm=0.453, loss_scale=4, train_wall=33, gb_free=6.7, wall=53745
2021-04-05 15:33:33 | INFO | train_inner | epoch 035:    228 / 4751 loss=4.569, nll_loss=2.97, ppl=7.83, wps=87317.7, ups=3.04, wpb=28697.5, bsz=932.6, num_updates=161700, lr=7.86403e-05, gnorm=0.461, loss_scale=4, train_wall=33, gb_free=6.2, wall=53778
2021-04-05 15:34:06 | INFO | train_inner | epoch 035:    328 / 4751 loss=4.601, nll_loss=3.006, ppl=8.04, wps=88471.7, ups=3.06, wpb=28937.7, bsz=948, num_updates=161800, lr=7.8616e-05, gnorm=0.463, loss_scale=4, train_wall=33, gb_free=6.1, wall=53811
2021-04-05 15:34:39 | INFO | train_inner | epoch 035:    428 / 4751 loss=4.613, nll_loss=3.019, ppl=8.1, wps=88213.3, ups=3.05, wpb=28953.9, bsz=934, num_updates=161900, lr=7.85917e-05, gnorm=0.458, loss_scale=4, train_wall=33, gb_free=6.2, wall=53844
2021-04-05 15:34:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-05 15:35:12 | INFO | train_inner | epoch 035:    529 / 4751 loss=4.568, nll_loss=2.969, ppl=7.83, wps=86740.2, ups=3, wpb=28879.1, bsz=956.9, num_updates=162000, lr=7.85674e-05, gnorm=0.46, loss_scale=2, train_wall=33, gb_free=6.3, wall=53877
2021-04-05 15:35:45 | INFO | train_inner | epoch 035:    629 / 4751 loss=4.552, nll_loss=2.95, ppl=7.73, wps=87516.4, ups=3.04, wpb=28795.3, bsz=926.6, num_updates=162100, lr=7.85432e-05, gnorm=0.458, loss_scale=2, train_wall=33, gb_free=6.3, wall=53910
2021-04-05 15:36:18 | INFO | train_inner | epoch 035:    729 / 4751 loss=4.557, nll_loss=2.956, ppl=7.76, wps=88188.5, ups=3.03, wpb=29097.4, bsz=961.5, num_updates=162200, lr=7.8519e-05, gnorm=0.458, loss_scale=2, train_wall=33, gb_free=6.2, wall=53943
2021-04-05 15:36:51 | INFO | train_inner | epoch 035:    829 / 4751 loss=4.523, nll_loss=2.918, ppl=7.56, wps=88741.2, ups=3.05, wpb=29100.4, bsz=977.4, num_updates=162300, lr=7.84948e-05, gnorm=0.445, loss_scale=2, train_wall=33, gb_free=6.2, wall=53976
2021-04-05 15:37:24 | INFO | train_inner | epoch 035:    929 / 4751 loss=4.557, nll_loss=2.957, ppl=7.76, wps=87362.4, ups=3.03, wpb=28800.2, bsz=950.6, num_updates=162400, lr=7.84706e-05, gnorm=0.454, loss_scale=2, train_wall=33, gb_free=6.5, wall=54009
2021-04-05 15:37:57 | INFO | train_inner | epoch 035:   1029 / 4751 loss=4.542, nll_loss=2.939, ppl=7.67, wps=87019.4, ups=3.02, wpb=28842, bsz=930.4, num_updates=162500, lr=7.84465e-05, gnorm=0.45, loss_scale=2, train_wall=33, gb_free=6.3, wall=54042
2021-04-05 15:38:30 | INFO | train_inner | epoch 035:   1129 / 4751 loss=4.519, nll_loss=2.913, ppl=7.53, wps=89438.6, ups=3.04, wpb=29389.7, bsz=935.3, num_updates=162600, lr=7.84223e-05, gnorm=0.439, loss_scale=2, train_wall=33, gb_free=6.2, wall=54075
2021-04-05 15:39:03 | INFO | train_inner | epoch 035:   1229 / 4751 loss=4.62, nll_loss=3.027, ppl=8.15, wps=87352.2, ups=3.04, wpb=28731.9, bsz=905.3, num_updates=162700, lr=7.83982e-05, gnorm=0.458, loss_scale=2, train_wall=33, gb_free=6.2, wall=54108
2021-04-05 15:39:36 | INFO | train_inner | epoch 035:   1329 / 4751 loss=4.614, nll_loss=3.02, ppl=8.11, wps=89194.6, ups=3.05, wpb=29225.4, bsz=902.6, num_updates=162800, lr=7.83741e-05, gnorm=0.454, loss_scale=2, train_wall=33, gb_free=6.3, wall=54140
2021-04-05 15:40:09 | INFO | train_inner | epoch 035:   1429 / 4751 loss=4.579, nll_loss=2.981, ppl=7.89, wps=87868.7, ups=3.03, wpb=28981.9, bsz=926.6, num_updates=162900, lr=7.83501e-05, gnorm=0.456, loss_scale=2, train_wall=33, gb_free=6.2, wall=54173
2021-04-05 15:40:41 | INFO | train_inner | epoch 035:   1529 / 4751 loss=4.568, nll_loss=2.968, ppl=7.83, wps=87962.4, ups=3.04, wpb=28966, bsz=947.8, num_updates=163000, lr=7.8326e-05, gnorm=0.455, loss_scale=2, train_wall=33, gb_free=6.1, wall=54206
2021-04-05 15:40:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-04-05 15:41:15 | INFO | train_inner | epoch 035:   1630 / 4751 loss=4.517, nll_loss=2.911, ppl=7.52, wps=85271.9, ups=2.94, wpb=28987.7, bsz=952.8, num_updates=163100, lr=7.8302e-05, gnorm=0.454, loss_scale=1, train_wall=34, gb_free=6.4, wall=54240
2021-04-05 15:41:48 | INFO | train_inner | epoch 035:   1730 / 4751 loss=4.57, nll_loss=2.971, ppl=7.84, wps=88306.5, ups=3.04, wpb=29052.3, bsz=923.7, num_updates=163200, lr=7.8278e-05, gnorm=0.45, loss_scale=1, train_wall=33, gb_free=6.3, wall=54273
2021-04-05 15:42:21 | INFO | train_inner | epoch 035:   1830 / 4751 loss=4.47, nll_loss=2.858, ppl=7.25, wps=87963.2, ups=3.03, wpb=29001.1, bsz=981, num_updates=163300, lr=7.82541e-05, gnorm=0.45, loss_scale=1, train_wall=33, gb_free=6.1, wall=54306
2021-04-05 15:42:54 | INFO | train_inner | epoch 035:   1930 / 4751 loss=4.557, nll_loss=2.956, ppl=7.76, wps=88549.4, ups=3.04, wpb=29138.4, bsz=926.3, num_updates=163400, lr=7.82301e-05, gnorm=0.451, loss_scale=1, train_wall=33, gb_free=6.2, wall=54339
2021-04-05 15:43:27 | INFO | train_inner | epoch 035:   2030 / 4751 loss=4.636, nll_loss=3.046, ppl=8.26, wps=87677.5, ups=3.02, wpb=29039.6, bsz=946.8, num_updates=163500, lr=7.82062e-05, gnorm=0.453, loss_scale=1, train_wall=33, gb_free=6.2, wall=54372
2021-04-05 15:44:00 | INFO | train_inner | epoch 035:   2130 / 4751 loss=4.551, nll_loss=2.949, ppl=7.72, wps=88464.3, ups=3.05, wpb=28999.6, bsz=922.5, num_updates=163600, lr=7.81823e-05, gnorm=0.451, loss_scale=1, train_wall=33, gb_free=6.1, wall=54405
2021-04-05 15:44:33 | INFO | train_inner | epoch 035:   2230 / 4751 loss=4.597, nll_loss=3.002, ppl=8.01, wps=88054.8, ups=3.04, wpb=28967.7, bsz=918.7, num_updates=163700, lr=7.81584e-05, gnorm=0.457, loss_scale=1, train_wall=33, gb_free=6.1, wall=54438
2021-04-05 15:45:06 | INFO | train_inner | epoch 035:   2330 / 4751 loss=4.55, nll_loss=2.949, ppl=7.72, wps=88309.9, ups=3.03, wpb=29121.5, bsz=973.4, num_updates=163800, lr=7.81345e-05, gnorm=0.459, loss_scale=1, train_wall=33, gb_free=5.9, wall=54471
2021-04-05 15:45:39 | INFO | train_inner | epoch 035:   2430 / 4751 loss=4.607, nll_loss=3.013, ppl=8.07, wps=87723.3, ups=3.04, wpb=28840.1, bsz=937.5, num_updates=163900, lr=7.81107e-05, gnorm=0.456, loss_scale=1, train_wall=33, gb_free=6.2, wall=54504
2021-04-05 15:46:12 | INFO | train_inner | epoch 035:   2530 / 4751 loss=4.584, nll_loss=2.987, ppl=7.93, wps=88244, ups=3.03, wpb=29106.2, bsz=957.1, num_updates=164000, lr=7.80869e-05, gnorm=0.452, loss_scale=1, train_wall=33, gb_free=6.2, wall=54537
2021-04-05 15:46:45 | INFO | train_inner | epoch 035:   2630 / 4751 loss=4.551, nll_loss=2.95, ppl=7.73, wps=89336.1, ups=3.04, wpb=29386.2, bsz=980.3, num_updates=164100, lr=7.80631e-05, gnorm=0.45, loss_scale=1, train_wall=33, gb_free=6.1, wall=54570
2021-04-05 15:47:18 | INFO | train_inner | epoch 035:   2730 / 4751 loss=4.609, nll_loss=3.015, ppl=8.08, wps=87596.4, ups=3.03, wpb=28904.2, bsz=934.4, num_updates=164200, lr=7.80393e-05, gnorm=0.458, loss_scale=1, train_wall=33, gb_free=6.2, wall=54603
2021-04-05 15:47:51 | INFO | train_inner | epoch 035:   2830 / 4751 loss=4.538, nll_loss=2.935, ppl=7.65, wps=88480.6, ups=3.04, wpb=29141.3, bsz=965, num_updates=164300, lr=7.80156e-05, gnorm=0.441, loss_scale=1, train_wall=33, gb_free=6.5, wall=54636
2021-04-05 15:48:24 | INFO | train_inner | epoch 035:   2930 / 4751 loss=4.516, nll_loss=2.91, ppl=7.52, wps=87769.2, ups=3.04, wpb=28877.8, bsz=951.7, num_updates=164400, lr=7.79918e-05, gnorm=0.451, loss_scale=1, train_wall=33, gb_free=6.6, wall=54668
2021-04-05 15:48:57 | INFO | train_inner | epoch 035:   3030 / 4751 loss=4.544, nll_loss=2.942, ppl=7.68, wps=88502, ups=3.04, wpb=29132.3, bsz=988.8, num_updates=164500, lr=7.79681e-05, gnorm=0.452, loss_scale=1, train_wall=33, gb_free=6.1, wall=54701
2021-04-05 15:49:30 | INFO | train_inner | epoch 035:   3130 / 4751 loss=4.531, nll_loss=2.928, ppl=7.61, wps=86757.8, ups=3.03, wpb=28650.5, bsz=937.4, num_updates=164600, lr=7.79444e-05, gnorm=0.458, loss_scale=1, train_wall=33, gb_free=6, wall=54734
2021-04-05 15:50:02 | INFO | train_inner | epoch 035:   3230 / 4751 loss=4.552, nll_loss=2.951, ppl=7.73, wps=88511.7, ups=3.04, wpb=29116.6, bsz=972.2, num_updates=164700, lr=7.79208e-05, gnorm=0.453, loss_scale=1, train_wall=33, gb_free=6.3, wall=54767
2021-04-05 15:50:35 | INFO | train_inner | epoch 035:   3330 / 4751 loss=4.564, nll_loss=2.965, ppl=7.81, wps=87991.2, ups=3.03, wpb=29002, bsz=974.5, num_updates=164800, lr=7.78971e-05, gnorm=0.456, loss_scale=1, train_wall=33, gb_free=6.4, wall=54800
2021-04-05 15:51:08 | INFO | train_inner | epoch 035:   3430 / 4751 loss=4.507, nll_loss=2.9, ppl=7.46, wps=88078.6, ups=3.04, wpb=29006.7, bsz=929.1, num_updates=164900, lr=7.78735e-05, gnorm=0.443, loss_scale=1, train_wall=33, gb_free=6.2, wall=54833
2021-04-05 15:51:41 | INFO | train_inner | epoch 035:   3530 / 4751 loss=4.591, nll_loss=2.995, ppl=7.97, wps=89308.7, ups=3.07, wpb=29101.9, bsz=949.1, num_updates=165000, lr=7.78499e-05, gnorm=0.451, loss_scale=1, train_wall=32, gb_free=6.1, wall=54866
2021-04-05 15:52:14 | INFO | train_inner | epoch 035:   3630 / 4751 loss=4.566, nll_loss=2.966, ppl=7.82, wps=88629.8, ups=3.04, wpb=29120.9, bsz=978.1, num_updates=165100, lr=7.78263e-05, gnorm=0.455, loss_scale=2, train_wall=33, gb_free=6.4, wall=54899
2021-04-05 15:52:47 | INFO | train_inner | epoch 035:   3730 / 4751 loss=4.583, nll_loss=2.986, ppl=7.92, wps=87959.3, ups=3.03, wpb=29029.4, bsz=955.7, num_updates=165200, lr=7.78028e-05, gnorm=0.454, loss_scale=2, train_wall=33, gb_free=6.3, wall=54932
2021-04-05 15:53:19 | INFO | train_inner | epoch 035:   3830 / 4751 loss=4.566, nll_loss=2.967, ppl=7.82, wps=87807.4, ups=3.05, wpb=28744, bsz=944.6, num_updates=165300, lr=7.77792e-05, gnorm=0.452, loss_scale=2, train_wall=33, gb_free=6.1, wall=54964
2021-04-05 15:53:52 | INFO | train_inner | epoch 035:   3930 / 4751 loss=4.549, nll_loss=2.947, ppl=7.71, wps=88088.8, ups=3.05, wpb=28890.1, bsz=953.6, num_updates=165400, lr=7.77557e-05, gnorm=0.455, loss_scale=2, train_wall=33, gb_free=6.2, wall=54997
2021-04-05 15:54:25 | INFO | train_inner | epoch 035:   4030 / 4751 loss=4.542, nll_loss=2.939, ppl=7.67, wps=87726.7, ups=3.04, wpb=28900.8, bsz=915, num_updates=165500, lr=7.77322e-05, gnorm=0.45, loss_scale=2, train_wall=33, gb_free=6, wall=55030
2021-04-05 15:54:58 | INFO | train_inner | epoch 035:   4130 / 4751 loss=4.546, nll_loss=2.945, ppl=7.7, wps=87317.9, ups=3.03, wpb=28790.1, bsz=994.1, num_updates=165600, lr=7.77087e-05, gnorm=0.457, loss_scale=2, train_wall=33, gb_free=6.1, wall=55063
2021-04-05 15:55:31 | INFO | train_inner | epoch 035:   4230 / 4751 loss=4.541, nll_loss=2.938, ppl=7.66, wps=87177.9, ups=3.02, wpb=28901.4, bsz=921.5, num_updates=165700, lr=7.76853e-05, gnorm=0.45, loss_scale=2, train_wall=33, gb_free=6.2, wall=55096
2021-04-05 15:56:04 | INFO | train_inner | epoch 035:   4330 / 4751 loss=4.56, nll_loss=2.959, ppl=7.78, wps=87302.3, ups=3.03, wpb=28844.5, bsz=917.2, num_updates=165800, lr=7.76619e-05, gnorm=0.45, loss_scale=2, train_wall=33, gb_free=6.4, wall=55129
2021-04-05 15:56:37 | INFO | train_inner | epoch 035:   4430 / 4751 loss=4.568, nll_loss=2.97, ppl=7.83, wps=87884.5, ups=3.03, wpb=28963.2, bsz=944.4, num_updates=165900, lr=7.76384e-05, gnorm=0.459, loss_scale=2, train_wall=33, gb_free=6.2, wall=55162
2021-04-05 15:57:10 | INFO | train_inner | epoch 035:   4530 / 4751 loss=4.585, nll_loss=2.988, ppl=7.93, wps=88233.8, ups=3.05, wpb=28958.3, bsz=951, num_updates=166000, lr=7.76151e-05, gnorm=0.455, loss_scale=2, train_wall=33, gb_free=6.3, wall=55195
2021-04-05 15:57:43 | INFO | train_inner | epoch 035:   4630 / 4751 loss=4.517, nll_loss=2.911, ppl=7.52, wps=87333.1, ups=3.03, wpb=28844.4, bsz=975.1, num_updates=166100, lr=7.75917e-05, gnorm=0.454, loss_scale=2, train_wall=33, gb_free=6.1, wall=55228
2021-04-05 15:58:16 | INFO | train_inner | epoch 035:   4730 / 4751 loss=4.55, nll_loss=2.948, ppl=7.72, wps=88139.7, ups=3.04, wpb=29017.7, bsz=954.4, num_updates=166200, lr=7.75683e-05, gnorm=0.453, loss_scale=2, train_wall=33, gb_free=6.1, wall=55261
2021-04-05 15:58:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-05 15:58:24 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 4.201 | nll_loss 2.426 | ppl 5.37 | wps 196358 | wpb 10489.1 | bsz 375 | num_updates 166221 | best_loss 4.188
2021-04-05 15:58:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 166221 updates
2021-04-05 15:58:24 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-05 15:58:31 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-05 15:58:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt (epoch 35 @ 166221 updates, score 4.201) (writing took 6.478775609284639 seconds)
2021-04-05 15:58:31 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2021-04-05 15:58:31 | INFO | train | epoch 035 | loss 4.559 | nll_loss 2.959 | ppl 7.78 | wps 87426.1 | ups 3.02 | wpb 28968.3 | bsz 946.7 | num_updates 166221 | lr 7.75634e-05 | gnorm 0.453 | loss_scale 2 | train_wall 1558 | gb_free 6.5 | wall 55276
2021-04-05 15:58:31 | INFO | fairseq.trainer | begin training epoch 36
2021-04-05 15:58:31 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-05 15:58:58 | INFO | train_inner | epoch 036:     79 / 4751 loss=4.56, nll_loss=2.96, ppl=7.78, wps=69077, ups=2.39, wpb=28891.7, bsz=930.3, num_updates=166300, lr=7.7545e-05, gnorm=0.455, loss_scale=2, train_wall=33, gb_free=6.5, wall=55303
2021-04-05 15:59:31 | INFO | train_inner | epoch 036:    179 / 4751 loss=4.553, nll_loss=2.952, ppl=7.74, wps=88366.2, ups=3.05, wpb=28977.5, bsz=957.7, num_updates=166400, lr=7.75217e-05, gnorm=0.453, loss_scale=2, train_wall=33, gb_free=6.2, wall=55336
2021-04-05 16:00:03 | INFO | train_inner | epoch 036:    279 / 4751 loss=4.542, nll_loss=2.939, ppl=7.67, wps=88658.1, ups=3.06, wpb=28989.6, bsz=932.4, num_updates=166500, lr=7.74984e-05, gnorm=0.452, loss_scale=2, train_wall=33, gb_free=6.1, wall=55368
2021-04-05 16:00:36 | INFO | train_inner | epoch 036:    379 / 4751 loss=4.498, nll_loss=2.889, ppl=7.41, wps=87244.6, ups=3.03, wpb=28758.5, bsz=940.9, num_updates=166600, lr=7.74752e-05, gnorm=0.457, loss_scale=2, train_wall=33, gb_free=6.2, wall=55401
2021-04-05 16:01:09 | INFO | train_inner | epoch 036:    479 / 4751 loss=4.56, nll_loss=2.959, ppl=7.78, wps=87406.8, ups=3.03, wpb=28827.8, bsz=934.8, num_updates=166700, lr=7.74519e-05, gnorm=0.459, loss_scale=2, train_wall=33, gb_free=6.3, wall=55434
2021-04-05 16:01:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-04-05 16:01:43 | INFO | train_inner | epoch 036:    580 / 4751 loss=4.515, nll_loss=2.909, ppl=7.51, wps=86222.3, ups=2.98, wpb=28887.9, bsz=985.7, num_updates=166800, lr=7.74287e-05, gnorm=0.459, loss_scale=1, train_wall=33, gb_free=6.4, wall=55468
2021-04-05 16:02:16 | INFO | train_inner | epoch 036:    680 / 4751 loss=4.571, nll_loss=2.972, ppl=7.85, wps=88111, ups=3.05, wpb=28935, bsz=937.8, num_updates=166900, lr=7.74055e-05, gnorm=0.452, loss_scale=1, train_wall=33, gb_free=6.5, wall=55501
2021-04-05 16:02:49 | INFO | train_inner | epoch 036:    780 / 4751 loss=4.554, nll_loss=2.953, ppl=7.74, wps=88481.9, ups=3.05, wpb=29025, bsz=953.6, num_updates=167000, lr=7.73823e-05, gnorm=0.458, loss_scale=1, train_wall=33, gb_free=6.3, wall=55533
2021-04-05 16:03:21 | INFO | train_inner | epoch 036:    880 / 4751 loss=4.576, nll_loss=2.978, ppl=7.88, wps=88109.6, ups=3.04, wpb=29019, bsz=987.9, num_updates=167100, lr=7.73592e-05, gnorm=0.451, loss_scale=1, train_wall=33, gb_free=6.4, wall=55566
2021-04-05 16:03:55 | INFO | train_inner | epoch 036:    980 / 4751 loss=4.573, nll_loss=2.974, ppl=7.86, wps=87346.5, ups=3.03, wpb=28860.6, bsz=936.3, num_updates=167200, lr=7.7336e-05, gnorm=0.471, loss_scale=1, train_wall=33, gb_free=6.9, wall=55599
2021-04-05 16:04:27 | INFO | train_inner | epoch 036:   1080 / 4751 loss=4.518, nll_loss=2.912, ppl=7.53, wps=87995.5, ups=3.04, wpb=28906.2, bsz=943, num_updates=167300, lr=7.73129e-05, gnorm=0.453, loss_scale=1, train_wall=33, gb_free=6.3, wall=55632
2021-04-05 16:05:00 | INFO | train_inner | epoch 036:   1180 / 4751 loss=4.509, nll_loss=2.902, ppl=7.48, wps=87164.4, ups=3.03, wpb=28740.2, bsz=938, num_updates=167400, lr=7.72898e-05, gnorm=0.446, loss_scale=1, train_wall=33, gb_free=6.4, wall=55665
2021-04-05 16:05:34 | INFO | train_inner | epoch 036:   1280 / 4751 loss=4.569, nll_loss=2.97, ppl=7.84, wps=87921.8, ups=3.02, wpb=29160.9, bsz=961.5, num_updates=167500, lr=7.72667e-05, gnorm=0.454, loss_scale=1, train_wall=33, gb_free=6.1, wall=55698
2021-04-05 16:06:06 | INFO | train_inner | epoch 036:   1380 / 4751 loss=4.513, nll_loss=2.907, ppl=7.5, wps=89122, ups=3.04, wpb=29329.6, bsz=972.9, num_updates=167600, lr=7.72437e-05, gnorm=0.452, loss_scale=1, train_wall=33, gb_free=6.1, wall=55731
2021-04-05 16:06:39 | INFO | train_inner | epoch 036:   1480 / 4751 loss=4.554, nll_loss=2.953, ppl=7.74, wps=88123.5, ups=3.04, wpb=28995.7, bsz=931.6, num_updates=167700, lr=7.72207e-05, gnorm=0.458, loss_scale=1, train_wall=33, gb_free=6.3, wall=55764
2021-04-05 16:07:12 | INFO | train_inner | epoch 036:   1580 / 4751 loss=4.541, nll_loss=2.938, ppl=7.67, wps=87380.2, ups=3.04, wpb=28711.1, bsz=968.6, num_updates=167800, lr=7.71976e-05, gnorm=0.454, loss_scale=1, train_wall=33, gb_free=6.6, wall=55797
2021-04-05 16:07:45 | INFO | train_inner | epoch 036:   1680 / 4751 loss=4.596, nll_loss=3.001, ppl=8, wps=88399.5, ups=3.05, wpb=29026.8, bsz=923.9, num_updates=167900, lr=7.71746e-05, gnorm=0.452, loss_scale=1, train_wall=33, gb_free=6.4, wall=55830
2021-04-05 16:08:18 | INFO | train_inner | epoch 036:   1780 / 4751 loss=4.556, nll_loss=2.955, ppl=7.76, wps=88803, ups=3.03, wpb=29261.7, bsz=942.6, num_updates=168000, lr=7.71517e-05, gnorm=0.448, loss_scale=1, train_wall=33, gb_free=6, wall=55863
2021-04-05 16:08:51 | INFO | train_inner | epoch 036:   1880 / 4751 loss=4.574, nll_loss=2.975, ppl=7.86, wps=87457.3, ups=3.03, wpb=28889.6, bsz=927.2, num_updates=168100, lr=7.71287e-05, gnorm=0.452, loss_scale=1, train_wall=33, gb_free=6.3, wall=55896
2021-04-05 16:09:24 | INFO | train_inner | epoch 036:   1980 / 4751 loss=4.516, nll_loss=2.911, ppl=7.52, wps=88247.2, ups=3.03, wpb=29106.6, bsz=956.2, num_updates=168200, lr=7.71058e-05, gnorm=0.45, loss_scale=1, train_wall=33, gb_free=6.4, wall=55929
2021-04-05 16:09:57 | INFO | train_inner | epoch 036:   2080 / 4751 loss=4.559, nll_loss=2.959, ppl=7.78, wps=88073.7, ups=3.04, wpb=28970.8, bsz=955.4, num_updates=168300, lr=7.70829e-05, gnorm=0.449, loss_scale=1, train_wall=33, gb_free=6.4, wall=55962
2021-04-05 16:10:30 | INFO | train_inner | epoch 036:   2180 / 4751 loss=4.524, nll_loss=2.92, ppl=7.57, wps=88946.5, ups=3.05, wpb=29200.4, bsz=953.8, num_updates=168400, lr=7.706e-05, gnorm=0.453, loss_scale=1, train_wall=33, gb_free=6.1, wall=55995
2021-04-05 16:11:03 | INFO | train_inner | epoch 036:   2280 / 4751 loss=4.535, nll_loss=2.932, ppl=7.63, wps=88450.9, ups=3.05, wpb=29027.8, bsz=939.8, num_updates=168500, lr=7.70371e-05, gnorm=0.453, loss_scale=1, train_wall=33, gb_free=6.3, wall=56027
2021-04-05 16:11:35 | INFO | train_inner | epoch 036:   2380 / 4751 loss=4.551, nll_loss=2.95, ppl=7.73, wps=87374.2, ups=3.04, wpb=28779.1, bsz=946.6, num_updates=168600, lr=7.70143e-05, gnorm=0.453, loss_scale=1, train_wall=33, gb_free=6.3, wall=56060
2021-04-05 16:12:08 | INFO | train_inner | epoch 036:   2480 / 4751 loss=4.567, nll_loss=2.968, ppl=7.82, wps=88362.8, ups=3.04, wpb=29020.2, bsz=936.5, num_updates=168700, lr=7.69914e-05, gnorm=0.451, loss_scale=1, train_wall=33, gb_free=6, wall=56093
2021-04-05 16:12:41 | INFO | train_inner | epoch 036:   2580 / 4751 loss=4.522, nll_loss=2.917, ppl=7.55, wps=87984.8, ups=3.05, wpb=28832.1, bsz=985.3, num_updates=168800, lr=7.69686e-05, gnorm=0.455, loss_scale=2, train_wall=33, gb_free=6.7, wall=56126
2021-04-05 16:13:15 | INFO | train_inner | epoch 036:   2680 / 4751 loss=4.574, nll_loss=2.976, ppl=7.87, wps=86023.5, ups=2.97, wpb=28945.9, bsz=916.3, num_updates=168900, lr=7.69458e-05, gnorm=0.463, loss_scale=2, train_wall=34, gb_free=6.4, wall=56160
2021-04-05 16:13:47 | INFO | train_inner | epoch 036:   2780 / 4751 loss=4.584, nll_loss=2.987, ppl=7.93, wps=87837.4, ups=3.05, wpb=28754.7, bsz=920.6, num_updates=169000, lr=7.69231e-05, gnorm=0.455, loss_scale=2, train_wall=33, gb_free=6.2, wall=56192
2021-04-05 16:14:20 | INFO | train_inner | epoch 036:   2880 / 4751 loss=4.593, nll_loss=2.998, ppl=7.99, wps=87773.8, ups=3.03, wpb=28960.4, bsz=944.1, num_updates=169100, lr=7.69003e-05, gnorm=0.452, loss_scale=2, train_wall=33, gb_free=6, wall=56225
2021-04-05 16:14:53 | INFO | train_inner | epoch 036:   2980 / 4751 loss=4.537, nll_loss=2.934, ppl=7.64, wps=88357.3, ups=3.04, wpb=29033.8, bsz=994.2, num_updates=169200, lr=7.68776e-05, gnorm=0.453, loss_scale=2, train_wall=33, gb_free=6.3, wall=56258
2021-04-05 16:15:26 | INFO | train_inner | epoch 036:   3080 / 4751 loss=4.574, nll_loss=2.976, ppl=7.87, wps=87269.2, ups=3.05, wpb=28602.7, bsz=934.9, num_updates=169300, lr=7.68549e-05, gnorm=0.478, loss_scale=2, train_wall=33, gb_free=6.2, wall=56291
2021-04-05 16:15:59 | INFO | train_inner | epoch 036:   3180 / 4751 loss=4.594, nll_loss=2.998, ppl=7.99, wps=87901.1, ups=3.05, wpb=28845.6, bsz=933.9, num_updates=169400, lr=7.68322e-05, gnorm=0.454, loss_scale=2, train_wall=33, gb_free=6.2, wall=56324
2021-04-05 16:16:32 | INFO | train_inner | epoch 036:   3280 / 4751 loss=4.545, nll_loss=2.943, ppl=7.69, wps=88465, ups=3.06, wpb=28945.4, bsz=956.2, num_updates=169500, lr=7.68095e-05, gnorm=0.449, loss_scale=2, train_wall=33, gb_free=6.2, wall=56356
2021-04-05 16:17:05 | INFO | train_inner | epoch 036:   3380 / 4751 loss=4.506, nll_loss=2.899, ppl=7.46, wps=89479.8, ups=3.04, wpb=29455.9, bsz=939.6, num_updates=169600, lr=7.67869e-05, gnorm=0.449, loss_scale=2, train_wall=33, gb_free=6, wall=56389
2021-04-05 16:17:37 | INFO | train_inner | epoch 036:   3480 / 4751 loss=4.617, nll_loss=3.025, ppl=8.14, wps=88961.5, ups=3.05, wpb=29173, bsz=948.6, num_updates=169700, lr=7.67643e-05, gnorm=0.454, loss_scale=2, train_wall=33, gb_free=6, wall=56422
2021-04-05 16:18:10 | INFO | train_inner | epoch 036:   3580 / 4751 loss=4.546, nll_loss=2.944, ppl=7.7, wps=87369, ups=3.02, wpb=28907.4, bsz=966.4, num_updates=169800, lr=7.67417e-05, gnorm=0.459, loss_scale=2, train_wall=33, gb_free=6.3, wall=56455
2021-04-05 16:18:43 | INFO | train_inner | epoch 036:   3680 / 4751 loss=4.539, nll_loss=2.937, ppl=7.66, wps=88404.9, ups=3.05, wpb=28995.9, bsz=962.1, num_updates=169900, lr=7.67191e-05, gnorm=0.452, loss_scale=2, train_wall=33, gb_free=6.4, wall=56488
2021-04-05 16:19:16 | INFO | train_inner | epoch 036:   3780 / 4751 loss=4.523, nll_loss=2.918, ppl=7.56, wps=88425.3, ups=3.04, wpb=29072, bsz=947.6, num_updates=170000, lr=7.66965e-05, gnorm=0.453, loss_scale=2, train_wall=33, gb_free=6.1, wall=56521
2021-04-05 16:19:49 | INFO | train_inner | epoch 036:   3880 / 4751 loss=4.545, nll_loss=2.944, ppl=7.69, wps=87111.1, ups=3.03, wpb=28787.2, bsz=988.6, num_updates=170100, lr=7.6674e-05, gnorm=0.453, loss_scale=2, train_wall=33, gb_free=6.5, wall=56554
2021-04-05 16:20:22 | INFO | train_inner | epoch 036:   3980 / 4751 loss=4.53, nll_loss=2.926, ppl=7.6, wps=87656, ups=3.03, wpb=28949.6, bsz=953.7, num_updates=170200, lr=7.66514e-05, gnorm=0.456, loss_scale=2, train_wall=33, gb_free=6.2, wall=56587
2021-04-05 16:20:55 | INFO | train_inner | epoch 036:   4080 / 4751 loss=4.625, nll_loss=3.034, ppl=8.19, wps=88273, ups=3.05, wpb=28987.3, bsz=934.5, num_updates=170300, lr=7.66289e-05, gnorm=0.456, loss_scale=2, train_wall=33, gb_free=6.2, wall=56620
2021-04-05 16:21:28 | INFO | train_inner | epoch 036:   4180 / 4751 loss=4.531, nll_loss=2.928, ppl=7.61, wps=88240.1, ups=3.05, wpb=28977, bsz=930.9, num_updates=170400, lr=7.66064e-05, gnorm=0.451, loss_scale=2, train_wall=33, gb_free=6.1, wall=56653
2021-04-05 16:22:01 | INFO | train_inner | epoch 036:   4280 / 4751 loss=4.571, nll_loss=2.972, ppl=7.85, wps=87870.3, ups=3.05, wpb=28812.1, bsz=914.6, num_updates=170500, lr=7.6584e-05, gnorm=0.474, loss_scale=2, train_wall=33, gb_free=6.2, wall=56685
2021-04-05 16:22:33 | INFO | train_inner | epoch 036:   4380 / 4751 loss=4.637, nll_loss=3.048, ppl=8.27, wps=88388.1, ups=3.06, wpb=28901.6, bsz=931.5, num_updates=170600, lr=7.65615e-05, gnorm=0.454, loss_scale=2, train_wall=33, gb_free=6.3, wall=56718
2021-04-05 16:23:06 | INFO | train_inner | epoch 036:   4480 / 4751 loss=4.547, nll_loss=2.945, ppl=7.7, wps=87251.2, ups=3.03, wpb=28814.5, bsz=914.3, num_updates=170700, lr=7.65391e-05, gnorm=0.454, loss_scale=2, train_wall=33, gb_free=6.3, wall=56751
2021-04-05 16:23:39 | INFO | train_inner | epoch 036:   4580 / 4751 loss=4.59, nll_loss=2.995, ppl=7.97, wps=89115.7, ups=3.05, wpb=29223.4, bsz=956.1, num_updates=170800, lr=7.65167e-05, gnorm=0.445, loss_scale=2, train_wall=33, gb_free=6.1, wall=56784
2021-04-05 16:24:12 | INFO | train_inner | epoch 036:   4680 / 4751 loss=4.56, nll_loss=2.96, ppl=7.78, wps=89175.1, ups=3.05, wpb=29248.5, bsz=933.4, num_updates=170900, lr=7.64943e-05, gnorm=0.453, loss_scale=4, train_wall=33, gb_free=6.1, wall=56817
2021-04-05 16:24:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-05 16:24:37 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 4.186 | nll_loss 2.416 | ppl 5.34 | wps 190480 | wpb 10489.1 | bsz 375 | num_updates 170971 | best_loss 4.186
2021-04-05 16:24:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 170971 updates
2021-04-05 16:24:37 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 16:24:43 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 16:24:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt (epoch 36 @ 170971 updates, score 4.186) (writing took 12.903544407337904 seconds)
2021-04-05 16:24:49 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2021-04-05 16:24:49 | INFO | train | epoch 036 | loss 4.556 | nll_loss 2.955 | ppl 7.76 | wps 87156.6 | ups 3.01 | wpb 28968.1 | bsz 947 | num_updates 170971 | lr 7.64784e-05 | gnorm 0.455 | loss_scale 4 | train_wall 1557 | gb_free 6.2 | wall 56854
2021-04-05 16:24:50 | INFO | fairseq.trainer | begin training epoch 37
2021-04-05 16:24:50 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-05 16:25:00 | INFO | train_inner | epoch 037:     29 / 4751 loss=4.625, nll_loss=3.034, ppl=8.19, wps=59199.2, ups=2.07, wpb=28634.4, bsz=955.1, num_updates=171000, lr=7.64719e-05, gnorm=0.467, loss_scale=4, train_wall=33, gb_free=6.4, wall=56865
2021-04-05 16:25:33 | INFO | train_inner | epoch 037:    129 / 4751 loss=4.533, nll_loss=2.93, ppl=7.62, wps=87889.5, ups=3.05, wpb=28845.8, bsz=961.1, num_updates=171100, lr=7.64496e-05, gnorm=0.457, loss_scale=4, train_wall=33, gb_free=6.7, wall=56898
2021-04-05 16:26:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-05 16:26:06 | INFO | train_inner | epoch 037:    230 / 4751 loss=4.59, nll_loss=2.993, ppl=7.96, wps=85817.5, ups=3, wpb=28579.7, bsz=913.8, num_updates=171200, lr=7.64272e-05, gnorm=0.468, loss_scale=2, train_wall=33, gb_free=6.2, wall=56931
2021-04-05 16:26:39 | INFO | train_inner | epoch 037:    330 / 4751 loss=4.568, nll_loss=2.968, ppl=7.82, wps=88415.3, ups=3.05, wpb=28991.2, bsz=932.3, num_updates=171300, lr=7.64049e-05, gnorm=0.449, loss_scale=2, train_wall=33, gb_free=6.2, wall=56964
2021-04-05 16:27:12 | INFO | train_inner | epoch 037:    430 / 4751 loss=4.511, nll_loss=2.905, ppl=7.49, wps=87978.8, ups=3.05, wpb=28811.9, bsz=950.9, num_updates=171400, lr=7.63826e-05, gnorm=0.449, loss_scale=2, train_wall=33, gb_free=6.4, wall=56997
2021-04-05 16:27:45 | INFO | train_inner | epoch 037:    530 / 4751 loss=4.56, nll_loss=2.959, ppl=7.78, wps=87793.9, ups=3.03, wpb=28979.4, bsz=945.2, num_updates=171500, lr=7.63604e-05, gnorm=0.46, loss_scale=2, train_wall=33, gb_free=6.2, wall=57030
2021-04-05 16:28:18 | INFO | train_inner | epoch 037:    630 / 4751 loss=4.598, nll_loss=3.003, ppl=8.02, wps=88167, ups=3.02, wpb=29191, bsz=964.9, num_updates=171600, lr=7.63381e-05, gnorm=0.466, loss_scale=2, train_wall=33, gb_free=6.1, wall=57063
2021-04-05 16:28:51 | INFO | train_inner | epoch 037:    730 / 4751 loss=4.546, nll_loss=2.945, ppl=7.7, wps=87006, ups=3.03, wpb=28753.8, bsz=968.2, num_updates=171700, lr=7.63159e-05, gnorm=0.456, loss_scale=2, train_wall=33, gb_free=6.2, wall=57096
2021-04-05 16:29:24 | INFO | train_inner | epoch 037:    830 / 4751 loss=4.591, nll_loss=2.995, ppl=7.97, wps=88257.9, ups=3.03, wpb=29100, bsz=950.2, num_updates=171800, lr=7.62937e-05, gnorm=0.463, loss_scale=2, train_wall=33, gb_free=6.2, wall=57129
2021-04-05 16:29:57 | INFO | train_inner | epoch 037:    930 / 4751 loss=4.508, nll_loss=2.901, ppl=7.47, wps=88254.3, ups=3.05, wpb=28930.6, bsz=955.1, num_updates=171900, lr=7.62715e-05, gnorm=0.45, loss_scale=2, train_wall=33, gb_free=6.4, wall=57162
2021-04-05 16:30:30 | INFO | train_inner | epoch 037:   1030 / 4751 loss=4.539, nll_loss=2.936, ppl=7.65, wps=88172.8, ups=3.01, wpb=29276.2, bsz=939.4, num_updates=172000, lr=7.62493e-05, gnorm=0.456, loss_scale=2, train_wall=33, gb_free=6.3, wall=57195
2021-04-05 16:31:03 | INFO | train_inner | epoch 037:   1130 / 4751 loss=4.547, nll_loss=2.945, ppl=7.7, wps=88595.4, ups=3.04, wpb=29145.2, bsz=933.8, num_updates=172100, lr=7.62271e-05, gnorm=0.453, loss_scale=2, train_wall=33, gb_free=6.2, wall=57228
2021-04-05 16:31:36 | INFO | train_inner | epoch 037:   1230 / 4751 loss=4.495, nll_loss=2.886, ppl=7.39, wps=88637.2, ups=3.05, wpb=29092.3, bsz=957.8, num_updates=172200, lr=7.6205e-05, gnorm=0.45, loss_scale=2, train_wall=33, gb_free=6.2, wall=57261
2021-04-05 16:32:09 | INFO | train_inner | epoch 037:   1330 / 4751 loss=4.518, nll_loss=2.912, ppl=7.53, wps=88180.5, ups=3.05, wpb=28945.7, bsz=950.8, num_updates=172300, lr=7.61829e-05, gnorm=0.461, loss_scale=2, train_wall=33, gb_free=6.1, wall=57293
2021-04-05 16:32:42 | INFO | train_inner | epoch 037:   1430 / 4751 loss=4.55, nll_loss=2.948, ppl=7.72, wps=87194.1, ups=3.03, wpb=28800.6, bsz=958.5, num_updates=172400, lr=7.61608e-05, gnorm=0.455, loss_scale=2, train_wall=33, gb_free=6.1, wall=57327
2021-04-05 16:33:15 | INFO | train_inner | epoch 037:   1530 / 4751 loss=4.558, nll_loss=2.957, ppl=7.77, wps=88229.5, ups=3.04, wpb=28988.8, bsz=946.2, num_updates=172500, lr=7.61387e-05, gnorm=0.454, loss_scale=2, train_wall=33, gb_free=6.2, wall=57359
2021-04-05 16:33:47 | INFO | train_inner | epoch 037:   1630 / 4751 loss=4.54, nll_loss=2.937, ppl=7.66, wps=89102, ups=3.04, wpb=29312.6, bsz=973.5, num_updates=172600, lr=7.61166e-05, gnorm=0.448, loss_scale=2, train_wall=33, gb_free=6.1, wall=57392
2021-04-05 16:34:20 | INFO | train_inner | epoch 037:   1730 / 4751 loss=4.551, nll_loss=2.95, ppl=7.73, wps=87984.8, ups=3.04, wpb=28912.6, bsz=947.8, num_updates=172700, lr=7.60946e-05, gnorm=0.454, loss_scale=2, train_wall=33, gb_free=6.2, wall=57425
2021-04-05 16:34:53 | INFO | train_inner | epoch 037:   1830 / 4751 loss=4.527, nll_loss=2.923, ppl=7.58, wps=88677.7, ups=3.05, wpb=29059.5, bsz=975, num_updates=172800, lr=7.60726e-05, gnorm=0.452, loss_scale=2, train_wall=33, gb_free=6.2, wall=57458
2021-04-05 16:35:26 | INFO | train_inner | epoch 037:   1930 / 4751 loss=4.582, nll_loss=2.984, ppl=7.91, wps=87883.8, ups=3.05, wpb=28824.5, bsz=910.7, num_updates=172900, lr=7.60506e-05, gnorm=0.452, loss_scale=2, train_wall=33, gb_free=6.5, wall=57491
2021-04-05 16:35:59 | INFO | train_inner | epoch 037:   2030 / 4751 loss=4.546, nll_loss=2.944, ppl=7.7, wps=87611.2, ups=3.04, wpb=28829.7, bsz=946.6, num_updates=173000, lr=7.60286e-05, gnorm=0.458, loss_scale=2, train_wall=33, gb_free=6.4, wall=57524
2021-04-05 16:36:32 | INFO | train_inner | epoch 037:   2130 / 4751 loss=4.509, nll_loss=2.902, ppl=7.48, wps=87978.5, ups=3.02, wpb=29169.2, bsz=946.6, num_updates=173100, lr=7.60066e-05, gnorm=0.449, loss_scale=2, train_wall=33, gb_free=6.4, wall=57557
2021-04-05 16:37:05 | INFO | train_inner | epoch 037:   2230 / 4751 loss=4.6, nll_loss=3.006, ppl=8.03, wps=87587.5, ups=3.04, wpb=28837.5, bsz=969.5, num_updates=173200, lr=7.59847e-05, gnorm=0.461, loss_scale=2, train_wall=33, gb_free=6.2, wall=57590
2021-04-05 16:37:38 | INFO | train_inner | epoch 037:   2330 / 4751 loss=4.56, nll_loss=2.96, ppl=7.78, wps=87606.8, ups=3.04, wpb=28788.6, bsz=924.7, num_updates=173300, lr=7.59628e-05, gnorm=0.458, loss_scale=4, train_wall=33, gb_free=6.3, wall=57623
2021-04-05 16:38:11 | INFO | train_inner | epoch 037:   2430 / 4751 loss=4.471, nll_loss=2.859, ppl=7.26, wps=88402.9, ups=3.03, wpb=29144.2, bsz=953.6, num_updates=173400, lr=7.59408e-05, gnorm=0.454, loss_scale=4, train_wall=33, gb_free=6.5, wall=57656
2021-04-05 16:38:43 | INFO | train_inner | epoch 037:   2530 / 4751 loss=4.568, nll_loss=2.969, ppl=7.83, wps=87894.6, ups=3.05, wpb=28812.6, bsz=927.6, num_updates=173500, lr=7.5919e-05, gnorm=0.461, loss_scale=4, train_wall=33, gb_free=6.2, wall=57688
2021-04-05 16:39:16 | INFO | train_inner | epoch 037:   2630 / 4751 loss=4.591, nll_loss=2.995, ppl=7.97, wps=88819.7, ups=3.05, wpb=29133.5, bsz=935.5, num_updates=173600, lr=7.58971e-05, gnorm=0.453, loss_scale=4, train_wall=33, gb_free=6.3, wall=57721
2021-04-05 16:39:49 | INFO | train_inner | epoch 037:   2730 / 4751 loss=4.556, nll_loss=2.956, ppl=7.76, wps=87590.5, ups=3.04, wpb=28835.8, bsz=917.8, num_updates=173700, lr=7.58752e-05, gnorm=0.46, loss_scale=4, train_wall=33, gb_free=6.3, wall=57754
2021-04-05 16:40:23 | INFO | train_inner | epoch 037:   2830 / 4751 loss=4.551, nll_loss=2.949, ppl=7.72, wps=86863.8, ups=2.97, wpb=29231.3, bsz=937.2, num_updates=173800, lr=7.58534e-05, gnorm=0.449, loss_scale=4, train_wall=34, gb_free=6.4, wall=57788
2021-04-05 16:40:56 | INFO | train_inner | epoch 037:   2930 / 4751 loss=4.538, nll_loss=2.935, ppl=7.65, wps=88463.9, ups=3.04, wpb=29128.8, bsz=936.1, num_updates=173900, lr=7.58316e-05, gnorm=0.451, loss_scale=4, train_wall=33, gb_free=6.4, wall=57821
2021-04-05 16:41:29 | INFO | train_inner | epoch 037:   3030 / 4751 loss=4.512, nll_loss=2.905, ppl=7.49, wps=88825.8, ups=3.04, wpb=29259, bsz=944.4, num_updates=174000, lr=7.58098e-05, gnorm=0.446, loss_scale=4, train_wall=33, gb_free=6.3, wall=57854
2021-04-05 16:41:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-05 16:42:02 | INFO | train_inner | epoch 037:   3131 / 4751 loss=4.493, nll_loss=2.885, ppl=7.39, wps=87915.3, ups=3, wpb=29274.3, bsz=993.9, num_updates=174100, lr=7.5788e-05, gnorm=0.448, loss_scale=2, train_wall=33, gb_free=6.1, wall=57887
2021-04-05 16:42:35 | INFO | train_inner | epoch 037:   3231 / 4751 loss=4.6, nll_loss=3.005, ppl=8.03, wps=86947.7, ups=3.04, wpb=28567.4, bsz=895.4, num_updates=174200, lr=7.57663e-05, gnorm=0.458, loss_scale=2, train_wall=33, gb_free=6.1, wall=57920
2021-04-05 16:43:08 | INFO | train_inner | epoch 037:   3331 / 4751 loss=4.561, nll_loss=2.961, ppl=7.79, wps=87249.5, ups=3.01, wpb=28986, bsz=955.8, num_updates=174300, lr=7.57445e-05, gnorm=0.454, loss_scale=2, train_wall=33, gb_free=6.2, wall=57953
2021-04-05 16:43:41 | INFO | train_inner | epoch 037:   3431 / 4751 loss=4.548, nll_loss=2.946, ppl=7.7, wps=87661.8, ups=3.03, wpb=28972.2, bsz=934.1, num_updates=174400, lr=7.57228e-05, gnorm=0.448, loss_scale=2, train_wall=33, gb_free=6.3, wall=57986
2021-04-05 16:44:14 | INFO | train_inner | epoch 037:   3531 / 4751 loss=4.601, nll_loss=3.006, ppl=8.03, wps=88021.9, ups=3.06, wpb=28770.2, bsz=909.1, num_updates=174500, lr=7.57011e-05, gnorm=0.46, loss_scale=2, train_wall=33, gb_free=6.4, wall=58019
2021-04-05 16:44:47 | INFO | train_inner | epoch 037:   3631 / 4751 loss=4.571, nll_loss=2.973, ppl=7.85, wps=88139.1, ups=3.05, wpb=28895.5, bsz=959.9, num_updates=174600, lr=7.56794e-05, gnorm=0.457, loss_scale=2, train_wall=33, gb_free=6.1, wall=58051
2021-04-05 16:45:19 | INFO | train_inner | epoch 037:   3731 / 4751 loss=4.529, nll_loss=2.925, ppl=7.6, wps=89129.1, ups=3.05, wpb=29241.3, bsz=935, num_updates=174700, lr=7.56578e-05, gnorm=0.447, loss_scale=2, train_wall=33, gb_free=6.3, wall=58084
2021-04-05 16:45:53 | INFO | train_inner | epoch 037:   3831 / 4751 loss=4.516, nll_loss=2.911, ppl=7.52, wps=88292.2, ups=3.02, wpb=29212.1, bsz=951.4, num_updates=174800, lr=7.56361e-05, gnorm=0.454, loss_scale=2, train_wall=33, gb_free=6.4, wall=58117
2021-04-05 16:46:25 | INFO | train_inner | epoch 037:   3931 / 4751 loss=4.612, nll_loss=3.019, ppl=8.1, wps=87767, ups=3.04, wpb=28844.9, bsz=927.8, num_updates=174900, lr=7.56145e-05, gnorm=0.464, loss_scale=2, train_wall=33, gb_free=6.1, wall=58150
2021-04-05 16:46:58 | INFO | train_inner | epoch 037:   4031 / 4751 loss=4.556, nll_loss=2.956, ppl=7.76, wps=86731.4, ups=3.03, wpb=28655.2, bsz=942.8, num_updates=175000, lr=7.55929e-05, gnorm=0.457, loss_scale=2, train_wall=33, gb_free=6.6, wall=58183
2021-04-05 16:47:31 | INFO | train_inner | epoch 037:   4131 / 4751 loss=4.573, nll_loss=2.976, ppl=7.87, wps=88224.6, ups=3.04, wpb=29061.5, bsz=975.4, num_updates=175100, lr=7.55713e-05, gnorm=0.458, loss_scale=2, train_wall=33, gb_free=6.2, wall=58216
2021-04-05 16:48:04 | INFO | train_inner | epoch 037:   4231 / 4751 loss=4.6, nll_loss=3.005, ppl=8.03, wps=87759.4, ups=3.06, wpb=28671, bsz=947.8, num_updates=175200, lr=7.55497e-05, gnorm=0.469, loss_scale=2, train_wall=33, gb_free=6.1, wall=58249
2021-04-05 16:48:37 | INFO | train_inner | epoch 037:   4331 / 4751 loss=4.547, nll_loss=2.946, ppl=7.7, wps=87188.8, ups=3.03, wpb=28759.6, bsz=930.5, num_updates=175300, lr=7.55282e-05, gnorm=0.464, loss_scale=2, train_wall=33, gb_free=6.4, wall=58282
2021-04-05 16:49:10 | INFO | train_inner | epoch 037:   4431 / 4751 loss=4.582, nll_loss=2.986, ppl=7.92, wps=88099.1, ups=3.04, wpb=28961.7, bsz=942.8, num_updates=175400, lr=7.55067e-05, gnorm=0.463, loss_scale=2, train_wall=33, gb_free=6.4, wall=58315
2021-04-05 16:49:43 | INFO | train_inner | epoch 037:   4531 / 4751 loss=4.612, nll_loss=3.019, ppl=8.11, wps=89465.2, ups=3.06, wpb=29218.3, bsz=990.1, num_updates=175500, lr=7.54851e-05, gnorm=0.459, loss_scale=2, train_wall=33, gb_free=6.1, wall=58347
2021-04-05 16:50:16 | INFO | train_inner | epoch 037:   4631 / 4751 loss=4.506, nll_loss=2.899, ppl=7.46, wps=87173.3, ups=3.03, wpb=28797.9, bsz=944.6, num_updates=175600, lr=7.54636e-05, gnorm=0.449, loss_scale=2, train_wall=33, gb_free=6.3, wall=58380
2021-04-05 16:50:49 | INFO | train_inner | epoch 037:   4731 / 4751 loss=4.524, nll_loss=2.92, ppl=7.57, wps=88693, ups=3.03, wpb=29233.6, bsz=994.4, num_updates=175700, lr=7.54422e-05, gnorm=0.452, loss_scale=2, train_wall=33, gb_free=6.2, wall=58413
2021-04-05 16:50:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-05 16:50:56 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 4.185 | nll_loss 2.412 | ppl 5.32 | wps 187250 | wpb 10489.1 | bsz 375 | num_updates 175720 | best_loss 4.185
2021-04-05 16:50:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 175720 updates
2021-04-05 16:50:56 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 16:51:02 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 16:51:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt (epoch 37 @ 175720 updates, score 4.185) (writing took 13.47480108961463 seconds)
2021-04-05 16:51:10 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2021-04-05 16:51:10 | INFO | train | epoch 037 | loss 4.553 | nll_loss 2.952 | ppl 7.74 | wps 87060.4 | ups 3.01 | wpb 28968.1 | bsz 946.7 | num_updates 175720 | lr 7.54379e-05 | gnorm 0.456 | loss_scale 2 | train_wall 1557 | gb_free 6.3 | wall 58434
2021-04-05 16:51:10 | INFO | fairseq.trainer | begin training epoch 38
2021-04-05 16:51:10 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-05 16:51:37 | INFO | train_inner | epoch 038:     80 / 4751 loss=4.523, nll_loss=2.918, ppl=7.56, wps=59515.4, ups=2.06, wpb=28959.3, bsz=926.2, num_updates=175800, lr=7.54207e-05, gnorm=0.454, loss_scale=2, train_wall=32, gb_free=6.4, wall=58462
2021-04-05 16:52:10 | INFO | train_inner | epoch 038:    180 / 4751 loss=4.599, nll_loss=3.003, ppl=8.02, wps=86928, ups=3.05, wpb=28509.4, bsz=912, num_updates=175900, lr=7.53993e-05, gnorm=0.462, loss_scale=2, train_wall=33, gb_free=6.2, wall=58495
2021-04-05 16:52:43 | INFO | train_inner | epoch 038:    280 / 4751 loss=4.553, nll_loss=2.952, ppl=7.74, wps=88397.1, ups=3.05, wpb=28962.5, bsz=923.5, num_updates=176000, lr=7.53778e-05, gnorm=0.457, loss_scale=2, train_wall=33, gb_free=6.4, wall=58528
2021-04-05 16:53:16 | INFO | train_inner | epoch 038:    380 / 4751 loss=4.517, nll_loss=2.911, ppl=7.52, wps=87961.7, ups=3.04, wpb=28906.5, bsz=971.8, num_updates=176100, lr=7.53564e-05, gnorm=0.451, loss_scale=2, train_wall=33, gb_free=6.3, wall=58560
2021-04-05 16:53:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-05 16:53:49 | INFO | train_inner | epoch 038:    481 / 4751 loss=4.548, nll_loss=2.946, ppl=7.7, wps=86943.4, ups=3.01, wpb=28863.4, bsz=920.6, num_updates=176200, lr=7.5335e-05, gnorm=0.451, loss_scale=2, train_wall=33, gb_free=6.1, wall=58594
2021-04-05 16:54:22 | INFO | train_inner | epoch 038:    581 / 4751 loss=4.545, nll_loss=2.942, ppl=7.69, wps=87215.2, ups=3.04, wpb=28731.3, bsz=922.4, num_updates=176300, lr=7.53137e-05, gnorm=0.454, loss_scale=2, train_wall=33, gb_free=6.1, wall=58627
2021-04-05 16:54:55 | INFO | train_inner | epoch 038:    681 / 4751 loss=4.559, nll_loss=2.958, ppl=7.77, wps=87104.5, ups=3.04, wpb=28676, bsz=936.1, num_updates=176400, lr=7.52923e-05, gnorm=0.458, loss_scale=2, train_wall=33, gb_free=6.5, wall=58660
2021-04-05 16:55:28 | INFO | train_inner | epoch 038:    781 / 4751 loss=4.521, nll_loss=2.915, ppl=7.54, wps=87589.6, ups=3.02, wpb=28969.7, bsz=950.5, num_updates=176500, lr=7.5271e-05, gnorm=0.449, loss_scale=2, train_wall=33, gb_free=6.1, wall=58693
2021-04-05 16:56:01 | INFO | train_inner | epoch 038:    881 / 4751 loss=4.541, nll_loss=2.939, ppl=7.67, wps=87640, ups=3.04, wpb=28831, bsz=983.1, num_updates=176600, lr=7.52497e-05, gnorm=0.462, loss_scale=2, train_wall=33, gb_free=6.4, wall=58725
2021-04-05 16:56:34 | INFO | train_inner | epoch 038:    981 / 4751 loss=4.592, nll_loss=2.996, ppl=7.98, wps=88778.1, ups=3.03, wpb=29322.2, bsz=923.8, num_updates=176700, lr=7.52284e-05, gnorm=0.454, loss_scale=2, train_wall=33, gb_free=6, wall=58759
2021-04-05 16:57:06 | INFO | train_inner | epoch 038:   1081 / 4751 loss=4.525, nll_loss=2.92, ppl=7.57, wps=88307.5, ups=3.05, wpb=28963.1, bsz=977, num_updates=176800, lr=7.52071e-05, gnorm=0.452, loss_scale=2, train_wall=33, gb_free=6.7, wall=58791
2021-04-05 16:57:40 | INFO | train_inner | epoch 038:   1181 / 4751 loss=4.585, nll_loss=2.988, ppl=7.93, wps=87562.9, ups=3.01, wpb=29070.9, bsz=910.1, num_updates=176900, lr=7.51858e-05, gnorm=0.459, loss_scale=2, train_wall=33, gb_free=6.3, wall=58824
2021-04-05 16:58:12 | INFO | train_inner | epoch 038:   1281 / 4751 loss=4.558, nll_loss=2.957, ppl=7.76, wps=88406.1, ups=3.05, wpb=29003.7, bsz=921.4, num_updates=177000, lr=7.51646e-05, gnorm=0.464, loss_scale=2, train_wall=33, gb_free=6.3, wall=58857
2021-04-05 16:58:45 | INFO | train_inner | epoch 038:   1381 / 4751 loss=4.575, nll_loss=2.977, ppl=7.87, wps=88787.3, ups=3.04, wpb=29178.1, bsz=962.1, num_updates=177100, lr=7.51434e-05, gnorm=0.458, loss_scale=2, train_wall=33, gb_free=6.1, wall=58890
2021-04-05 16:59:18 | INFO | train_inner | epoch 038:   1481 / 4751 loss=4.557, nll_loss=2.957, ppl=7.76, wps=86826.4, ups=3.03, wpb=28610, bsz=930.6, num_updates=177200, lr=7.51222e-05, gnorm=0.458, loss_scale=2, train_wall=33, gb_free=6.4, wall=58923
2021-04-05 16:59:51 | INFO | train_inner | epoch 038:   1581 / 4751 loss=4.504, nll_loss=2.897, ppl=7.45, wps=88291.5, ups=3.04, wpb=29061.5, bsz=978.9, num_updates=177300, lr=7.5101e-05, gnorm=0.452, loss_scale=2, train_wall=33, gb_free=6.1, wall=58956
2021-04-05 17:00:24 | INFO | train_inner | epoch 038:   1681 / 4751 loss=4.524, nll_loss=2.92, ppl=7.57, wps=88331.5, ups=3.03, wpb=29166, bsz=983.4, num_updates=177400, lr=7.50798e-05, gnorm=0.453, loss_scale=2, train_wall=33, gb_free=6.1, wall=58989
2021-04-05 17:00:57 | INFO | train_inner | epoch 038:   1781 / 4751 loss=4.502, nll_loss=2.895, ppl=7.44, wps=87649.2, ups=3.03, wpb=28964.3, bsz=959, num_updates=177500, lr=7.50587e-05, gnorm=0.459, loss_scale=2, train_wall=33, gb_free=6.2, wall=59022
2021-04-05 17:01:30 | INFO | train_inner | epoch 038:   1881 / 4751 loss=4.537, nll_loss=2.934, ppl=7.64, wps=88256.3, ups=3.04, wpb=28998.1, bsz=945, num_updates=177600, lr=7.50375e-05, gnorm=0.461, loss_scale=2, train_wall=33, gb_free=6.4, wall=59055
2021-04-05 17:02:03 | INFO | train_inner | epoch 038:   1981 / 4751 loss=4.549, nll_loss=2.948, ppl=7.72, wps=87744.4, ups=3.03, wpb=28968.7, bsz=960.6, num_updates=177700, lr=7.50164e-05, gnorm=0.46, loss_scale=2, train_wall=33, gb_free=6, wall=59088
2021-04-05 17:02:36 | INFO | train_inner | epoch 038:   2081 / 4751 loss=4.561, nll_loss=2.96, ppl=7.78, wps=89137.8, ups=3.06, wpb=29169, bsz=934.4, num_updates=177800, lr=7.49953e-05, gnorm=0.461, loss_scale=2, train_wall=33, gb_free=6.4, wall=59121
2021-04-05 17:03:09 | INFO | train_inner | epoch 038:   2181 / 4751 loss=4.608, nll_loss=3.014, ppl=8.08, wps=87430.9, ups=3.03, wpb=28835.2, bsz=983.5, num_updates=177900, lr=7.49742e-05, gnorm=0.465, loss_scale=2, train_wall=33, gb_free=6.1, wall=59154
2021-04-05 17:03:41 | INFO | train_inner | epoch 038:   2281 / 4751 loss=4.573, nll_loss=2.975, ppl=7.86, wps=89239.5, ups=3.07, wpb=29039.9, bsz=946.9, num_updates=178000, lr=7.49532e-05, gnorm=0.462, loss_scale=2, train_wall=32, gb_free=6.3, wall=59186
2021-04-05 17:04:14 | INFO | train_inner | epoch 038:   2381 / 4751 loss=4.576, nll_loss=2.978, ppl=7.88, wps=88432.3, ups=3.05, wpb=28961.7, bsz=958.6, num_updates=178100, lr=7.49321e-05, gnorm=0.459, loss_scale=2, train_wall=33, gb_free=6.1, wall=59219
2021-04-05 17:04:47 | INFO | train_inner | epoch 038:   2481 / 4751 loss=4.548, nll_loss=2.946, ppl=7.71, wps=88044.3, ups=3.05, wpb=28901.8, bsz=949.9, num_updates=178200, lr=7.49111e-05, gnorm=0.458, loss_scale=2, train_wall=33, gb_free=6, wall=59252
2021-04-05 17:05:20 | INFO | train_inner | epoch 038:   2581 / 4751 loss=4.507, nll_loss=2.9, ppl=7.46, wps=88147.5, ups=3.03, wpb=29082.6, bsz=953.2, num_updates=178300, lr=7.48901e-05, gnorm=0.448, loss_scale=4, train_wall=33, gb_free=6.2, wall=59285
2021-04-05 17:05:53 | INFO | train_inner | epoch 038:   2681 / 4751 loss=4.556, nll_loss=2.956, ppl=7.76, wps=88472.2, ups=3.04, wpb=29143.4, bsz=942.7, num_updates=178400, lr=7.48691e-05, gnorm=0.453, loss_scale=4, train_wall=33, gb_free=6.1, wall=59318
2021-04-05 17:06:26 | INFO | train_inner | epoch 038:   2781 / 4751 loss=4.557, nll_loss=2.956, ppl=7.76, wps=87949.4, ups=3.05, wpb=28861.6, bsz=961.5, num_updates=178500, lr=7.48481e-05, gnorm=0.466, loss_scale=4, train_wall=33, gb_free=6.1, wall=59351
2021-04-05 17:06:58 | INFO | train_inner | epoch 038:   2881 / 4751 loss=4.536, nll_loss=2.934, ppl=7.64, wps=87826.3, ups=3.05, wpb=28768.7, bsz=935, num_updates=178600, lr=7.48272e-05, gnorm=0.455, loss_scale=4, train_wall=33, gb_free=6.3, wall=59383
2021-04-05 17:07:31 | INFO | train_inner | epoch 038:   2981 / 4751 loss=4.55, nll_loss=2.949, ppl=7.72, wps=87509.7, ups=3.04, wpb=28812.7, bsz=945.4, num_updates=178700, lr=7.48062e-05, gnorm=0.453, loss_scale=4, train_wall=33, gb_free=6.1, wall=59416
2021-04-05 17:08:04 | INFO | train_inner | epoch 038:   3081 / 4751 loss=4.535, nll_loss=2.932, ppl=7.63, wps=88550.9, ups=3.04, wpb=29106.8, bsz=944.9, num_updates=178800, lr=7.47853e-05, gnorm=0.456, loss_scale=4, train_wall=33, gb_free=6.2, wall=59449
2021-04-05 17:08:37 | INFO | train_inner | epoch 038:   3181 / 4751 loss=4.582, nll_loss=2.985, ppl=7.92, wps=88012.7, ups=3.06, wpb=28806.4, bsz=899.8, num_updates=178900, lr=7.47644e-05, gnorm=0.46, loss_scale=4, train_wall=33, gb_free=6.2, wall=59482
2021-04-05 17:09:10 | INFO | train_inner | epoch 038:   3281 / 4751 loss=4.537, nll_loss=2.934, ppl=7.64, wps=88201, ups=3.04, wpb=29046, bsz=954.6, num_updates=179000, lr=7.47435e-05, gnorm=0.455, loss_scale=4, train_wall=33, gb_free=6.3, wall=59515
2021-04-05 17:09:43 | INFO | train_inner | epoch 038:   3381 / 4751 loss=4.564, nll_loss=2.965, ppl=7.81, wps=87273.1, ups=3.02, wpb=28918.8, bsz=927.1, num_updates=179100, lr=7.47226e-05, gnorm=0.459, loss_scale=4, train_wall=33, gb_free=6.2, wall=59548
2021-04-05 17:10:16 | INFO | train_inner | epoch 038:   3481 / 4751 loss=4.558, nll_loss=2.959, ppl=7.77, wps=87940.2, ups=3.03, wpb=28981, bsz=997.9, num_updates=179200, lr=7.47018e-05, gnorm=0.469, loss_scale=4, train_wall=33, gb_free=6.4, wall=59581
2021-04-05 17:10:49 | INFO | train_inner | epoch 038:   3581 / 4751 loss=4.559, nll_loss=2.959, ppl=7.78, wps=88209.3, ups=3.03, wpb=29086, bsz=952.2, num_updates=179300, lr=7.4681e-05, gnorm=0.451, loss_scale=4, train_wall=33, gb_free=6.1, wall=59614
2021-04-05 17:11:22 | INFO | train_inner | epoch 038:   3681 / 4751 loss=4.493, nll_loss=2.885, ppl=7.39, wps=87424.6, ups=3.03, wpb=28856.8, bsz=955.7, num_updates=179400, lr=7.46601e-05, gnorm=0.452, loss_scale=4, train_wall=33, gb_free=6.5, wall=59647
2021-04-05 17:11:55 | INFO | train_inner | epoch 038:   3781 / 4751 loss=4.533, nll_loss=2.93, ppl=7.62, wps=87907.1, ups=3.03, wpb=29050.2, bsz=939.5, num_updates=179500, lr=7.46393e-05, gnorm=0.456, loss_scale=4, train_wall=33, gb_free=6.3, wall=59680
2021-04-05 17:12:28 | INFO | train_inner | epoch 038:   3881 / 4751 loss=4.602, nll_loss=3.008, ppl=8.04, wps=88532.3, ups=3.04, wpb=29107.4, bsz=957.4, num_updates=179600, lr=7.46186e-05, gnorm=0.46, loss_scale=4, train_wall=33, gb_free=6.4, wall=59713
2021-04-05 17:13:01 | INFO | train_inner | epoch 038:   3981 / 4751 loss=4.474, nll_loss=2.863, ppl=7.28, wps=88370.8, ups=3.03, wpb=29153.3, bsz=984.2, num_updates=179700, lr=7.45978e-05, gnorm=0.449, loss_scale=4, train_wall=33, gb_free=6.1, wall=59746
2021-04-05 17:13:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-05 17:13:35 | INFO | train_inner | epoch 038:   4082 / 4751 loss=4.51, nll_loss=2.904, ppl=7.48, wps=85509.9, ups=2.93, wpb=29166.3, bsz=947.8, num_updates=179800, lr=7.4577e-05, gnorm=0.46, loss_scale=2, train_wall=34, gb_free=6.2, wall=59780
2021-04-05 17:14:08 | INFO | train_inner | epoch 038:   4182 / 4751 loss=4.592, nll_loss=2.997, ppl=7.98, wps=87525.6, ups=3.04, wpb=28789.4, bsz=928.2, num_updates=179900, lr=7.45563e-05, gnorm=0.48, loss_scale=2, train_wall=33, gb_free=6.1, wall=59813
2021-04-05 17:14:41 | INFO | train_inner | epoch 038:   4282 / 4751 loss=4.598, nll_loss=3.003, ppl=8.02, wps=88276.2, ups=3.07, wpb=28757, bsz=918.4, num_updates=180000, lr=7.45356e-05, gnorm=0.463, loss_scale=2, train_wall=32, gb_free=6.2, wall=59845
2021-04-05 17:15:13 | INFO | train_inner | epoch 038:   4382 / 4751 loss=4.561, nll_loss=2.962, ppl=7.79, wps=89080, ups=3.05, wpb=29218.6, bsz=971.4, num_updates=180100, lr=7.45149e-05, gnorm=0.456, loss_scale=2, train_wall=33, gb_free=6.1, wall=59878
2021-04-05 17:15:46 | INFO | train_inner | epoch 038:   4482 / 4751 loss=4.562, nll_loss=2.962, ppl=7.79, wps=88614, ups=3.04, wpb=29117.2, bsz=945.7, num_updates=180200, lr=7.44942e-05, gnorm=0.46, loss_scale=2, train_wall=33, gb_free=5.9, wall=59911
2021-04-05 17:16:19 | INFO | train_inner | epoch 038:   4582 / 4751 loss=4.531, nll_loss=2.928, ppl=7.61, wps=87062, ups=3.01, wpb=28931.4, bsz=940.3, num_updates=180300, lr=7.44736e-05, gnorm=0.461, loss_scale=2, train_wall=33, gb_free=6.3, wall=59944
2021-04-05 17:16:52 | INFO | train_inner | epoch 038:   4682 / 4751 loss=4.581, nll_loss=2.984, ppl=7.91, wps=87886.1, ups=3.04, wpb=28865.7, bsz=916, num_updates=180400, lr=7.44529e-05, gnorm=0.471, loss_scale=2, train_wall=33, gb_free=6.4, wall=59977
2021-04-05 17:17:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-05 17:17:16 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 4.175 | nll_loss 2.41 | ppl 5.31 | wps 171649 | wpb 10489.1 | bsz 375 | num_updates 180469 | best_loss 4.175
2021-04-05 17:17:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 180469 updates
2021-04-05 17:17:16 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 17:17:22 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 17:17:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt (epoch 38 @ 180469 updates, score 4.175) (writing took 12.782995775341988 seconds)
2021-04-05 17:17:29 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2021-04-05 17:17:29 | INFO | train | epoch 038 | loss 4.55 | nll_loss 2.948 | ppl 7.72 | wps 87119.6 | ups 3.01 | wpb 28969 | bsz 946.7 | num_updates 180469 | lr 7.44387e-05 | gnorm 0.458 | loss_scale 2 | train_wall 1557 | gb_free 6.3 | wall 60014
2021-04-05 17:17:29 | INFO | fairseq.trainer | begin training epoch 39
2021-04-05 17:17:29 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-05 17:17:40 | INFO | train_inner | epoch 039:     31 / 4751 loss=4.54, nll_loss=2.937, ppl=7.66, wps=60416.9, ups=2.08, wpb=29064.5, bsz=931.5, num_updates=180500, lr=7.44323e-05, gnorm=0.453, loss_scale=2, train_wall=33, gb_free=6.2, wall=60025
2021-04-05 17:18:13 | INFO | train_inner | epoch 039:    131 / 4751 loss=4.56, nll_loss=2.959, ppl=7.78, wps=88183.1, ups=3.06, wpb=28843.2, bsz=913.5, num_updates=180600, lr=7.44117e-05, gnorm=0.464, loss_scale=2, train_wall=33, gb_free=6.2, wall=60058
2021-04-05 17:18:46 | INFO | train_inner | epoch 039:    231 / 4751 loss=4.527, nll_loss=2.923, ppl=7.58, wps=88162.5, ups=3.03, wpb=29085.7, bsz=958.6, num_updates=180700, lr=7.43911e-05, gnorm=0.459, loss_scale=2, train_wall=33, gb_free=6.2, wall=60091
2021-04-05 17:19:19 | INFO | train_inner | epoch 039:    331 / 4751 loss=4.505, nll_loss=2.897, ppl=7.45, wps=87568.7, ups=3.03, wpb=28920.9, bsz=935, num_updates=180800, lr=7.43705e-05, gnorm=0.456, loss_scale=2, train_wall=33, gb_free=6.3, wall=60124
2021-04-05 17:19:52 | INFO | train_inner | epoch 039:    431 / 4751 loss=4.542, nll_loss=2.94, ppl=7.67, wps=87994.3, ups=3.04, wpb=28982.4, bsz=937.7, num_updates=180900, lr=7.435e-05, gnorm=0.46, loss_scale=2, train_wall=33, gb_free=6.2, wall=60157
2021-04-05 17:20:25 | INFO | train_inner | epoch 039:    531 / 4751 loss=4.481, nll_loss=2.87, ppl=7.31, wps=89188.8, ups=3.03, wpb=29392.2, bsz=975.4, num_updates=181000, lr=7.43294e-05, gnorm=0.448, loss_scale=2, train_wall=33, gb_free=6.2, wall=60190
2021-04-05 17:20:58 | INFO | train_inner | epoch 039:    631 / 4751 loss=4.544, nll_loss=2.942, ppl=7.68, wps=87128.8, ups=3.04, wpb=28618, bsz=926.9, num_updates=181100, lr=7.43089e-05, gnorm=0.465, loss_scale=2, train_wall=33, gb_free=6.1, wall=60223
2021-04-05 17:21:31 | INFO | train_inner | epoch 039:    731 / 4751 loss=4.549, nll_loss=2.946, ppl=7.71, wps=87602.6, ups=3.05, wpb=28734.2, bsz=936.8, num_updates=181200, lr=7.42884e-05, gnorm=0.457, loss_scale=2, train_wall=33, gb_free=6.3, wall=60255
2021-04-05 17:22:03 | INFO | train_inner | epoch 039:    831 / 4751 loss=4.526, nll_loss=2.922, ppl=7.58, wps=88309.9, ups=3.04, wpb=29003.5, bsz=955.6, num_updates=181300, lr=7.42679e-05, gnorm=0.461, loss_scale=2, train_wall=33, gb_free=6.4, wall=60288
2021-04-05 17:22:36 | INFO | train_inner | epoch 039:    931 / 4751 loss=4.552, nll_loss=2.951, ppl=7.73, wps=88199.8, ups=3.05, wpb=28913.8, bsz=966.5, num_updates=181400, lr=7.42474e-05, gnorm=0.467, loss_scale=2, train_wall=33, gb_free=6.2, wall=60321
2021-04-05 17:23:09 | INFO | train_inner | epoch 039:   1031 / 4751 loss=4.573, nll_loss=2.974, ppl=7.86, wps=87349.1, ups=3.05, wpb=28678.2, bsz=923.5, num_updates=181500, lr=7.4227e-05, gnorm=0.463, loss_scale=2, train_wall=33, gb_free=6.1, wall=60354
2021-04-05 17:23:42 | INFO | train_inner | epoch 039:   1131 / 4751 loss=4.541, nll_loss=2.939, ppl=7.67, wps=88107.3, ups=3.05, wpb=28926.7, bsz=957.8, num_updates=181600, lr=7.42065e-05, gnorm=0.457, loss_scale=2, train_wall=33, gb_free=6.4, wall=60387
2021-04-05 17:24:15 | INFO | train_inner | epoch 039:   1231 / 4751 loss=4.542, nll_loss=2.939, ppl=7.67, wps=88212, ups=3.05, wpb=28936.9, bsz=965.4, num_updates=181700, lr=7.41861e-05, gnorm=0.462, loss_scale=2, train_wall=33, gb_free=6.1, wall=60420
2021-04-05 17:24:48 | INFO | train_inner | epoch 039:   1331 / 4751 loss=4.546, nll_loss=2.944, ppl=7.69, wps=88224.3, ups=3.04, wpb=29006.7, bsz=925.8, num_updates=181800, lr=7.41657e-05, gnorm=0.452, loss_scale=2, train_wall=33, gb_free=6.1, wall=60452
2021-04-05 17:25:20 | INFO | train_inner | epoch 039:   1431 / 4751 loss=4.55, nll_loss=2.949, ppl=7.72, wps=87948.1, ups=3.04, wpb=28918.8, bsz=953.3, num_updates=181900, lr=7.41453e-05, gnorm=0.453, loss_scale=4, train_wall=33, gb_free=6.4, wall=60485
2021-04-05 17:25:54 | INFO | train_inner | epoch 039:   1531 / 4751 loss=4.601, nll_loss=3.006, ppl=8.03, wps=86760.8, ups=3.01, wpb=28792.9, bsz=930.1, num_updates=182000, lr=7.41249e-05, gnorm=0.458, loss_scale=4, train_wall=33, gb_free=6.5, wall=60518
2021-04-05 17:26:27 | INFO | train_inner | epoch 039:   1631 / 4751 loss=4.519, nll_loss=2.913, ppl=7.53, wps=87865.8, ups=3.03, wpb=29012.7, bsz=953, num_updates=182100, lr=7.41046e-05, gnorm=0.461, loss_scale=4, train_wall=33, gb_free=6.3, wall=60551
2021-04-05 17:27:00 | INFO | train_inner | epoch 039:   1731 / 4751 loss=4.575, nll_loss=2.977, ppl=7.88, wps=87415, ups=3.04, wpb=28710.2, bsz=932.6, num_updates=182200, lr=7.40842e-05, gnorm=0.462, loss_scale=4, train_wall=33, gb_free=6.4, wall=60584
2021-04-05 17:27:32 | INFO | train_inner | epoch 039:   1831 / 4751 loss=4.55, nll_loss=2.949, ppl=7.72, wps=87603.7, ups=3.03, wpb=28887.2, bsz=920.2, num_updates=182300, lr=7.40639e-05, gnorm=0.452, loss_scale=4, train_wall=33, gb_free=6.2, wall=60617
2021-04-05 17:28:06 | INFO | train_inner | epoch 039:   1931 / 4751 loss=4.571, nll_loss=2.973, ppl=7.85, wps=88111.8, ups=3.02, wpb=29140, bsz=928.4, num_updates=182400, lr=7.40436e-05, gnorm=0.455, loss_scale=4, train_wall=33, gb_free=6.2, wall=60650
2021-04-05 17:28:39 | INFO | train_inner | epoch 039:   2031 / 4751 loss=4.523, nll_loss=2.918, ppl=7.56, wps=87126.2, ups=3.03, wpb=28710.8, bsz=928, num_updates=182500, lr=7.40233e-05, gnorm=0.456, loss_scale=4, train_wall=33, gb_free=6.3, wall=60683
2021-04-05 17:29:11 | INFO | train_inner | epoch 039:   2131 / 4751 loss=4.574, nll_loss=2.976, ppl=7.87, wps=87992, ups=3.04, wpb=28915.1, bsz=924.2, num_updates=182600, lr=7.4003e-05, gnorm=0.462, loss_scale=4, train_wall=33, gb_free=6.2, wall=60716
2021-04-05 17:29:44 | INFO | train_inner | epoch 039:   2231 / 4751 loss=4.554, nll_loss=2.953, ppl=7.74, wps=88868.6, ups=3.06, wpb=29055.8, bsz=916.6, num_updates=182700, lr=7.39828e-05, gnorm=0.455, loss_scale=4, train_wall=33, gb_free=6.1, wall=60749
2021-04-05 17:30:17 | INFO | train_inner | epoch 039:   2331 / 4751 loss=4.574, nll_loss=2.976, ppl=7.87, wps=88404.5, ups=3.05, wpb=29029.1, bsz=968.6, num_updates=182800, lr=7.39626e-05, gnorm=0.465, loss_scale=4, train_wall=33, gb_free=6.4, wall=60782
2021-04-05 17:30:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-05 17:30:50 | INFO | train_inner | epoch 039:   2432 / 4751 loss=4.553, nll_loss=2.952, ppl=7.74, wps=87027.7, ups=3.01, wpb=28946.4, bsz=955.9, num_updates=182900, lr=7.39423e-05, gnorm=0.455, loss_scale=2, train_wall=33, gb_free=6.2, wall=60815
2021-04-05 17:31:23 | INFO | train_inner | epoch 039:   2532 / 4751 loss=4.523, nll_loss=2.918, ppl=7.56, wps=88223, ups=3.04, wpb=29010.5, bsz=986.7, num_updates=183000, lr=7.39221e-05, gnorm=0.454, loss_scale=2, train_wall=33, gb_free=5.8, wall=60848
2021-04-05 17:31:57 | INFO | train_inner | epoch 039:   2632 / 4751 loss=4.508, nll_loss=2.902, ppl=7.47, wps=86385, ups=2.96, wpb=29230.4, bsz=954.3, num_updates=183100, lr=7.39019e-05, gnorm=0.457, loss_scale=2, train_wall=34, gb_free=6.1, wall=60882
2021-04-05 17:32:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-04-05 17:32:30 | INFO | train_inner | epoch 039:   2733 / 4751 loss=4.537, nll_loss=2.934, ppl=7.64, wps=87282.1, ups=3, wpb=29089, bsz=945.3, num_updates=183200, lr=7.38818e-05, gnorm=0.456, loss_scale=1, train_wall=33, gb_free=6.3, wall=60915
2021-04-05 17:33:03 | INFO | train_inner | epoch 039:   2833 / 4751 loss=4.543, nll_loss=2.94, ppl=7.68, wps=88699, ups=3.04, wpb=29189, bsz=950.5, num_updates=183300, lr=7.38616e-05, gnorm=0.456, loss_scale=1, train_wall=33, gb_free=6.2, wall=60948
2021-04-05 17:33:36 | INFO | train_inner | epoch 039:   2933 / 4751 loss=4.622, nll_loss=3.03, ppl=8.17, wps=87327.9, ups=3.05, wpb=28658.4, bsz=897, num_updates=183400, lr=7.38415e-05, gnorm=0.463, loss_scale=1, train_wall=33, gb_free=6.4, wall=60981
2021-04-05 17:34:09 | INFO | train_inner | epoch 039:   3033 / 4751 loss=4.517, nll_loss=2.912, ppl=7.52, wps=88800.6, ups=3.03, wpb=29330.6, bsz=965, num_updates=183500, lr=7.38213e-05, gnorm=0.455, loss_scale=1, train_wall=33, gb_free=6.2, wall=61014
2021-04-05 17:34:42 | INFO | train_inner | epoch 039:   3133 / 4751 loss=4.544, nll_loss=2.942, ppl=7.69, wps=88653.4, ups=3.05, wpb=29108.1, bsz=939.3, num_updates=183600, lr=7.38012e-05, gnorm=0.456, loss_scale=1, train_wall=33, gb_free=6.2, wall=61047
2021-04-05 17:35:15 | INFO | train_inner | epoch 039:   3233 / 4751 loss=4.528, nll_loss=2.924, ppl=7.59, wps=87523.8, ups=3.03, wpb=28877.4, bsz=939.9, num_updates=183700, lr=7.37812e-05, gnorm=0.455, loss_scale=1, train_wall=33, gb_free=6.2, wall=61080
2021-04-05 17:35:48 | INFO | train_inner | epoch 039:   3333 / 4751 loss=4.484, nll_loss=2.874, ppl=7.33, wps=88708.9, ups=3.04, wpb=29193.7, bsz=982.1, num_updates=183800, lr=7.37611e-05, gnorm=0.452, loss_scale=1, train_wall=33, gb_free=6.2, wall=61113
2021-04-05 17:36:21 | INFO | train_inner | epoch 039:   3433 / 4751 loss=4.587, nll_loss=2.992, ppl=7.96, wps=88132.4, ups=3.05, wpb=28940, bsz=979.6, num_updates=183900, lr=7.3741e-05, gnorm=0.461, loss_scale=1, train_wall=33, gb_free=6.4, wall=61145
2021-04-05 17:36:54 | INFO | train_inner | epoch 039:   3533 / 4751 loss=4.539, nll_loss=2.936, ppl=7.65, wps=87966.7, ups=3.02, wpb=29160.7, bsz=964.6, num_updates=184000, lr=7.3721e-05, gnorm=0.456, loss_scale=1, train_wall=33, gb_free=6.1, wall=61179
2021-04-05 17:37:26 | INFO | train_inner | epoch 039:   3633 / 4751 loss=4.522, nll_loss=2.918, ppl=7.56, wps=87822.1, ups=3.05, wpb=28782.7, bsz=962.1, num_updates=184100, lr=7.3701e-05, gnorm=0.456, loss_scale=1, train_wall=33, gb_free=6.1, wall=61211
2021-04-05 17:38:00 | INFO | train_inner | epoch 039:   3733 / 4751 loss=4.558, nll_loss=2.958, ppl=7.77, wps=87280.2, ups=3.02, wpb=28943.7, bsz=969.8, num_updates=184200, lr=7.36809e-05, gnorm=0.488, loss_scale=1, train_wall=33, gb_free=6.1, wall=61244
2021-04-05 17:38:33 | INFO | train_inner | epoch 039:   3833 / 4751 loss=4.538, nll_loss=2.935, ppl=7.65, wps=86735, ups=3.03, wpb=28645.4, bsz=957.4, num_updates=184300, lr=7.3661e-05, gnorm=0.464, loss_scale=1, train_wall=33, gb_free=5.9, wall=61277
2021-04-05 17:39:06 | INFO | train_inner | epoch 039:   3933 / 4751 loss=4.541, nll_loss=2.94, ppl=7.67, wps=87932.7, ups=3.04, wpb=28934.5, bsz=945.4, num_updates=184400, lr=7.3641e-05, gnorm=0.46, loss_scale=1, train_wall=33, gb_free=6.3, wall=61310
2021-04-05 17:39:38 | INFO | train_inner | epoch 039:   4033 / 4751 loss=4.561, nll_loss=2.962, ppl=7.79, wps=87530.9, ups=3.04, wpb=28768.6, bsz=944, num_updates=184500, lr=7.3621e-05, gnorm=0.457, loss_scale=1, train_wall=33, gb_free=6.7, wall=61343
2021-04-05 17:40:11 | INFO | train_inner | epoch 039:   4133 / 4751 loss=4.557, nll_loss=2.957, ppl=7.76, wps=88755.6, ups=3.05, wpb=29113.2, bsz=971.4, num_updates=184600, lr=7.36011e-05, gnorm=0.463, loss_scale=1, train_wall=33, gb_free=6, wall=61376
2021-04-05 17:40:44 | INFO | train_inner | epoch 039:   4233 / 4751 loss=4.568, nll_loss=2.97, ppl=7.83, wps=88127.9, ups=3.05, wpb=28887.7, bsz=972.6, num_updates=184700, lr=7.35811e-05, gnorm=0.464, loss_scale=1, train_wall=33, gb_free=6.3, wall=61409
2021-04-05 17:41:17 | INFO | train_inner | epoch 039:   4333 / 4751 loss=4.548, nll_loss=2.947, ppl=7.71, wps=89094.8, ups=3.06, wpb=29130.7, bsz=905.4, num_updates=184800, lr=7.35612e-05, gnorm=0.453, loss_scale=1, train_wall=33, gb_free=6.3, wall=61442
2021-04-05 17:41:49 | INFO | train_inner | epoch 039:   4433 / 4751 loss=4.551, nll_loss=2.951, ppl=7.73, wps=89084.9, ups=3.06, wpb=29156, bsz=986.6, num_updates=184900, lr=7.35413e-05, gnorm=0.465, loss_scale=1, train_wall=33, gb_free=6.1, wall=61474
2021-04-05 17:42:22 | INFO | train_inner | epoch 039:   4533 / 4751 loss=4.563, nll_loss=2.964, ppl=7.8, wps=88951.6, ups=3.05, wpb=29203.9, bsz=956.8, num_updates=185000, lr=7.35215e-05, gnorm=0.455, loss_scale=1, train_wall=33, gb_free=6.2, wall=61507
2021-04-05 17:42:55 | INFO | train_inner | epoch 039:   4633 / 4751 loss=4.517, nll_loss=2.912, ppl=7.52, wps=87564.2, ups=3.03, wpb=28883.6, bsz=940.2, num_updates=185100, lr=7.35016e-05, gnorm=0.451, loss_scale=1, train_wall=33, gb_free=6.2, wall=61540
2021-04-05 17:43:28 | INFO | train_inner | epoch 039:   4733 / 4751 loss=4.609, nll_loss=3.016, ppl=8.09, wps=89136.3, ups=3.06, wpb=29149.9, bsz=918.6, num_updates=185200, lr=7.34818e-05, gnorm=0.461, loss_scale=1, train_wall=33, gb_free=6.3, wall=61573
2021-04-05 17:43:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-05 17:43:35 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 4.178 | nll_loss 2.408 | ppl 5.31 | wps 199868 | wpb 10489.1 | bsz 375 | num_updates 185218 | best_loss 4.175
2021-04-05 17:43:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 185218 updates
2021-04-05 17:43:35 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-05 17:43:42 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-05 17:43:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt (epoch 39 @ 185218 updates, score 4.178) (writing took 6.588003948330879 seconds)
2021-04-05 17:43:42 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2021-04-05 17:43:42 | INFO | train | epoch 039 | loss 4.547 | nll_loss 2.945 | ppl 7.7 | wps 87467.9 | ups 3.02 | wpb 28967.7 | bsz 947 | num_updates 185218 | lr 7.34782e-05 | gnorm 0.459 | loss_scale 1 | train_wall 1557 | gb_free 6.2 | wall 61586
2021-04-05 17:43:42 | INFO | fairseq.trainer | begin training epoch 40
2021-04-05 17:43:42 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-05 17:44:10 | INFO | train_inner | epoch 040:     82 / 4751 loss=4.541, nll_loss=2.938, ppl=7.67, wps=69020.2, ups=2.39, wpb=28819, bsz=924, num_updates=185300, lr=7.34619e-05, gnorm=0.46, loss_scale=2, train_wall=33, gb_free=6.3, wall=61615
2021-04-05 17:44:43 | INFO | train_inner | epoch 040:    182 / 4751 loss=4.519, nll_loss=2.913, ppl=7.53, wps=88415.2, ups=3.03, wpb=29142.2, bsz=945.2, num_updates=185400, lr=7.34421e-05, gnorm=0.459, loss_scale=2, train_wall=33, gb_free=6.5, wall=61648
2021-04-05 17:45:16 | INFO | train_inner | epoch 040:    282 / 4751 loss=4.531, nll_loss=2.927, ppl=7.61, wps=88042, ups=3.03, wpb=29056.2, bsz=913.1, num_updates=185500, lr=7.34223e-05, gnorm=0.469, loss_scale=2, train_wall=33, gb_free=6.2, wall=61681
2021-04-05 17:45:49 | INFO | train_inner | epoch 040:    382 / 4751 loss=4.561, nll_loss=2.96, ppl=7.78, wps=87531.9, ups=3.02, wpb=28960.3, bsz=921.3, num_updates=185600, lr=7.34025e-05, gnorm=0.457, loss_scale=2, train_wall=33, gb_free=6, wall=61714
2021-04-05 17:46:22 | INFO | train_inner | epoch 040:    482 / 4751 loss=4.517, nll_loss=2.912, ppl=7.53, wps=88643.3, ups=3.04, wpb=29127.9, bsz=977.3, num_updates=185700, lr=7.33828e-05, gnorm=0.455, loss_scale=2, train_wall=33, gb_free=6.1, wall=61746
2021-04-05 17:46:55 | INFO | train_inner | epoch 040:    582 / 4751 loss=4.556, nll_loss=2.955, ppl=7.75, wps=87921.2, ups=3.04, wpb=28914.3, bsz=923.3, num_updates=185800, lr=7.3363e-05, gnorm=0.459, loss_scale=2, train_wall=33, gb_free=6.1, wall=61779
2021-04-05 17:47:28 | INFO | train_inner | epoch 040:    682 / 4751 loss=4.456, nll_loss=2.842, ppl=7.17, wps=87236.2, ups=3, wpb=29031.7, bsz=1008.1, num_updates=185900, lr=7.33433e-05, gnorm=0.462, loss_scale=2, train_wall=33, gb_free=6.3, wall=61813
2021-04-05 17:48:01 | INFO | train_inner | epoch 040:    782 / 4751 loss=4.531, nll_loss=2.927, ppl=7.61, wps=87931.1, ups=3.04, wpb=28920.1, bsz=943, num_updates=186000, lr=7.33236e-05, gnorm=0.46, loss_scale=2, train_wall=33, gb_free=6, wall=61846
2021-04-05 17:48:34 | INFO | train_inner | epoch 040:    882 / 4751 loss=4.524, nll_loss=2.919, ppl=7.56, wps=87706.4, ups=3.03, wpb=28951.6, bsz=920.2, num_updates=186100, lr=7.33039e-05, gnorm=0.458, loss_scale=2, train_wall=33, gb_free=5.9, wall=61879
2021-04-05 17:49:07 | INFO | train_inner | epoch 040:    982 / 4751 loss=4.553, nll_loss=2.952, ppl=7.74, wps=88145.8, ups=3.03, wpb=29065.8, bsz=959.9, num_updates=186200, lr=7.32842e-05, gnorm=0.458, loss_scale=2, train_wall=33, gb_free=6.3, wall=61911
2021-04-05 17:49:39 | INFO | train_inner | epoch 040:   1082 / 4751 loss=4.538, nll_loss=2.935, ppl=7.65, wps=87735.8, ups=3.05, wpb=28761, bsz=981.3, num_updates=186300, lr=7.32645e-05, gnorm=0.475, loss_scale=2, train_wall=33, gb_free=6.4, wall=61944
2021-04-05 17:50:13 | INFO | train_inner | epoch 040:   1182 / 4751 loss=4.547, nll_loss=2.946, ppl=7.71, wps=87341.5, ups=3.02, wpb=28885.9, bsz=955.5, num_updates=186400, lr=7.32448e-05, gnorm=0.456, loss_scale=2, train_wall=33, gb_free=6.4, wall=61977
2021-04-05 17:50:46 | INFO | train_inner | epoch 040:   1282 / 4751 loss=4.507, nll_loss=2.9, ppl=7.46, wps=87549.4, ups=3.02, wpb=28967.2, bsz=939.9, num_updates=186500, lr=7.32252e-05, gnorm=0.464, loss_scale=2, train_wall=33, gb_free=6.3, wall=62010
2021-04-05 17:51:18 | INFO | train_inner | epoch 040:   1382 / 4751 loss=4.583, nll_loss=2.986, ppl=7.92, wps=88493.7, ups=3.06, wpb=28934.6, bsz=923, num_updates=186600, lr=7.32056e-05, gnorm=0.469, loss_scale=2, train_wall=33, gb_free=6.2, wall=62043
2021-04-05 17:51:51 | INFO | train_inner | epoch 040:   1482 / 4751 loss=4.557, nll_loss=2.957, ppl=7.76, wps=88098.8, ups=3.04, wpb=28951.3, bsz=959.1, num_updates=186700, lr=7.3186e-05, gnorm=0.458, loss_scale=2, train_wall=33, gb_free=6.5, wall=62076
2021-04-05 17:52:24 | INFO | train_inner | epoch 040:   1582 / 4751 loss=4.49, nll_loss=2.881, ppl=7.37, wps=88381.8, ups=3.02, wpb=29240, bsz=966.2, num_updates=186800, lr=7.31664e-05, gnorm=0.452, loss_scale=2, train_wall=33, gb_free=6.2, wall=62109
2021-04-05 17:52:57 | INFO | train_inner | epoch 040:   1682 / 4751 loss=4.501, nll_loss=2.893, ppl=7.43, wps=87898.9, ups=3.05, wpb=28862.5, bsz=961.7, num_updates=186900, lr=7.31468e-05, gnorm=0.457, loss_scale=2, train_wall=33, gb_free=6.2, wall=62142
2021-04-05 17:53:30 | INFO | train_inner | epoch 040:   1782 / 4751 loss=4.582, nll_loss=2.986, ppl=7.92, wps=87891.9, ups=3.05, wpb=28815.8, bsz=938.3, num_updates=187000, lr=7.31272e-05, gnorm=0.47, loss_scale=2, train_wall=33, gb_free=6.1, wall=62175
2021-04-05 17:54:03 | INFO | train_inner | epoch 040:   1882 / 4751 loss=4.536, nll_loss=2.933, ppl=7.64, wps=87726.6, ups=3.01, wpb=29139.2, bsz=971.4, num_updates=187100, lr=7.31077e-05, gnorm=0.453, loss_scale=2, train_wall=33, gb_free=6, wall=62208
2021-04-05 17:54:36 | INFO | train_inner | epoch 040:   1982 / 4751 loss=4.585, nll_loss=2.989, ppl=7.94, wps=88098.5, ups=3.05, wpb=28842.8, bsz=966.5, num_updates=187200, lr=7.30882e-05, gnorm=0.467, loss_scale=2, train_wall=33, gb_free=6.1, wall=62241
2021-04-05 17:55:09 | INFO | train_inner | epoch 040:   2082 / 4751 loss=4.536, nll_loss=2.934, ppl=7.64, wps=87334.2, ups=3.01, wpb=28968.1, bsz=980, num_updates=187300, lr=7.30687e-05, gnorm=0.475, loss_scale=4, train_wall=33, gb_free=6.4, wall=62274
2021-04-05 17:55:42 | INFO | train_inner | epoch 040:   2182 / 4751 loss=4.517, nll_loss=2.912, ppl=7.52, wps=88376.5, ups=3.03, wpb=29169, bsz=980.4, num_updates=187400, lr=7.30492e-05, gnorm=0.454, loss_scale=4, train_wall=33, gb_free=6.2, wall=62307
2021-04-05 17:55:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-05 17:56:15 | INFO | train_inner | epoch 040:   2283 / 4751 loss=4.512, nll_loss=2.906, ppl=7.49, wps=87083.9, ups=2.99, wpb=29116.2, bsz=934.2, num_updates=187500, lr=7.30297e-05, gnorm=0.458, loss_scale=2, train_wall=33, gb_free=6.4, wall=62340
2021-04-05 17:56:48 | INFO | train_inner | epoch 040:   2383 / 4751 loss=4.557, nll_loss=2.957, ppl=7.76, wps=88385.6, ups=3.03, wpb=29134.8, bsz=965.9, num_updates=187600, lr=7.30102e-05, gnorm=0.46, loss_scale=2, train_wall=33, gb_free=6.2, wall=62373
2021-04-05 17:57:21 | INFO | train_inner | epoch 040:   2483 / 4751 loss=4.547, nll_loss=2.945, ppl=7.7, wps=88968.1, ups=3.04, wpb=29261.1, bsz=931.4, num_updates=187700, lr=7.29908e-05, gnorm=0.458, loss_scale=2, train_wall=33, gb_free=6.2, wall=62406
2021-04-05 17:57:54 | INFO | train_inner | epoch 040:   2583 / 4751 loss=4.522, nll_loss=2.917, ppl=7.55, wps=87469, ups=3.03, wpb=28872.5, bsz=960.3, num_updates=187800, lr=7.29713e-05, gnorm=0.457, loss_scale=2, train_wall=33, gb_free=6.2, wall=62439
2021-04-05 17:58:27 | INFO | train_inner | epoch 040:   2683 / 4751 loss=4.571, nll_loss=2.973, ppl=7.85, wps=88023.9, ups=3.05, wpb=28864.4, bsz=931.9, num_updates=187900, lr=7.29519e-05, gnorm=0.468, loss_scale=2, train_wall=33, gb_free=6.1, wall=62472
2021-04-05 17:59:00 | INFO | train_inner | epoch 040:   2783 / 4751 loss=4.561, nll_loss=2.962, ppl=7.79, wps=87528.3, ups=3.03, wpb=28854.1, bsz=941, num_updates=188000, lr=7.29325e-05, gnorm=0.462, loss_scale=2, train_wall=33, gb_free=6.6, wall=62505
2021-04-05 17:59:33 | INFO | train_inner | epoch 040:   2883 / 4751 loss=4.562, nll_loss=2.962, ppl=7.79, wps=87348.5, ups=3.03, wpb=28838.7, bsz=945.7, num_updates=188100, lr=7.29131e-05, gnorm=0.467, loss_scale=2, train_wall=33, gb_free=6.3, wall=62538
2021-04-05 18:00:06 | INFO | train_inner | epoch 040:   2983 / 4751 loss=4.549, nll_loss=2.948, ppl=7.72, wps=87873.6, ups=3.05, wpb=28787, bsz=929.3, num_updates=188200, lr=7.28937e-05, gnorm=0.464, loss_scale=2, train_wall=33, gb_free=6.1, wall=62571
2021-04-05 18:00:39 | INFO | train_inner | epoch 040:   3083 / 4751 loss=4.564, nll_loss=2.965, ppl=7.81, wps=88797.3, ups=3.05, wpb=29142.4, bsz=941.6, num_updates=188300, lr=7.28744e-05, gnorm=0.458, loss_scale=2, train_wall=33, gb_free=6.2, wall=62603
2021-04-05 18:01:11 | INFO | train_inner | epoch 040:   3183 / 4751 loss=4.582, nll_loss=2.985, ppl=7.92, wps=88013.3, ups=3.06, wpb=28783, bsz=939.8, num_updates=188400, lr=7.2855e-05, gnorm=0.466, loss_scale=2, train_wall=33, gb_free=6.4, wall=62636
2021-04-05 18:01:44 | INFO | train_inner | epoch 040:   3283 / 4751 loss=4.566, nll_loss=2.967, ppl=7.82, wps=88021, ups=3.04, wpb=28965.8, bsz=928.6, num_updates=188500, lr=7.28357e-05, gnorm=0.46, loss_scale=2, train_wall=33, gb_free=6, wall=62669
2021-04-05 18:02:17 | INFO | train_inner | epoch 040:   3383 / 4751 loss=4.499, nll_loss=2.891, ppl=7.42, wps=88929.1, ups=3.04, wpb=29270.3, bsz=934.9, num_updates=188600, lr=7.28164e-05, gnorm=0.449, loss_scale=2, train_wall=33, gb_free=6.7, wall=62702
2021-04-05 18:02:50 | INFO | train_inner | epoch 040:   3483 / 4751 loss=4.572, nll_loss=2.974, ppl=7.85, wps=88661.9, ups=3.05, wpb=29073.3, bsz=930.2, num_updates=188700, lr=7.27971e-05, gnorm=0.46, loss_scale=2, train_wall=33, gb_free=6.2, wall=62735
2021-04-05 18:03:23 | INFO | train_inner | epoch 040:   3583 / 4751 loss=4.516, nll_loss=2.911, ppl=7.52, wps=87659.2, ups=3.03, wpb=28897.3, bsz=955.2, num_updates=188800, lr=7.27778e-05, gnorm=0.453, loss_scale=2, train_wall=33, gb_free=6.3, wall=62768
2021-04-05 18:03:56 | INFO | train_inner | epoch 040:   3683 / 4751 loss=4.542, nll_loss=2.94, ppl=7.67, wps=87836, ups=3.03, wpb=28952.1, bsz=933.8, num_updates=188900, lr=7.27585e-05, gnorm=0.459, loss_scale=2, train_wall=33, gb_free=6.2, wall=62801
2021-04-05 18:04:29 | INFO | train_inner | epoch 040:   3783 / 4751 loss=4.543, nll_loss=2.942, ppl=7.69, wps=87579.2, ups=3.03, wpb=28858.5, bsz=957.8, num_updates=189000, lr=7.27393e-05, gnorm=0.475, loss_scale=2, train_wall=33, gb_free=6.4, wall=62834
2021-04-05 18:05:02 | INFO | train_inner | epoch 040:   3883 / 4751 loss=4.484, nll_loss=2.875, ppl=7.33, wps=89127.1, ups=3.04, wpb=29343, bsz=957.9, num_updates=189100, lr=7.27201e-05, gnorm=0.448, loss_scale=2, train_wall=33, gb_free=6.3, wall=62867
2021-04-05 18:05:35 | INFO | train_inner | epoch 040:   3983 / 4751 loss=4.54, nll_loss=2.938, ppl=7.66, wps=87262.2, ups=3.04, wpb=28674.1, bsz=960.6, num_updates=189200, lr=7.27008e-05, gnorm=0.466, loss_scale=2, train_wall=33, gb_free=6.2, wall=62899
2021-04-05 18:06:07 | INFO | train_inner | epoch 040:   4083 / 4751 loss=4.606, nll_loss=3.012, ppl=8.07, wps=86988.3, ups=3.04, wpb=28579.1, bsz=898, num_updates=189300, lr=7.26816e-05, gnorm=0.47, loss_scale=2, train_wall=33, gb_free=6.3, wall=62932
2021-04-05 18:06:41 | INFO | train_inner | epoch 040:   4183 / 4751 loss=4.569, nll_loss=2.971, ppl=7.84, wps=88596.5, ups=3.03, wpb=29279.8, bsz=937.2, num_updates=189400, lr=7.26624e-05, gnorm=0.451, loss_scale=2, train_wall=33, gb_free=6, wall=62965
2021-04-05 18:07:13 | INFO | train_inner | epoch 040:   4283 / 4751 loss=4.584, nll_loss=2.988, ppl=7.93, wps=87644.2, ups=3.05, wpb=28715.8, bsz=944.8, num_updates=189500, lr=7.26433e-05, gnorm=0.463, loss_scale=4, train_wall=33, gb_free=6.2, wall=62998
2021-04-05 18:07:47 | INFO | train_inner | epoch 040:   4383 / 4751 loss=4.549, nll_loss=2.948, ppl=7.72, wps=85343.4, ups=2.96, wpb=28816, bsz=953.4, num_updates=189600, lr=7.26241e-05, gnorm=0.466, loss_scale=4, train_wall=34, gb_free=6.1, wall=63032
2021-04-05 18:08:20 | INFO | train_inner | epoch 040:   4483 / 4751 loss=4.538, nll_loss=2.936, ppl=7.65, wps=88160, ups=3.03, wpb=29084.5, bsz=974.2, num_updates=189700, lr=7.2605e-05, gnorm=0.455, loss_scale=4, train_wall=33, gb_free=6.6, wall=63065
2021-04-05 18:08:53 | INFO | train_inner | epoch 040:   4583 / 4751 loss=4.518, nll_loss=2.913, ppl=7.53, wps=88322.4, ups=3.05, wpb=28984, bsz=949.4, num_updates=189800, lr=7.25858e-05, gnorm=0.45, loss_scale=4, train_wall=33, gb_free=6.1, wall=63098
2021-04-05 18:09:26 | INFO | train_inner | epoch 040:   4683 / 4751 loss=4.604, nll_loss=3.01, ppl=8.05, wps=88306.8, ups=3.06, wpb=28900.8, bsz=914, num_updates=189900, lr=7.25667e-05, gnorm=0.466, loss_scale=4, train_wall=33, gb_free=6.1, wall=63130
2021-04-05 18:09:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-05 18:09:49 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 4.164 | nll_loss 2.394 | ppl 5.26 | wps 200097 | wpb 10489.1 | bsz 375 | num_updates 189968 | best_loss 4.164
2021-04-05 18:09:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 189968 updates
2021-04-05 18:09:49 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 18:09:55 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 18:10:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt (epoch 40 @ 189968 updates, score 4.164) (writing took 12.743224445730448 seconds)
2021-04-05 18:10:02 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2021-04-05 18:10:02 | INFO | train | epoch 040 | loss 4.544 | nll_loss 2.942 | ppl 7.68 | wps 87073.7 | ups 3.01 | wpb 28968 | bsz 946.9 | num_updates 189968 | lr 7.25537e-05 | gnorm 0.461 | loss_scale 4 | train_wall 1558 | gb_free 6.7 | wall 63167
2021-04-05 18:10:02 | INFO | fairseq.trainer | begin training epoch 41
2021-04-05 18:10:02 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-05 18:10:14 | INFO | train_inner | epoch 041:     32 / 4751 loss=4.544, nll_loss=2.942, ppl=7.69, wps=60400.6, ups=2.08, wpb=29023.3, bsz=947.4, num_updates=190000, lr=7.25476e-05, gnorm=0.462, loss_scale=4, train_wall=33, gb_free=6, wall=63178
2021-04-05 18:10:47 | INFO | train_inner | epoch 041:    132 / 4751 loss=4.534, nll_loss=2.931, ppl=7.63, wps=88843.3, ups=3.04, wpb=29218.4, bsz=972, num_updates=190100, lr=7.25285e-05, gnorm=0.465, loss_scale=4, train_wall=33, gb_free=6.8, wall=63211
2021-04-05 18:11:19 | INFO | train_inner | epoch 041:    232 / 4751 loss=4.615, nll_loss=3.022, ppl=8.12, wps=87473.7, ups=3.04, wpb=28802.9, bsz=927.9, num_updates=190200, lr=7.25095e-05, gnorm=0.472, loss_scale=4, train_wall=33, gb_free=6.1, wall=63244
2021-04-05 18:11:52 | INFO | train_inner | epoch 041:    332 / 4751 loss=4.541, nll_loss=2.938, ppl=7.66, wps=88304.2, ups=3.04, wpb=29025.1, bsz=949.2, num_updates=190300, lr=7.24904e-05, gnorm=0.459, loss_scale=4, train_wall=33, gb_free=6.6, wall=63277
2021-04-05 18:12:25 | INFO | train_inner | epoch 041:    432 / 4751 loss=4.526, nll_loss=2.921, ppl=7.58, wps=88736.7, ups=3.03, wpb=29238.7, bsz=956.8, num_updates=190400, lr=7.24714e-05, gnorm=0.448, loss_scale=4, train_wall=33, gb_free=6.5, wall=63310
2021-04-05 18:12:58 | INFO | train_inner | epoch 041:    532 / 4751 loss=4.554, nll_loss=2.953, ppl=7.74, wps=87806.1, ups=3.03, wpb=28942, bsz=921.4, num_updates=190500, lr=7.24524e-05, gnorm=0.459, loss_scale=4, train_wall=33, gb_free=6.3, wall=63343
2021-04-05 18:13:31 | INFO | train_inner | epoch 041:    632 / 4751 loss=4.509, nll_loss=2.902, ppl=7.48, wps=88282.1, ups=3.04, wpb=29077.9, bsz=960.6, num_updates=190600, lr=7.24333e-05, gnorm=0.453, loss_scale=4, train_wall=33, gb_free=6.1, wall=63376
2021-04-05 18:14:04 | INFO | train_inner | epoch 041:    732 / 4751 loss=4.587, nll_loss=2.99, ppl=7.95, wps=87999.5, ups=3.05, wpb=28848.5, bsz=915.8, num_updates=190700, lr=7.24144e-05, gnorm=0.465, loss_scale=4, train_wall=33, gb_free=6.1, wall=63409
2021-04-05 18:14:37 | INFO | train_inner | epoch 041:    832 / 4751 loss=4.577, nll_loss=2.979, ppl=7.89, wps=88049.9, ups=3.05, wpb=28843.2, bsz=918.9, num_updates=190800, lr=7.23954e-05, gnorm=0.459, loss_scale=4, train_wall=33, gb_free=6.4, wall=63442
2021-04-05 18:15:10 | INFO | train_inner | epoch 041:    932 / 4751 loss=4.551, nll_loss=2.95, ppl=7.73, wps=88095.2, ups=3.05, wpb=28904.4, bsz=940, num_updates=190900, lr=7.23764e-05, gnorm=0.462, loss_scale=4, train_wall=33, gb_free=6.2, wall=63474
2021-04-05 18:15:42 | INFO | train_inner | epoch 041:   1032 / 4751 loss=4.527, nll_loss=2.923, ppl=7.59, wps=88368.4, ups=3.05, wpb=28959.3, bsz=944.4, num_updates=191000, lr=7.23575e-05, gnorm=0.462, loss_scale=4, train_wall=33, gb_free=6.4, wall=63507
2021-04-05 18:16:15 | INFO | train_inner | epoch 041:   1132 / 4751 loss=4.556, nll_loss=2.956, ppl=7.76, wps=87186, ups=3.04, wpb=28662.7, bsz=981, num_updates=191100, lr=7.23385e-05, gnorm=0.463, loss_scale=4, train_wall=33, gb_free=6.3, wall=63540
2021-04-05 18:16:48 | INFO | train_inner | epoch 041:   1232 / 4751 loss=4.524, nll_loss=2.919, ppl=7.56, wps=87147.8, ups=3.01, wpb=28970.6, bsz=923.2, num_updates=191200, lr=7.23196e-05, gnorm=0.466, loss_scale=4, train_wall=33, gb_free=6.6, wall=63573
2021-04-05 18:17:21 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-05 18:17:22 | INFO | train_inner | epoch 041:   1333 / 4751 loss=4.556, nll_loss=2.956, ppl=7.76, wps=86396.1, ups=3, wpb=28795.3, bsz=965.4, num_updates=191300, lr=7.23007e-05, gnorm=0.459, loss_scale=2, train_wall=33, gb_free=6.4, wall=63607
2021-04-05 18:17:55 | INFO | train_inner | epoch 041:   1433 / 4751 loss=4.515, nll_loss=2.909, ppl=7.51, wps=87145, ups=3.02, wpb=28864.4, bsz=943.5, num_updates=191400, lr=7.22818e-05, gnorm=0.465, loss_scale=2, train_wall=33, gb_free=6.3, wall=63640
2021-04-05 18:18:28 | INFO | train_inner | epoch 041:   1533 / 4751 loss=4.552, nll_loss=2.951, ppl=7.73, wps=87239, ups=3.02, wpb=28849.3, bsz=975.5, num_updates=191500, lr=7.22629e-05, gnorm=0.463, loss_scale=2, train_wall=33, gb_free=6.1, wall=63673
2021-04-05 18:19:01 | INFO | train_inner | epoch 041:   1633 / 4751 loss=4.539, nll_loss=2.937, ppl=7.66, wps=87823.8, ups=3.05, wpb=28779.7, bsz=921.1, num_updates=191600, lr=7.22441e-05, gnorm=0.468, loss_scale=2, train_wall=33, gb_free=6.3, wall=63706
2021-04-05 18:19:34 | INFO | train_inner | epoch 041:   1733 / 4751 loss=4.521, nll_loss=2.917, ppl=7.55, wps=89397.8, ups=3.04, wpb=29417.1, bsz=924.9, num_updates=191700, lr=7.22252e-05, gnorm=0.455, loss_scale=2, train_wall=33, gb_free=6.2, wall=63738
2021-04-05 18:20:06 | INFO | train_inner | epoch 041:   1833 / 4751 loss=4.595, nll_loss=3.001, ppl=8, wps=87608.2, ups=3.06, wpb=28654.2, bsz=947.8, num_updates=191800, lr=7.22064e-05, gnorm=0.463, loss_scale=2, train_wall=33, gb_free=6.3, wall=63771
2021-04-05 18:20:40 | INFO | train_inner | epoch 041:   1933 / 4751 loss=4.556, nll_loss=2.955, ppl=7.76, wps=87014, ups=2.99, wpb=29140.9, bsz=952.4, num_updates=191900, lr=7.21876e-05, gnorm=0.462, loss_scale=2, train_wall=33, gb_free=6.4, wall=63805
2021-04-05 18:21:13 | INFO | train_inner | epoch 041:   2033 / 4751 loss=4.562, nll_loss=2.963, ppl=7.8, wps=87268.6, ups=3.03, wpb=28762.8, bsz=930.5, num_updates=192000, lr=7.21688e-05, gnorm=0.46, loss_scale=2, train_wall=33, gb_free=6.1, wall=63838
2021-04-05 18:21:45 | INFO | train_inner | epoch 041:   2133 / 4751 loss=4.534, nll_loss=2.931, ppl=7.63, wps=89411.8, ups=3.06, wpb=29226, bsz=939.6, num_updates=192100, lr=7.215e-05, gnorm=0.455, loss_scale=2, train_wall=33, gb_free=6.2, wall=63870
2021-04-05 18:22:18 | INFO | train_inner | epoch 041:   2233 / 4751 loss=4.49, nll_loss=2.882, ppl=7.37, wps=88274.6, ups=3.03, wpb=29122.4, bsz=961.1, num_updates=192200, lr=7.21312e-05, gnorm=0.458, loss_scale=2, train_wall=33, gb_free=6.2, wall=63903
2021-04-05 18:22:52 | INFO | train_inner | epoch 041:   2333 / 4751 loss=4.518, nll_loss=2.913, ppl=7.53, wps=87777.9, ups=3.03, wpb=29003.9, bsz=929.2, num_updates=192300, lr=7.21125e-05, gnorm=0.458, loss_scale=2, train_wall=33, gb_free=6.3, wall=63936
2021-04-05 18:23:24 | INFO | train_inner | epoch 041:   2433 / 4751 loss=4.554, nll_loss=2.954, ppl=7.75, wps=87487.2, ups=3.04, wpb=28788.9, bsz=959.7, num_updates=192400, lr=7.20937e-05, gnorm=0.461, loss_scale=2, train_wall=33, gb_free=6.5, wall=63969
2021-04-05 18:23:57 | INFO | train_inner | epoch 041:   2533 / 4751 loss=4.58, nll_loss=2.982, ppl=7.9, wps=87509.3, ups=3.04, wpb=28822.2, bsz=902.2, num_updates=192500, lr=7.2075e-05, gnorm=0.463, loss_scale=2, train_wall=33, gb_free=6.3, wall=64002
2021-04-05 18:24:30 | INFO | train_inner | epoch 041:   2633 / 4751 loss=4.499, nll_loss=2.891, ppl=7.42, wps=88577.7, ups=3.05, wpb=29080.1, bsz=968.6, num_updates=192600, lr=7.20563e-05, gnorm=0.462, loss_scale=2, train_wall=33, gb_free=6.7, wall=64035
2021-04-05 18:25:03 | INFO | train_inner | epoch 041:   2733 / 4751 loss=4.6, nll_loss=3.005, ppl=8.03, wps=86930.6, ups=3.04, wpb=28605.8, bsz=929, num_updates=192700, lr=7.20376e-05, gnorm=0.468, loss_scale=2, train_wall=33, gb_free=6.3, wall=64068
2021-04-05 18:25:36 | INFO | train_inner | epoch 041:   2833 / 4751 loss=4.494, nll_loss=2.885, ppl=7.39, wps=87372, ups=3.02, wpb=28912.6, bsz=950.6, num_updates=192800, lr=7.20189e-05, gnorm=0.457, loss_scale=2, train_wall=33, gb_free=6.3, wall=64101
2021-04-05 18:26:09 | INFO | train_inner | epoch 041:   2933 / 4751 loss=4.578, nll_loss=2.981, ppl=7.89, wps=87968.3, ups=3.05, wpb=28869.4, bsz=929.6, num_updates=192900, lr=7.20002e-05, gnorm=0.472, loss_scale=2, train_wall=33, gb_free=6.3, wall=64134
2021-04-05 18:26:42 | INFO | train_inner | epoch 041:   3033 / 4751 loss=4.528, nll_loss=2.924, ppl=7.59, wps=88435.9, ups=3.04, wpb=29104.4, bsz=948, num_updates=193000, lr=7.19816e-05, gnorm=0.454, loss_scale=2, train_wall=33, gb_free=6, wall=64167
2021-04-05 18:27:15 | INFO | train_inner | epoch 041:   3133 / 4751 loss=4.521, nll_loss=2.916, ppl=7.55, wps=88981.8, ups=3.04, wpb=29257.5, bsz=959.2, num_updates=193100, lr=7.19629e-05, gnorm=0.455, loss_scale=2, train_wall=33, gb_free=6.4, wall=64200
2021-04-05 18:27:48 | INFO | train_inner | epoch 041:   3233 / 4751 loss=4.505, nll_loss=2.898, ppl=7.45, wps=87395.9, ups=3.02, wpb=28923.9, bsz=940.3, num_updates=193200, lr=7.19443e-05, gnorm=0.459, loss_scale=2, train_wall=33, gb_free=6.1, wall=64233
2021-04-05 18:28:21 | INFO | train_inner | epoch 041:   3333 / 4751 loss=4.521, nll_loss=2.916, ppl=7.55, wps=87756.3, ups=3.04, wpb=28842.7, bsz=947.4, num_updates=193300, lr=7.19257e-05, gnorm=0.457, loss_scale=2, train_wall=33, gb_free=6.1, wall=64266
2021-04-05 18:28:54 | INFO | train_inner | epoch 041:   3433 / 4751 loss=4.475, nll_loss=2.865, ppl=7.28, wps=88188.1, ups=3.03, wpb=29147.6, bsz=994.5, num_updates=193400, lr=7.19071e-05, gnorm=0.453, loss_scale=4, train_wall=33, gb_free=6.1, wall=64299
2021-04-05 18:29:27 | INFO | train_inner | epoch 041:   3533 / 4751 loss=4.507, nll_loss=2.901, ppl=7.47, wps=87856.2, ups=3.04, wpb=28912.7, bsz=957.5, num_updates=193500, lr=7.18885e-05, gnorm=0.456, loss_scale=4, train_wall=33, gb_free=6.2, wall=64332
2021-04-05 18:29:47 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-05 18:30:00 | INFO | train_inner | epoch 041:   3634 / 4751 loss=4.542, nll_loss=2.94, ppl=7.67, wps=87200.7, ups=3.01, wpb=28938.4, bsz=957.1, num_updates=193600, lr=7.18699e-05, gnorm=0.464, loss_scale=2, train_wall=33, gb_free=6.2, wall=64365
2021-04-05 18:30:33 | INFO | train_inner | epoch 041:   3734 / 4751 loss=4.564, nll_loss=2.965, ppl=7.81, wps=87489.2, ups=3.04, wpb=28784.9, bsz=932.6, num_updates=193700, lr=7.18514e-05, gnorm=0.463, loss_scale=2, train_wall=33, gb_free=5.9, wall=64398
2021-04-05 18:31:06 | INFO | train_inner | epoch 041:   3834 / 4751 loss=4.565, nll_loss=2.967, ppl=7.82, wps=87400.7, ups=3.03, wpb=28810.9, bsz=969.5, num_updates=193800, lr=7.18329e-05, gnorm=0.466, loss_scale=2, train_wall=33, gb_free=6.2, wall=64431
2021-04-05 18:31:39 | INFO | train_inner | epoch 041:   3934 / 4751 loss=4.573, nll_loss=2.975, ppl=7.86, wps=88174.5, ups=3.04, wpb=28972.4, bsz=934.3, num_updates=193900, lr=7.18143e-05, gnorm=0.463, loss_scale=2, train_wall=33, gb_free=6.3, wall=64463
2021-04-05 18:32:12 | INFO | train_inner | epoch 041:   4034 / 4751 loss=4.527, nll_loss=2.923, ppl=7.59, wps=87381.9, ups=3.03, wpb=28875.8, bsz=962.8, num_updates=194000, lr=7.17958e-05, gnorm=0.466, loss_scale=2, train_wall=33, gb_free=5.9, wall=64496
2021-04-05 18:32:44 | INFO | train_inner | epoch 041:   4134 / 4751 loss=4.555, nll_loss=2.955, ppl=7.75, wps=89244.2, ups=3.05, wpb=29275.9, bsz=1001.8, num_updates=194100, lr=7.17773e-05, gnorm=0.481, loss_scale=2, train_wall=33, gb_free=6.1, wall=64529
2021-04-05 18:33:17 | INFO | train_inner | epoch 041:   4234 / 4751 loss=4.565, nll_loss=2.966, ppl=7.82, wps=88745.9, ups=3.06, wpb=29036.9, bsz=931.8, num_updates=194200, lr=7.17588e-05, gnorm=0.464, loss_scale=2, train_wall=33, gb_free=6, wall=64562
2021-04-05 18:33:50 | INFO | train_inner | epoch 041:   4334 / 4751 loss=4.541, nll_loss=2.939, ppl=7.67, wps=88262.6, ups=3.05, wpb=28939.9, bsz=940.1, num_updates=194300, lr=7.17404e-05, gnorm=0.46, loss_scale=2, train_wall=33, gb_free=6.4, wall=64595
2021-04-05 18:34:23 | INFO | train_inner | epoch 041:   4434 / 4751 loss=4.58, nll_loss=2.983, ppl=7.9, wps=88727, ups=3.02, wpb=29345, bsz=914.1, num_updates=194400, lr=7.17219e-05, gnorm=0.457, loss_scale=2, train_wall=33, gb_free=6.1, wall=64628
2021-04-05 18:34:56 | INFO | train_inner | epoch 041:   4534 / 4751 loss=4.529, nll_loss=2.926, ppl=7.6, wps=87628.8, ups=3.03, wpb=28881, bsz=941, num_updates=194500, lr=7.17035e-05, gnorm=0.46, loss_scale=2, train_wall=33, gb_free=6.3, wall=64661
2021-04-05 18:35:29 | INFO | train_inner | epoch 041:   4634 / 4751 loss=4.526, nll_loss=2.922, ppl=7.58, wps=88082.7, ups=3.04, wpb=28964, bsz=920.9, num_updates=194600, lr=7.1685e-05, gnorm=0.467, loss_scale=2, train_wall=33, gb_free=6.3, wall=64694
2021-04-05 18:36:02 | INFO | train_inner | epoch 041:   4734 / 4751 loss=4.521, nll_loss=2.917, ppl=7.55, wps=89254.4, ups=3.05, wpb=29235.7, bsz=981.1, num_updates=194700, lr=7.16666e-05, gnorm=0.459, loss_scale=2, train_wall=33, gb_free=6.4, wall=64726
2021-04-05 18:36:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-05 18:36:08 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 4.179 | nll_loss 2.407 | ppl 5.3 | wps 192714 | wpb 10489.1 | bsz 375 | num_updates 194717 | best_loss 4.164
2021-04-05 18:36:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 194717 updates
2021-04-05 18:36:08 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-05 18:36:15 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-05 18:36:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt (epoch 41 @ 194717 updates, score 4.179) (writing took 6.678824063390493 seconds)
2021-04-05 18:36:15 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2021-04-05 18:36:15 | INFO | train | epoch 041 | loss 4.541 | nll_loss 2.939 | ppl 7.67 | wps 87446.8 | ups 3.02 | wpb 28968.3 | bsz 946.9 | num_updates 194717 | lr 7.16635e-05 | gnorm 0.461 | loss_scale 2 | train_wall 1557 | gb_free 6.3 | wall 64740
2021-04-05 18:36:15 | INFO | fairseq.trainer | begin training epoch 42
2021-04-05 18:36:15 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-05 18:36:44 | INFO | train_inner | epoch 042:     83 / 4751 loss=4.503, nll_loss=2.895, ppl=7.44, wps=68871, ups=2.38, wpb=28883.5, bsz=958.4, num_updates=194800, lr=7.16482e-05, gnorm=0.462, loss_scale=2, train_wall=33, gb_free=6.1, wall=64768
2021-04-05 18:37:16 | INFO | train_inner | epoch 042:    183 / 4751 loss=4.531, nll_loss=2.927, ppl=7.61, wps=88646.1, ups=3.05, wpb=29087.1, bsz=939.5, num_updates=194900, lr=7.16299e-05, gnorm=0.457, loss_scale=2, train_wall=33, gb_free=6.4, wall=64801
2021-04-05 18:37:49 | INFO | train_inner | epoch 042:    283 / 4751 loss=4.543, nll_loss=2.941, ppl=7.68, wps=87520.6, ups=3.03, wpb=28839.4, bsz=944.2, num_updates=195000, lr=7.16115e-05, gnorm=0.462, loss_scale=2, train_wall=33, gb_free=6.1, wall=64834
2021-04-05 18:38:23 | INFO | train_inner | epoch 042:    383 / 4751 loss=4.505, nll_loss=2.898, ppl=7.45, wps=87560.7, ups=3.01, wpb=29078.3, bsz=964.1, num_updates=195100, lr=7.15931e-05, gnorm=0.458, loss_scale=2, train_wall=33, gb_free=6.1, wall=64867
2021-04-05 18:38:56 | INFO | train_inner | epoch 042:    483 / 4751 loss=4.524, nll_loss=2.92, ppl=7.57, wps=87782.1, ups=3.03, wpb=28926.4, bsz=948.7, num_updates=195200, lr=7.15748e-05, gnorm=0.457, loss_scale=2, train_wall=33, gb_free=6.3, wall=64900
2021-04-05 18:39:29 | INFO | train_inner | epoch 042:    583 / 4751 loss=4.511, nll_loss=2.904, ppl=7.49, wps=88357.7, ups=3.03, wpb=29160.2, bsz=976.5, num_updates=195300, lr=7.15565e-05, gnorm=0.469, loss_scale=2, train_wall=33, gb_free=6.3, wall=64933
2021-04-05 18:40:02 | INFO | train_inner | epoch 042:    683 / 4751 loss=4.492, nll_loss=2.884, ppl=7.38, wps=87365.8, ups=3.02, wpb=28931.1, bsz=974.2, num_updates=195400, lr=7.15382e-05, gnorm=0.459, loss_scale=2, train_wall=33, gb_free=6.1, wall=64966
2021-04-05 18:40:34 | INFO | train_inner | epoch 042:    783 / 4751 loss=4.539, nll_loss=2.937, ppl=7.66, wps=87988, ups=3.05, wpb=28837.9, bsz=955.4, num_updates=195500, lr=7.15199e-05, gnorm=0.467, loss_scale=2, train_wall=33, gb_free=6.3, wall=64999
2021-04-05 18:41:07 | INFO | train_inner | epoch 042:    883 / 4751 loss=4.525, nll_loss=2.921, ppl=7.57, wps=87485.2, ups=3.03, wpb=28827.6, bsz=925.4, num_updates=195600, lr=7.15016e-05, gnorm=0.461, loss_scale=2, train_wall=33, gb_free=6.1, wall=65032
2021-04-05 18:41:41 | INFO | train_inner | epoch 042:    983 / 4751 loss=4.502, nll_loss=2.895, ppl=7.44, wps=87894.1, ups=3.01, wpb=29168.5, bsz=969.9, num_updates=195700, lr=7.14833e-05, gnorm=0.454, loss_scale=4, train_wall=33, gb_free=6.1, wall=65065
2021-04-05 18:42:14 | INFO | train_inner | epoch 042:   1083 / 4751 loss=4.468, nll_loss=2.856, ppl=7.24, wps=87972.6, ups=3.03, wpb=29010, bsz=967, num_updates=195800, lr=7.1465e-05, gnorm=0.468, loss_scale=4, train_wall=33, gb_free=5.8, wall=65098
2021-04-05 18:42:47 | INFO | train_inner | epoch 042:   1183 / 4751 loss=4.56, nll_loss=2.96, ppl=7.78, wps=87467.9, ups=3.03, wpb=28892.4, bsz=937, num_updates=195900, lr=7.14468e-05, gnorm=0.467, loss_scale=4, train_wall=33, gb_free=6.4, wall=65131
2021-04-05 18:43:19 | INFO | train_inner | epoch 042:   1283 / 4751 loss=4.542, nll_loss=2.94, ppl=7.67, wps=86813.5, ups=3.04, wpb=28553.4, bsz=935, num_updates=196000, lr=7.14286e-05, gnorm=0.471, loss_scale=4, train_wall=33, gb_free=6.4, wall=65164
2021-04-05 18:43:52 | INFO | train_inner | epoch 042:   1383 / 4751 loss=4.515, nll_loss=2.909, ppl=7.51, wps=87970.6, ups=3.04, wpb=28921, bsz=942.1, num_updates=196100, lr=7.14104e-05, gnorm=0.469, loss_scale=4, train_wall=33, gb_free=6.1, wall=65197
2021-04-05 18:44:25 | INFO | train_inner | epoch 042:   1483 / 4751 loss=4.534, nll_loss=2.93, ppl=7.62, wps=88624.7, ups=3.05, wpb=29103.2, bsz=945.2, num_updates=196200, lr=7.13922e-05, gnorm=0.461, loss_scale=4, train_wall=33, gb_free=6.4, wall=65230
2021-04-05 18:44:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-05 18:44:58 | INFO | train_inner | epoch 042:   1584 / 4751 loss=4.521, nll_loss=2.917, ppl=7.55, wps=86887.6, ups=3.01, wpb=28872.7, bsz=960.4, num_updates=196300, lr=7.1374e-05, gnorm=0.47, loss_scale=2, train_wall=33, gb_free=6.2, wall=65263
2021-04-05 18:45:31 | INFO | train_inner | epoch 042:   1684 / 4751 loss=4.547, nll_loss=2.946, ppl=7.7, wps=88272.2, ups=3.04, wpb=29031.6, bsz=943.3, num_updates=196400, lr=7.13558e-05, gnorm=0.457, loss_scale=2, train_wall=33, gb_free=6, wall=65296
2021-04-05 18:46:04 | INFO | train_inner | epoch 042:   1784 / 4751 loss=4.506, nll_loss=2.899, ppl=7.46, wps=87687.1, ups=3.03, wpb=28986.5, bsz=936.4, num_updates=196500, lr=7.13376e-05, gnorm=0.465, loss_scale=2, train_wall=33, gb_free=6.3, wall=65329
2021-04-05 18:46:37 | INFO | train_inner | epoch 042:   1884 / 4751 loss=4.607, nll_loss=3.014, ppl=8.08, wps=87221, ups=3.02, wpb=28909.3, bsz=965.5, num_updates=196600, lr=7.13195e-05, gnorm=0.467, loss_scale=2, train_wall=33, gb_free=6.2, wall=65362
2021-04-05 18:47:10 | INFO | train_inner | epoch 042:   1984 / 4751 loss=4.579, nll_loss=2.982, ppl=7.9, wps=88162, ups=3.05, wpb=28910.4, bsz=913.7, num_updates=196700, lr=7.13014e-05, gnorm=0.468, loss_scale=2, train_wall=33, gb_free=6.5, wall=65395
2021-04-05 18:47:43 | INFO | train_inner | epoch 042:   2084 / 4751 loss=4.529, nll_loss=2.925, ppl=7.59, wps=88572, ups=3.05, wpb=28992.6, bsz=956.9, num_updates=196800, lr=7.12832e-05, gnorm=0.462, loss_scale=2, train_wall=33, gb_free=6.3, wall=65428
2021-04-05 18:48:16 | INFO | train_inner | epoch 042:   2184 / 4751 loss=4.565, nll_loss=2.966, ppl=7.81, wps=87579.7, ups=3.03, wpb=28865.5, bsz=920.6, num_updates=196900, lr=7.12651e-05, gnorm=0.462, loss_scale=2, train_wall=33, gb_free=6.4, wall=65461
2021-04-05 18:48:49 | INFO | train_inner | epoch 042:   2284 / 4751 loss=4.559, nll_loss=2.959, ppl=7.78, wps=89245.8, ups=3.05, wpb=29261.4, bsz=968.4, num_updates=197000, lr=7.1247e-05, gnorm=0.465, loss_scale=2, train_wall=33, gb_free=6.3, wall=65494
2021-04-05 18:49:22 | INFO | train_inner | epoch 042:   2384 / 4751 loss=4.561, nll_loss=2.961, ppl=7.79, wps=87901.4, ups=3.04, wpb=28907, bsz=944.7, num_updates=197100, lr=7.1229e-05, gnorm=0.459, loss_scale=2, train_wall=33, gb_free=6.3, wall=65526
2021-04-05 18:49:54 | INFO | train_inner | epoch 042:   2484 / 4751 loss=4.563, nll_loss=2.964, ppl=7.8, wps=89426.9, ups=3.06, wpb=29235.2, bsz=935.4, num_updates=197200, lr=7.12109e-05, gnorm=0.465, loss_scale=2, train_wall=33, gb_free=6, wall=65559
2021-04-05 18:50:27 | INFO | train_inner | epoch 042:   2584 / 4751 loss=4.561, nll_loss=2.962, ppl=7.79, wps=87781.5, ups=3.05, wpb=28790.5, bsz=916.2, num_updates=197300, lr=7.11929e-05, gnorm=0.465, loss_scale=2, train_wall=33, gb_free=6.2, wall=65592
2021-04-05 18:51:00 | INFO | train_inner | epoch 042:   2684 / 4751 loss=4.505, nll_loss=2.898, ppl=7.46, wps=87560.3, ups=3.04, wpb=28802.7, bsz=948.2, num_updates=197400, lr=7.11748e-05, gnorm=0.464, loss_scale=2, train_wall=33, gb_free=6.1, wall=65625
2021-04-05 18:51:33 | INFO | train_inner | epoch 042:   2784 / 4751 loss=4.523, nll_loss=2.919, ppl=7.56, wps=88215.1, ups=3.04, wpb=28995.4, bsz=936.5, num_updates=197500, lr=7.11568e-05, gnorm=0.462, loss_scale=2, train_wall=33, gb_free=6.1, wall=65658
2021-04-05 18:52:06 | INFO | train_inner | epoch 042:   2884 / 4751 loss=4.55, nll_loss=2.949, ppl=7.72, wps=88794.9, ups=3.05, wpb=29146.8, bsz=986, num_updates=197600, lr=7.11388e-05, gnorm=0.464, loss_scale=2, train_wall=33, gb_free=6.3, wall=65691
2021-04-05 18:52:39 | INFO | train_inner | epoch 042:   2984 / 4751 loss=4.552, nll_loss=2.952, ppl=7.74, wps=88987.8, ups=3.04, wpb=29253.1, bsz=967.4, num_updates=197700, lr=7.11208e-05, gnorm=0.458, loss_scale=2, train_wall=33, gb_free=6.1, wall=65723
2021-04-05 18:53:11 | INFO | train_inner | epoch 042:   3084 / 4751 loss=4.587, nll_loss=2.991, ppl=7.95, wps=87713.6, ups=3.05, wpb=28753.2, bsz=928.4, num_updates=197800, lr=7.11028e-05, gnorm=0.468, loss_scale=2, train_wall=33, gb_free=6.2, wall=65756
2021-04-05 18:53:44 | INFO | train_inner | epoch 042:   3184 / 4751 loss=4.496, nll_loss=2.888, ppl=7.4, wps=88297, ups=3.04, wpb=29086.2, bsz=953.4, num_updates=197900, lr=7.10849e-05, gnorm=0.456, loss_scale=2, train_wall=33, gb_free=6.1, wall=65789
2021-04-05 18:54:17 | INFO | train_inner | epoch 042:   3284 / 4751 loss=4.502, nll_loss=2.895, ppl=7.44, wps=88865.6, ups=3.04, wpb=29222.8, bsz=970.4, num_updates=198000, lr=7.10669e-05, gnorm=0.457, loss_scale=2, train_wall=33, gb_free=6.1, wall=65822
2021-04-05 18:54:50 | INFO | train_inner | epoch 042:   3384 / 4751 loss=4.543, nll_loss=2.942, ppl=7.68, wps=88300.6, ups=3.06, wpb=28874.4, bsz=944.7, num_updates=198100, lr=7.1049e-05, gnorm=0.456, loss_scale=2, train_wall=33, gb_free=6.2, wall=65855
2021-04-05 18:55:23 | INFO | train_inner | epoch 042:   3484 / 4751 loss=4.479, nll_loss=2.869, ppl=7.31, wps=88180.3, ups=3.04, wpb=29001.8, bsz=968.6, num_updates=198200, lr=7.1031e-05, gnorm=0.452, loss_scale=2, train_wall=33, gb_free=6.3, wall=65888
2021-04-05 18:55:56 | INFO | train_inner | epoch 042:   3584 / 4751 loss=4.563, nll_loss=2.964, ppl=7.8, wps=87902.3, ups=3.04, wpb=28916.7, bsz=925.4, num_updates=198300, lr=7.10131e-05, gnorm=0.461, loss_scale=4, train_wall=33, gb_free=6.5, wall=65921
2021-04-05 18:56:29 | INFO | train_inner | epoch 042:   3684 / 4751 loss=4.528, nll_loss=2.924, ppl=7.59, wps=88052.8, ups=3.02, wpb=29111.1, bsz=934.1, num_updates=198400, lr=7.09952e-05, gnorm=0.462, loss_scale=4, train_wall=33, gb_free=6.3, wall=65954
2021-04-05 18:57:01 | INFO | train_inner | epoch 042:   3784 / 4751 loss=4.579, nll_loss=2.982, ppl=7.9, wps=88684.8, ups=3.06, wpb=29016.1, bsz=927.3, num_updates=198500, lr=7.09773e-05, gnorm=0.466, loss_scale=4, train_wall=33, gb_free=6.3, wall=65986
2021-04-05 18:57:34 | INFO | train_inner | epoch 042:   3884 / 4751 loss=4.569, nll_loss=2.971, ppl=7.84, wps=87308.4, ups=3.04, wpb=28757.5, bsz=939, num_updates=198600, lr=7.09595e-05, gnorm=0.467, loss_scale=4, train_wall=33, gb_free=6.2, wall=66019
2021-04-05 18:58:07 | INFO | train_inner | epoch 042:   3984 / 4751 loss=4.551, nll_loss=2.95, ppl=7.73, wps=88338.3, ups=3.05, wpb=28941.1, bsz=932.2, num_updates=198700, lr=7.09416e-05, gnorm=0.465, loss_scale=4, train_wall=33, gb_free=6, wall=66052
2021-04-05 18:58:40 | INFO | train_inner | epoch 042:   4084 / 4751 loss=4.574, nll_loss=2.977, ppl=7.87, wps=88413.2, ups=3.07, wpb=28821.5, bsz=942.7, num_updates=198800, lr=7.09238e-05, gnorm=0.465, loss_scale=4, train_wall=32, gb_free=7.2, wall=66085
2021-04-05 18:59:13 | INFO | train_inner | epoch 042:   4184 / 4751 loss=4.558, nll_loss=2.958, ppl=7.77, wps=86266.6, ups=2.98, wpb=28923.9, bsz=930.6, num_updates=198900, lr=7.09059e-05, gnorm=0.471, loss_scale=4, train_wall=33, gb_free=6.4, wall=66118
2021-04-05 18:59:46 | INFO | train_inner | epoch 042:   4284 / 4751 loss=4.58, nll_loss=2.983, ppl=7.9, wps=87544.4, ups=3.04, wpb=28829.7, bsz=927.2, num_updates=199000, lr=7.08881e-05, gnorm=0.464, loss_scale=4, train_wall=33, gb_free=6.4, wall=66151
2021-04-05 19:00:19 | INFO | train_inner | epoch 042:   4384 / 4751 loss=4.552, nll_loss=2.951, ppl=7.73, wps=88435.8, ups=3.06, wpb=28871.3, bsz=938.6, num_updates=199100, lr=7.08703e-05, gnorm=0.455, loss_scale=4, train_wall=32, gb_free=6.1, wall=66184
2021-04-05 19:00:52 | INFO | train_inner | epoch 042:   4484 / 4751 loss=4.504, nll_loss=2.898, ppl=7.45, wps=87667.2, ups=3.05, wpb=28755.5, bsz=961.2, num_updates=199200, lr=7.08525e-05, gnorm=0.461, loss_scale=4, train_wall=33, gb_free=6.1, wall=66217
2021-04-05 19:01:25 | INFO | train_inner | epoch 042:   4584 / 4751 loss=4.519, nll_loss=2.914, ppl=7.54, wps=89091.3, ups=3.04, wpb=29339.7, bsz=963.8, num_updates=199300, lr=7.08347e-05, gnorm=0.454, loss_scale=4, train_wall=33, gb_free=6.2, wall=66249
2021-04-05 19:01:57 | INFO | train_inner | epoch 042:   4684 / 4751 loss=4.55, nll_loss=2.949, ppl=7.72, wps=88956.4, ups=3.05, wpb=29140, bsz=949.5, num_updates=199400, lr=7.0817e-05, gnorm=0.455, loss_scale=4, train_wall=33, gb_free=6.1, wall=66282
2021-04-05 19:02:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-05 19:02:21 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 4.167 | nll_loss 2.401 | ppl 5.28 | wps 188042 | wpb 10489.1 | bsz 375 | num_updates 199467 | best_loss 4.164
2021-04-05 19:02:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 199467 updates
2021-04-05 19:02:21 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-05 19:02:27 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-05 19:02:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt (epoch 42 @ 199467 updates, score 4.167) (writing took 6.193431090563536 seconds)
2021-04-05 19:02:27 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2021-04-05 19:02:27 | INFO | train | epoch 042 | loss 4.538 | nll_loss 2.936 | ppl 7.65 | wps 87542.2 | ups 3.02 | wpb 28968.3 | bsz 947.2 | num_updates 199467 | lr 7.08051e-05 | gnorm 0.462 | loss_scale 4 | train_wall 1556 | gb_free 6.4 | wall 66312
2021-04-05 19:02:27 | INFO | fairseq.trainer | begin training epoch 43
2021-04-05 19:02:27 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-05 19:02:39 | INFO | train_inner | epoch 043:     33 / 4751 loss=4.578, nll_loss=2.981, ppl=7.9, wps=68935.5, ups=2.4, wpb=28680.6, bsz=943.3, num_updates=199500, lr=7.07992e-05, gnorm=0.468, loss_scale=4, train_wall=33, gb_free=6.2, wall=66324
2021-04-05 19:03:12 | INFO | train_inner | epoch 043:    133 / 4751 loss=4.563, nll_loss=2.964, ppl=7.8, wps=87914.8, ups=3.05, wpb=28781.7, bsz=925.8, num_updates=199600, lr=7.07815e-05, gnorm=0.467, loss_scale=4, train_wall=33, gb_free=6.1, wall=66357
2021-04-05 19:03:44 | INFO | train_inner | epoch 043:    233 / 4751 loss=4.558, nll_loss=2.957, ppl=7.77, wps=88326.7, ups=3.05, wpb=28935.1, bsz=931.9, num_updates=199700, lr=7.07638e-05, gnorm=0.46, loss_scale=4, train_wall=33, gb_free=6.2, wall=66389
2021-04-05 19:04:17 | INFO | train_inner | epoch 043:    333 / 4751 loss=4.503, nll_loss=2.896, ppl=7.44, wps=87785.2, ups=3.04, wpb=28892.8, bsz=928.6, num_updates=199800, lr=7.07461e-05, gnorm=0.458, loss_scale=4, train_wall=33, gb_free=7.5, wall=66422
2021-04-05 19:04:50 | INFO | train_inner | epoch 043:    433 / 4751 loss=4.557, nll_loss=2.957, ppl=7.77, wps=87376.4, ups=3.04, wpb=28763.8, bsz=924.4, num_updates=199900, lr=7.07284e-05, gnorm=0.464, loss_scale=4, train_wall=33, gb_free=6.2, wall=66455
2021-04-05 19:05:23 | INFO | train_inner | epoch 043:    533 / 4751 loss=4.524, nll_loss=2.919, ppl=7.57, wps=88905.4, ups=3.05, wpb=29136, bsz=950.6, num_updates=200000, lr=7.07107e-05, gnorm=0.457, loss_scale=4, train_wall=33, gb_free=6.2, wall=66488
2021-04-05 19:05:23 | INFO | fairseq_cli.train | Stopping training due to num_updates: 200000 >= max_update: 200000
2021-04-05 19:05:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-05 19:05:24 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 4.165 | nll_loss 2.392 | ppl 5.25 | wps 181065 | wpb 10489.1 | bsz 375 | num_updates 200000 | best_loss 4.164
2021-04-05 19:05:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 200000 updates
2021-04-05 19:05:24 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-05 19:05:30 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-05 19:05:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt (epoch 43 @ 200000 updates, score 4.165) (writing took 5.988594334572554 seconds)
2021-04-05 19:05:30 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2021-04-05 19:05:30 | INFO | train | epoch 043 | loss 4.54 | nll_loss 2.938 | ppl 7.66 | wps 83887.8 | ups 2.9 | wpb 28886 | bsz 930.3 | num_updates 200000 | lr 7.07107e-05 | gnorm 0.462 | loss_scale 4 | train_wall 174 | gb_free 6.2 | wall 66495
2021-04-05 19:05:30 | INFO | fairseq_cli.train | done training in 66493.6 seconds
Traceback (most recent call last):
  File "/home/amax/Codes/flstm-nmt/fairseq_cli/train.py", line 454, in <module>
    cli_main()
  File "/home/amax/Codes/flstm-nmt/fairseq_cli/train.py", line 450, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/home/amax/Codes/flstm-nmt/fairseq/distributed/utils.py", line 342, in call_main
    torch.multiprocessing.spawn(
  File "/home/amax/miniconda3/envs/nmt/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 200, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/home/amax/miniconda3/envs/nmt/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 158, in start_processes
    while not context.join():
  File "/home/amax/miniconda3/envs/nmt/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 106, in join
    raise Exception(
Exception: process 1 terminated with signal SIGSEGV
/home/amax/miniconda3/envs/nmt/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 344 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
Start training...
2021-04-05 22:34:02 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:12901
2021-04-05 22:34:02 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:12901
2021-04-05 22:34:02 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:12901
2021-04-05 22:34:02 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:12901
2021-04-05 22:34:02 | INFO | fairseq.distributed.utils | initialized host haroldl as rank 2
2021-04-05 22:34:03 | INFO | fairseq.distributed.utils | initialized host haroldl as rank 1
2021-04-05 22:34:03 | INFO | fairseq.distributed.utils | initialized host haroldl as rank 3
2021-04-05 22:34:03 | INFO | fairseq.distributed.utils | initialized host haroldl as rank 0
2021-04-05 22:34:04 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:12901', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'tpu': False, 'distributed_num_procs': 4}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4096, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4096, 'batch_size_valid': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 200, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [2], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': 50, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'model_parallel_size': 1, 'distributed_rank': 0}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='vslstm_tf_fc4_attnfeat_wmt', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='vslstm_tf_fc4_attnfeat_wmt', attention_dropout=0.1, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', curriculum=0, data='data-bin/wmt16_en_de_bpe32k', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', dec_layernorm_embedding=False, decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_layerdrop=0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=4, dropout=0.3, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=6, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=False, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, ffoncell=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', heartbeat_timeout=-1, ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, kernel_size=1, label_smoothing=0.1, layer_wise_attention=False, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', mask_dummy_for_fgate=False, max_epoch=200, max_source_positions=1024, max_target_positions=1024, max_tokens=4096, max_tokens_valid=4096, max_update=400000, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_layer=False, min_loss_scale=0.0001, model_parallel_size=1, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=4, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', pad=1, patience=50, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=False, simul_type=None, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, suppress_crashes=False, target_lang=None, task='translation', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_freq=[2], upsample_primary=-1, use_bmuf=False, use_last_global=False, use_layerwise_global=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin/wmt16_en_de_bpe32k', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'simul_type': None}
2021-04-05 22:34:04 | INFO | fairseq.tasks.translation | [en] dictionary: 32768 types
2021-04-05 22:34:04 | INFO | fairseq.tasks.translation | [de] dictionary: 32768 types
2021-04-05 22:34:04 | INFO | fairseq.data.data_utils | loaded 3,000 examples from: data-bin/wmt16_en_de_bpe32k/valid.en-de.en
2021-04-05 22:34:04 | INFO | fairseq.data.data_utils | loaded 3,000 examples from: data-bin/wmt16_en_de_bpe32k/valid.en-de.de
2021-04-05 22:34:04 | INFO | fairseq.tasks.translation | data-bin/wmt16_en_de_bpe32k valid en-de 3000 examples
2021-04-05 22:34:05 | INFO | fairseq_cli.train | VanillaSlstmFeatTransformerModel(
  (encoder): SLSTMEncoder(
    (embed_tokens): Embedding(32768, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): VanillaSLSTMFeat(
      (norm_gate): Linear(in_features=2048, out_features=3584, bias=True)
      (emb_gate_linear): Linear(in_features=512, out_features=3584, bias=False)
      (peep_gate_linear): Linear(in_features=512, out_features=3584, bias=False)
      (attn_feautre): MultiheadAttention(
        (dropout_module): FairseqDropout()
        (k_proj): Linear(in_features=512, out_features=512, bias=True)
        (v_proj): Linear(in_features=512, out_features=512, bias=True)
        (q_proj): Linear(in_features=512, out_features=512, bias=True)
        (out_proj): Linear(in_features=512, out_features=512, bias=True)
        (relpos_k): RelativePosition()
        (relpos_v): RelativePosition()
      )
      (fc1): Linear(in_features=512, out_features=2048, bias=True)
      (fc2): Linear(in_features=2048, out_features=512, bias=True)
      (act_func): ReLU(inplace=True)
      (ffn_LN): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(32768, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=32768, bias=False)
  )
)
2021-04-05 22:34:05 | INFO | fairseq_cli.train | task: TranslationTask
2021-04-05 22:34:05 | INFO | fairseq_cli.train | model: VanillaSlstmFeatTransformerModel
2021-04-05 22:34:05 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2021-04-05 22:34:05 | INFO | fairseq_cli.train | num. model params: 56,170,624 (num. trained: 56,170,624)
2021-04-05 22:34:06 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2021-04-05 22:34:06 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2021-04-05 22:34:06 | INFO | fairseq.trainer | detected shared parameter: encoder.layers.norm_gates_b <- encoder.layers.norm_gate.bias
2021-04-05 22:34:06 | INFO | fairseq.trainer | detected shared parameter: encoder.layers.emb_gate_linear.bias <- encoder.layers.peep_gate_linear.bias
2021-04-05 22:34:06 | INFO | fairseq.trainer | detected shared parameter: encoder.layers.emb_gate_linear.bias <- decoder.output_projection.bias
2021-04-05 22:34:06 | INFO | fairseq.utils | ***********************CUDA enviroments for all 4 workers***********************
2021-04-05 22:34:06 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 10.761 GB ; name = GeForce RTX 2080 Ti                     
2021-04-05 22:34:06 | INFO | fairseq.utils | rank   1: capabilities =  7.5  ; total memory = 10.761 GB ; name = GeForce RTX 2080 Ti                     
2021-04-05 22:34:06 | INFO | fairseq.utils | rank   2: capabilities =  7.5  ; total memory = 10.761 GB ; name = GeForce RTX 2080 Ti                     
2021-04-05 22:34:06 | INFO | fairseq.utils | rank   3: capabilities =  7.5  ; total memory = 10.760 GB ; name = GeForce RTX 2080 Ti                     
2021-04-05 22:34:06 | INFO | fairseq.utils | ***********************CUDA enviroments for all 4 workers***********************
2021-04-05 22:34:06 | INFO | fairseq_cli.train | training on 4 devices (GPUs/TPUs)
2021-04-05 22:34:06 | INFO | fairseq_cli.train | max tokens per GPU = 4096 and batch size per GPU = None
2021-04-05 22:34:06 | INFO | fairseq.trainer | Preparing to load checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-05 22:34:07 | INFO | fairseq.trainer | Loaded checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt (epoch 43 @ 200000 updates)
2021-04-05 22:34:07 | INFO | fairseq.trainer | loading train data for epoch 43
2021-04-05 22:34:07 | INFO | fairseq.data.data_utils | loaded 4,500,966 examples from: data-bin/wmt16_en_de_bpe32k/train.en-de.en
2021-04-05 22:34:07 | INFO | fairseq.data.data_utils | loaded 4,500,966 examples from: data-bin/wmt16_en_de_bpe32k/train.en-de.de
2021-04-05 22:34:07 | INFO | fairseq.tasks.translation | data-bin/wmt16_en_de_bpe32k train en-de 4500966 examples
2021-04-05 22:34:08 | INFO | fairseq.trainer | begin training epoch 43
2021-04-05 22:34:08 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-05 22:34:42 | INFO | train_inner | epoch 043:    633 / 4751 loss=4.534, nll_loss=2.931, ppl=7.63, wps=79348.4, ups=2.75, wpb=28900.4, bsz=991.3, num_updates=200100, lr=7.0693e-05, gnorm=0.468, loss_scale=4, train_wall=32, gb_free=6.1, wall=0
2021-04-05 22:35:14 | INFO | train_inner | epoch 043:    733 / 4751 loss=4.508, nll_loss=2.901, ppl=7.47, wps=90041.8, ups=3.09, wpb=29098.8, bsz=955, num_updates=200200, lr=7.06753e-05, gnorm=0.461, loss_scale=4, train_wall=32, gb_free=6.4, wall=0
2021-04-05 22:35:47 | INFO | train_inner | epoch 043:    833 / 4751 loss=4.528, nll_loss=2.923, ppl=7.59, wps=89190.7, ups=3.07, wpb=29019.3, bsz=929.4, num_updates=200300, lr=7.06577e-05, gnorm=0.462, loss_scale=4, train_wall=32, gb_free=6.8, wall=0
2021-04-05 22:36:19 | INFO | train_inner | epoch 043:    933 / 4751 loss=4.552, nll_loss=2.951, ppl=7.73, wps=89238.7, ups=3.08, wpb=28970.8, bsz=955.6, num_updates=200400, lr=7.06401e-05, gnorm=0.466, loss_scale=4, train_wall=32, gb_free=6.2, wall=0
2021-04-05 22:36:52 | INFO | train_inner | epoch 043:   1033 / 4751 loss=4.497, nll_loss=2.889, ppl=7.41, wps=88716.4, ups=3.05, wpb=29111.6, bsz=964.8, num_updates=200500, lr=7.06225e-05, gnorm=0.461, loss_scale=4, train_wall=33, gb_free=6.7, wall=0
2021-04-05 22:37:25 | INFO | train_inner | epoch 043:   1133 / 4751 loss=4.485, nll_loss=2.875, ppl=7.34, wps=88499, ups=3.05, wpb=28973.2, bsz=945.8, num_updates=200600, lr=7.06049e-05, gnorm=0.458, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-05 22:37:57 | INFO | train_inner | epoch 043:   1233 / 4751 loss=4.552, nll_loss=2.951, ppl=7.73, wps=89285.1, ups=3.06, wpb=29210.8, bsz=929.4, num_updates=200700, lr=7.05873e-05, gnorm=0.462, loss_scale=4, train_wall=33, gb_free=6, wall=0
2021-04-05 22:38:30 | INFO | train_inner | epoch 043:   1333 / 4751 loss=4.477, nll_loss=2.867, ppl=7.29, wps=88551.9, ups=3.04, wpb=29098.7, bsz=948.6, num_updates=200800, lr=7.05697e-05, gnorm=0.461, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-05 22:39:03 | INFO | train_inner | epoch 043:   1433 / 4751 loss=4.509, nll_loss=2.903, ppl=7.48, wps=87775.4, ups=3.06, wpb=28710.5, bsz=981.2, num_updates=200900, lr=7.05521e-05, gnorm=0.467, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-05 22:39:36 | INFO | train_inner | epoch 043:   1533 / 4751 loss=4.561, nll_loss=2.962, ppl=7.79, wps=88921.7, ups=3.06, wpb=29091.5, bsz=931.1, num_updates=201000, lr=7.05346e-05, gnorm=0.459, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-05 22:40:09 | INFO | train_inner | epoch 043:   1633 / 4751 loss=4.482, nll_loss=2.872, ppl=7.32, wps=88700.6, ups=3.05, wpb=29090.3, bsz=953.5, num_updates=201100, lr=7.0517e-05, gnorm=0.456, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-05 22:40:41 | INFO | train_inner | epoch 043:   1733 / 4751 loss=4.526, nll_loss=2.922, ppl=7.58, wps=87110.9, ups=3.04, wpb=28673.6, bsz=941.1, num_updates=201200, lr=7.04995e-05, gnorm=0.462, loss_scale=4, train_wall=33, gb_free=6.4, wall=0
2021-04-05 22:41:14 | INFO | train_inner | epoch 043:   1833 / 4751 loss=4.541, nll_loss=2.939, ppl=7.67, wps=87607.4, ups=3.06, wpb=28675.6, bsz=917.8, num_updates=201300, lr=7.0482e-05, gnorm=0.471, loss_scale=4, train_wall=33, gb_free=6.4, wall=0
2021-04-05 22:41:47 | INFO | train_inner | epoch 043:   1933 / 4751 loss=4.565, nll_loss=2.967, ppl=7.82, wps=87118.4, ups=3.03, wpb=28759.6, bsz=950.5, num_updates=201400, lr=7.04645e-05, gnorm=0.476, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-05 22:42:20 | INFO | train_inner | epoch 043:   2033 / 4751 loss=4.57, nll_loss=2.971, ppl=7.84, wps=89238.4, ups=3.06, wpb=29151.1, bsz=923.8, num_updates=201500, lr=7.0447e-05, gnorm=0.461, loss_scale=4, train_wall=33, gb_free=6.5, wall=0
2021-04-05 22:42:53 | INFO | train_inner | epoch 043:   2133 / 4751 loss=4.541, nll_loss=2.939, ppl=7.67, wps=88266, ups=3.04, wpb=29047.5, bsz=950.4, num_updates=201600, lr=7.04295e-05, gnorm=0.465, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-05 22:43:26 | INFO | train_inner | epoch 043:   2233 / 4751 loss=4.517, nll_loss=2.912, ppl=7.53, wps=88153, ups=3.03, wpb=29080.5, bsz=970.6, num_updates=201700, lr=7.04121e-05, gnorm=0.461, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-05 22:43:59 | INFO | train_inner | epoch 043:   2333 / 4751 loss=4.539, nll_loss=2.937, ppl=7.66, wps=88335.8, ups=3.04, wpb=29089.2, bsz=916, num_updates=201800, lr=7.03946e-05, gnorm=0.461, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-05 22:44:32 | INFO | train_inner | epoch 043:   2433 / 4751 loss=4.552, nll_loss=2.952, ppl=7.74, wps=87929.7, ups=3.04, wpb=28952.9, bsz=973.2, num_updates=201900, lr=7.03772e-05, gnorm=0.462, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-05 22:45:05 | INFO | train_inner | epoch 043:   2533 / 4751 loss=4.501, nll_loss=2.894, ppl=7.43, wps=87387.5, ups=3.02, wpb=28956.4, bsz=959.2, num_updates=202000, lr=7.03598e-05, gnorm=0.461, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-05 22:45:38 | INFO | train_inner | epoch 043:   2633 / 4751 loss=4.467, nll_loss=2.855, ppl=7.24, wps=86944.3, ups=2.98, wpb=29194, bsz=957.9, num_updates=202100, lr=7.03423e-05, gnorm=0.451, loss_scale=8, train_wall=33, gb_free=5.9, wall=0
2021-04-05 22:46:11 | INFO | train_inner | epoch 043:   2733 / 4751 loss=4.554, nll_loss=2.954, ppl=7.75, wps=88095.8, ups=3.04, wpb=28958.3, bsz=980.1, num_updates=202200, lr=7.03249e-05, gnorm=0.468, loss_scale=8, train_wall=33, gb_free=6.1, wall=0
2021-04-05 22:46:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2021-04-05 22:46:44 | INFO | train_inner | epoch 043:   2834 / 4751 loss=4.552, nll_loss=2.952, ppl=7.74, wps=87317.2, ups=3.02, wpb=28947.2, bsz=959.5, num_updates=202300, lr=7.03076e-05, gnorm=0.463, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-05 22:47:17 | INFO | train_inner | epoch 043:   2934 / 4751 loss=4.518, nll_loss=2.914, ppl=7.54, wps=88022.4, ups=3.05, wpb=28885.9, bsz=951.9, num_updates=202400, lr=7.02902e-05, gnorm=0.46, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-05 22:47:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-05 22:47:51 | INFO | train_inner | epoch 043:   3035 / 4751 loss=4.546, nll_loss=2.944, ppl=7.7, wps=86083.8, ups=3, wpb=28705.6, bsz=917.1, num_updates=202500, lr=7.02728e-05, gnorm=0.464, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-05 22:48:24 | INFO | train_inner | epoch 043:   3135 / 4751 loss=4.491, nll_loss=2.883, ppl=7.38, wps=87667.2, ups=3.03, wpb=28958, bsz=978.6, num_updates=202600, lr=7.02555e-05, gnorm=0.461, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-05 22:48:57 | INFO | train_inner | epoch 043:   3235 / 4751 loss=4.477, nll_loss=2.867, ppl=7.3, wps=87724.5, ups=3.02, wpb=29012.2, bsz=969.6, num_updates=202700, lr=7.02382e-05, gnorm=0.461, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-05 22:49:30 | INFO | train_inner | epoch 043:   3335 / 4751 loss=4.49, nll_loss=2.881, ppl=7.37, wps=88413.9, ups=3.02, wpb=29255.9, bsz=938, num_updates=202800, lr=7.02208e-05, gnorm=0.458, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-05 22:50:03 | INFO | train_inner | epoch 043:   3435 / 4751 loss=4.566, nll_loss=2.967, ppl=7.82, wps=87937.5, ups=3.02, wpb=29077.3, bsz=954.7, num_updates=202900, lr=7.02035e-05, gnorm=0.468, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-05 22:50:36 | INFO | train_inner | epoch 043:   3535 / 4751 loss=4.546, nll_loss=2.945, ppl=7.7, wps=87440.3, ups=3.03, wpb=28899.4, bsz=932.4, num_updates=203000, lr=7.01862e-05, gnorm=0.463, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-05 22:51:09 | INFO | train_inner | epoch 043:   3635 / 4751 loss=4.546, nll_loss=2.945, ppl=7.7, wps=87671.8, ups=3.02, wpb=29005.1, bsz=971.4, num_updates=203100, lr=7.0169e-05, gnorm=0.464, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-05 22:51:42 | INFO | train_inner | epoch 043:   3735 / 4751 loss=4.505, nll_loss=2.899, ppl=7.46, wps=87336, ups=3.04, wpb=28718.7, bsz=960.8, num_updates=203200, lr=7.01517e-05, gnorm=0.474, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-05 22:52:14 | INFO | train_inner | epoch 043:   3835 / 4751 loss=4.546, nll_loss=2.945, ppl=7.7, wps=88417.6, ups=3.06, wpb=28904, bsz=933.6, num_updates=203300, lr=7.01344e-05, gnorm=0.469, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-05 22:52:47 | INFO | train_inner | epoch 043:   3935 / 4751 loss=4.495, nll_loss=2.887, ppl=7.4, wps=88180.1, ups=3.03, wpb=29108.7, bsz=945.3, num_updates=203400, lr=7.01172e-05, gnorm=0.456, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-05 22:53:20 | INFO | train_inner | epoch 043:   4035 / 4751 loss=4.596, nll_loss=3.001, ppl=8.01, wps=87725.6, ups=3.03, wpb=28914.2, bsz=910.8, num_updates=203500, lr=7.01e-05, gnorm=0.467, loss_scale=2, train_wall=33, gb_free=6.7, wall=0
2021-04-05 22:53:54 | INFO | train_inner | epoch 043:   4135 / 4751 loss=4.604, nll_loss=3.01, ppl=8.06, wps=87173.2, ups=3.02, wpb=28882.8, bsz=925.5, num_updates=203600, lr=7.00827e-05, gnorm=0.465, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-05 22:54:26 | INFO | train_inner | epoch 043:   4235 / 4751 loss=4.533, nll_loss=2.931, ppl=7.62, wps=88283.9, ups=3.04, wpb=28998.2, bsz=960.7, num_updates=203700, lr=7.00655e-05, gnorm=0.46, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-05 22:54:59 | INFO | train_inner | epoch 043:   4335 / 4751 loss=4.583, nll_loss=2.987, ppl=7.93, wps=88266.9, ups=3.04, wpb=29007.8, bsz=918.3, num_updates=203800, lr=7.00484e-05, gnorm=0.463, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-05 22:55:32 | INFO | train_inner | epoch 043:   4435 / 4751 loss=4.527, nll_loss=2.924, ppl=7.59, wps=89143.3, ups=3.05, wpb=29273.1, bsz=958.3, num_updates=203900, lr=7.00312e-05, gnorm=0.454, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-05 22:56:05 | INFO | train_inner | epoch 043:   4535 / 4751 loss=4.626, nll_loss=3.035, ppl=8.2, wps=87935.3, ups=3.04, wpb=28924.7, bsz=939.5, num_updates=204000, lr=7.0014e-05, gnorm=0.468, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-05 22:56:38 | INFO | train_inner | epoch 043:   4635 / 4751 loss=4.595, nll_loss=3, ppl=8, wps=88580.3, ups=3.05, wpb=29054.1, bsz=948.5, num_updates=204100, lr=6.99969e-05, gnorm=0.463, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-05 22:57:11 | INFO | train_inner | epoch 043:   4735 / 4751 loss=4.546, nll_loss=2.945, ppl=7.7, wps=88102.3, ups=3.04, wpb=28952.7, bsz=968.5, num_updates=204200, lr=6.99797e-05, gnorm=0.487, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-05 22:57:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-05 22:57:17 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 4.168 | nll_loss 2.4 | ppl 5.28 | wps 207188 | wpb 10489.1 | bsz 375 | num_updates 204216 | best_loss 4.164
2021-04-05 22:57:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 204216 updates
2021-04-05 22:57:17 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-05 22:57:24 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-05 22:57:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt (epoch 43 @ 204216 updates, score 4.168) (writing took 6.766506355255842 seconds)
2021-04-05 22:57:24 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2021-04-05 22:57:24 | INFO | train | epoch 043 | loss 4.536 | nll_loss 2.933 | ppl 7.64 | wps 87364.4 | ups 3.02 | wpb 28967.7 | bsz 946.8 | num_updates 204216 | lr 6.9977e-05 | gnorm 0.464 | loss_scale 2 | train_wall 1554 | gb_free 6.8 | wall 0
2021-04-05 22:57:24 | INFO | fairseq.trainer | begin training epoch 44
2021-04-05 22:57:24 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-05 22:57:53 | INFO | train_inner | epoch 044:     84 / 4751 loss=4.557, nll_loss=2.957, ppl=7.76, wps=68172.5, ups=2.38, wpb=28609.1, bsz=920.1, num_updates=204300, lr=6.99626e-05, gnorm=0.474, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-05 22:58:26 | INFO | train_inner | epoch 044:    184 / 4751 loss=4.538, nll_loss=2.935, ppl=7.65, wps=87770.3, ups=3.02, wpb=29034.6, bsz=913.1, num_updates=204400, lr=6.99455e-05, gnorm=0.47, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-05 22:58:58 | INFO | train_inner | epoch 044:    284 / 4751 loss=4.54, nll_loss=2.938, ppl=7.66, wps=88795, ups=3.05, wpb=29070.2, bsz=942.8, num_updates=204500, lr=6.99284e-05, gnorm=0.469, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-05 22:59:31 | INFO | train_inner | epoch 044:    384 / 4751 loss=4.528, nll_loss=2.924, ppl=7.59, wps=88427.7, ups=3.04, wpb=29092.3, bsz=942.6, num_updates=204600, lr=6.99113e-05, gnorm=0.459, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-05 23:00:05 | INFO | train_inner | epoch 044:    484 / 4751 loss=4.516, nll_loss=2.911, ppl=7.52, wps=87795.8, ups=3.02, wpb=29092, bsz=951.8, num_updates=204700, lr=6.98942e-05, gnorm=0.473, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-05 23:00:38 | INFO | train_inner | epoch 044:    584 / 4751 loss=4.563, nll_loss=2.963, ppl=7.8, wps=87653, ups=3.03, wpb=28931.8, bsz=919.8, num_updates=204800, lr=6.98771e-05, gnorm=0.465, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-05 23:01:10 | INFO | train_inner | epoch 044:    684 / 4751 loss=4.491, nll_loss=2.882, ppl=7.37, wps=87183.8, ups=3.04, wpb=28717.2, bsz=954.5, num_updates=204900, lr=6.98601e-05, gnorm=0.463, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-05 23:01:43 | INFO | train_inner | epoch 044:    784 / 4751 loss=4.504, nll_loss=2.897, ppl=7.45, wps=88673.1, ups=3.05, wpb=29083.3, bsz=953.8, num_updates=205000, lr=6.9843e-05, gnorm=0.461, loss_scale=4, train_wall=33, gb_free=6.4, wall=0
2021-04-05 23:02:16 | INFO | train_inner | epoch 044:    884 / 4751 loss=4.527, nll_loss=2.923, ppl=7.59, wps=88377.5, ups=3.03, wpb=29145.6, bsz=952.5, num_updates=205100, lr=6.9826e-05, gnorm=0.464, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-05 23:02:49 | INFO | train_inner | epoch 044:    984 / 4751 loss=4.485, nll_loss=2.876, ppl=7.34, wps=87637.7, ups=3.03, wpb=28894, bsz=965.7, num_updates=205200, lr=6.9809e-05, gnorm=0.458, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-05 23:03:22 | INFO | train_inner | epoch 044:   1084 / 4751 loss=4.541, nll_loss=2.939, ppl=7.67, wps=88358.2, ups=3.05, wpb=28960.8, bsz=961.5, num_updates=205300, lr=6.9792e-05, gnorm=0.469, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-05 23:03:56 | INFO | train_inner | epoch 044:   1184 / 4751 loss=4.5, nll_loss=2.893, ppl=7.43, wps=86189.9, ups=2.97, wpb=29025.4, bsz=948.2, num_updates=205400, lr=6.9775e-05, gnorm=0.465, loss_scale=4, train_wall=34, gb_free=6.3, wall=0
2021-04-05 23:04:28 | INFO | train_inner | epoch 044:   1284 / 4751 loss=4.536, nll_loss=2.933, ppl=7.64, wps=88404.8, ups=3.05, wpb=29004.9, bsz=948.6, num_updates=205500, lr=6.9758e-05, gnorm=0.475, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-05 23:04:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-05 23:05:02 | INFO | train_inner | epoch 044:   1385 / 4751 loss=4.556, nll_loss=2.955, ppl=7.76, wps=86821.7, ups=2.99, wpb=29065.9, bsz=925.6, num_updates=205600, lr=6.9741e-05, gnorm=0.459, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-05 23:05:35 | INFO | train_inner | epoch 044:   1485 / 4751 loss=4.545, nll_loss=2.943, ppl=7.69, wps=88829.1, ups=3.05, wpb=29112.6, bsz=974.7, num_updates=205700, lr=6.97241e-05, gnorm=0.464, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-05 23:06:08 | INFO | train_inner | epoch 044:   1585 / 4751 loss=4.565, nll_loss=2.966, ppl=7.82, wps=87961, ups=3.03, wpb=29020.3, bsz=939.4, num_updates=205800, lr=6.97071e-05, gnorm=0.467, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-05 23:06:40 | INFO | train_inner | epoch 044:   1685 / 4751 loss=4.548, nll_loss=2.946, ppl=7.71, wps=88387.9, ups=3.06, wpb=28926.4, bsz=941.4, num_updates=205900, lr=6.96902e-05, gnorm=0.472, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-05 23:07:13 | INFO | train_inner | epoch 044:   1785 / 4751 loss=4.513, nll_loss=2.907, ppl=7.5, wps=87778.5, ups=3.03, wpb=29010.1, bsz=964.8, num_updates=206000, lr=6.96733e-05, gnorm=0.464, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-05 23:07:46 | INFO | train_inner | epoch 044:   1885 / 4751 loss=4.473, nll_loss=2.862, ppl=7.27, wps=88269.1, ups=3.04, wpb=29045.2, bsz=925.6, num_updates=206100, lr=6.96564e-05, gnorm=0.457, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-05 23:08:19 | INFO | train_inner | epoch 044:   1985 / 4751 loss=4.553, nll_loss=2.952, ppl=7.74, wps=87875, ups=3.04, wpb=28951.1, bsz=942.7, num_updates=206200, lr=6.96395e-05, gnorm=0.465, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-05 23:08:52 | INFO | train_inner | epoch 044:   2085 / 4751 loss=4.506, nll_loss=2.899, ppl=7.46, wps=87721.8, ups=3.02, wpb=29074.6, bsz=952.9, num_updates=206300, lr=6.96226e-05, gnorm=0.464, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-05 23:09:26 | INFO | train_inner | epoch 044:   2185 / 4751 loss=4.538, nll_loss=2.936, ppl=7.65, wps=88018.4, ups=3.03, wpb=29090.9, bsz=960.9, num_updates=206400, lr=6.96058e-05, gnorm=0.464, loss_scale=2, train_wall=33, gb_free=6.6, wall=0
2021-04-05 23:09:59 | INFO | train_inner | epoch 044:   2285 / 4751 loss=4.55, nll_loss=2.949, ppl=7.72, wps=86301.4, ups=3, wpb=28794.4, bsz=932.2, num_updates=206500, lr=6.95889e-05, gnorm=0.469, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-05 23:10:32 | INFO | train_inner | epoch 044:   2385 / 4751 loss=4.514, nll_loss=2.909, ppl=7.51, wps=87582.6, ups=3.01, wpb=29096.1, bsz=978.2, num_updates=206600, lr=6.95721e-05, gnorm=0.466, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-05 23:11:05 | INFO | train_inner | epoch 044:   2485 / 4751 loss=4.573, nll_loss=2.976, ppl=7.87, wps=87872.8, ups=3.06, wpb=28747.1, bsz=936.6, num_updates=206700, lr=6.95552e-05, gnorm=0.469, loss_scale=2, train_wall=33, gb_free=6.7, wall=0
2021-04-05 23:11:38 | INFO | train_inner | epoch 044:   2585 / 4751 loss=4.583, nll_loss=2.986, ppl=7.92, wps=87416.1, ups=3.04, wpb=28799.6, bsz=930.2, num_updates=206800, lr=6.95384e-05, gnorm=0.472, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-05 23:12:11 | INFO | train_inner | epoch 044:   2685 / 4751 loss=4.564, nll_loss=2.966, ppl=7.81, wps=88076.5, ups=3.04, wpb=28932.6, bsz=937.8, num_updates=206900, lr=6.95216e-05, gnorm=0.468, loss_scale=2, train_wall=33, gb_free=6.7, wall=0
2021-04-05 23:12:44 | INFO | train_inner | epoch 044:   2785 / 4751 loss=4.515, nll_loss=2.91, ppl=7.52, wps=87035.5, ups=3.03, wpb=28744.9, bsz=975.7, num_updates=207000, lr=6.95048e-05, gnorm=0.471, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-05 23:13:17 | INFO | train_inner | epoch 044:   2885 / 4751 loss=4.517, nll_loss=2.912, ppl=7.53, wps=87683.8, ups=3.03, wpb=28957.5, bsz=926.7, num_updates=207100, lr=6.9488e-05, gnorm=0.46, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-05 23:13:50 | INFO | train_inner | epoch 044:   2985 / 4751 loss=4.537, nll_loss=2.935, ppl=7.65, wps=88371.9, ups=3.03, wpb=29123.2, bsz=967.8, num_updates=207200, lr=6.94713e-05, gnorm=0.463, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-05 23:14:23 | INFO | train_inner | epoch 044:   3085 / 4751 loss=4.502, nll_loss=2.895, ppl=7.44, wps=88035.5, ups=3.04, wpb=28951.9, bsz=967.5, num_updates=207300, lr=6.94545e-05, gnorm=0.468, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-05 23:14:55 | INFO | train_inner | epoch 044:   3185 / 4751 loss=4.587, nll_loss=2.991, ppl=7.95, wps=87437, ups=3.04, wpb=28774.4, bsz=926.7, num_updates=207400, lr=6.94377e-05, gnorm=0.48, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-05 23:15:28 | INFO | train_inner | epoch 044:   3285 / 4751 loss=4.499, nll_loss=2.892, ppl=7.42, wps=88587.4, ups=3.04, wpb=29099.8, bsz=993, num_updates=207500, lr=6.9421e-05, gnorm=0.463, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-05 23:16:01 | INFO | train_inner | epoch 044:   3385 / 4751 loss=4.531, nll_loss=2.928, ppl=7.61, wps=88310.1, ups=3.05, wpb=28972.8, bsz=907.8, num_updates=207600, lr=6.94043e-05, gnorm=0.464, loss_scale=4, train_wall=33, gb_free=6.6, wall=0
2021-04-05 23:16:34 | INFO | train_inner | epoch 044:   3485 / 4751 loss=4.488, nll_loss=2.879, ppl=7.36, wps=88845.6, ups=3.04, wpb=29215.5, bsz=948.6, num_updates=207700, lr=6.93876e-05, gnorm=0.459, loss_scale=4, train_wall=33, gb_free=6, wall=0
2021-04-05 23:17:07 | INFO | train_inner | epoch 044:   3585 / 4751 loss=4.553, nll_loss=2.953, ppl=7.74, wps=87534, ups=3.03, wpb=28856.2, bsz=981, num_updates=207800, lr=6.93709e-05, gnorm=0.463, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-05 23:17:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-05 23:17:40 | INFO | train_inner | epoch 044:   3686 / 4751 loss=4.551, nll_loss=2.95, ppl=7.73, wps=86457, ups=2.99, wpb=28881.2, bsz=941.8, num_updates=207900, lr=6.93542e-05, gnorm=0.464, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-05 23:18:13 | INFO | train_inner | epoch 044:   3786 / 4751 loss=4.476, nll_loss=2.866, ppl=7.29, wps=87947.5, ups=3.04, wpb=28900.2, bsz=973.8, num_updates=208000, lr=6.93375e-05, gnorm=0.459, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-05 23:18:46 | INFO | train_inner | epoch 044:   3886 / 4751 loss=4.549, nll_loss=2.949, ppl=7.72, wps=89038.8, ups=3.06, wpb=29070.7, bsz=954.4, num_updates=208100, lr=6.93209e-05, gnorm=0.468, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-05 23:19:18 | INFO | train_inner | epoch 044:   3986 / 4751 loss=4.547, nll_loss=2.946, ppl=7.71, wps=89508.3, ups=3.06, wpb=29210.7, bsz=964.2, num_updates=208200, lr=6.93042e-05, gnorm=0.473, loss_scale=2, train_wall=32, gb_free=6.4, wall=0
2021-04-05 23:19:51 | INFO | train_inner | epoch 044:   4086 / 4751 loss=4.564, nll_loss=2.966, ppl=7.81, wps=87520.4, ups=3.03, wpb=28894.1, bsz=952.7, num_updates=208300, lr=6.92876e-05, gnorm=0.462, loss_scale=2, train_wall=33, gb_free=6.8, wall=0
2021-04-05 23:20:25 | INFO | train_inner | epoch 044:   4186 / 4751 loss=4.542, nll_loss=2.94, ppl=7.68, wps=87243.7, ups=3.02, wpb=28843.1, bsz=961.1, num_updates=208400, lr=6.92709e-05, gnorm=0.47, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-05 23:20:58 | INFO | train_inner | epoch 044:   4286 / 4751 loss=4.531, nll_loss=2.928, ppl=7.61, wps=87338.4, ups=3.04, wpb=28774, bsz=933, num_updates=208500, lr=6.92543e-05, gnorm=0.473, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-05 23:21:31 | INFO | train_inner | epoch 044:   4386 / 4751 loss=4.553, nll_loss=2.953, ppl=7.74, wps=87673.6, ups=3.02, wpb=29018.2, bsz=941, num_updates=208600, lr=6.92377e-05, gnorm=0.462, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-05 23:22:03 | INFO | train_inner | epoch 044:   4486 / 4751 loss=4.575, nll_loss=2.977, ppl=7.88, wps=88038.1, ups=3.05, wpb=28870.5, bsz=915, num_updates=208700, lr=6.92211e-05, gnorm=0.459, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-05 23:22:36 | INFO | train_inner | epoch 044:   4586 / 4751 loss=4.509, nll_loss=2.902, ppl=7.48, wps=87952, ups=3.04, wpb=28886.7, bsz=914.9, num_updates=208800, lr=6.92046e-05, gnorm=0.464, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-05 23:23:09 | INFO | train_inner | epoch 044:   4686 / 4751 loss=4.575, nll_loss=2.977, ppl=7.88, wps=87875.8, ups=3.04, wpb=28925.4, bsz=935.2, num_updates=208900, lr=6.9188e-05, gnorm=0.461, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-05 23:23:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-05 23:23:32 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 4.159 | nll_loss 2.39 | ppl 5.24 | wps 180345 | wpb 10489.1 | bsz 375 | num_updates 208965 | best_loss 4.159
2021-04-05 23:23:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 208965 updates
2021-04-05 23:23:32 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 23:23:38 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-05 23:23:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt (epoch 44 @ 208965 updates, score 4.159) (writing took 12.81860900297761 seconds)
2021-04-05 23:23:44 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2021-04-05 23:23:44 | INFO | train | epoch 044 | loss 4.533 | nll_loss 2.93 | ppl 7.62 | wps 87035.2 | ups 3 | wpb 28967.8 | bsz 946.7 | num_updates 208965 | lr 6.91772e-05 | gnorm 0.466 | loss_scale 2 | train_wall 1558 | gb_free 6.3 | wall 0
2021-04-05 23:23:45 | INFO | fairseq.trainer | begin training epoch 45
2021-04-05 23:23:45 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-05 23:23:57 | INFO | train_inner | epoch 045:     35 / 4751 loss=4.528, nll_loss=2.925, ppl=7.59, wps=60403.3, ups=2.08, wpb=29018.8, bsz=906.6, num_updates=209000, lr=6.91714e-05, gnorm=0.465, loss_scale=2, train_wall=32, gb_free=6.5, wall=0
2021-04-05 23:24:30 | INFO | train_inner | epoch 045:    135 / 4751 loss=4.577, nll_loss=2.98, ppl=7.89, wps=86708.6, ups=3.03, wpb=28571.4, bsz=945.6, num_updates=209100, lr=6.91549e-05, gnorm=0.504, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-05 23:25:03 | INFO | train_inner | epoch 045:    235 / 4751 loss=4.527, nll_loss=2.923, ppl=7.58, wps=87423.9, ups=3.03, wpb=28894.2, bsz=956.6, num_updates=209200, lr=6.91384e-05, gnorm=0.467, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-05 23:25:36 | INFO | train_inner | epoch 045:    335 / 4751 loss=4.584, nll_loss=2.988, ppl=7.93, wps=88032.5, ups=3.06, wpb=28792.2, bsz=930.1, num_updates=209300, lr=6.91219e-05, gnorm=0.473, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-05 23:26:09 | INFO | train_inner | epoch 045:    435 / 4751 loss=4.58, nll_loss=2.982, ppl=7.9, wps=87075.7, ups=3.04, wpb=28648.4, bsz=904.8, num_updates=209400, lr=6.91053e-05, gnorm=0.472, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-05 23:26:42 | INFO | train_inner | epoch 045:    535 / 4751 loss=4.481, nll_loss=2.872, ppl=7.32, wps=87390.7, ups=3.03, wpb=28829.8, bsz=962.2, num_updates=209500, lr=6.90889e-05, gnorm=0.46, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-05 23:27:15 | INFO | train_inner | epoch 045:    635 / 4751 loss=4.539, nll_loss=2.937, ppl=7.66, wps=88352.8, ups=3.05, wpb=29015.2, bsz=966.6, num_updates=209600, lr=6.90724e-05, gnorm=0.464, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-05 23:27:48 | INFO | train_inner | epoch 045:    735 / 4751 loss=4.509, nll_loss=2.903, ppl=7.48, wps=87625.7, ups=3.04, wpb=28853.5, bsz=948.5, num_updates=209700, lr=6.90559e-05, gnorm=0.464, loss_scale=2, train_wall=33, gb_free=6.6, wall=0
2021-04-05 23:28:21 | INFO | train_inner | epoch 045:    835 / 4751 loss=4.504, nll_loss=2.897, ppl=7.45, wps=87423.8, ups=3.02, wpb=28938.6, bsz=969.4, num_updates=209800, lr=6.90394e-05, gnorm=0.489, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-05 23:28:54 | INFO | train_inner | epoch 045:    935 / 4751 loss=4.494, nll_loss=2.886, ppl=7.39, wps=89315, ups=3.04, wpb=29354.2, bsz=974.6, num_updates=209900, lr=6.9023e-05, gnorm=0.461, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-05 23:29:26 | INFO | train_inner | epoch 045:   1035 / 4751 loss=4.495, nll_loss=2.887, ppl=7.4, wps=87893.2, ups=3.03, wpb=28969.4, bsz=947.6, num_updates=210000, lr=6.90066e-05, gnorm=0.464, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-05 23:29:59 | INFO | train_inner | epoch 045:   1135 / 4751 loss=4.536, nll_loss=2.934, ppl=7.64, wps=87658.5, ups=3.04, wpb=28858.3, bsz=938, num_updates=210100, lr=6.89901e-05, gnorm=0.472, loss_scale=4, train_wall=33, gb_free=6, wall=0
2021-04-05 23:30:32 | INFO | train_inner | epoch 045:   1235 / 4751 loss=4.499, nll_loss=2.891, ppl=7.42, wps=88502.2, ups=3.03, wpb=29202.1, bsz=959.6, num_updates=210200, lr=6.89737e-05, gnorm=0.463, loss_scale=4, train_wall=33, gb_free=6.4, wall=0
2021-04-05 23:31:05 | INFO | train_inner | epoch 045:   1335 / 4751 loss=4.513, nll_loss=2.907, ppl=7.5, wps=88343.5, ups=3.04, wpb=29037.1, bsz=939.4, num_updates=210300, lr=6.89573e-05, gnorm=0.465, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-05 23:31:38 | INFO | train_inner | epoch 045:   1435 / 4751 loss=4.49, nll_loss=2.881, ppl=7.37, wps=87717.7, ups=3.02, wpb=29032.5, bsz=949.2, num_updates=210400, lr=6.89409e-05, gnorm=0.463, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-05 23:32:11 | INFO | train_inner | epoch 045:   1535 / 4751 loss=4.551, nll_loss=2.95, ppl=7.73, wps=87923.8, ups=3.05, wpb=28868.9, bsz=929.1, num_updates=210500, lr=6.89246e-05, gnorm=0.468, loss_scale=4, train_wall=33, gb_free=6.4, wall=0
2021-04-05 23:32:44 | INFO | train_inner | epoch 045:   1635 / 4751 loss=4.544, nll_loss=2.942, ppl=7.69, wps=88908.7, ups=3.04, wpb=29223.5, bsz=959.8, num_updates=210600, lr=6.89082e-05, gnorm=0.465, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-05 23:33:17 | INFO | train_inner | epoch 045:   1735 / 4751 loss=4.512, nll_loss=2.906, ppl=7.49, wps=88908.4, ups=3.06, wpb=29074.4, bsz=970.2, num_updates=210700, lr=6.88918e-05, gnorm=0.465, loss_scale=4, train_wall=33, gb_free=6, wall=0
2021-04-05 23:33:49 | INFO | train_inner | epoch 045:   1835 / 4751 loss=4.58, nll_loss=2.984, ppl=7.91, wps=88202.7, ups=3.06, wpb=28835.5, bsz=938.2, num_updates=210800, lr=6.88755e-05, gnorm=0.468, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-05 23:34:23 | INFO | train_inner | epoch 045:   1935 / 4751 loss=4.489, nll_loss=2.88, ppl=7.36, wps=87822.2, ups=3.01, wpb=29151, bsz=963.8, num_updates=210900, lr=6.88592e-05, gnorm=0.458, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-05 23:34:55 | INFO | train_inner | epoch 045:   2035 / 4751 loss=4.552, nll_loss=2.951, ppl=7.73, wps=88199.5, ups=3.05, wpb=28943.1, bsz=936.2, num_updates=211000, lr=6.88428e-05, gnorm=0.472, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-05 23:35:28 | INFO | train_inner | epoch 045:   2135 / 4751 loss=4.434, nll_loss=2.819, ppl=7.06, wps=87650.4, ups=3.04, wpb=28821.5, bsz=960.8, num_updates=211100, lr=6.88265e-05, gnorm=0.461, loss_scale=4, train_wall=33, gb_free=5.9, wall=0
2021-04-05 23:36:02 | INFO | train_inner | epoch 045:   2235 / 4751 loss=4.53, nll_loss=2.926, ppl=7.6, wps=86174.6, ups=2.97, wpb=29005.3, bsz=953.2, num_updates=211200, lr=6.88102e-05, gnorm=0.462, loss_scale=4, train_wall=34, gb_free=6, wall=0
2021-04-05 23:36:35 | INFO | train_inner | epoch 045:   2335 / 4751 loss=4.495, nll_loss=2.887, ppl=7.4, wps=89481.4, ups=3.04, wpb=29386.9, bsz=941.5, num_updates=211300, lr=6.8794e-05, gnorm=0.46, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-05 23:37:08 | INFO | train_inner | epoch 045:   2435 / 4751 loss=4.581, nll_loss=2.984, ppl=7.91, wps=88661.2, ups=3.04, wpb=29125, bsz=904.8, num_updates=211400, lr=6.87777e-05, gnorm=0.466, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-05 23:37:41 | INFO | train_inner | epoch 045:   2535 / 4751 loss=4.589, nll_loss=2.994, ppl=7.97, wps=87725.3, ups=3.05, wpb=28761.6, bsz=949.6, num_updates=211500, lr=6.87614e-05, gnorm=0.473, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-05 23:38:14 | INFO | train_inner | epoch 045:   2635 / 4751 loss=4.506, nll_loss=2.899, ppl=7.46, wps=87578.8, ups=3.03, wpb=28899, bsz=944.6, num_updates=211600, lr=6.87452e-05, gnorm=0.464, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-05 23:38:46 | INFO | train_inner | epoch 045:   2735 / 4751 loss=4.556, nll_loss=2.957, ppl=7.76, wps=87742, ups=3.04, wpb=28907.1, bsz=968.9, num_updates=211700, lr=6.87289e-05, gnorm=0.473, loss_scale=4, train_wall=33, gb_free=7.1, wall=0
2021-04-05 23:39:20 | INFO | train_inner | epoch 045:   2835 / 4751 loss=4.463, nll_loss=2.851, ppl=7.21, wps=87864.7, ups=3.02, wpb=29062.9, bsz=959.3, num_updates=211800, lr=6.87127e-05, gnorm=0.476, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-05 23:39:52 | INFO | train_inner | epoch 045:   2935 / 4751 loss=4.53, nll_loss=2.928, ppl=7.61, wps=88072.8, ups=3.04, wpb=28946.9, bsz=939.8, num_updates=211900, lr=6.86965e-05, gnorm=0.469, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-05 23:40:25 | INFO | train_inner | epoch 045:   3035 / 4751 loss=4.565, nll_loss=2.966, ppl=7.81, wps=88243.3, ups=3.04, wpb=29049.9, bsz=937.4, num_updates=212000, lr=6.86803e-05, gnorm=0.465, loss_scale=8, train_wall=33, gb_free=6.3, wall=0
2021-04-05 23:40:58 | INFO | train_inner | epoch 045:   3135 / 4751 loss=4.559, nll_loss=2.96, ppl=7.78, wps=87138.9, ups=3.02, wpb=28810.4, bsz=969.1, num_updates=212100, lr=6.86641e-05, gnorm=0.472, loss_scale=8, train_wall=33, gb_free=6.1, wall=0
2021-04-05 23:41:31 | INFO | train_inner | epoch 045:   3235 / 4751 loss=4.528, nll_loss=2.925, ppl=7.59, wps=88232.7, ups=3.04, wpb=29031, bsz=957.4, num_updates=212200, lr=6.86479e-05, gnorm=0.47, loss_scale=8, train_wall=33, gb_free=6.3, wall=0
2021-04-05 23:42:04 | INFO | train_inner | epoch 045:   3335 / 4751 loss=4.559, nll_loss=2.959, ppl=7.78, wps=88336.5, ups=3.03, wpb=29198.1, bsz=947, num_updates=212300, lr=6.86317e-05, gnorm=0.466, loss_scale=8, train_wall=33, gb_free=6.3, wall=0
2021-04-05 23:42:37 | INFO | train_inner | epoch 045:   3435 / 4751 loss=4.508, nll_loss=2.902, ppl=7.47, wps=88370.9, ups=3.04, wpb=29114.9, bsz=969.3, num_updates=212400, lr=6.86156e-05, gnorm=0.463, loss_scale=8, train_wall=33, gb_free=6, wall=0
2021-04-05 23:43:10 | INFO | train_inner | epoch 045:   3535 / 4751 loss=4.515, nll_loss=2.909, ppl=7.51, wps=88000.2, ups=3.03, wpb=29063.7, bsz=938.6, num_updates=212500, lr=6.85994e-05, gnorm=0.463, loss_scale=8, train_wall=33, gb_free=6.3, wall=0
2021-04-05 23:43:43 | INFO | train_inner | epoch 045:   3635 / 4751 loss=4.583, nll_loss=2.987, ppl=7.93, wps=86168.4, ups=3.04, wpb=28329.8, bsz=955.9, num_updates=212600, lr=6.85833e-05, gnorm=0.477, loss_scale=8, train_wall=33, gb_free=6.1, wall=0
2021-04-05 23:44:16 | INFO | train_inner | epoch 045:   3735 / 4751 loss=4.542, nll_loss=2.94, ppl=7.67, wps=87638.6, ups=3.03, wpb=28914.5, bsz=931.6, num_updates=212700, lr=6.85672e-05, gnorm=0.465, loss_scale=8, train_wall=33, gb_free=6.2, wall=0
2021-04-05 23:44:49 | INFO | train_inner | epoch 045:   3835 / 4751 loss=4.537, nll_loss=2.935, ppl=7.65, wps=87772.9, ups=3.03, wpb=29005.4, bsz=910.6, num_updates=212800, lr=6.85511e-05, gnorm=0.466, loss_scale=8, train_wall=33, gb_free=6.4, wall=0
2021-04-05 23:45:22 | INFO | train_inner | epoch 045:   3935 / 4751 loss=4.479, nll_loss=2.87, ppl=7.31, wps=87603.4, ups=3.02, wpb=29033.5, bsz=936.6, num_updates=212900, lr=6.8535e-05, gnorm=0.46, loss_scale=8, train_wall=33, gb_free=6.1, wall=0
2021-04-05 23:45:56 | INFO | train_inner | epoch 045:   4035 / 4751 loss=4.557, nll_loss=2.957, ppl=7.77, wps=87757.3, ups=3.02, wpb=29094.6, bsz=944.4, num_updates=213000, lr=6.85189e-05, gnorm=0.469, loss_scale=8, train_wall=33, gb_free=6.3, wall=0
2021-04-05 23:46:29 | INFO | train_inner | epoch 045:   4135 / 4751 loss=4.522, nll_loss=2.918, ppl=7.56, wps=87822.9, ups=3.03, wpb=29026.7, bsz=945.7, num_updates=213100, lr=6.85028e-05, gnorm=0.463, loss_scale=8, train_wall=33, gb_free=6.3, wall=0
2021-04-05 23:47:01 | INFO | train_inner | epoch 045:   4235 / 4751 loss=4.563, nll_loss=2.965, ppl=7.81, wps=87989.9, ups=3.05, wpb=28833.2, bsz=949.4, num_updates=213200, lr=6.84867e-05, gnorm=0.468, loss_scale=8, train_wall=33, gb_free=6.1, wall=0
2021-04-05 23:47:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2021-04-05 23:47:35 | INFO | train_inner | epoch 045:   4336 / 4751 loss=4.537, nll_loss=2.935, ppl=7.65, wps=87089, ups=3, wpb=29026.2, bsz=922, num_updates=213300, lr=6.84707e-05, gnorm=0.469, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-05 23:48:07 | INFO | train_inner | epoch 045:   4436 / 4751 loss=4.59, nll_loss=2.994, ppl=7.97, wps=88906.1, ups=3.05, wpb=29132.9, bsz=942.3, num_updates=213400, lr=6.84546e-05, gnorm=0.474, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-05 23:48:40 | INFO | train_inner | epoch 045:   4536 / 4751 loss=4.481, nll_loss=2.871, ppl=7.32, wps=88417.8, ups=3.03, wpb=29179.1, bsz=958.1, num_updates=213500, lr=6.84386e-05, gnorm=0.458, loss_scale=4, train_wall=33, gb_free=6.7, wall=0
2021-04-05 23:49:13 | INFO | train_inner | epoch 045:   4636 / 4751 loss=4.529, nll_loss=2.925, ppl=7.6, wps=87434.5, ups=3.03, wpb=28833.3, bsz=952.4, num_updates=213600, lr=6.84226e-05, gnorm=0.462, loss_scale=4, train_wall=33, gb_free=6, wall=0
2021-04-05 23:49:46 | INFO | train_inner | epoch 045:   4736 / 4751 loss=4.547, nll_loss=2.946, ppl=7.71, wps=88258.8, ups=3.05, wpb=28965.9, bsz=950.6, num_updates=213700, lr=6.84066e-05, gnorm=0.469, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-05 23:49:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-05 23:49:52 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 4.164 | nll_loss 2.394 | ppl 5.26 | wps 210824 | wpb 10489.1 | bsz 375 | num_updates 213715 | best_loss 4.159
2021-04-05 23:49:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 213715 updates
2021-04-05 23:49:52 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-05 23:49:59 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-05 23:49:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt (epoch 45 @ 213715 updates, score 4.164) (writing took 6.7451628521084785 seconds)
2021-04-05 23:49:59 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2021-04-05 23:49:59 | INFO | train | epoch 045 | loss 4.531 | nll_loss 2.927 | ppl 7.61 | wps 87391.2 | ups 3.02 | wpb 28969.2 | bsz 947.2 | num_updates 213715 | lr 6.84042e-05 | gnorm 0.468 | loss_scale 4 | train_wall 1558 | gb_free 6.1 | wall 0
2021-04-05 23:49:59 | INFO | fairseq.trainer | begin training epoch 46
2021-04-05 23:49:59 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-05 23:50:28 | INFO | train_inner | epoch 046:     85 / 4751 loss=4.487, nll_loss=2.879, ppl=7.35, wps=69083.4, ups=2.38, wpb=29053.2, bsz=981.7, num_updates=213800, lr=6.83906e-05, gnorm=0.462, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-05 23:51:01 | INFO | train_inner | epoch 046:    185 / 4751 loss=4.557, nll_loss=2.957, ppl=7.77, wps=87454, ups=3.05, wpb=28687.1, bsz=937.9, num_updates=213900, lr=6.83746e-05, gnorm=0.473, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-05 23:51:34 | INFO | train_inner | epoch 046:    285 / 4751 loss=4.561, nll_loss=2.961, ppl=7.79, wps=87106.5, ups=3.02, wpb=28867.8, bsz=912.3, num_updates=214000, lr=6.83586e-05, gnorm=0.466, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-05 23:52:07 | INFO | train_inner | epoch 046:    385 / 4751 loss=4.55, nll_loss=2.948, ppl=7.72, wps=87371.5, ups=3.06, wpb=28587.5, bsz=919.6, num_updates=214100, lr=6.83426e-05, gnorm=0.47, loss_scale=4, train_wall=33, gb_free=6.5, wall=0
2021-04-05 23:52:40 | INFO | train_inner | epoch 046:    485 / 4751 loss=4.488, nll_loss=2.879, ppl=7.36, wps=88742.2, ups=3.04, wpb=29174.8, bsz=952.3, num_updates=214200, lr=6.83267e-05, gnorm=0.459, loss_scale=4, train_wall=33, gb_free=6.5, wall=0
2021-04-05 23:53:13 | INFO | train_inner | epoch 046:    585 / 4751 loss=4.522, nll_loss=2.917, ppl=7.55, wps=88495.8, ups=3.03, wpb=29182.2, bsz=935.4, num_updates=214300, lr=6.83107e-05, gnorm=0.466, loss_scale=4, train_wall=33, gb_free=6, wall=0
2021-04-05 23:53:46 | INFO | train_inner | epoch 046:    685 / 4751 loss=4.545, nll_loss=2.943, ppl=7.69, wps=87704.7, ups=3.04, wpb=28827.4, bsz=938.2, num_updates=214400, lr=6.82948e-05, gnorm=0.467, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-05 23:54:19 | INFO | train_inner | epoch 046:    785 / 4751 loss=4.573, nll_loss=2.974, ppl=7.86, wps=87682.1, ups=3.03, wpb=28941, bsz=908.8, num_updates=214500, lr=6.82789e-05, gnorm=0.466, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-05 23:54:52 | INFO | train_inner | epoch 046:    885 / 4751 loss=4.478, nll_loss=2.867, ppl=7.3, wps=87100.4, ups=3.02, wpb=28870.6, bsz=939.7, num_updates=214600, lr=6.8263e-05, gnorm=0.462, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-05 23:55:25 | INFO | train_inner | epoch 046:    985 / 4751 loss=4.546, nll_loss=2.945, ppl=7.7, wps=88225.6, ups=3.03, wpb=29125.9, bsz=942.2, num_updates=214700, lr=6.82471e-05, gnorm=0.468, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-05 23:55:58 | INFO | train_inner | epoch 046:   1085 / 4751 loss=4.511, nll_loss=2.905, ppl=7.49, wps=88335.8, ups=3.04, wpb=29056, bsz=962.3, num_updates=214800, lr=6.82312e-05, gnorm=0.469, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-05 23:56:31 | INFO | train_inner | epoch 046:   1185 / 4751 loss=4.518, nll_loss=2.913, ppl=7.53, wps=88670.7, ups=3.04, wpb=29208.8, bsz=972.7, num_updates=214900, lr=6.82153e-05, gnorm=0.469, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-05 23:57:04 | INFO | train_inner | epoch 046:   1285 / 4751 loss=4.508, nll_loss=2.902, ppl=7.47, wps=87730, ups=3.02, wpb=29015, bsz=956.8, num_updates=215000, lr=6.81994e-05, gnorm=0.468, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-05 23:57:37 | INFO | train_inner | epoch 046:   1385 / 4751 loss=4.508, nll_loss=2.901, ppl=7.47, wps=88112.9, ups=3.02, wpb=29147.4, bsz=935.3, num_updates=215100, lr=6.81836e-05, gnorm=0.461, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-05 23:58:10 | INFO | train_inner | epoch 046:   1485 / 4751 loss=4.534, nll_loss=2.931, ppl=7.63, wps=88181.4, ups=3.04, wpb=29025.5, bsz=977.8, num_updates=215200, lr=6.81677e-05, gnorm=0.474, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-05 23:58:43 | INFO | train_inner | epoch 046:   1585 / 4751 loss=4.555, nll_loss=2.955, ppl=7.76, wps=87891.6, ups=3.04, wpb=28880.6, bsz=959, num_updates=215300, lr=6.81519e-05, gnorm=0.469, loss_scale=4, train_wall=33, gb_free=6.4, wall=0
2021-04-05 23:59:16 | INFO | train_inner | epoch 046:   1685 / 4751 loss=4.495, nll_loss=2.887, ppl=7.4, wps=87333.8, ups=3.04, wpb=28772.8, bsz=972.3, num_updates=215400, lr=6.81361e-05, gnorm=0.467, loss_scale=8, train_wall=33, gb_free=6.2, wall=0
2021-04-05 23:59:49 | INFO | train_inner | epoch 046:   1785 / 4751 loss=4.548, nll_loss=2.947, ppl=7.71, wps=85963, ups=2.99, wpb=28783.3, bsz=927.7, num_updates=215500, lr=6.81203e-05, gnorm=0.474, loss_scale=8, train_wall=33, gb_free=6.5, wall=0
2021-04-06 00:00:22 | INFO | train_inner | epoch 046:   1885 / 4751 loss=4.552, nll_loss=2.951, ppl=7.73, wps=88704.8, ups=3.04, wpb=29151.5, bsz=932.4, num_updates=215600, lr=6.81045e-05, gnorm=0.462, loss_scale=8, train_wall=33, gb_free=6.4, wall=0
2021-04-06 00:00:55 | INFO | train_inner | epoch 046:   1985 / 4751 loss=4.559, nll_loss=2.959, ppl=7.78, wps=88581.4, ups=3.04, wpb=29158.6, bsz=970.6, num_updates=215700, lr=6.80887e-05, gnorm=0.468, loss_scale=8, train_wall=33, gb_free=6, wall=0
2021-04-06 00:00:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2021-04-06 00:01:28 | INFO | train_inner | epoch 046:   2086 / 4751 loss=4.521, nll_loss=2.916, ppl=7.55, wps=87184, ups=2.99, wpb=29126.7, bsz=946.6, num_updates=215800, lr=6.80729e-05, gnorm=0.464, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 00:02:01 | INFO | train_inner | epoch 046:   2186 / 4751 loss=4.49, nll_loss=2.881, ppl=7.37, wps=87542.2, ups=3.02, wpb=28957, bsz=946.3, num_updates=215900, lr=6.80571e-05, gnorm=0.463, loss_scale=4, train_wall=33, gb_free=6, wall=0
2021-04-06 00:02:34 | INFO | train_inner | epoch 046:   2286 / 4751 loss=4.525, nll_loss=2.921, ppl=7.57, wps=87617.4, ups=3.03, wpb=28919.8, bsz=925.2, num_updates=216000, lr=6.80414e-05, gnorm=0.464, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-06 00:03:07 | INFO | train_inner | epoch 046:   2386 / 4751 loss=4.516, nll_loss=2.91, ppl=7.52, wps=87666.7, ups=3.03, wpb=28893.5, bsz=936.7, num_updates=216100, lr=6.80256e-05, gnorm=0.467, loss_scale=4, train_wall=33, gb_free=6.4, wall=0
2021-04-06 00:03:40 | INFO | train_inner | epoch 046:   2486 / 4751 loss=4.495, nll_loss=2.888, ppl=7.4, wps=88132.9, ups=3.02, wpb=29224.4, bsz=966.1, num_updates=216200, lr=6.80099e-05, gnorm=0.457, loss_scale=4, train_wall=33, gb_free=6.4, wall=0
2021-04-06 00:04:13 | INFO | train_inner | epoch 046:   2586 / 4751 loss=4.548, nll_loss=2.948, ppl=7.72, wps=87289.6, ups=3.04, wpb=28711.4, bsz=976.6, num_updates=216300, lr=6.79942e-05, gnorm=0.475, loss_scale=4, train_wall=33, gb_free=6.4, wall=0
2021-04-06 00:04:46 | INFO | train_inner | epoch 046:   2686 / 4751 loss=4.555, nll_loss=2.956, ppl=7.76, wps=87810.3, ups=3.05, wpb=28819.9, bsz=955.8, num_updates=216400, lr=6.79785e-05, gnorm=0.468, loss_scale=4, train_wall=33, gb_free=6.4, wall=0
2021-04-06 00:05:19 | INFO | train_inner | epoch 046:   2786 / 4751 loss=4.575, nll_loss=2.978, ppl=7.88, wps=89103.6, ups=3.05, wpb=29175.9, bsz=944.5, num_updates=216500, lr=6.79628e-05, gnorm=0.469, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 00:05:52 | INFO | train_inner | epoch 046:   2886 / 4751 loss=4.524, nll_loss=2.92, ppl=7.57, wps=88914.7, ups=3.05, wpb=29144.8, bsz=945.1, num_updates=216600, lr=6.79471e-05, gnorm=0.466, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-06 00:05:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-06 00:06:25 | INFO | train_inner | epoch 046:   2987 / 4751 loss=4.512, nll_loss=2.906, ppl=7.5, wps=85999.2, ups=2.99, wpb=28771.2, bsz=952, num_updates=216700, lr=6.79314e-05, gnorm=0.475, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 00:06:58 | INFO | train_inner | epoch 046:   3087 / 4751 loss=4.506, nll_loss=2.9, ppl=7.46, wps=87963.6, ups=3.03, wpb=28996.2, bsz=924.2, num_updates=216800, lr=6.79157e-05, gnorm=0.469, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 00:07:31 | INFO | train_inner | epoch 046:   3187 / 4751 loss=4.529, nll_loss=2.926, ppl=7.6, wps=87754.4, ups=3.02, wpb=29050.1, bsz=974.2, num_updates=216900, lr=6.79001e-05, gnorm=0.467, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 00:08:04 | INFO | train_inner | epoch 046:   3287 / 4751 loss=4.574, nll_loss=2.976, ppl=7.87, wps=87729.1, ups=3.04, wpb=28885, bsz=941.7, num_updates=217000, lr=6.78844e-05, gnorm=0.49, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 00:08:37 | INFO | train_inner | epoch 046:   3387 / 4751 loss=4.528, nll_loss=2.925, ppl=7.59, wps=88830.9, ups=3.04, wpb=29205, bsz=971.6, num_updates=217100, lr=6.78688e-05, gnorm=0.463, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 00:09:10 | INFO | train_inner | epoch 046:   3487 / 4751 loss=4.52, nll_loss=2.916, ppl=7.55, wps=88030.9, ups=3.03, wpb=29030.1, bsz=944, num_updates=217200, lr=6.78532e-05, gnorm=0.467, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 00:09:43 | INFO | train_inner | epoch 046:   3587 / 4751 loss=4.55, nll_loss=2.95, ppl=7.73, wps=87582.2, ups=3.03, wpb=28889.2, bsz=971.7, num_updates=217300, lr=6.78375e-05, gnorm=0.467, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 00:10:16 | INFO | train_inner | epoch 046:   3687 / 4751 loss=4.522, nll_loss=2.918, ppl=7.56, wps=88359.9, ups=3.03, wpb=29117.6, bsz=965.4, num_updates=217400, lr=6.78219e-05, gnorm=0.464, loss_scale=2, train_wall=33, gb_free=7, wall=0
2021-04-06 00:10:49 | INFO | train_inner | epoch 046:   3787 / 4751 loss=4.515, nll_loss=2.91, ppl=7.52, wps=88074.9, ups=3.03, wpb=29054.2, bsz=965, num_updates=217500, lr=6.78064e-05, gnorm=0.464, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 00:11:22 | INFO | train_inner | epoch 046:   3887 / 4751 loss=4.563, nll_loss=2.964, ppl=7.8, wps=87735.7, ups=3.05, wpb=28730.3, bsz=938.4, num_updates=217600, lr=6.77908e-05, gnorm=0.49, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 00:11:55 | INFO | train_inner | epoch 046:   3987 / 4751 loss=4.514, nll_loss=2.909, ppl=7.51, wps=88009.7, ups=3.04, wpb=28923.3, bsz=942.8, num_updates=217700, lr=6.77752e-05, gnorm=0.469, loss_scale=2, train_wall=33, gb_free=6.6, wall=0
2021-04-06 00:12:27 | INFO | train_inner | epoch 046:   4087 / 4751 loss=4.503, nll_loss=2.897, ppl=7.45, wps=88462.7, ups=3.05, wpb=28997.9, bsz=959, num_updates=217800, lr=6.77596e-05, gnorm=0.465, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 00:13:00 | INFO | train_inner | epoch 046:   4187 / 4751 loss=4.495, nll_loss=2.888, ppl=7.4, wps=88175.9, ups=3.05, wpb=28941.7, bsz=936.3, num_updates=217900, lr=6.77441e-05, gnorm=0.465, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 00:13:33 | INFO | train_inner | epoch 046:   4287 / 4751 loss=4.559, nll_loss=2.96, ppl=7.78, wps=87571, ups=3.03, wpb=28888.4, bsz=954.1, num_updates=218000, lr=6.77285e-05, gnorm=0.47, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-06 00:14:06 | INFO | train_inner | epoch 046:   4387 / 4751 loss=4.483, nll_loss=2.874, ppl=7.33, wps=87688.7, ups=3.02, wpb=29000.4, bsz=916.2, num_updates=218100, lr=6.7713e-05, gnorm=0.459, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 00:14:39 | INFO | train_inner | epoch 046:   4487 / 4751 loss=4.541, nll_loss=2.939, ppl=7.67, wps=87087.6, ups=3.04, wpb=28654.8, bsz=939.8, num_updates=218200, lr=6.76975e-05, gnorm=0.472, loss_scale=2, train_wall=33, gb_free=6.6, wall=0
2021-04-06 00:15:12 | INFO | train_inner | epoch 046:   4587 / 4751 loss=4.557, nll_loss=2.958, ppl=7.77, wps=88285.2, ups=3.04, wpb=29084, bsz=918.2, num_updates=218300, lr=6.7682e-05, gnorm=0.472, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 00:15:45 | INFO | train_inner | epoch 046:   4687 / 4751 loss=4.54, nll_loss=2.938, ppl=7.66, wps=87042.3, ups=3.03, wpb=28727.6, bsz=943, num_updates=218400, lr=6.76665e-05, gnorm=0.467, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 00:16:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-06 00:16:07 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 4.172 | nll_loss 2.399 | ppl 5.27 | wps 188920 | wpb 10489.1 | bsz 375 | num_updates 218464 | best_loss 4.159
2021-04-06 00:16:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 218464 updates
2021-04-06 00:16:07 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-06 00:16:13 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-06 00:16:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt (epoch 46 @ 218464 updates, score 4.172) (writing took 5.9902780167758465 seconds)
2021-04-06 00:16:13 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2021-04-06 00:16:13 | INFO | train | epoch 046 | loss 4.529 | nll_loss 2.925 | ppl 7.6 | wps 87392.4 | ups 3.02 | wpb 28968.7 | bsz 946.8 | num_updates 218464 | lr 6.76566e-05 | gnorm 0.468 | loss_scale 2 | train_wall 1559 | gb_free 6.3 | wall 0
2021-04-06 00:16:13 | INFO | fairseq.trainer | begin training epoch 47
2021-04-06 00:16:13 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-06 00:16:26 | INFO | train_inner | epoch 047:     36 / 4751 loss=4.502, nll_loss=2.895, ppl=7.44, wps=69838.7, ups=2.43, wpb=28713.4, bsz=910.3, num_updates=218500, lr=6.7651e-05, gnorm=0.464, loss_scale=2, train_wall=32, gb_free=6.2, wall=0
2021-04-06 00:16:59 | INFO | train_inner | epoch 047:    136 / 4751 loss=4.498, nll_loss=2.89, ppl=7.41, wps=88328.8, ups=3.05, wpb=28985.3, bsz=943.4, num_updates=218600, lr=6.76355e-05, gnorm=0.475, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 00:17:32 | INFO | train_inner | epoch 047:    236 / 4751 loss=4.438, nll_loss=2.823, ppl=7.08, wps=88670.6, ups=3.03, wpb=29282.7, bsz=997.4, num_updates=218700, lr=6.76201e-05, gnorm=0.458, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-06 00:17:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-06 00:18:05 | INFO | train_inner | epoch 047:    337 / 4751 loss=4.516, nll_loss=2.911, ppl=7.52, wps=87843, ups=3.02, wpb=29126.6, bsz=954.3, num_updates=218800, lr=6.76046e-05, gnorm=0.466, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-06 00:18:38 | INFO | train_inner | epoch 047:    437 / 4751 loss=4.505, nll_loss=2.898, ppl=7.45, wps=88310.4, ups=3.05, wpb=28967.7, bsz=961.9, num_updates=218900, lr=6.75892e-05, gnorm=0.461, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 00:19:11 | INFO | train_inner | epoch 047:    537 / 4751 loss=4.521, nll_loss=2.916, ppl=7.55, wps=88493.1, ups=3.06, wpb=28955.3, bsz=962.6, num_updates=219000, lr=6.75737e-05, gnorm=0.466, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 00:19:44 | INFO | train_inner | epoch 047:    637 / 4751 loss=4.495, nll_loss=2.887, ppl=7.4, wps=88271.5, ups=3.04, wpb=29060.3, bsz=955.1, num_updates=219100, lr=6.75583e-05, gnorm=0.466, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 00:20:16 | INFO | train_inner | epoch 047:    737 / 4751 loss=4.547, nll_loss=2.946, ppl=7.71, wps=87815.8, ups=3.05, wpb=28831, bsz=952.3, num_updates=219200, lr=6.75429e-05, gnorm=0.475, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-06 00:20:49 | INFO | train_inner | epoch 047:    837 / 4751 loss=4.481, nll_loss=2.871, ppl=7.31, wps=87873, ups=3.03, wpb=29044.8, bsz=969.9, num_updates=219300, lr=6.75275e-05, gnorm=0.485, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 00:21:23 | INFO | train_inner | epoch 047:    937 / 4751 loss=4.515, nll_loss=2.91, ppl=7.52, wps=88044.3, ups=3.02, wpb=29167.5, bsz=958.9, num_updates=219400, lr=6.75121e-05, gnorm=0.465, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 00:21:55 | INFO | train_inner | epoch 047:   1037 / 4751 loss=4.542, nll_loss=2.94, ppl=7.68, wps=88556.9, ups=3.04, wpb=29099.8, bsz=962.3, num_updates=219500, lr=6.74967e-05, gnorm=0.464, loss_scale=2, train_wall=33, gb_free=6.6, wall=0
2021-04-06 00:22:29 | INFO | train_inner | epoch 047:   1137 / 4751 loss=4.543, nll_loss=2.941, ppl=7.68, wps=86608, ups=3.02, wpb=28643.5, bsz=886.2, num_updates=219600, lr=6.74814e-05, gnorm=0.469, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 00:23:02 | INFO | train_inner | epoch 047:   1237 / 4751 loss=4.456, nll_loss=2.843, ppl=7.17, wps=87972.8, ups=3.01, wpb=29216.3, bsz=955.8, num_updates=219700, lr=6.7466e-05, gnorm=0.457, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 00:23:35 | INFO | train_inner | epoch 047:   1337 / 4751 loss=4.489, nll_loss=2.88, ppl=7.36, wps=87429.4, ups=3.01, wpb=29041.7, bsz=944.9, num_updates=219800, lr=6.74507e-05, gnorm=0.464, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 00:24:08 | INFO | train_inner | epoch 047:   1437 / 4751 loss=4.474, nll_loss=2.863, ppl=7.28, wps=87192.2, ups=3.03, wpb=28758.2, bsz=947.2, num_updates=219900, lr=6.74353e-05, gnorm=0.463, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 00:24:41 | INFO | train_inner | epoch 047:   1537 / 4751 loss=4.568, nll_loss=2.97, ppl=7.83, wps=88440.9, ups=3.03, wpb=29190.5, bsz=937.5, num_updates=220000, lr=6.742e-05, gnorm=0.475, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 00:25:14 | INFO | train_inner | epoch 047:   1637 / 4751 loss=4.567, nll_loss=2.969, ppl=7.83, wps=88730.2, ups=3.05, wpb=29082.5, bsz=957, num_updates=220100, lr=6.74047e-05, gnorm=0.472, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-06 00:25:47 | INFO | train_inner | epoch 047:   1737 / 4751 loss=4.517, nll_loss=2.912, ppl=7.53, wps=87928.2, ups=3.03, wpb=28997.1, bsz=938.2, num_updates=220200, lr=6.73894e-05, gnorm=0.47, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 00:26:20 | INFO | train_inner | epoch 047:   1837 / 4751 loss=4.524, nll_loss=2.919, ppl=7.57, wps=88485.1, ups=3.04, wpb=29134.5, bsz=949.4, num_updates=220300, lr=6.73741e-05, gnorm=0.465, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 00:26:53 | INFO | train_inner | epoch 047:   1937 / 4751 loss=4.465, nll_loss=2.853, ppl=7.23, wps=86755.3, ups=2.98, wpb=29070, bsz=940.1, num_updates=220400, lr=6.73588e-05, gnorm=0.461, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 00:27:26 | INFO | train_inner | epoch 047:   2037 / 4751 loss=4.549, nll_loss=2.948, ppl=7.72, wps=87440.1, ups=3.04, wpb=28796.8, bsz=923.5, num_updates=220500, lr=6.73435e-05, gnorm=0.475, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-06 00:27:59 | INFO | train_inner | epoch 047:   2137 / 4751 loss=4.495, nll_loss=2.887, ppl=7.4, wps=88255.3, ups=3.04, wpb=29015.3, bsz=960.6, num_updates=220600, lr=6.73282e-05, gnorm=0.462, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 00:28:32 | INFO | train_inner | epoch 047:   2237 / 4751 loss=4.585, nll_loss=2.989, ppl=7.94, wps=88069.6, ups=3.05, wpb=28907.5, bsz=946.2, num_updates=220700, lr=6.7313e-05, gnorm=0.476, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-06 00:29:04 | INFO | train_inner | epoch 047:   2337 / 4751 loss=4.573, nll_loss=2.975, ppl=7.86, wps=87996.1, ups=3.06, wpb=28712.4, bsz=934.6, num_updates=220800, lr=6.72977e-05, gnorm=0.47, loss_scale=2, train_wall=32, gb_free=6.1, wall=0
2021-04-06 00:29:37 | INFO | train_inner | epoch 047:   2437 / 4751 loss=4.52, nll_loss=2.915, ppl=7.54, wps=88805.4, ups=3.05, wpb=29122.2, bsz=930.8, num_updates=220900, lr=6.72825e-05, gnorm=0.466, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 00:30:10 | INFO | train_inner | epoch 047:   2537 / 4751 loss=4.517, nll_loss=2.912, ppl=7.53, wps=87241.6, ups=3.03, wpb=28794.5, bsz=950.7, num_updates=221000, lr=6.72673e-05, gnorm=0.475, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 00:30:43 | INFO | train_inner | epoch 047:   2637 / 4751 loss=4.554, nll_loss=2.955, ppl=7.75, wps=87592.5, ups=3.02, wpb=28956.4, bsz=966, num_updates=221100, lr=6.72521e-05, gnorm=0.476, loss_scale=4, train_wall=33, gb_free=6.5, wall=0
2021-04-06 00:31:16 | INFO | train_inner | epoch 047:   2737 / 4751 loss=4.559, nll_loss=2.959, ppl=7.78, wps=87279.5, ups=3.02, wpb=28899.1, bsz=935.8, num_updates=221200, lr=6.72369e-05, gnorm=0.468, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-06 00:31:49 | INFO | train_inner | epoch 047:   2837 / 4751 loss=4.56, nll_loss=2.961, ppl=7.78, wps=88253.6, ups=3.04, wpb=28984.8, bsz=930.6, num_updates=221300, lr=6.72217e-05, gnorm=0.471, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 00:32:22 | INFO | train_inner | epoch 047:   2937 / 4751 loss=4.544, nll_loss=2.942, ppl=7.69, wps=88375.1, ups=3.04, wpb=29045.2, bsz=922.1, num_updates=221400, lr=6.72065e-05, gnorm=0.467, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-06 00:32:55 | INFO | train_inner | epoch 047:   3037 / 4751 loss=4.564, nll_loss=2.966, ppl=7.81, wps=89195.3, ups=3.06, wpb=29141.8, bsz=968.1, num_updates=221500, lr=6.71913e-05, gnorm=0.466, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 00:33:28 | INFO | train_inner | epoch 047:   3137 / 4751 loss=4.518, nll_loss=2.913, ppl=7.53, wps=87920.1, ups=3.04, wpb=28943.4, bsz=945.8, num_updates=221600, lr=6.71762e-05, gnorm=0.462, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-06 00:34:01 | INFO | train_inner | epoch 047:   3237 / 4751 loss=4.586, nll_loss=2.99, ppl=7.95, wps=88327.1, ups=3.04, wpb=29007.3, bsz=929.1, num_updates=221700, lr=6.7161e-05, gnorm=0.484, loss_scale=4, train_wall=33, gb_free=6.4, wall=0
2021-04-06 00:34:34 | INFO | train_inner | epoch 047:   3337 / 4751 loss=4.502, nll_loss=2.895, ppl=7.44, wps=87840.4, ups=3.03, wpb=29013.6, bsz=969.8, num_updates=221800, lr=6.71459e-05, gnorm=0.469, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 00:35:06 | INFO | train_inner | epoch 047:   3437 / 4751 loss=4.488, nll_loss=2.88, ppl=7.36, wps=88418, ups=3.04, wpb=29068.6, bsz=956.9, num_updates=221900, lr=6.71307e-05, gnorm=0.464, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 00:35:39 | INFO | train_inner | epoch 047:   3537 / 4751 loss=4.469, nll_loss=2.858, ppl=7.25, wps=87879.5, ups=3.03, wpb=29009.2, bsz=953.6, num_updates=222000, lr=6.71156e-05, gnorm=0.462, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-06 00:36:12 | INFO | train_inner | epoch 047:   3637 / 4751 loss=4.555, nll_loss=2.956, ppl=7.76, wps=88127, ups=3.04, wpb=29000, bsz=927.3, num_updates=222100, lr=6.71005e-05, gnorm=0.472, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 00:36:45 | INFO | train_inner | epoch 047:   3737 / 4751 loss=4.566, nll_loss=2.968, ppl=7.83, wps=87713, ups=3.04, wpb=28818.2, bsz=979.7, num_updates=222200, lr=6.70854e-05, gnorm=0.467, loss_scale=4, train_wall=33, gb_free=6, wall=0
2021-04-06 00:37:18 | INFO | train_inner | epoch 047:   3837 / 4751 loss=4.528, nll_loss=2.924, ppl=7.59, wps=87571.8, ups=3.02, wpb=28956.4, bsz=941.2, num_updates=222300, lr=6.70703e-05, gnorm=0.468, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-06 00:37:51 | INFO | train_inner | epoch 047:   3937 / 4751 loss=4.541, nll_loss=2.939, ppl=7.67, wps=88020.6, ups=3.03, wpb=29019.2, bsz=944, num_updates=222400, lr=6.70552e-05, gnorm=0.468, loss_scale=4, train_wall=33, gb_free=6.5, wall=0
2021-04-06 00:38:24 | INFO | train_inner | epoch 047:   4037 / 4751 loss=4.523, nll_loss=2.919, ppl=7.56, wps=87537.9, ups=3.05, wpb=28724.8, bsz=920.8, num_updates=222500, lr=6.70402e-05, gnorm=0.475, loss_scale=4, train_wall=33, gb_free=6, wall=0
2021-04-06 00:38:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-06 00:38:57 | INFO | train_inner | epoch 047:   4138 / 4751 loss=4.618, nll_loss=3.027, ppl=8.15, wps=86721.7, ups=3.02, wpb=28686.9, bsz=951, num_updates=222600, lr=6.70251e-05, gnorm=0.483, loss_scale=2, train_wall=33, gb_free=7.1, wall=0
2021-04-06 00:39:30 | INFO | train_inner | epoch 047:   4238 / 4751 loss=4.518, nll_loss=2.913, ppl=7.53, wps=87923.5, ups=3.05, wpb=28869.7, bsz=963.2, num_updates=222700, lr=6.701e-05, gnorm=0.47, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 00:40:03 | INFO | train_inner | epoch 047:   4338 / 4751 loss=4.538, nll_loss=2.936, ppl=7.65, wps=87819.6, ups=3.04, wpb=28887.7, bsz=939.6, num_updates=222800, lr=6.6995e-05, gnorm=0.47, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 00:40:36 | INFO | train_inner | epoch 047:   4438 / 4751 loss=4.511, nll_loss=2.906, ppl=7.49, wps=87028.5, ups=3.02, wpb=28862.9, bsz=977.8, num_updates=222900, lr=6.698e-05, gnorm=0.467, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 00:41:09 | INFO | train_inner | epoch 047:   4538 / 4751 loss=4.49, nll_loss=2.882, ppl=7.37, wps=87679.5, ups=3.04, wpb=28871.2, bsz=936.4, num_updates=223000, lr=6.6965e-05, gnorm=0.465, loss_scale=2, train_wall=33, gb_free=6.7, wall=0
2021-04-06 00:41:42 | INFO | train_inner | epoch 047:   4638 / 4751 loss=4.577, nll_loss=2.98, ppl=7.89, wps=87835.3, ups=3.05, wpb=28774.9, bsz=911.9, num_updates=223100, lr=6.69499e-05, gnorm=0.475, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 00:42:15 | INFO | train_inner | epoch 047:   4738 / 4751 loss=4.548, nll_loss=2.947, ppl=7.71, wps=88528.9, ups=3.04, wpb=29126.8, bsz=919.5, num_updates=223200, lr=6.69349e-05, gnorm=0.462, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 00:42:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-06 00:42:20 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 4.158 | nll_loss 2.386 | ppl 5.23 | wps 204151 | wpb 10489.1 | bsz 375 | num_updates 223213 | best_loss 4.158
2021-04-06 00:42:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 223213 updates
2021-04-06 00:42:20 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-06 00:42:26 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-06 00:42:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt (epoch 47 @ 223213 updates, score 4.158) (writing took 13.501689963042736 seconds)
2021-04-06 00:42:34 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2021-04-06 00:42:34 | INFO | train | epoch 047 | loss 4.526 | nll_loss 2.923 | ppl 7.58 | wps 87049.5 | ups 3.01 | wpb 28967.9 | bsz 946.9 | num_updates 223213 | lr 6.6933e-05 | gnorm 0.469 | loss_scale 2 | train_wall 1558 | gb_free 6.2 | wall 0
2021-04-06 00:42:34 | INFO | fairseq.trainer | begin training epoch 48
2021-04-06 00:42:34 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-06 00:42:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-04-06 00:43:04 | INFO | train_inner | epoch 048:     88 / 4751 loss=4.455, nll_loss=2.842, ppl=7.17, wps=59098.1, ups=2.03, wpb=29133.2, bsz=967.7, num_updates=223300, lr=6.692e-05, gnorm=0.466, loss_scale=1, train_wall=33, gb_free=6.5, wall=0
2021-04-06 00:43:37 | INFO | train_inner | epoch 048:    188 / 4751 loss=4.55, nll_loss=2.949, ppl=7.72, wps=88504.4, ups=3.04, wpb=29096.8, bsz=976.1, num_updates=223400, lr=6.6905e-05, gnorm=0.473, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 00:44:10 | INFO | train_inner | epoch 048:    288 / 4751 loss=4.483, nll_loss=2.873, ppl=7.33, wps=89491.9, ups=3.05, wpb=29361.4, bsz=960.6, num_updates=223500, lr=6.689e-05, gnorm=0.458, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 00:44:42 | INFO | train_inner | epoch 048:    388 / 4751 loss=4.512, nll_loss=2.906, ppl=7.5, wps=88208.9, ups=3.04, wpb=28985.9, bsz=945.9, num_updates=223600, lr=6.6875e-05, gnorm=0.483, loss_scale=1, train_wall=33, gb_free=5.8, wall=0
2021-04-06 00:45:15 | INFO | train_inner | epoch 048:    488 / 4751 loss=4.555, nll_loss=2.955, ppl=7.75, wps=87309.5, ups=3.04, wpb=28719.5, bsz=937.4, num_updates=223700, lr=6.68601e-05, gnorm=0.471, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 00:45:48 | INFO | train_inner | epoch 048:    588 / 4751 loss=4.535, nll_loss=2.933, ppl=7.63, wps=87270.5, ups=3.04, wpb=28748, bsz=926.6, num_updates=223800, lr=6.68452e-05, gnorm=0.469, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 00:46:21 | INFO | train_inner | epoch 048:    688 / 4751 loss=4.494, nll_loss=2.886, ppl=7.39, wps=87495.3, ups=3.04, wpb=28793.4, bsz=941.3, num_updates=223900, lr=6.68302e-05, gnorm=0.473, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 00:46:54 | INFO | train_inner | epoch 048:    788 / 4751 loss=4.536, nll_loss=2.934, ppl=7.64, wps=88964.9, ups=3.05, wpb=29186.8, bsz=942.1, num_updates=224000, lr=6.68153e-05, gnorm=0.465, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 00:47:27 | INFO | train_inner | epoch 048:    888 / 4751 loss=4.513, nll_loss=2.908, ppl=7.51, wps=87242.4, ups=3.03, wpb=28826.8, bsz=940.6, num_updates=224100, lr=6.68004e-05, gnorm=0.468, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 00:48:00 | INFO | train_inner | epoch 048:    988 / 4751 loss=4.533, nll_loss=2.93, ppl=7.62, wps=87786.3, ups=3.05, wpb=28797.8, bsz=947.1, num_updates=224200, lr=6.67855e-05, gnorm=0.469, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 00:48:33 | INFO | train_inner | epoch 048:   1088 / 4751 loss=4.483, nll_loss=2.873, ppl=7.33, wps=87021.6, ups=3.03, wpb=28755.7, bsz=930.7, num_updates=224300, lr=6.67706e-05, gnorm=0.472, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 00:49:06 | INFO | train_inner | epoch 048:   1188 / 4751 loss=4.481, nll_loss=2.872, ppl=7.32, wps=87363.3, ups=3.04, wpb=28783.7, bsz=975.2, num_updates=224400, lr=6.67557e-05, gnorm=0.48, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 00:49:39 | INFO | train_inner | epoch 048:   1288 / 4751 loss=4.532, nll_loss=2.929, ppl=7.62, wps=87841.3, ups=3.04, wpb=28870.6, bsz=975.8, num_updates=224500, lr=6.67409e-05, gnorm=0.472, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 00:50:12 | INFO | train_inner | epoch 048:   1388 / 4751 loss=4.54, nll_loss=2.938, ppl=7.66, wps=87849.9, ups=3.05, wpb=28835.5, bsz=911.4, num_updates=224600, lr=6.6726e-05, gnorm=0.476, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 00:50:45 | INFO | train_inner | epoch 048:   1488 / 4751 loss=4.505, nll_loss=2.899, ppl=7.46, wps=87998.2, ups=3.03, wpb=29063.7, bsz=940.4, num_updates=224700, lr=6.67112e-05, gnorm=0.469, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 00:51:18 | INFO | train_inner | epoch 048:   1588 / 4751 loss=4.513, nll_loss=2.908, ppl=7.51, wps=87198.5, ups=3.03, wpb=28797, bsz=958.6, num_updates=224800, lr=6.66963e-05, gnorm=0.468, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 00:51:51 | INFO | train_inner | epoch 048:   1688 / 4751 loss=4.529, nll_loss=2.925, ppl=7.59, wps=87282.9, ups=3.02, wpb=28892.1, bsz=934.8, num_updates=224900, lr=6.66815e-05, gnorm=0.466, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 00:52:24 | INFO | train_inner | epoch 048:   1788 / 4751 loss=4.473, nll_loss=2.862, ppl=7.27, wps=88777.2, ups=3.03, wpb=29302.5, bsz=947.9, num_updates=225000, lr=6.66667e-05, gnorm=0.466, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 00:52:57 | INFO | train_inner | epoch 048:   1888 / 4751 loss=4.487, nll_loss=2.879, ppl=7.35, wps=88242.2, ups=3.02, wpb=29248.4, bsz=962.3, num_updates=225100, lr=6.66519e-05, gnorm=0.472, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 00:53:30 | INFO | train_inner | epoch 048:   1988 / 4751 loss=4.519, nll_loss=2.915, ppl=7.54, wps=87140.1, ups=3.04, wpb=28690.9, bsz=944.1, num_updates=225200, lr=6.66371e-05, gnorm=0.474, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 00:54:03 | INFO | train_inner | epoch 048:   2088 / 4751 loss=4.559, nll_loss=2.96, ppl=7.78, wps=87512.8, ups=3.04, wpb=28774.3, bsz=922.7, num_updates=225300, lr=6.66223e-05, gnorm=0.483, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-06 00:54:36 | INFO | train_inner | epoch 048:   2188 / 4751 loss=4.498, nll_loss=2.891, ppl=7.42, wps=88373.4, ups=3.02, wpb=29239.1, bsz=954.2, num_updates=225400, lr=6.66075e-05, gnorm=0.466, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 00:55:09 | INFO | train_inner | epoch 048:   2288 / 4751 loss=4.517, nll_loss=2.912, ppl=7.52, wps=87934.6, ups=3.03, wpb=29025.2, bsz=956.3, num_updates=225500, lr=6.65927e-05, gnorm=0.468, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 00:55:42 | INFO | train_inner | epoch 048:   2388 / 4751 loss=4.553, nll_loss=2.953, ppl=7.74, wps=86883.2, ups=3, wpb=28974.7, bsz=967, num_updates=225600, lr=6.6578e-05, gnorm=0.467, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 00:56:15 | INFO | train_inner | epoch 048:   2488 / 4751 loss=4.503, nll_loss=2.897, ppl=7.45, wps=88059.7, ups=3.04, wpb=28978.9, bsz=957.6, num_updates=225700, lr=6.65632e-05, gnorm=0.473, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 00:56:48 | INFO | train_inner | epoch 048:   2588 / 4751 loss=4.567, nll_loss=2.969, ppl=7.83, wps=88643.4, ups=3.06, wpb=29015.7, bsz=939.2, num_updates=225800, lr=6.65485e-05, gnorm=0.468, loss_scale=2, train_wall=33, gb_free=6.8, wall=0
2021-04-06 00:57:21 | INFO | train_inner | epoch 048:   2688 / 4751 loss=4.524, nll_loss=2.92, ppl=7.57, wps=88122.1, ups=3.04, wpb=28954.1, bsz=942.6, num_updates=225900, lr=6.65337e-05, gnorm=0.464, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 00:57:54 | INFO | train_inner | epoch 048:   2788 / 4751 loss=4.474, nll_loss=2.864, ppl=7.28, wps=88163.2, ups=3.01, wpb=29279.5, bsz=968.3, num_updates=226000, lr=6.6519e-05, gnorm=0.466, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 00:58:27 | INFO | train_inner | epoch 048:   2888 / 4751 loss=4.516, nll_loss=2.911, ppl=7.52, wps=88842.4, ups=3.05, wpb=29156.6, bsz=951.3, num_updates=226100, lr=6.65043e-05, gnorm=0.464, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 00:58:59 | INFO | train_inner | epoch 048:   2988 / 4751 loss=4.56, nll_loss=2.961, ppl=7.79, wps=88545, ups=3.07, wpb=28877.9, bsz=951.4, num_updates=226200, lr=6.64896e-05, gnorm=0.468, loss_scale=2, train_wall=32, gb_free=6.3, wall=0
2021-04-06 00:59:32 | INFO | train_inner | epoch 048:   3088 / 4751 loss=4.532, nll_loss=2.93, ppl=7.62, wps=88541.5, ups=3.05, wpb=28986, bsz=944.7, num_updates=226300, lr=6.64749e-05, gnorm=0.466, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 01:00:05 | INFO | train_inner | epoch 048:   3188 / 4751 loss=4.521, nll_loss=2.916, ppl=7.55, wps=87962.4, ups=3.02, wpb=29094.4, bsz=936.1, num_updates=226400, lr=6.64602e-05, gnorm=0.466, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-06 01:00:38 | INFO | train_inner | epoch 048:   3288 / 4751 loss=4.532, nll_loss=2.93, ppl=7.62, wps=87298.1, ups=3, wpb=29085, bsz=992.3, num_updates=226500, lr=6.64455e-05, gnorm=0.478, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-06 01:01:11 | INFO | train_inner | epoch 048:   3388 / 4751 loss=4.537, nll_loss=2.936, ppl=7.65, wps=86327.8, ups=3.03, wpb=28484.7, bsz=947, num_updates=226600, lr=6.64309e-05, gnorm=0.474, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 01:01:44 | INFO | train_inner | epoch 048:   3488 / 4751 loss=4.508, nll_loss=2.902, ppl=7.48, wps=88301.2, ups=3.04, wpb=29066.7, bsz=933, num_updates=226700, lr=6.64162e-05, gnorm=0.469, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 01:02:17 | INFO | train_inner | epoch 048:   3588 / 4751 loss=4.533, nll_loss=2.931, ppl=7.63, wps=87653, ups=3.05, wpb=28740.7, bsz=927.5, num_updates=226800, lr=6.64016e-05, gnorm=0.465, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 01:02:50 | INFO | train_inner | epoch 048:   3688 / 4751 loss=4.544, nll_loss=2.944, ppl=7.69, wps=89278, ups=3.03, wpb=29421.1, bsz=954.6, num_updates=226900, lr=6.6387e-05, gnorm=0.459, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 01:03:23 | INFO | train_inner | epoch 048:   3788 / 4751 loss=4.528, nll_loss=2.925, ppl=7.59, wps=87473.4, ups=3.03, wpb=28842.5, bsz=941.8, num_updates=227000, lr=6.63723e-05, gnorm=0.476, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 01:03:56 | INFO | train_inner | epoch 048:   3888 / 4751 loss=4.498, nll_loss=2.891, ppl=7.42, wps=88017.9, ups=3.03, wpb=29014.7, bsz=934.6, num_updates=227100, lr=6.63577e-05, gnorm=0.466, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 01:04:30 | INFO | train_inner | epoch 048:   3988 / 4751 loss=4.528, nll_loss=2.925, ppl=7.6, wps=85026.2, ups=2.97, wpb=28629.8, bsz=944.6, num_updates=227200, lr=6.63431e-05, gnorm=0.47, loss_scale=2, train_wall=34, gb_free=6.5, wall=0
2021-04-06 01:05:02 | INFO | train_inner | epoch 048:   4088 / 4751 loss=4.542, nll_loss=2.941, ppl=7.68, wps=88162.9, ups=3.05, wpb=28940.2, bsz=938.9, num_updates=227300, lr=6.63285e-05, gnorm=0.469, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 01:05:35 | INFO | train_inner | epoch 048:   4188 / 4751 loss=4.592, nll_loss=2.998, ppl=7.99, wps=87902.9, ups=3.05, wpb=28780.2, bsz=929.7, num_updates=227400, lr=6.63139e-05, gnorm=0.48, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 01:06:09 | INFO | train_inner | epoch 048:   4288 / 4751 loss=4.469, nll_loss=2.858, ppl=7.25, wps=88551.6, ups=3, wpb=29524.3, bsz=967.1, num_updates=227500, lr=6.62994e-05, gnorm=0.462, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 01:06:41 | INFO | train_inner | epoch 048:   4388 / 4751 loss=4.554, nll_loss=2.954, ppl=7.75, wps=88288.7, ups=3.06, wpb=28895.6, bsz=916.6, num_updates=227600, lr=6.62848e-05, gnorm=0.469, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-06 01:07:14 | INFO | train_inner | epoch 048:   4488 / 4751 loss=4.603, nll_loss=3.01, ppl=8.05, wps=88576.2, ups=3.04, wpb=29123.2, bsz=935.9, num_updates=227700, lr=6.62702e-05, gnorm=0.473, loss_scale=4, train_wall=33, gb_free=5.9, wall=0
2021-04-06 01:07:47 | INFO | train_inner | epoch 048:   4588 / 4751 loss=4.57, nll_loss=2.973, ppl=7.85, wps=88510.4, ups=3.05, wpb=29000, bsz=930.2, num_updates=227800, lr=6.62557e-05, gnorm=0.47, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 01:08:20 | INFO | train_inner | epoch 048:   4688 / 4751 loss=4.555, nll_loss=2.956, ppl=7.76, wps=87999, ups=3.04, wpb=28983.6, bsz=950.7, num_updates=227900, lr=6.62411e-05, gnorm=0.469, loss_scale=4, train_wall=33, gb_free=6.5, wall=0
2021-04-06 01:08:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-06 01:08:42 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 4.165 | nll_loss 2.395 | ppl 5.26 | wps 208444 | wpb 10489.1 | bsz 375 | num_updates 227963 | best_loss 4.158
2021-04-06 01:08:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 227963 updates
2021-04-06 01:08:42 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-06 01:08:48 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-06 01:08:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt (epoch 48 @ 227963 updates, score 4.165) (writing took 5.9997624680399895 seconds)
2021-04-06 01:08:48 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2021-04-06 01:08:48 | INFO | train | epoch 048 | loss 4.524 | nll_loss 2.92 | ppl 7.57 | wps 87416.6 | ups 3.02 | wpb 28968.5 | bsz 947 | num_updates 227963 | lr 6.6232e-05 | gnorm 0.47 | loss_scale 4 | train_wall 1559 | gb_free 6.3 | wall 0
2021-04-06 01:08:48 | INFO | fairseq.trainer | begin training epoch 49
2021-04-06 01:08:48 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-06 01:08:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-06 01:09:01 | INFO | train_inner | epoch 049:     38 / 4751 loss=4.501, nll_loss=2.895, ppl=7.44, wps=69445.6, ups=2.42, wpb=28748.1, bsz=953.4, num_updates=228000, lr=6.62266e-05, gnorm=0.469, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 01:09:34 | INFO | train_inner | epoch 049:    138 / 4751 loss=4.52, nll_loss=2.915, ppl=7.54, wps=87717, ups=3.03, wpb=28962.7, bsz=963, num_updates=228100, lr=6.62121e-05, gnorm=0.47, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 01:10:07 | INFO | train_inner | epoch 049:    238 / 4751 loss=4.489, nll_loss=2.881, ppl=7.37, wps=87493.7, ups=3.04, wpb=28826.8, bsz=967, num_updates=228200, lr=6.61976e-05, gnorm=0.465, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 01:10:40 | INFO | train_inner | epoch 049:    338 / 4751 loss=4.546, nll_loss=2.945, ppl=7.7, wps=87609.8, ups=3.04, wpb=28814.6, bsz=931.1, num_updates=228300, lr=6.61831e-05, gnorm=0.474, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 01:11:13 | INFO | train_inner | epoch 049:    438 / 4751 loss=4.533, nll_loss=2.93, ppl=7.62, wps=88334, ups=3.04, wpb=29064.8, bsz=946.2, num_updates=228400, lr=6.61686e-05, gnorm=0.469, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 01:11:46 | INFO | train_inner | epoch 049:    538 / 4751 loss=4.432, nll_loss=2.816, ppl=7.04, wps=87743.6, ups=3.02, wpb=29027.8, bsz=947.6, num_updates=228500, lr=6.61541e-05, gnorm=0.459, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 01:12:19 | INFO | train_inner | epoch 049:    638 / 4751 loss=4.559, nll_loss=2.96, ppl=7.78, wps=88035.9, ups=3.05, wpb=28830.8, bsz=949.7, num_updates=228600, lr=6.61396e-05, gnorm=0.471, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 01:12:52 | INFO | train_inner | epoch 049:    738 / 4751 loss=4.53, nll_loss=2.926, ppl=7.6, wps=89306.4, ups=3.06, wpb=29181.2, bsz=913.4, num_updates=228700, lr=6.61252e-05, gnorm=0.469, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 01:13:24 | INFO | train_inner | epoch 049:    838 / 4751 loss=4.493, nll_loss=2.885, ppl=7.39, wps=87629.5, ups=3.04, wpb=28840.3, bsz=969.2, num_updates=228800, lr=6.61107e-05, gnorm=0.473, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 01:13:57 | INFO | train_inner | epoch 049:    938 / 4751 loss=4.531, nll_loss=2.928, ppl=7.61, wps=88618.7, ups=3.05, wpb=29092.3, bsz=978.2, num_updates=228900, lr=6.60963e-05, gnorm=0.466, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 01:14:30 | INFO | train_inner | epoch 049:   1038 / 4751 loss=4.592, nll_loss=2.997, ppl=7.98, wps=88393.5, ups=3.03, wpb=29144.1, bsz=961.6, num_updates=229000, lr=6.60819e-05, gnorm=0.478, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 01:15:04 | INFO | train_inner | epoch 049:   1138 / 4751 loss=4.463, nll_loss=2.851, ppl=7.21, wps=86852.4, ups=3, wpb=28956, bsz=943.7, num_updates=229100, lr=6.60674e-05, gnorm=0.468, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 01:15:36 | INFO | train_inner | epoch 049:   1238 / 4751 loss=4.494, nll_loss=2.886, ppl=7.39, wps=88013.9, ups=3.06, wpb=28790.6, bsz=937.6, num_updates=229200, lr=6.6053e-05, gnorm=0.466, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-06 01:16:09 | INFO | train_inner | epoch 049:   1338 / 4751 loss=4.508, nll_loss=2.902, ppl=7.47, wps=87081, ups=3.03, wpb=28714, bsz=922.2, num_updates=229300, lr=6.60386e-05, gnorm=0.469, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 01:16:42 | INFO | train_inner | epoch 049:   1438 / 4751 loss=4.522, nll_loss=2.918, ppl=7.56, wps=89109.1, ups=3.04, wpb=29307.3, bsz=919.5, num_updates=229400, lr=6.60242e-05, gnorm=0.464, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 01:17:15 | INFO | train_inner | epoch 049:   1538 / 4751 loss=4.553, nll_loss=2.952, ppl=7.74, wps=87601, ups=3.02, wpb=29038.4, bsz=910.6, num_updates=229500, lr=6.60098e-05, gnorm=0.472, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-06 01:17:48 | INFO | train_inner | epoch 049:   1638 / 4751 loss=4.528, nll_loss=2.925, ppl=7.59, wps=87412.9, ups=3.03, wpb=28852.6, bsz=941.4, num_updates=229600, lr=6.59955e-05, gnorm=0.475, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 01:18:21 | INFO | train_inner | epoch 049:   1738 / 4751 loss=4.516, nll_loss=2.911, ppl=7.52, wps=87907.6, ups=3.03, wpb=29043, bsz=942.3, num_updates=229700, lr=6.59811e-05, gnorm=0.466, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 01:18:54 | INFO | train_inner | epoch 049:   1838 / 4751 loss=4.559, nll_loss=2.959, ppl=7.78, wps=88290.7, ups=3.05, wpb=28975.8, bsz=950.6, num_updates=229800, lr=6.59667e-05, gnorm=0.468, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 01:19:27 | INFO | train_inner | epoch 049:   1938 / 4751 loss=4.522, nll_loss=2.918, ppl=7.56, wps=87643, ups=3.03, wpb=28910, bsz=948.6, num_updates=229900, lr=6.59524e-05, gnorm=0.471, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 01:20:00 | INFO | train_inner | epoch 049:   2038 / 4751 loss=4.5, nll_loss=2.892, ppl=7.42, wps=87401.4, ups=3.02, wpb=28923.3, bsz=946.6, num_updates=230000, lr=6.5938e-05, gnorm=0.471, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 01:20:33 | INFO | train_inner | epoch 049:   2138 / 4751 loss=4.504, nll_loss=2.898, ppl=7.45, wps=88226.3, ups=3.04, wpb=28998.1, bsz=941.4, num_updates=230100, lr=6.59237e-05, gnorm=0.472, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 01:21:06 | INFO | train_inner | epoch 049:   2238 / 4751 loss=4.555, nll_loss=2.955, ppl=7.75, wps=88885.5, ups=3.05, wpb=29118.9, bsz=935.4, num_updates=230200, lr=6.59094e-05, gnorm=0.467, loss_scale=4, train_wall=33, gb_free=7.1, wall=0
2021-04-06 01:21:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-06 01:21:39 | INFO | train_inner | epoch 049:   2339 / 4751 loss=4.583, nll_loss=2.987, ppl=7.93, wps=87104.4, ups=3.02, wpb=28882.8, bsz=959, num_updates=230300, lr=6.58951e-05, gnorm=0.475, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 01:22:12 | INFO | train_inner | epoch 049:   2439 / 4751 loss=4.479, nll_loss=2.87, ppl=7.31, wps=88042.1, ups=3.03, wpb=29054.7, bsz=986.2, num_updates=230400, lr=6.58808e-05, gnorm=0.469, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 01:22:46 | INFO | train_inner | epoch 049:   2539 / 4751 loss=4.528, nll_loss=2.925, ppl=7.59, wps=85473.7, ups=2.96, wpb=28852.5, bsz=906.1, num_updates=230500, lr=6.58665e-05, gnorm=0.473, loss_scale=2, train_wall=34, gb_free=6.2, wall=0
2021-04-06 01:23:19 | INFO | train_inner | epoch 049:   2639 / 4751 loss=4.514, nll_loss=2.909, ppl=7.51, wps=88528.6, ups=3.03, wpb=29191.7, bsz=974, num_updates=230600, lr=6.58522e-05, gnorm=0.467, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 01:23:52 | INFO | train_inner | epoch 049:   2739 / 4751 loss=4.475, nll_loss=2.865, ppl=7.29, wps=88234.4, ups=3.04, wpb=29040.6, bsz=963, num_updates=230700, lr=6.58379e-05, gnorm=0.474, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-06 01:24:24 | INFO | train_inner | epoch 049:   2839 / 4751 loss=4.587, nll_loss=2.991, ppl=7.95, wps=88097.3, ups=3.05, wpb=28884.4, bsz=936.2, num_updates=230800, lr=6.58237e-05, gnorm=0.479, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 01:24:57 | INFO | train_inner | epoch 049:   2939 / 4751 loss=4.53, nll_loss=2.926, ppl=7.6, wps=88480.8, ups=3.03, wpb=29210.8, bsz=923.2, num_updates=230900, lr=6.58094e-05, gnorm=0.468, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 01:25:30 | INFO | train_inner | epoch 049:   3039 / 4751 loss=4.49, nll_loss=2.883, ppl=7.38, wps=87543, ups=3.03, wpb=28890.7, bsz=952.1, num_updates=231000, lr=6.57952e-05, gnorm=0.463, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 01:26:04 | INFO | train_inner | epoch 049:   3139 / 4751 loss=4.514, nll_loss=2.909, ppl=7.51, wps=86727.1, ups=3.01, wpb=28810.3, bsz=954.2, num_updates=231100, lr=6.57809e-05, gnorm=0.474, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 01:26:37 | INFO | train_inner | epoch 049:   3239 / 4751 loss=4.508, nll_loss=2.903, ppl=7.48, wps=87714.7, ups=3.04, wpb=28843.3, bsz=952.6, num_updates=231200, lr=6.57667e-05, gnorm=0.469, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 01:27:09 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-04-06 01:27:10 | INFO | train_inner | epoch 049:   3340 / 4751 loss=4.502, nll_loss=2.895, ppl=7.44, wps=87729.5, ups=3, wpb=29213.8, bsz=953.4, num_updates=231300, lr=6.57525e-05, gnorm=0.466, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 01:27:43 | INFO | train_inner | epoch 049:   3440 / 4751 loss=4.533, nll_loss=2.931, ppl=7.62, wps=87699.9, ups=3.03, wpb=28956.2, bsz=956, num_updates=231400, lr=6.57383e-05, gnorm=0.474, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 01:28:16 | INFO | train_inner | epoch 049:   3540 / 4751 loss=4.49, nll_loss=2.881, ppl=7.37, wps=87246, ups=3.04, wpb=28730.7, bsz=920.7, num_updates=231500, lr=6.57241e-05, gnorm=0.475, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 01:28:49 | INFO | train_inner | epoch 049:   3640 / 4751 loss=4.523, nll_loss=2.919, ppl=7.57, wps=87589.2, ups=3.05, wpb=28761.1, bsz=932.5, num_updates=231600, lr=6.57099e-05, gnorm=0.474, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 01:29:22 | INFO | train_inner | epoch 049:   3740 / 4751 loss=4.583, nll_loss=2.987, ppl=7.93, wps=87531.8, ups=3.03, wpb=28868.8, bsz=949.6, num_updates=231700, lr=6.56957e-05, gnorm=0.473, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 01:29:55 | INFO | train_inner | epoch 049:   3840 / 4751 loss=4.536, nll_loss=2.934, ppl=7.64, wps=87363.4, ups=3.04, wpb=28726.5, bsz=941.9, num_updates=231800, lr=6.56815e-05, gnorm=0.471, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 01:30:27 | INFO | train_inner | epoch 049:   3940 / 4751 loss=4.528, nll_loss=2.925, ppl=7.59, wps=88373.7, ups=3.05, wpb=29004.5, bsz=926, num_updates=231900, lr=6.56674e-05, gnorm=0.468, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 01:31:00 | INFO | train_inner | epoch 049:   4040 / 4751 loss=4.484, nll_loss=2.875, ppl=7.34, wps=88162.2, ups=3.03, wpb=29140, bsz=955.4, num_updates=232000, lr=6.56532e-05, gnorm=0.462, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 01:31:33 | INFO | train_inner | epoch 049:   4140 / 4751 loss=4.523, nll_loss=2.919, ppl=7.57, wps=87918.2, ups=3.04, wpb=28927.4, bsz=987.4, num_updates=232100, lr=6.56391e-05, gnorm=0.468, loss_scale=1, train_wall=33, gb_free=6.4, wall=0
2021-04-06 01:32:06 | INFO | train_inner | epoch 049:   4240 / 4751 loss=4.538, nll_loss=2.936, ppl=7.65, wps=87497.4, ups=3.03, wpb=28874.1, bsz=912.1, num_updates=232200, lr=6.56249e-05, gnorm=0.473, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 01:32:39 | INFO | train_inner | epoch 049:   4340 / 4751 loss=4.522, nll_loss=2.918, ppl=7.56, wps=89256.6, ups=3.05, wpb=29225, bsz=965, num_updates=232300, lr=6.56108e-05, gnorm=0.464, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 01:33:12 | INFO | train_inner | epoch 049:   4440 / 4751 loss=4.536, nll_loss=2.934, ppl=7.64, wps=87822.2, ups=3.03, wpb=28990.5, bsz=943.2, num_updates=232400, lr=6.55967e-05, gnorm=0.474, loss_scale=1, train_wall=33, gb_free=6, wall=0
2021-04-06 01:33:45 | INFO | train_inner | epoch 049:   4540 / 4751 loss=4.455, nll_loss=2.842, ppl=7.17, wps=88467.4, ups=3.04, wpb=29112, bsz=961.1, num_updates=232500, lr=6.55826e-05, gnorm=0.47, loss_scale=1, train_wall=33, gb_free=6.4, wall=0
2021-04-06 01:34:18 | INFO | train_inner | epoch 049:   4640 / 4751 loss=4.525, nll_loss=2.922, ppl=7.58, wps=87820.9, ups=3.04, wpb=28928.6, bsz=949.1, num_updates=232600, lr=6.55685e-05, gnorm=0.471, loss_scale=1, train_wall=33, gb_free=6.5, wall=0
2021-04-06 01:34:51 | INFO | train_inner | epoch 049:   4740 / 4751 loss=4.552, nll_loss=2.953, ppl=7.74, wps=88569.4, ups=3.04, wpb=29162, bsz=969, num_updates=232700, lr=6.55544e-05, gnorm=0.474, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 01:34:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-06 01:34:56 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 4.158 | nll_loss 2.387 | ppl 5.23 | wps 203585 | wpb 10489.1 | bsz 375 | num_updates 232711 | best_loss 4.158
2021-04-06 01:34:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 232711 updates
2021-04-06 01:34:56 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-06 01:35:02 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-06 01:35:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt (epoch 49 @ 232711 updates, score 4.158) (writing took 13.335520192980766 seconds)
2021-04-06 01:35:09 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2021-04-06 01:35:09 | INFO | train | epoch 049 | loss 4.522 | nll_loss 2.918 | ppl 7.56 | wps 86982.2 | ups 3 | wpb 28968.6 | bsz 946.5 | num_updates 232711 | lr 6.55528e-05 | gnorm 0.47 | loss_scale 1 | train_wall 1559 | gb_free 6.1 | wall 0
2021-04-06 01:35:09 | INFO | fairseq.trainer | begin training epoch 50
2021-04-06 01:35:09 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-06 01:35:39 | INFO | train_inner | epoch 050:     89 / 4751 loss=4.524, nll_loss=2.92, ppl=7.57, wps=59679.1, ups=2.06, wpb=29017.7, bsz=983, num_updates=232800, lr=6.55403e-05, gnorm=0.478, loss_scale=1, train_wall=33, gb_free=6.7, wall=0
2021-04-06 01:36:12 | INFO | train_inner | epoch 050:    189 / 4751 loss=4.53, nll_loss=2.926, ppl=7.6, wps=88019.5, ups=3.04, wpb=28917.6, bsz=948.2, num_updates=232900, lr=6.55262e-05, gnorm=0.468, loss_scale=1, train_wall=33, gb_free=6.4, wall=0
2021-04-06 01:36:45 | INFO | train_inner | epoch 050:    289 / 4751 loss=4.502, nll_loss=2.895, ppl=7.44, wps=87369.5, ups=3.03, wpb=28841.7, bsz=932.8, num_updates=233000, lr=6.55122e-05, gnorm=0.466, loss_scale=1, train_wall=33, gb_free=6, wall=0
2021-04-06 01:37:18 | INFO | train_inner | epoch 050:    389 / 4751 loss=4.506, nll_loss=2.9, ppl=7.46, wps=87954.2, ups=3.04, wpb=28920.5, bsz=947, num_updates=233100, lr=6.54981e-05, gnorm=0.47, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 01:37:51 | INFO | train_inner | epoch 050:    489 / 4751 loss=4.505, nll_loss=2.898, ppl=7.45, wps=87841.9, ups=3.02, wpb=29120, bsz=938.2, num_updates=233200, lr=6.54841e-05, gnorm=0.468, loss_scale=1, train_wall=33, gb_free=6.4, wall=0
2021-04-06 01:38:24 | INFO | train_inner | epoch 050:    589 / 4751 loss=4.511, nll_loss=2.905, ppl=7.49, wps=87385.8, ups=3.03, wpb=28796.3, bsz=928, num_updates=233300, lr=6.547e-05, gnorm=0.474, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 01:38:57 | INFO | train_inner | epoch 050:    689 / 4751 loss=4.556, nll_loss=2.955, ppl=7.76, wps=88306.8, ups=3.05, wpb=28938.4, bsz=905.5, num_updates=233400, lr=6.5456e-05, gnorm=0.475, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 01:39:30 | INFO | train_inner | epoch 050:    789 / 4751 loss=4.506, nll_loss=2.9, ppl=7.47, wps=87046.4, ups=3.04, wpb=28659.4, bsz=970.9, num_updates=233500, lr=6.5442e-05, gnorm=0.481, loss_scale=2, train_wall=33, gb_free=6.7, wall=0
2021-04-06 01:40:03 | INFO | train_inner | epoch 050:    889 / 4751 loss=4.514, nll_loss=2.909, ppl=7.51, wps=87693.5, ups=3.03, wpb=28951.4, bsz=958, num_updates=233600, lr=6.5428e-05, gnorm=0.471, loss_scale=2, train_wall=33, gb_free=6.7, wall=0
2021-04-06 01:40:36 | INFO | train_inner | epoch 050:    989 / 4751 loss=4.501, nll_loss=2.895, ppl=7.44, wps=88976, ups=3.04, wpb=29234.9, bsz=969.8, num_updates=233700, lr=6.5414e-05, gnorm=0.48, loss_scale=2, train_wall=33, gb_free=6.6, wall=0
2021-04-06 01:41:09 | INFO | train_inner | epoch 050:   1089 / 4751 loss=4.505, nll_loss=2.899, ppl=7.46, wps=87688.6, ups=3.03, wpb=28933.2, bsz=958, num_updates=233800, lr=6.54e-05, gnorm=0.471, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 01:41:42 | INFO | train_inner | epoch 050:   1189 / 4751 loss=4.512, nll_loss=2.907, ppl=7.5, wps=88701.5, ups=3.04, wpb=29144.7, bsz=928, num_updates=233900, lr=6.5386e-05, gnorm=0.467, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 01:42:15 | INFO | train_inner | epoch 050:   1289 / 4751 loss=4.494, nll_loss=2.886, ppl=7.39, wps=87635.3, ups=3.03, wpb=28927.6, bsz=972.5, num_updates=234000, lr=6.5372e-05, gnorm=0.482, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 01:42:48 | INFO | train_inner | epoch 050:   1389 / 4751 loss=4.541, nll_loss=2.939, ppl=7.67, wps=87111.9, ups=3.01, wpb=28983.3, bsz=963.9, num_updates=234100, lr=6.53581e-05, gnorm=0.478, loss_scale=2, train_wall=33, gb_free=5.9, wall=0
2021-04-06 01:43:21 | INFO | train_inner | epoch 050:   1489 / 4751 loss=4.521, nll_loss=2.916, ppl=7.55, wps=87979.3, ups=3.06, wpb=28764.1, bsz=924.9, num_updates=234200, lr=6.53441e-05, gnorm=0.472, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-06 01:43:54 | INFO | train_inner | epoch 050:   1589 / 4751 loss=4.53, nll_loss=2.927, ppl=7.61, wps=88651.1, ups=3.04, wpb=29175.7, bsz=943, num_updates=234300, lr=6.53302e-05, gnorm=0.469, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 01:44:26 | INFO | train_inner | epoch 050:   1689 / 4751 loss=4.549, nll_loss=2.948, ppl=7.72, wps=88309.3, ups=3.04, wpb=29006.6, bsz=923, num_updates=234400, lr=6.53162e-05, gnorm=0.472, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 01:45:00 | INFO | train_inner | epoch 050:   1789 / 4751 loss=4.543, nll_loss=2.941, ppl=7.68, wps=87682.5, ups=3.02, wpb=29030.7, bsz=951, num_updates=234500, lr=6.53023e-05, gnorm=0.473, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 01:45:32 | INFO | train_inner | epoch 050:   1889 / 4751 loss=4.479, nll_loss=2.87, ppl=7.31, wps=88724.3, ups=3.05, wpb=29072.3, bsz=945.4, num_updates=234600, lr=6.52884e-05, gnorm=0.464, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 01:46:05 | INFO | train_inner | epoch 050:   1989 / 4751 loss=4.536, nll_loss=2.934, ppl=7.64, wps=87391.8, ups=3.04, wpb=28790.5, bsz=926.8, num_updates=234700, lr=6.52745e-05, gnorm=0.479, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 01:46:38 | INFO | train_inner | epoch 050:   2089 / 4751 loss=4.51, nll_loss=2.905, ppl=7.49, wps=86289.5, ups=3.02, wpb=28604, bsz=957, num_updates=234800, lr=6.52606e-05, gnorm=0.475, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-06 01:47:12 | INFO | train_inner | epoch 050:   2189 / 4751 loss=4.46, nll_loss=2.848, ppl=7.2, wps=88525.1, ups=3.02, wpb=29281.5, bsz=947.1, num_updates=234900, lr=6.52467e-05, gnorm=0.464, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 01:47:45 | INFO | train_inner | epoch 050:   2289 / 4751 loss=4.491, nll_loss=2.883, ppl=7.38, wps=86763.7, ups=3.02, wpb=28759.2, bsz=935.7, num_updates=235000, lr=6.52328e-05, gnorm=0.47, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 01:48:18 | INFO | train_inner | epoch 050:   2389 / 4751 loss=4.473, nll_loss=2.863, ppl=7.27, wps=87407.1, ups=3.03, wpb=28827.6, bsz=973.5, num_updates=235100, lr=6.52189e-05, gnorm=0.471, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 01:48:51 | INFO | train_inner | epoch 050:   2489 / 4751 loss=4.528, nll_loss=2.925, ppl=7.6, wps=88294.3, ups=3.04, wpb=29045.8, bsz=943.1, num_updates=235200, lr=6.52051e-05, gnorm=0.483, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 01:49:24 | INFO | train_inner | epoch 050:   2589 / 4751 loss=4.555, nll_loss=2.955, ppl=7.76, wps=87569.7, ups=3.02, wpb=28995, bsz=954.1, num_updates=235300, lr=6.51912e-05, gnorm=0.472, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 01:49:57 | INFO | train_inner | epoch 050:   2689 / 4751 loss=4.569, nll_loss=2.971, ppl=7.84, wps=87902.3, ups=3.04, wpb=28928.7, bsz=937, num_updates=235400, lr=6.51774e-05, gnorm=0.476, loss_scale=4, train_wall=33, gb_free=6.4, wall=0
2021-04-06 01:50:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-06 01:50:30 | INFO | train_inner | epoch 050:   2790 / 4751 loss=4.506, nll_loss=2.9, ppl=7.47, wps=86819.1, ups=3, wpb=28930.6, bsz=936.2, num_updates=235500, lr=6.51635e-05, gnorm=0.473, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 01:51:03 | INFO | train_inner | epoch 050:   2890 / 4751 loss=4.54, nll_loss=2.938, ppl=7.66, wps=88221.9, ups=3.04, wpb=28996.4, bsz=916.8, num_updates=235600, lr=6.51497e-05, gnorm=0.472, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 01:51:36 | INFO | train_inner | epoch 050:   2990 / 4751 loss=4.497, nll_loss=2.89, ppl=7.41, wps=87689.9, ups=3.04, wpb=28814.7, bsz=929.2, num_updates=235700, lr=6.51359e-05, gnorm=0.471, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 01:52:08 | INFO | train_inner | epoch 050:   3090 / 4751 loss=4.568, nll_loss=2.97, ppl=7.84, wps=89078.2, ups=3.06, wpb=29090.3, bsz=941.4, num_updates=235800, lr=6.51221e-05, gnorm=0.472, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 01:52:41 | INFO | train_inner | epoch 050:   3190 / 4751 loss=4.527, nll_loss=2.924, ppl=7.59, wps=88883.6, ups=3.06, wpb=29087.4, bsz=925.4, num_updates=235900, lr=6.51083e-05, gnorm=0.471, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-06 01:53:14 | INFO | train_inner | epoch 050:   3290 / 4751 loss=4.569, nll_loss=2.971, ppl=7.84, wps=87728.5, ups=3.03, wpb=28905.6, bsz=915.3, num_updates=236000, lr=6.50945e-05, gnorm=0.48, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-06 01:53:47 | INFO | train_inner | epoch 050:   3390 / 4751 loss=4.539, nll_loss=2.937, ppl=7.66, wps=88540, ups=3.03, wpb=29185.1, bsz=963.3, num_updates=236100, lr=6.50807e-05, gnorm=0.473, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 01:54:20 | INFO | train_inner | epoch 050:   3490 / 4751 loss=4.538, nll_loss=2.935, ppl=7.65, wps=88194.1, ups=3.05, wpb=28933.9, bsz=922.6, num_updates=236200, lr=6.50669e-05, gnorm=0.474, loss_scale=2, train_wall=33, gb_free=5.4, wall=0
2021-04-06 01:54:52 | INFO | train_inner | epoch 050:   3590 / 4751 loss=4.555, nll_loss=2.955, ppl=7.75, wps=88638.6, ups=3.06, wpb=29014.1, bsz=952.2, num_updates=236300, lr=6.50531e-05, gnorm=0.471, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 01:55:26 | INFO | train_inner | epoch 050:   3690 / 4751 loss=4.482, nll_loss=2.873, ppl=7.32, wps=86878.2, ups=3.02, wpb=28804.7, bsz=957.8, num_updates=236400, lr=6.50394e-05, gnorm=0.474, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 01:55:59 | INFO | train_inner | epoch 050:   3790 / 4751 loss=4.495, nll_loss=2.888, ppl=7.4, wps=88474.9, ups=3.02, wpb=29273.5, bsz=942.9, num_updates=236500, lr=6.50256e-05, gnorm=0.466, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 01:56:32 | INFO | train_inner | epoch 050:   3890 / 4751 loss=4.521, nll_loss=2.917, ppl=7.55, wps=88084.5, ups=3.03, wpb=29112.5, bsz=977.1, num_updates=236600, lr=6.50119e-05, gnorm=0.487, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 01:57:05 | INFO | train_inner | epoch 050:   3990 / 4751 loss=4.498, nll_loss=2.89, ppl=7.42, wps=87862.8, ups=3.04, wpb=28907.9, bsz=937, num_updates=236700, lr=6.49981e-05, gnorm=0.471, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 01:57:37 | INFO | train_inner | epoch 050:   4090 / 4751 loss=4.584, nll_loss=2.989, ppl=7.94, wps=88470.8, ups=3.05, wpb=29024.9, bsz=979.3, num_updates=236800, lr=6.49844e-05, gnorm=0.473, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 01:58:10 | INFO | train_inner | epoch 050:   4190 / 4751 loss=4.527, nll_loss=2.924, ppl=7.59, wps=88781.5, ups=3.04, wpb=29189.5, bsz=961.8, num_updates=236900, lr=6.49707e-05, gnorm=0.474, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 01:58:43 | INFO | train_inner | epoch 050:   4290 / 4751 loss=4.452, nll_loss=2.84, ppl=7.16, wps=87057.8, ups=3.02, wpb=28856.9, bsz=992.4, num_updates=237000, lr=6.4957e-05, gnorm=0.477, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 01:59:17 | INFO | train_inner | epoch 050:   4390 / 4751 loss=4.51, nll_loss=2.905, ppl=7.49, wps=85361.2, ups=3, wpb=28493.1, bsz=944.3, num_updates=237100, lr=6.49433e-05, gnorm=0.479, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 01:59:50 | INFO | train_inner | epoch 050:   4490 / 4751 loss=4.511, nll_loss=2.906, ppl=7.5, wps=88335.6, ups=3.05, wpb=28958, bsz=953.9, num_updates=237200, lr=6.49296e-05, gnorm=0.473, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 02:00:22 | INFO | train_inner | epoch 050:   4590 / 4751 loss=4.506, nll_loss=2.9, ppl=7.46, wps=88335.9, ups=3.05, wpb=28928.7, bsz=954.6, num_updates=237300, lr=6.49159e-05, gnorm=0.462, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 02:00:56 | INFO | train_inner | epoch 050:   4690 / 4751 loss=4.552, nll_loss=2.952, ppl=7.74, wps=86832.1, ups=2.99, wpb=29076.8, bsz=946.6, num_updates=237400, lr=6.49022e-05, gnorm=0.474, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 02:01:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-06 02:01:17 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 4.148 | nll_loss 2.377 | ppl 5.19 | wps 207803 | wpb 10489.1 | bsz 375 | num_updates 237461 | best_loss 4.148
2021-04-06 02:01:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 237461 updates
2021-04-06 02:01:17 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-06 02:01:23 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-06 02:01:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt (epoch 50 @ 237461 updates, score 4.148) (writing took 12.765908062458038 seconds)
2021-04-06 02:01:30 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2021-04-06 02:01:30 | INFO | train | epoch 050 | loss 4.519 | nll_loss 2.915 | ppl 7.54 | wps 87036.1 | ups 3 | wpb 28967.8 | bsz 946.9 | num_updates 237461 | lr 6.48939e-05 | gnorm 0.473 | loss_scale 2 | train_wall 1559 | gb_free 6.3 | wall 0
2021-04-06 02:01:30 | INFO | fairseq.trainer | begin training epoch 51
2021-04-06 02:01:30 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-06 02:01:44 | INFO | train_inner | epoch 051:     39 / 4751 loss=4.533, nll_loss=2.93, ppl=7.62, wps=60354.4, ups=2.08, wpb=28988.6, bsz=918.8, num_updates=237500, lr=6.48886e-05, gnorm=0.475, loss_scale=4, train_wall=33, gb_free=6.6, wall=0
2021-04-06 02:02:17 | INFO | train_inner | epoch 051:    139 / 4751 loss=4.488, nll_loss=2.88, ppl=7.36, wps=87774.5, ups=3.04, wpb=28883.2, bsz=957.2, num_updates=237600, lr=6.48749e-05, gnorm=0.47, loss_scale=4, train_wall=33, gb_free=6.4, wall=0
2021-04-06 02:02:50 | INFO | train_inner | epoch 051:    239 / 4751 loss=4.499, nll_loss=2.891, ppl=7.42, wps=87807.7, ups=3.03, wpb=28978.4, bsz=911.7, num_updates=237700, lr=6.48613e-05, gnorm=0.47, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-06 02:03:23 | INFO | train_inner | epoch 051:    339 / 4751 loss=4.497, nll_loss=2.889, ppl=7.41, wps=88285.2, ups=3.04, wpb=29066, bsz=974.5, num_updates=237800, lr=6.48476e-05, gnorm=0.469, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 02:03:56 | INFO | train_inner | epoch 051:    439 / 4751 loss=4.539, nll_loss=2.937, ppl=7.66, wps=88642.5, ups=3.05, wpb=29089, bsz=934.3, num_updates=237900, lr=6.4834e-05, gnorm=0.472, loss_scale=4, train_wall=33, gb_free=6.4, wall=0
2021-04-06 02:04:29 | INFO | train_inner | epoch 051:    539 / 4751 loss=4.487, nll_loss=2.878, ppl=7.35, wps=87366.5, ups=3.02, wpb=28976.9, bsz=924.2, num_updates=238000, lr=6.48204e-05, gnorm=0.466, loss_scale=4, train_wall=33, gb_free=6.5, wall=0
2021-04-06 02:05:02 | INFO | train_inner | epoch 051:    639 / 4751 loss=4.554, nll_loss=2.954, ppl=7.75, wps=88491, ups=3.04, wpb=29081.1, bsz=937.4, num_updates=238100, lr=6.48068e-05, gnorm=0.469, loss_scale=4, train_wall=33, gb_free=6, wall=0
2021-04-06 02:05:35 | INFO | train_inner | epoch 051:    739 / 4751 loss=4.494, nll_loss=2.886, ppl=7.39, wps=87320.1, ups=3.03, wpb=28785.7, bsz=960.3, num_updates=238200, lr=6.47932e-05, gnorm=0.47, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 02:06:08 | INFO | train_inner | epoch 051:    839 / 4751 loss=4.489, nll_loss=2.881, ppl=7.37, wps=87251.8, ups=3.02, wpb=28927.3, bsz=982.8, num_updates=238300, lr=6.47796e-05, gnorm=0.47, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 02:06:41 | INFO | train_inner | epoch 051:    939 / 4751 loss=4.577, nll_loss=2.981, ppl=7.89, wps=86869.5, ups=3.03, wpb=28658.8, bsz=968.4, num_updates=238400, lr=6.4766e-05, gnorm=0.483, loss_scale=4, train_wall=33, gb_free=6, wall=0
2021-04-06 02:07:14 | INFO | train_inner | epoch 051:   1039 / 4751 loss=4.5, nll_loss=2.893, ppl=7.43, wps=88943.6, ups=3.04, wpb=29276.2, bsz=953.1, num_updates=238500, lr=6.47524e-05, gnorm=0.468, loss_scale=4, train_wall=33, gb_free=6.6, wall=0
2021-04-06 02:07:46 | INFO | train_inner | epoch 051:   1139 / 4751 loss=4.482, nll_loss=2.873, ppl=7.32, wps=88674.9, ups=3.04, wpb=29158.8, bsz=957, num_updates=238600, lr=6.47388e-05, gnorm=0.467, loss_scale=4, train_wall=33, gb_free=6.5, wall=0
2021-04-06 02:08:20 | INFO | train_inner | epoch 051:   1239 / 4751 loss=4.54, nll_loss=2.938, ppl=7.66, wps=86704.3, ups=2.99, wpb=29026.2, bsz=929.9, num_updates=238700, lr=6.47253e-05, gnorm=0.474, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-06 02:08:53 | INFO | train_inner | epoch 051:   1339 / 4751 loss=4.516, nll_loss=2.912, ppl=7.53, wps=88020.4, ups=3.05, wpb=28885.7, bsz=935.4, num_updates=238800, lr=6.47117e-05, gnorm=0.474, loss_scale=4, train_wall=33, gb_free=6.4, wall=0
2021-04-06 02:09:26 | INFO | train_inner | epoch 051:   1439 / 4751 loss=4.514, nll_loss=2.908, ppl=7.51, wps=87051.2, ups=3.03, wpb=28745.4, bsz=919.9, num_updates=238900, lr=6.46982e-05, gnorm=0.474, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-06 02:09:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-06 02:09:59 | INFO | train_inner | epoch 051:   1540 / 4751 loss=4.476, nll_loss=2.866, ppl=7.29, wps=85708.4, ups=3, wpb=28611.6, bsz=939.8, num_updates=239000, lr=6.46846e-05, gnorm=0.473, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 02:10:32 | INFO | train_inner | epoch 051:   1640 / 4751 loss=4.493, nll_loss=2.886, ppl=7.39, wps=87646.1, ups=3.04, wpb=28829.8, bsz=958.2, num_updates=239100, lr=6.46711e-05, gnorm=0.476, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 02:11:05 | INFO | train_inner | epoch 051:   1740 / 4751 loss=4.541, nll_loss=2.939, ppl=7.67, wps=88042.8, ups=3.05, wpb=28907.6, bsz=900.6, num_updates=239200, lr=6.46576e-05, gnorm=0.478, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 02:11:38 | INFO | train_inner | epoch 051:   1840 / 4751 loss=4.586, nll_loss=2.99, ppl=7.94, wps=87455, ups=3.05, wpb=28707.6, bsz=943.6, num_updates=239300, lr=6.46441e-05, gnorm=0.481, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 02:12:11 | INFO | train_inner | epoch 051:   1940 / 4751 loss=4.562, nll_loss=2.964, ppl=7.8, wps=87641.3, ups=3.04, wpb=28851.5, bsz=942.7, num_updates=239400, lr=6.46306e-05, gnorm=0.47, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 02:12:44 | INFO | train_inner | epoch 051:   2040 / 4751 loss=4.478, nll_loss=2.869, ppl=7.3, wps=88901.5, ups=3.04, wpb=29198.4, bsz=942.1, num_updates=239500, lr=6.46171e-05, gnorm=0.466, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 02:13:17 | INFO | train_inner | epoch 051:   2140 / 4751 loss=4.507, nll_loss=2.901, ppl=7.47, wps=87151.7, ups=3.03, wpb=28787.7, bsz=981.7, num_updates=239600, lr=6.46036e-05, gnorm=0.471, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 02:13:49 | INFO | train_inner | epoch 051:   2240 / 4751 loss=4.522, nll_loss=2.918, ppl=7.56, wps=88960, ups=3.06, wpb=29111, bsz=922.7, num_updates=239700, lr=6.45901e-05, gnorm=0.473, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 02:14:22 | INFO | train_inner | epoch 051:   2340 / 4751 loss=4.493, nll_loss=2.886, ppl=7.39, wps=88125.8, ups=3.04, wpb=29009.3, bsz=941.6, num_updates=239800, lr=6.45766e-05, gnorm=0.473, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 02:14:55 | INFO | train_inner | epoch 051:   2440 / 4751 loss=4.52, nll_loss=2.916, ppl=7.55, wps=87933.9, ups=3.03, wpb=28994.2, bsz=945.2, num_updates=239900, lr=6.45632e-05, gnorm=0.477, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-06 02:15:28 | INFO | train_inner | epoch 051:   2540 / 4751 loss=4.544, nll_loss=2.942, ppl=7.69, wps=87542.1, ups=3.04, wpb=28790.7, bsz=905.8, num_updates=240000, lr=6.45497e-05, gnorm=0.483, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 02:16:01 | INFO | train_inner | epoch 051:   2640 / 4751 loss=4.512, nll_loss=2.907, ppl=7.5, wps=89156.7, ups=3.04, wpb=29287.8, bsz=945, num_updates=240100, lr=6.45363e-05, gnorm=0.468, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 02:16:34 | INFO | train_inner | epoch 051:   2740 / 4751 loss=4.481, nll_loss=2.871, ppl=7.32, wps=88472, ups=3.04, wpb=29095.6, bsz=972.6, num_updates=240200, lr=6.45228e-05, gnorm=0.47, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 02:17:07 | INFO | train_inner | epoch 051:   2840 / 4751 loss=4.5, nll_loss=2.893, ppl=7.43, wps=87811.3, ups=3.03, wpb=29010.7, bsz=938.4, num_updates=240300, lr=6.45094e-05, gnorm=0.468, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 02:17:39 | INFO | train_inner | epoch 051:   2940 / 4751 loss=4.538, nll_loss=2.936, ppl=7.65, wps=87425.4, ups=3.06, wpb=28547.6, bsz=926.9, num_updates=240400, lr=6.4496e-05, gnorm=0.498, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 02:18:12 | INFO | train_inner | epoch 051:   3040 / 4751 loss=4.44, nll_loss=2.825, ppl=7.09, wps=88212.4, ups=3.03, wpb=29079.6, bsz=964.6, num_updates=240500, lr=6.44826e-05, gnorm=0.466, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-06 02:18:45 | INFO | train_inner | epoch 051:   3140 / 4751 loss=4.541, nll_loss=2.94, ppl=7.67, wps=87585.9, ups=3.05, wpb=28738.3, bsz=948.9, num_updates=240600, lr=6.44692e-05, gnorm=0.474, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 02:19:18 | INFO | train_inner | epoch 051:   3240 / 4751 loss=4.504, nll_loss=2.898, ppl=7.45, wps=87508.9, ups=3.03, wpb=28898, bsz=953.4, num_updates=240700, lr=6.44558e-05, gnorm=0.477, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 02:19:51 | INFO | train_inner | epoch 051:   3340 / 4751 loss=4.555, nll_loss=2.956, ppl=7.76, wps=86955.2, ups=3.02, wpb=28785.7, bsz=953.7, num_updates=240800, lr=6.44424e-05, gnorm=0.482, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 02:20:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-04-06 02:20:25 | INFO | train_inner | epoch 051:   3441 / 4751 loss=4.506, nll_loss=2.9, ppl=7.47, wps=87412.5, ups=3, wpb=29137.1, bsz=933.8, num_updates=240900, lr=6.4429e-05, gnorm=0.468, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 02:20:58 | INFO | train_inner | epoch 051:   3541 / 4751 loss=4.608, nll_loss=3.016, ppl=8.09, wps=88921.5, ups=3.04, wpb=29218.6, bsz=943.6, num_updates=241000, lr=6.44157e-05, gnorm=0.475, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 02:21:31 | INFO | train_inner | epoch 051:   3641 / 4751 loss=4.489, nll_loss=2.881, ppl=7.37, wps=87655.2, ups=3.04, wpb=28872, bsz=959.3, num_updates=241100, lr=6.44023e-05, gnorm=0.469, loss_scale=1, train_wall=33, gb_free=5.8, wall=0
2021-04-06 02:22:03 | INFO | train_inner | epoch 051:   3741 / 4751 loss=4.512, nll_loss=2.907, ppl=7.5, wps=88511.6, ups=3.05, wpb=28983, bsz=963.8, num_updates=241200, lr=6.4389e-05, gnorm=0.474, loss_scale=1, train_wall=33, gb_free=6.6, wall=0
2021-04-06 02:22:36 | INFO | train_inner | epoch 051:   3841 / 4751 loss=4.488, nll_loss=2.88, ppl=7.36, wps=88529.5, ups=3.04, wpb=29147.6, bsz=940.4, num_updates=241300, lr=6.43756e-05, gnorm=0.468, loss_scale=1, train_wall=33, gb_free=6.8, wall=0
2021-04-06 02:23:09 | INFO | train_inner | epoch 051:   3941 / 4751 loss=4.563, nll_loss=2.964, ppl=7.8, wps=88258, ups=3.06, wpb=28851.4, bsz=948.9, num_updates=241400, lr=6.43623e-05, gnorm=0.474, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 02:23:42 | INFO | train_inner | epoch 051:   4041 / 4751 loss=4.494, nll_loss=2.887, ppl=7.4, wps=88048.7, ups=3.03, wpb=29064.2, bsz=987.6, num_updates=241500, lr=6.43489e-05, gnorm=0.47, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 02:24:15 | INFO | train_inner | epoch 051:   4141 / 4751 loss=4.547, nll_loss=2.947, ppl=7.71, wps=87355.6, ups=3.03, wpb=28873.9, bsz=952.8, num_updates=241600, lr=6.43356e-05, gnorm=0.482, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 02:24:48 | INFO | train_inner | epoch 051:   4241 / 4751 loss=4.534, nll_loss=2.931, ppl=7.63, wps=89308.5, ups=3.04, wpb=29334.3, bsz=939.4, num_updates=241700, lr=6.43223e-05, gnorm=0.468, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 02:25:21 | INFO | train_inner | epoch 051:   4341 / 4751 loss=4.555, nll_loss=2.956, ppl=7.76, wps=88244.4, ups=3.05, wpb=28966.3, bsz=946.7, num_updates=241800, lr=6.4309e-05, gnorm=0.473, loss_scale=1, train_wall=33, gb_free=6, wall=0
2021-04-06 02:25:54 | INFO | train_inner | epoch 051:   4441 / 4751 loss=4.552, nll_loss=2.953, ppl=7.74, wps=88410.7, ups=3.03, wpb=29176.5, bsz=958.6, num_updates=241900, lr=6.42957e-05, gnorm=0.474, loss_scale=1, train_wall=33, gb_free=6.4, wall=0
2021-04-06 02:26:27 | INFO | train_inner | epoch 051:   4541 / 4751 loss=4.472, nll_loss=2.862, ppl=7.27, wps=88497.9, ups=3.03, wpb=29172, bsz=944.4, num_updates=242000, lr=6.42824e-05, gnorm=0.466, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 02:27:01 | INFO | train_inner | epoch 051:   4641 / 4751 loss=4.51, nll_loss=2.904, ppl=7.49, wps=85332.5, ups=2.93, wpb=29104.7, bsz=965.7, num_updates=242100, lr=6.42692e-05, gnorm=0.466, loss_scale=1, train_wall=34, gb_free=6.1, wall=0
2021-04-06 02:27:34 | INFO | train_inner | epoch 051:   4741 / 4751 loss=4.501, nll_loss=2.895, ppl=7.44, wps=87996.4, ups=3.04, wpb=28968.1, bsz=953.1, num_updates=242200, lr=6.42559e-05, gnorm=0.477, loss_scale=1, train_wall=33, gb_free=6, wall=0
2021-04-06 02:27:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-06 02:27:38 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 4.153 | nll_loss 2.382 | ppl 5.21 | wps 209424 | wpb 10489.1 | bsz 375 | num_updates 242210 | best_loss 4.148
2021-04-06 02:27:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 242210 updates
2021-04-06 02:27:38 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-06 02:27:44 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-06 02:27:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt (epoch 51 @ 242210 updates, score 4.153) (writing took 5.954543646425009 seconds)
2021-04-06 02:27:44 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2021-04-06 02:27:44 | INFO | train | epoch 051 | loss 4.518 | nll_loss 2.913 | ppl 7.53 | wps 87387.5 | ups 3.02 | wpb 28967.8 | bsz 946.7 | num_updates 242210 | lr 6.42546e-05 | gnorm 0.473 | loss_scale 1 | train_wall 1559 | gb_free 6.3 | wall 0
2021-04-06 02:27:44 | INFO | fairseq.trainer | begin training epoch 52
2021-04-06 02:27:44 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-06 02:28:15 | INFO | train_inner | epoch 052:     90 / 4751 loss=4.544, nll_loss=2.943, ppl=7.69, wps=69749.7, ups=2.41, wpb=28902.3, bsz=957.8, num_updates=242300, lr=6.42426e-05, gnorm=0.478, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 02:28:48 | INFO | train_inner | epoch 052:    190 / 4751 loss=4.516, nll_loss=2.911, ppl=7.52, wps=87685, ups=3.05, wpb=28735.2, bsz=955.7, num_updates=242400, lr=6.42294e-05, gnorm=0.475, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 02:29:21 | INFO | train_inner | epoch 052:    290 / 4751 loss=4.546, nll_loss=2.945, ppl=7.7, wps=88380.8, ups=3.03, wpb=29148, bsz=971.1, num_updates=242500, lr=6.42161e-05, gnorm=0.482, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 02:29:54 | INFO | train_inner | epoch 052:    390 / 4751 loss=4.531, nll_loss=2.928, ppl=7.61, wps=87170.1, ups=3.04, wpb=28661.7, bsz=939.2, num_updates=242600, lr=6.42029e-05, gnorm=0.472, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 02:30:26 | INFO | train_inner | epoch 052:    490 / 4751 loss=4.529, nll_loss=2.926, ppl=7.6, wps=88802.5, ups=3.05, wpb=29138.5, bsz=923.4, num_updates=242700, lr=6.41897e-05, gnorm=0.469, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 02:30:59 | INFO | train_inner | epoch 052:    590 / 4751 loss=4.516, nll_loss=2.912, ppl=7.52, wps=88207.7, ups=3.04, wpb=28982.9, bsz=948.7, num_updates=242800, lr=6.41764e-05, gnorm=0.481, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 02:31:32 | INFO | train_inner | epoch 052:    690 / 4751 loss=4.499, nll_loss=2.892, ppl=7.42, wps=87837.2, ups=3.05, wpb=28803, bsz=957.7, num_updates=242900, lr=6.41632e-05, gnorm=0.472, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 02:32:05 | INFO | train_inner | epoch 052:    790 / 4751 loss=4.488, nll_loss=2.879, ppl=7.36, wps=88715.1, ups=3.05, wpb=29116, bsz=929.6, num_updates=243000, lr=6.415e-05, gnorm=0.467, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-06 02:32:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-04-06 02:32:38 | INFO | train_inner | epoch 052:    891 / 4751 loss=4.488, nll_loss=2.88, ppl=7.36, wps=87057.9, ups=3, wpb=28989.2, bsz=923.8, num_updates=243100, lr=6.41368e-05, gnorm=0.474, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 02:33:11 | INFO | train_inner | epoch 052:    991 / 4751 loss=4.493, nll_loss=2.886, ppl=7.39, wps=88311.9, ups=3.03, wpb=29109.6, bsz=983.3, num_updates=243200, lr=6.41236e-05, gnorm=0.472, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 02:33:44 | INFO | train_inner | epoch 052:   1091 / 4751 loss=4.483, nll_loss=2.873, ppl=7.33, wps=87758.6, ups=3.03, wpb=28949, bsz=942.5, num_updates=243300, lr=6.41105e-05, gnorm=0.477, loss_scale=1, train_wall=33, gb_free=6, wall=0
2021-04-06 02:34:17 | INFO | train_inner | epoch 052:   1191 / 4751 loss=4.523, nll_loss=2.919, ppl=7.56, wps=88927.5, ups=3.04, wpb=29226.8, bsz=932.6, num_updates=243400, lr=6.40973e-05, gnorm=0.468, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 02:34:50 | INFO | train_inner | epoch 052:   1291 / 4751 loss=4.508, nll_loss=2.903, ppl=7.48, wps=87334.4, ups=3.02, wpb=28929.4, bsz=963.9, num_updates=243500, lr=6.40841e-05, gnorm=0.476, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 02:35:23 | INFO | train_inner | epoch 052:   1391 / 4751 loss=4.519, nll_loss=2.914, ppl=7.54, wps=87557.1, ups=3.03, wpb=28914, bsz=939.4, num_updates=243600, lr=6.4071e-05, gnorm=0.47, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 02:35:56 | INFO | train_inner | epoch 052:   1491 / 4751 loss=4.5, nll_loss=2.894, ppl=7.43, wps=86691.7, ups=3.03, wpb=28657.9, bsz=953.3, num_updates=243700, lr=6.40578e-05, gnorm=0.475, loss_scale=1, train_wall=33, gb_free=6.4, wall=0
2021-04-06 02:36:29 | INFO | train_inner | epoch 052:   1591 / 4751 loss=4.606, nll_loss=3.013, ppl=8.07, wps=88635, ups=3.07, wpb=28878.4, bsz=931, num_updates=243800, lr=6.40447e-05, gnorm=0.478, loss_scale=1, train_wall=32, gb_free=6.5, wall=0
2021-04-06 02:37:02 | INFO | train_inner | epoch 052:   1691 / 4751 loss=4.461, nll_loss=2.849, ppl=7.2, wps=88503.2, ups=3.04, wpb=29068.5, bsz=997.6, num_updates=243900, lr=6.40316e-05, gnorm=0.472, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 02:37:35 | INFO | train_inner | epoch 052:   1791 / 4751 loss=4.545, nll_loss=2.944, ppl=7.7, wps=87892.8, ups=3.04, wpb=28876.7, bsz=938.7, num_updates=244000, lr=6.40184e-05, gnorm=0.473, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 02:38:07 | INFO | train_inner | epoch 052:   1891 / 4751 loss=4.553, nll_loss=2.954, ppl=7.75, wps=87863.6, ups=3.05, wpb=28797, bsz=976.2, num_updates=244100, lr=6.40053e-05, gnorm=0.48, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 02:38:40 | INFO | train_inner | epoch 052:   1991 / 4751 loss=4.528, nll_loss=2.925, ppl=7.59, wps=88824.3, ups=3.04, wpb=29228, bsz=982.2, num_updates=244200, lr=6.39922e-05, gnorm=0.468, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 02:39:13 | INFO | train_inner | epoch 052:   2091 / 4751 loss=4.522, nll_loss=2.918, ppl=7.56, wps=89154.5, ups=3.07, wpb=29067.9, bsz=963.1, num_updates=244300, lr=6.39791e-05, gnorm=0.472, loss_scale=1, train_wall=32, gb_free=6.2, wall=0
2021-04-06 02:39:46 | INFO | train_inner | epoch 052:   2191 / 4751 loss=4.487, nll_loss=2.879, ppl=7.35, wps=87874.8, ups=3.02, wpb=29103.7, bsz=959.1, num_updates=244400, lr=6.3966e-05, gnorm=0.478, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 02:40:19 | INFO | train_inner | epoch 052:   2291 / 4751 loss=4.522, nll_loss=2.918, ppl=7.56, wps=87266, ups=3.02, wpb=28878.6, bsz=932.6, num_updates=244500, lr=6.39529e-05, gnorm=0.472, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 02:40:52 | INFO | train_inner | epoch 052:   2391 / 4751 loss=4.509, nll_loss=2.903, ppl=7.48, wps=88491.5, ups=3.03, wpb=29159.8, bsz=929.4, num_updates=244600, lr=6.39399e-05, gnorm=0.469, loss_scale=1, train_wall=33, gb_free=6.6, wall=0
2021-04-06 02:41:25 | INFO | train_inner | epoch 052:   2491 / 4751 loss=4.499, nll_loss=2.892, ppl=7.42, wps=88303.2, ups=3.05, wpb=28974.3, bsz=933.6, num_updates=244700, lr=6.39268e-05, gnorm=0.471, loss_scale=1, train_wall=33, gb_free=6.4, wall=0
2021-04-06 02:41:58 | INFO | train_inner | epoch 052:   2591 / 4751 loss=4.509, nll_loss=2.903, ppl=7.48, wps=88389.2, ups=3.05, wpb=28998.6, bsz=944.3, num_updates=244800, lr=6.39137e-05, gnorm=0.47, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 02:42:31 | INFO | train_inner | epoch 052:   2691 / 4751 loss=4.506, nll_loss=2.901, ppl=7.47, wps=87469.1, ups=3.04, wpb=28790.5, bsz=953, num_updates=244900, lr=6.39007e-05, gnorm=0.475, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 02:43:04 | INFO | train_inner | epoch 052:   2791 / 4751 loss=4.497, nll_loss=2.89, ppl=7.41, wps=88662.9, ups=3.03, wpb=29237, bsz=960.1, num_updates=245000, lr=6.38877e-05, gnorm=0.471, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 02:43:36 | INFO | train_inner | epoch 052:   2891 / 4751 loss=4.517, nll_loss=2.912, ppl=7.53, wps=88137.1, ups=3.05, wpb=28929.7, bsz=913.4, num_updates=245100, lr=6.38746e-05, gnorm=0.473, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 02:44:09 | INFO | train_inner | epoch 052:   2991 / 4751 loss=4.493, nll_loss=2.885, ppl=7.39, wps=87976.1, ups=3.03, wpb=29020.9, bsz=944, num_updates=245200, lr=6.38616e-05, gnorm=0.469, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 02:44:42 | INFO | train_inner | epoch 052:   3091 / 4751 loss=4.52, nll_loss=2.917, ppl=7.55, wps=86839.6, ups=3.02, wpb=28740.2, bsz=946.9, num_updates=245300, lr=6.38486e-05, gnorm=0.475, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 02:45:15 | INFO | train_inner | epoch 052:   3191 / 4751 loss=4.496, nll_loss=2.889, ppl=7.41, wps=87504.7, ups=3.05, wpb=28697.7, bsz=952, num_updates=245400, lr=6.38356e-05, gnorm=0.476, loss_scale=2, train_wall=33, gb_free=6.6, wall=0
2021-04-06 02:45:48 | INFO | train_inner | epoch 052:   3291 / 4751 loss=4.548, nll_loss=2.948, ppl=7.72, wps=88357.8, ups=3.03, wpb=29139.8, bsz=912.5, num_updates=245500, lr=6.38226e-05, gnorm=0.471, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 02:46:21 | INFO | train_inner | epoch 052:   3391 / 4751 loss=4.513, nll_loss=2.908, ppl=7.51, wps=88611.9, ups=3.04, wpb=29175.6, bsz=913.8, num_updates=245600, lr=6.38096e-05, gnorm=0.479, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 02:46:54 | INFO | train_inner | epoch 052:   3491 / 4751 loss=4.49, nll_loss=2.883, ppl=7.37, wps=88706.6, ups=3.04, wpb=29179, bsz=958.2, num_updates=245700, lr=6.37966e-05, gnorm=0.47, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 02:47:27 | INFO | train_inner | epoch 052:   3591 / 4751 loss=4.527, nll_loss=2.925, ppl=7.59, wps=87619.2, ups=3.04, wpb=28805, bsz=970.3, num_updates=245800, lr=6.37836e-05, gnorm=0.48, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 02:48:00 | INFO | train_inner | epoch 052:   3691 / 4751 loss=4.477, nll_loss=2.867, ppl=7.3, wps=88609.4, ups=3.04, wpb=29146.8, bsz=934, num_updates=245900, lr=6.37706e-05, gnorm=0.472, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 02:48:33 | INFO | train_inner | epoch 052:   3791 / 4751 loss=4.523, nll_loss=2.919, ppl=7.56, wps=88769.5, ups=3.05, wpb=29143, bsz=942.1, num_updates=246000, lr=6.37577e-05, gnorm=0.469, loss_scale=2, train_wall=33, gb_free=6.6, wall=0
2021-04-06 02:48:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-04-06 02:49:06 | INFO | train_inner | epoch 052:   3892 / 4751 loss=4.496, nll_loss=2.889, ppl=7.41, wps=86388.9, ups=3, wpb=28790.8, bsz=889.1, num_updates=246100, lr=6.37447e-05, gnorm=0.476, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 02:49:39 | INFO | train_inner | epoch 052:   3992 / 4751 loss=4.506, nll_loss=2.901, ppl=7.47, wps=87370.5, ups=3.03, wpb=28811.3, bsz=967.4, num_updates=246200, lr=6.37318e-05, gnorm=0.471, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 02:50:12 | INFO | train_inner | epoch 052:   4092 / 4751 loss=4.546, nll_loss=2.946, ppl=7.71, wps=86536, ups=2.98, wpb=29029.9, bsz=941.1, num_updates=246300, lr=6.37188e-05, gnorm=0.48, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 02:50:45 | INFO | train_inner | epoch 052:   4192 / 4751 loss=4.536, nll_loss=2.935, ppl=7.65, wps=88069.5, ups=3.04, wpb=28999, bsz=928.7, num_updates=246400, lr=6.37059e-05, gnorm=0.479, loss_scale=1, train_wall=33, gb_free=6.4, wall=0
2021-04-06 02:51:19 | INFO | train_inner | epoch 052:   4292 / 4751 loss=4.524, nll_loss=2.92, ppl=7.57, wps=86754.6, ups=3, wpb=28872.5, bsz=947, num_updates=246500, lr=6.3693e-05, gnorm=0.476, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 02:51:52 | INFO | train_inner | epoch 052:   4392 / 4751 loss=4.548, nll_loss=2.948, ppl=7.72, wps=86902.3, ups=3.03, wpb=28691, bsz=964.2, num_updates=246600, lr=6.36801e-05, gnorm=0.476, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 02:52:25 | INFO | train_inner | epoch 052:   4492 / 4751 loss=4.567, nll_loss=2.97, ppl=7.84, wps=88117.6, ups=3.04, wpb=28956, bsz=939.1, num_updates=246700, lr=6.36672e-05, gnorm=0.475, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 02:52:57 | INFO | train_inner | epoch 052:   4592 / 4751 loss=4.484, nll_loss=2.876, ppl=7.34, wps=87798.5, ups=3.04, wpb=28849.7, bsz=931.4, num_updates=246800, lr=6.36543e-05, gnorm=0.471, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 02:53:30 | INFO | train_inner | epoch 052:   4692 / 4751 loss=4.508, nll_loss=2.902, ppl=7.47, wps=89392.7, ups=3.06, wpb=29240.9, bsz=942.8, num_updates=246900, lr=6.36414e-05, gnorm=0.475, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 02:53:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-06 02:53:51 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 4.16 | nll_loss 2.387 | ppl 5.23 | wps 163889 | wpb 10489.1 | bsz 375 | num_updates 246959 | best_loss 4.148
2021-04-06 02:53:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 246959 updates
2021-04-06 02:53:51 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-06 02:53:57 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-06 02:53:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt (epoch 52 @ 246959 updates, score 4.16) (writing took 5.990210223942995 seconds)
2021-04-06 02:53:57 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2021-04-06 02:53:57 | INFO | train | epoch 052 | loss 4.515 | nll_loss 2.911 | ppl 7.52 | wps 87481 | ups 3.02 | wpb 28968.2 | bsz 946.7 | num_updates 246959 | lr 6.36338e-05 | gnorm 0.474 | loss_scale 1 | train_wall 1557 | gb_free 8.2 | wall 0
2021-04-06 02:53:57 | INFO | fairseq.trainer | begin training epoch 53
2021-04-06 02:53:57 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-06 02:54:11 | INFO | train_inner | epoch 053:     41 / 4751 loss=4.464, nll_loss=2.853, ppl=7.23, wps=69820.2, ups=2.42, wpb=28801.3, bsz=968.7, num_updates=247000, lr=6.36285e-05, gnorm=0.472, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 02:54:44 | INFO | train_inner | epoch 053:    141 / 4751 loss=4.518, nll_loss=2.913, ppl=7.53, wps=88367.9, ups=3.05, wpb=28990, bsz=973.8, num_updates=247100, lr=6.36156e-05, gnorm=0.48, loss_scale=1, train_wall=33, gb_free=5.9, wall=0
2021-04-06 02:55:17 | INFO | train_inner | epoch 053:    241 / 4751 loss=4.514, nll_loss=2.909, ppl=7.51, wps=88029.2, ups=3.04, wpb=28933.1, bsz=942.1, num_updates=247200, lr=6.36027e-05, gnorm=0.476, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 02:55:50 | INFO | train_inner | epoch 053:    341 / 4751 loss=4.527, nll_loss=2.924, ppl=7.59, wps=86802, ups=3, wpb=28912.9, bsz=958.9, num_updates=247300, lr=6.35899e-05, gnorm=0.474, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 02:56:23 | INFO | train_inner | epoch 053:    441 / 4751 loss=4.455, nll_loss=2.842, ppl=7.17, wps=88295.5, ups=3.02, wpb=29254, bsz=954.5, num_updates=247400, lr=6.3577e-05, gnorm=0.465, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 02:56:56 | INFO | train_inner | epoch 053:    541 / 4751 loss=4.508, nll_loss=2.902, ppl=7.48, wps=88351.8, ups=3.05, wpb=28989.3, bsz=958.6, num_updates=247500, lr=6.35642e-05, gnorm=0.474, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 02:57:29 | INFO | train_inner | epoch 053:    641 / 4751 loss=4.476, nll_loss=2.865, ppl=7.29, wps=88105.3, ups=3.03, wpb=29123.2, bsz=940.3, num_updates=247600, lr=6.35513e-05, gnorm=0.475, loss_scale=1, train_wall=33, gb_free=6.4, wall=0
2021-04-06 02:58:02 | INFO | train_inner | epoch 053:    741 / 4751 loss=4.495, nll_loss=2.888, ppl=7.4, wps=88004.8, ups=3.03, wpb=29000.7, bsz=985, num_updates=247700, lr=6.35385e-05, gnorm=0.469, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 02:58:36 | INFO | train_inner | epoch 053:    841 / 4751 loss=4.478, nll_loss=2.869, ppl=7.3, wps=87231.7, ups=2.99, wpb=29219.7, bsz=950.5, num_updates=247800, lr=6.35257e-05, gnorm=0.472, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 02:59:09 | INFO | train_inner | epoch 053:    941 / 4751 loss=4.485, nll_loss=2.876, ppl=7.34, wps=89032.1, ups=3.02, wpb=29439.9, bsz=953.8, num_updates=247900, lr=6.35129e-05, gnorm=0.466, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 02:59:42 | INFO | train_inner | epoch 053:   1041 / 4751 loss=4.543, nll_loss=2.942, ppl=7.69, wps=88064.7, ups=3.04, wpb=28987.7, bsz=945.6, num_updates=248000, lr=6.35001e-05, gnorm=0.479, loss_scale=1, train_wall=33, gb_free=6.5, wall=0
2021-04-06 03:00:15 | INFO | train_inner | epoch 053:   1141 / 4751 loss=4.517, nll_loss=2.912, ppl=7.53, wps=87779.4, ups=3.05, wpb=28734.5, bsz=897.4, num_updates=248100, lr=6.34873e-05, gnorm=0.48, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 03:00:48 | INFO | train_inner | epoch 053:   1241 / 4751 loss=4.556, nll_loss=2.957, ppl=7.76, wps=88197.8, ups=3.03, wpb=29120.1, bsz=966.9, num_updates=248200, lr=6.34745e-05, gnorm=0.474, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 03:01:20 | INFO | train_inner | epoch 053:   1341 / 4751 loss=4.568, nll_loss=2.97, ppl=7.83, wps=87336.6, ups=3.04, wpb=28739.8, bsz=915.4, num_updates=248300, lr=6.34617e-05, gnorm=0.477, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 03:01:53 | INFO | train_inner | epoch 053:   1441 / 4751 loss=4.516, nll_loss=2.911, ppl=7.52, wps=88616, ups=3.04, wpb=29173.9, bsz=996.6, num_updates=248400, lr=6.34489e-05, gnorm=0.473, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 03:02:26 | INFO | train_inner | epoch 053:   1541 / 4751 loss=4.503, nll_loss=2.896, ppl=7.45, wps=88050.3, ups=3.03, wpb=29024.2, bsz=926.5, num_updates=248500, lr=6.34361e-05, gnorm=0.475, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 03:02:59 | INFO | train_inner | epoch 053:   1641 / 4751 loss=4.526, nll_loss=2.923, ppl=7.58, wps=87682, ups=3.04, wpb=28884.6, bsz=957.5, num_updates=248600, lr=6.34234e-05, gnorm=0.481, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 03:03:32 | INFO | train_inner | epoch 053:   1741 / 4751 loss=4.502, nll_loss=2.895, ppl=7.44, wps=86826.9, ups=3.03, wpb=28688.2, bsz=928.6, num_updates=248700, lr=6.34106e-05, gnorm=0.475, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 03:04:05 | INFO | train_inner | epoch 053:   1841 / 4751 loss=4.479, nll_loss=2.87, ppl=7.31, wps=88250.2, ups=3.04, wpb=29017.9, bsz=958.4, num_updates=248800, lr=6.33979e-05, gnorm=0.476, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 03:04:38 | INFO | train_inner | epoch 053:   1941 / 4751 loss=4.496, nll_loss=2.889, ppl=7.41, wps=88756.8, ups=3.05, wpb=29125.2, bsz=961.7, num_updates=248900, lr=6.33852e-05, gnorm=0.473, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 03:05:11 | INFO | train_inner | epoch 053:   2041 / 4751 loss=4.507, nll_loss=2.901, ppl=7.47, wps=87259.5, ups=3.02, wpb=28940.2, bsz=937.4, num_updates=249000, lr=6.33724e-05, gnorm=0.471, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-06 03:05:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-04-06 03:05:44 | INFO | train_inner | epoch 053:   2142 / 4751 loss=4.544, nll_loss=2.943, ppl=7.69, wps=87289, ups=3.01, wpb=29010.9, bsz=935.5, num_updates=249100, lr=6.33597e-05, gnorm=0.474, loss_scale=1, train_wall=33, gb_free=6.5, wall=0
2021-04-06 03:06:17 | INFO | train_inner | epoch 053:   2242 / 4751 loss=4.526, nll_loss=2.923, ppl=7.59, wps=88153.4, ups=3.03, wpb=29050, bsz=943.8, num_updates=249200, lr=6.3347e-05, gnorm=0.473, loss_scale=1, train_wall=33, gb_free=6.4, wall=0
2021-04-06 03:06:50 | INFO | train_inner | epoch 053:   2342 / 4751 loss=4.56, nll_loss=2.961, ppl=7.79, wps=87601.2, ups=3.05, wpb=28745.5, bsz=931.2, num_updates=249300, lr=6.33343e-05, gnorm=0.474, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 03:07:23 | INFO | train_inner | epoch 053:   2442 / 4751 loss=4.511, nll_loss=2.905, ppl=7.49, wps=88098.1, ups=3.03, wpb=29081.6, bsz=934.2, num_updates=249400, lr=6.33216e-05, gnorm=0.473, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 03:07:56 | INFO | train_inner | epoch 053:   2542 / 4751 loss=4.506, nll_loss=2.9, ppl=7.47, wps=87657.5, ups=3.04, wpb=28850.9, bsz=955.7, num_updates=249500, lr=6.33089e-05, gnorm=0.479, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 03:08:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
2021-04-06 03:08:29 | INFO | train_inner | epoch 053:   2643 / 4751 loss=4.517, nll_loss=2.912, ppl=7.53, wps=88011.1, ups=3.02, wpb=29112.1, bsz=946.5, num_updates=249600, lr=6.32962e-05, gnorm=0.473, loss_scale=0.5, train_wall=33, gb_free=6.3, wall=0
2021-04-06 03:09:02 | INFO | train_inner | epoch 053:   2743 / 4751 loss=4.478, nll_loss=2.869, ppl=7.3, wps=86542, ups=3, wpb=28815.6, bsz=987.5, num_updates=249700, lr=6.32835e-05, gnorm=0.481, loss_scale=0.5, train_wall=33, gb_free=6.3, wall=0
2021-04-06 03:09:35 | INFO | train_inner | epoch 053:   2843 / 4751 loss=4.51, nll_loss=2.905, ppl=7.49, wps=87650.5, ups=3.04, wpb=28863.7, bsz=942.4, num_updates=249800, lr=6.32709e-05, gnorm=0.499, loss_scale=0.5, train_wall=33, gb_free=6.4, wall=0
2021-04-06 03:10:08 | INFO | train_inner | epoch 053:   2943 / 4751 loss=4.473, nll_loss=2.862, ppl=7.27, wps=88087, ups=3.03, wpb=29060.9, bsz=922.6, num_updates=249900, lr=6.32582e-05, gnorm=0.466, loss_scale=0.5, train_wall=33, gb_free=6.1, wall=0
2021-04-06 03:10:41 | INFO | train_inner | epoch 053:   3043 / 4751 loss=4.548, nll_loss=2.948, ppl=7.72, wps=88269, ups=3.04, wpb=29007.9, bsz=907, num_updates=250000, lr=6.32456e-05, gnorm=0.475, loss_scale=0.5, train_wall=33, gb_free=6.5, wall=0
2021-04-06 03:11:14 | INFO | train_inner | epoch 053:   3143 / 4751 loss=4.525, nll_loss=2.922, ppl=7.58, wps=88084.5, ups=3.05, wpb=28880.9, bsz=925.3, num_updates=250100, lr=6.32329e-05, gnorm=0.476, loss_scale=0.5, train_wall=33, gb_free=6.4, wall=0
2021-04-06 03:11:47 | INFO | train_inner | epoch 053:   3243 / 4751 loss=4.529, nll_loss=2.926, ppl=7.6, wps=89139.8, ups=3.06, wpb=29116.9, bsz=940.9, num_updates=250200, lr=6.32203e-05, gnorm=0.476, loss_scale=0.5, train_wall=33, gb_free=6.1, wall=0
2021-04-06 03:12:20 | INFO | train_inner | epoch 053:   3343 / 4751 loss=4.488, nll_loss=2.881, ppl=7.36, wps=87634.1, ups=3.04, wpb=28865.7, bsz=978.5, num_updates=250300, lr=6.32076e-05, gnorm=0.474, loss_scale=0.5, train_wall=33, gb_free=6.2, wall=0
2021-04-06 03:12:53 | INFO | train_inner | epoch 053:   3443 / 4751 loss=4.467, nll_loss=2.857, ppl=7.25, wps=87533.9, ups=3.03, wpb=28855.9, bsz=974.3, num_updates=250400, lr=6.3195e-05, gnorm=0.475, loss_scale=0.5, train_wall=33, gb_free=6.2, wall=0
2021-04-06 03:13:25 | INFO | train_inner | epoch 053:   3543 / 4751 loss=4.477, nll_loss=2.868, ppl=7.3, wps=87915.1, ups=3.05, wpb=28789.6, bsz=976.6, num_updates=250500, lr=6.31824e-05, gnorm=0.477, loss_scale=0.5, train_wall=33, gb_free=6, wall=0
2021-04-06 03:13:59 | INFO | train_inner | epoch 053:   3643 / 4751 loss=4.489, nll_loss=2.881, ppl=7.37, wps=87573.9, ups=3.01, wpb=29107.7, bsz=933.6, num_updates=250600, lr=6.31698e-05, gnorm=0.469, loss_scale=0.5, train_wall=33, gb_free=6.1, wall=0
2021-04-06 03:14:32 | INFO | train_inner | epoch 053:   3743 / 4751 loss=4.527, nll_loss=2.925, ppl=7.59, wps=87864.5, ups=3.04, wpb=28932.8, bsz=959.5, num_updates=250700, lr=6.31572e-05, gnorm=0.49, loss_scale=0.5, train_wall=33, gb_free=6.1, wall=0
2021-04-06 03:15:04 | INFO | train_inner | epoch 053:   3843 / 4751 loss=4.557, nll_loss=2.958, ppl=7.77, wps=87174.8, ups=3.05, wpb=28608.9, bsz=937.5, num_updates=250800, lr=6.31446e-05, gnorm=0.483, loss_scale=0.5, train_wall=33, gb_free=6.6, wall=0
2021-04-06 03:15:37 | INFO | train_inner | epoch 053:   3943 / 4751 loss=4.504, nll_loss=2.898, ppl=7.46, wps=87829.1, ups=3.05, wpb=28791.9, bsz=963, num_updates=250900, lr=6.3132e-05, gnorm=0.477, loss_scale=0.5, train_wall=33, gb_free=6, wall=0
2021-04-06 03:16:10 | INFO | train_inner | epoch 053:   4043 / 4751 loss=4.53, nll_loss=2.927, ppl=7.6, wps=88678.5, ups=3.06, wpb=29012.2, bsz=925.8, num_updates=251000, lr=6.31194e-05, gnorm=0.48, loss_scale=0.5, train_wall=33, gb_free=6, wall=0
2021-04-06 03:16:43 | INFO | train_inner | epoch 053:   4143 / 4751 loss=4.511, nll_loss=2.906, ppl=7.5, wps=89045.7, ups=3.03, wpb=29367.2, bsz=969.7, num_updates=251100, lr=6.31069e-05, gnorm=0.471, loss_scale=0.5, train_wall=33, gb_free=6.2, wall=0
2021-04-06 03:17:16 | INFO | train_inner | epoch 053:   4243 / 4751 loss=4.551, nll_loss=2.952, ppl=7.74, wps=88022.3, ups=3.06, wpb=28809.9, bsz=931.4, num_updates=251200, lr=6.30943e-05, gnorm=0.476, loss_scale=0.5, train_wall=33, gb_free=6.1, wall=0
2021-04-06 03:17:49 | INFO | train_inner | epoch 053:   4343 / 4751 loss=4.524, nll_loss=2.922, ppl=7.58, wps=87013, ups=3.03, wpb=28734.9, bsz=958.3, num_updates=251300, lr=6.30818e-05, gnorm=0.482, loss_scale=0.5, train_wall=33, gb_free=6.5, wall=0
2021-04-06 03:18:21 | INFO | train_inner | epoch 053:   4443 / 4751 loss=4.498, nll_loss=2.891, ppl=7.42, wps=88556.7, ups=3.04, wpb=29084.2, bsz=939.4, num_updates=251400, lr=6.30692e-05, gnorm=0.469, loss_scale=0.5, train_wall=33, gb_free=6.2, wall=0
2021-04-06 03:18:54 | INFO | train_inner | epoch 053:   4543 / 4751 loss=4.611, nll_loss=3.019, ppl=8.11, wps=87695.5, ups=3.04, wpb=28820.1, bsz=905.4, num_updates=251500, lr=6.30567e-05, gnorm=0.483, loss_scale=0.5, train_wall=33, gb_free=6.4, wall=0
2021-04-06 03:19:27 | INFO | train_inner | epoch 053:   4643 / 4751 loss=4.501, nll_loss=2.895, ppl=7.44, wps=88120, ups=3.03, wpb=29038.5, bsz=962.2, num_updates=251600, lr=6.30441e-05, gnorm=0.475, loss_scale=0.5, train_wall=33, gb_free=6.4, wall=0
2021-04-06 03:20:00 | INFO | train_inner | epoch 053:   4743 / 4751 loss=4.54, nll_loss=2.939, ppl=7.67, wps=88179.1, ups=3.05, wpb=28934.7, bsz=908.2, num_updates=251700, lr=6.30316e-05, gnorm=0.478, loss_scale=1, train_wall=33, gb_free=6.5, wall=0
2021-04-06 03:20:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-06 03:20:04 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 4.15 | nll_loss 2.377 | ppl 5.2 | wps 181594 | wpb 10489.1 | bsz 375 | num_updates 251708 | best_loss 4.148
2021-04-06 03:20:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 251708 updates
2021-04-06 03:20:04 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-06 03:20:10 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-06 03:20:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt (epoch 53 @ 251708 updates, score 4.15) (writing took 6.585905950516462 seconds)
2021-04-06 03:20:10 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2021-04-06 03:20:10 | INFO | train | epoch 053 | loss 4.513 | nll_loss 2.908 | ppl 7.51 | wps 87417.7 | ups 3.02 | wpb 28969.4 | bsz 946.8 | num_updates 251708 | lr 6.30306e-05 | gnorm 0.476 | loss_scale 1 | train_wall 1558 | gb_free 7.7 | wall 0
2021-04-06 03:20:10 | INFO | fairseq.trainer | begin training epoch 54
2021-04-06 03:20:10 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-06 03:20:42 | INFO | train_inner | epoch 054:     92 / 4751 loss=4.47, nll_loss=2.859, ppl=7.26, wps=69960.9, ups=2.4, wpb=29202.8, bsz=971.7, num_updates=251800, lr=6.30191e-05, gnorm=0.462, loss_scale=1, train_wall=32, gb_free=6.3, wall=0
2021-04-06 03:21:15 | INFO | train_inner | epoch 054:    192 / 4751 loss=4.485, nll_loss=2.876, ppl=7.34, wps=87777.5, ups=3.03, wpb=28990.8, bsz=946.3, num_updates=251900, lr=6.30066e-05, gnorm=0.479, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 03:21:48 | INFO | train_inner | epoch 054:    292 / 4751 loss=4.512, nll_loss=2.906, ppl=7.5, wps=88557.6, ups=3.04, wpb=29129.8, bsz=942.9, num_updates=252000, lr=6.29941e-05, gnorm=0.479, loss_scale=1, train_wall=33, gb_free=6.4, wall=0
2021-04-06 03:22:21 | INFO | train_inner | epoch 054:    392 / 4751 loss=4.463, nll_loss=2.852, ppl=7.22, wps=87396.9, ups=3.03, wpb=28832.5, bsz=988.2, num_updates=252100, lr=6.29816e-05, gnorm=0.472, loss_scale=1, train_wall=33, gb_free=6, wall=0
2021-04-06 03:22:54 | INFO | train_inner | epoch 054:    492 / 4751 loss=4.501, nll_loss=2.895, ppl=7.44, wps=87626.7, ups=3.04, wpb=28822.5, bsz=984.2, num_updates=252200, lr=6.29691e-05, gnorm=0.504, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 03:23:26 | INFO | train_inner | epoch 054:    592 / 4751 loss=4.513, nll_loss=2.907, ppl=7.5, wps=88200.7, ups=3.05, wpb=28953.3, bsz=946.6, num_updates=252300, lr=6.29566e-05, gnorm=0.481, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 03:23:59 | INFO | train_inner | epoch 054:    692 / 4751 loss=4.472, nll_loss=2.861, ppl=7.27, wps=88610.3, ups=3.05, wpb=29060.7, bsz=931.4, num_updates=252400, lr=6.29441e-05, gnorm=0.475, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 03:24:32 | INFO | train_inner | epoch 054:    792 / 4751 loss=4.528, nll_loss=2.925, ppl=7.6, wps=86786.6, ups=3.03, wpb=28610, bsz=951.6, num_updates=252500, lr=6.29317e-05, gnorm=0.489, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 03:25:05 | INFO | train_inner | epoch 054:    892 / 4751 loss=4.496, nll_loss=2.89, ppl=7.41, wps=88272.6, ups=3.03, wpb=29092.5, bsz=975.5, num_updates=252600, lr=6.29192e-05, gnorm=0.477, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 03:25:38 | INFO | train_inner | epoch 054:    992 / 4751 loss=4.487, nll_loss=2.878, ppl=7.35, wps=88193.8, ups=3.04, wpb=29007.5, bsz=952.9, num_updates=252700, lr=6.29068e-05, gnorm=0.473, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 03:26:11 | INFO | train_inner | epoch 054:   1092 / 4751 loss=4.558, nll_loss=2.959, ppl=7.78, wps=88380.6, ups=3.05, wpb=28993.7, bsz=946, num_updates=252800, lr=6.28943e-05, gnorm=0.479, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 03:26:44 | INFO | train_inner | epoch 054:   1192 / 4751 loss=4.5, nll_loss=2.893, ppl=7.43, wps=87485.4, ups=3.03, wpb=28900.4, bsz=941.1, num_updates=252900, lr=6.28819e-05, gnorm=0.484, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 03:27:17 | INFO | train_inner | epoch 054:   1292 / 4751 loss=4.5, nll_loss=2.893, ppl=7.43, wps=87729.8, ups=3.03, wpb=28929.6, bsz=934.9, num_updates=253000, lr=6.28695e-05, gnorm=0.48, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 03:27:50 | INFO | train_inner | epoch 054:   1392 / 4751 loss=4.543, nll_loss=2.942, ppl=7.68, wps=88235.1, ups=3.05, wpb=28910, bsz=935.8, num_updates=253100, lr=6.2857e-05, gnorm=0.483, loss_scale=1, train_wall=33, gb_free=6.7, wall=0
2021-04-06 03:28:23 | INFO | train_inner | epoch 054:   1492 / 4751 loss=4.474, nll_loss=2.865, ppl=7.28, wps=87221.3, ups=3.03, wpb=28818.3, bsz=965.4, num_updates=253200, lr=6.28446e-05, gnorm=0.481, loss_scale=1, train_wall=33, gb_free=6, wall=0
2021-04-06 03:28:56 | INFO | train_inner | epoch 054:   1592 / 4751 loss=4.571, nll_loss=2.974, ppl=7.85, wps=87873.4, ups=3.04, wpb=28936, bsz=936.6, num_updates=253300, lr=6.28322e-05, gnorm=0.482, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 03:29:28 | INFO | train_inner | epoch 054:   1692 / 4751 loss=4.468, nll_loss=2.858, ppl=7.25, wps=88529.3, ups=3.06, wpb=28954.6, bsz=959.7, num_updates=253400, lr=6.28198e-05, gnorm=0.471, loss_scale=1, train_wall=33, gb_free=7, wall=0
2021-04-06 03:30:01 | INFO | train_inner | epoch 054:   1792 / 4751 loss=4.461, nll_loss=2.849, ppl=7.21, wps=87900.8, ups=3.02, wpb=29133.8, bsz=946.7, num_updates=253500, lr=6.28074e-05, gnorm=0.465, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 03:30:34 | INFO | train_inner | epoch 054:   1892 / 4751 loss=4.516, nll_loss=2.912, ppl=7.53, wps=88406.9, ups=3.06, wpb=28927.5, bsz=972.3, num_updates=253600, lr=6.2795e-05, gnorm=0.502, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 03:31:07 | INFO | train_inner | epoch 054:   1992 / 4751 loss=4.508, nll_loss=2.903, ppl=7.48, wps=88395.1, ups=3.04, wpb=29056.2, bsz=964.5, num_updates=253700, lr=6.27827e-05, gnorm=0.499, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 03:31:40 | INFO | train_inner | epoch 054:   2092 / 4751 loss=4.506, nll_loss=2.9, ppl=7.47, wps=87152.4, ups=3.01, wpb=28987.4, bsz=933, num_updates=253800, lr=6.27703e-05, gnorm=0.478, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 03:32:13 | INFO | train_inner | epoch 054:   2192 / 4751 loss=4.518, nll_loss=2.914, ppl=7.54, wps=88655.9, ups=3.05, wpb=29061.2, bsz=911.3, num_updates=253900, lr=6.27579e-05, gnorm=0.472, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 03:32:46 | INFO | train_inner | epoch 054:   2292 / 4751 loss=4.465, nll_loss=2.854, ppl=7.23, wps=88307.6, ups=3.05, wpb=28999.4, bsz=970.2, num_updates=254000, lr=6.27456e-05, gnorm=0.472, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-06 03:33:19 | INFO | train_inner | epoch 054:   2392 / 4751 loss=4.498, nll_loss=2.891, ppl=7.42, wps=86359.7, ups=2.98, wpb=28993.9, bsz=954.9, num_updates=254100, lr=6.27332e-05, gnorm=0.474, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 03:33:53 | INFO | train_inner | epoch 054:   2492 / 4751 loss=4.532, nll_loss=2.93, ppl=7.62, wps=86538.3, ups=3.01, wpb=28748, bsz=936.2, num_updates=254200, lr=6.27209e-05, gnorm=0.483, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 03:34:26 | INFO | train_inner | epoch 054:   2592 / 4751 loss=4.513, nll_loss=2.908, ppl=7.51, wps=87737.4, ups=3.02, wpb=29085.5, bsz=951.4, num_updates=254300, lr=6.27086e-05, gnorm=0.489, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-06 03:34:59 | INFO | train_inner | epoch 054:   2692 / 4751 loss=4.552, nll_loss=2.952, ppl=7.74, wps=88565.5, ups=3.04, wpb=29111.5, bsz=919.5, num_updates=254400, lr=6.26962e-05, gnorm=0.48, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-06 03:35:31 | INFO | train_inner | epoch 054:   2792 / 4751 loss=4.555, nll_loss=2.956, ppl=7.76, wps=88219.6, ups=3.06, wpb=28871.8, bsz=952.5, num_updates=254500, lr=6.26839e-05, gnorm=0.48, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-06 03:36:04 | INFO | train_inner | epoch 054:   2892 / 4751 loss=4.538, nll_loss=2.936, ppl=7.65, wps=88013, ups=3.04, wpb=28948.3, bsz=918.3, num_updates=254600, lr=6.26716e-05, gnorm=0.476, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 03:36:37 | INFO | train_inner | epoch 054:   2992 / 4751 loss=4.572, nll_loss=2.975, ppl=7.86, wps=88090.3, ups=3.05, wpb=28902.2, bsz=935.5, num_updates=254700, lr=6.26593e-05, gnorm=0.482, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 03:37:10 | INFO | train_inner | epoch 054:   3092 / 4751 loss=4.527, nll_loss=2.924, ppl=7.59, wps=86923.8, ups=3.05, wpb=28503.3, bsz=954, num_updates=254800, lr=6.2647e-05, gnorm=0.48, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 03:37:43 | INFO | train_inner | epoch 054:   3192 / 4751 loss=4.529, nll_loss=2.927, ppl=7.6, wps=88028.9, ups=3.04, wpb=28973.2, bsz=945.1, num_updates=254900, lr=6.26347e-05, gnorm=0.471, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 03:38:16 | INFO | train_inner | epoch 054:   3292 / 4751 loss=4.555, nll_loss=2.955, ppl=7.76, wps=87598.7, ups=3.03, wpb=28922.9, bsz=935.5, num_updates=255000, lr=6.26224e-05, gnorm=0.477, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 03:38:49 | INFO | train_inner | epoch 054:   3392 / 4751 loss=4.515, nll_loss=2.911, ppl=7.52, wps=87395.1, ups=3.03, wpb=28821.5, bsz=964.7, num_updates=255100, lr=6.26102e-05, gnorm=0.477, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 03:39:22 | INFO | train_inner | epoch 054:   3492 / 4751 loss=4.484, nll_loss=2.876, ppl=7.34, wps=88235, ups=3.03, wpb=29090.3, bsz=960.6, num_updates=255200, lr=6.25979e-05, gnorm=0.472, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 03:39:55 | INFO | train_inner | epoch 054:   3592 / 4751 loss=4.487, nll_loss=2.879, ppl=7.36, wps=87201.7, ups=3, wpb=29048.9, bsz=941.8, num_updates=255300, lr=6.25856e-05, gnorm=0.47, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 03:40:28 | INFO | train_inner | epoch 054:   3692 / 4751 loss=4.501, nll_loss=2.895, ppl=7.44, wps=87380.3, ups=3.03, wpb=28805.6, bsz=942.6, num_updates=255400, lr=6.25734e-05, gnorm=0.485, loss_scale=2, train_wall=33, gb_free=6.9, wall=0
2021-04-06 03:41:01 | INFO | train_inner | epoch 054:   3792 / 4751 loss=4.542, nll_loss=2.941, ppl=7.68, wps=88159.6, ups=3.03, wpb=29137.9, bsz=938, num_updates=255500, lr=6.25611e-05, gnorm=0.482, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 03:41:34 | INFO | train_inner | epoch 054:   3892 / 4751 loss=4.489, nll_loss=2.882, ppl=7.37, wps=87982.3, ups=3.03, wpb=29022.8, bsz=956.4, num_updates=255600, lr=6.25489e-05, gnorm=0.476, loss_scale=2, train_wall=33, gb_free=6.6, wall=0
2021-04-06 03:42:07 | INFO | train_inner | epoch 054:   3992 / 4751 loss=4.516, nll_loss=2.911, ppl=7.52, wps=87958.4, ups=3.01, wpb=29206.3, bsz=954.2, num_updates=255700, lr=6.25367e-05, gnorm=0.471, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 03:42:40 | INFO | train_inner | epoch 054:   4092 / 4751 loss=4.54, nll_loss=2.939, ppl=7.67, wps=87772.6, ups=3.03, wpb=28969.3, bsz=909.5, num_updates=255800, lr=6.25244e-05, gnorm=0.483, loss_scale=4, train_wall=33, gb_free=5.9, wall=0
2021-04-06 03:43:13 | INFO | train_inner | epoch 054:   4192 / 4751 loss=4.54, nll_loss=2.938, ppl=7.67, wps=87860.8, ups=3.04, wpb=28897.1, bsz=942.8, num_updates=255900, lr=6.25122e-05, gnorm=0.481, loss_scale=4, train_wall=33, gb_free=6, wall=0
2021-04-06 03:43:46 | INFO | train_inner | epoch 054:   4292 / 4751 loss=4.492, nll_loss=2.884, ppl=7.38, wps=88005, ups=3.03, wpb=29030.1, bsz=972.2, num_updates=256000, lr=6.25e-05, gnorm=0.483, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-06 03:44:19 | INFO | train_inner | epoch 054:   4392 / 4751 loss=4.518, nll_loss=2.914, ppl=7.54, wps=88441.8, ups=3.04, wpb=29094.1, bsz=934.7, num_updates=256100, lr=6.24878e-05, gnorm=0.481, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 03:44:52 | INFO | train_inner | epoch 054:   4492 / 4751 loss=4.511, nll_loss=2.907, ppl=7.5, wps=86916.4, ups=3.04, wpb=28612.7, bsz=953.6, num_updates=256200, lr=6.24756e-05, gnorm=0.485, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 03:45:25 | INFO | train_inner | epoch 054:   4592 / 4751 loss=4.501, nll_loss=2.895, ppl=7.44, wps=87683.4, ups=3, wpb=29193, bsz=952.8, num_updates=256300, lr=6.24634e-05, gnorm=0.475, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 03:45:58 | INFO | train_inner | epoch 054:   4692 / 4751 loss=4.535, nll_loss=2.933, ppl=7.64, wps=88673.9, ups=3.04, wpb=29144.9, bsz=907.4, num_updates=256400, lr=6.24512e-05, gnorm=0.479, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 03:46:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-06 03:46:19 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 4.148 | nll_loss 2.377 | ppl 5.19 | wps 191438 | wpb 10489.1 | bsz 375 | num_updates 256459 | best_loss 4.148
2021-04-06 03:46:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 256459 updates
2021-04-06 03:46:19 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-06 03:46:25 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-06 03:46:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt (epoch 54 @ 256459 updates, score 4.148) (writing took 12.81385651230812 seconds)
2021-04-06 03:46:31 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2021-04-06 03:46:31 | INFO | train | epoch 054 | loss 4.512 | nll_loss 2.907 | ppl 7.5 | wps 87046.2 | ups 3 | wpb 28968.3 | bsz 947.4 | num_updates 256459 | lr 6.2444e-05 | gnorm 0.479 | loss_scale 4 | train_wall 1559 | gb_free 6.1 | wall 0
2021-04-06 03:46:32 | INFO | fairseq.trainer | begin training epoch 55
2021-04-06 03:46:32 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-06 03:46:46 | INFO | train_inner | epoch 055:     41 / 4751 loss=4.486, nll_loss=2.877, ppl=7.35, wps=60423.7, ups=2.09, wpb=28905.4, bsz=917.2, num_updates=256500, lr=6.24391e-05, gnorm=0.475, loss_scale=4, train_wall=32, gb_free=6.5, wall=0
2021-04-06 03:47:19 | INFO | train_inner | epoch 055:    141 / 4751 loss=4.519, nll_loss=2.914, ppl=7.54, wps=87467.9, ups=3.03, wpb=28836.8, bsz=936.6, num_updates=256600, lr=6.24269e-05, gnorm=0.479, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 03:47:52 | INFO | train_inner | epoch 055:    241 / 4751 loss=4.481, nll_loss=2.872, ppl=7.32, wps=88559.2, ups=3.06, wpb=28983.5, bsz=957.8, num_updates=256700, lr=6.24147e-05, gnorm=0.478, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 03:48:25 | INFO | train_inner | epoch 055:    341 / 4751 loss=4.505, nll_loss=2.899, ppl=7.46, wps=87201.9, ups=3.01, wpb=28962.7, bsz=953, num_updates=256800, lr=6.24026e-05, gnorm=0.475, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-06 03:48:58 | INFO | train_inner | epoch 055:    441 / 4751 loss=4.495, nll_loss=2.887, ppl=7.4, wps=88215.2, ups=3.03, wpb=29096.9, bsz=971.8, num_updates=256900, lr=6.23904e-05, gnorm=0.481, loss_scale=4, train_wall=33, gb_free=6, wall=0
2021-04-06 03:49:31 | INFO | train_inner | epoch 055:    541 / 4751 loss=4.517, nll_loss=2.913, ppl=7.53, wps=87219.8, ups=3.02, wpb=28857.2, bsz=948.6, num_updates=257000, lr=6.23783e-05, gnorm=0.477, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 03:50:04 | INFO | train_inner | epoch 055:    641 / 4751 loss=4.509, nll_loss=2.903, ppl=7.48, wps=87051.1, ups=3.04, wpb=28630.5, bsz=947.4, num_updates=257100, lr=6.23662e-05, gnorm=0.483, loss_scale=4, train_wall=33, gb_free=6.4, wall=0
2021-04-06 03:50:37 | INFO | train_inner | epoch 055:    741 / 4751 loss=4.488, nll_loss=2.879, ppl=7.36, wps=88447.5, ups=3.04, wpb=29047.2, bsz=957.5, num_updates=257200, lr=6.2354e-05, gnorm=0.474, loss_scale=4, train_wall=33, gb_free=6.6, wall=0
2021-04-06 03:51:10 | INFO | train_inner | epoch 055:    841 / 4751 loss=4.504, nll_loss=2.897, ppl=7.45, wps=88154.6, ups=3.04, wpb=28987.1, bsz=941, num_updates=257300, lr=6.23419e-05, gnorm=0.48, loss_scale=4, train_wall=33, gb_free=6, wall=0
2021-04-06 03:51:43 | INFO | train_inner | epoch 055:    941 / 4751 loss=4.499, nll_loss=2.891, ppl=7.42, wps=88268, ups=3.04, wpb=29060.4, bsz=932, num_updates=257400, lr=6.23298e-05, gnorm=0.468, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 03:52:16 | INFO | train_inner | epoch 055:   1041 / 4751 loss=4.527, nll_loss=2.923, ppl=7.58, wps=87952.3, ups=3.03, wpb=29057.6, bsz=918.2, num_updates=257500, lr=6.23177e-05, gnorm=0.479, loss_scale=4, train_wall=33, gb_free=6.5, wall=0
2021-04-06 03:52:49 | INFO | train_inner | epoch 055:   1141 / 4751 loss=4.504, nll_loss=2.898, ppl=7.45, wps=88002.4, ups=3.03, wpb=29032.6, bsz=917.9, num_updates=257600, lr=6.23056e-05, gnorm=0.473, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 03:53:22 | INFO | train_inner | epoch 055:   1241 / 4751 loss=4.502, nll_loss=2.896, ppl=7.45, wps=87774.2, ups=3.04, wpb=28894.7, bsz=941.6, num_updates=257700, lr=6.22935e-05, gnorm=0.476, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-06 03:53:54 | INFO | train_inner | epoch 055:   1341 / 4751 loss=4.518, nll_loss=2.914, ppl=7.54, wps=88292.7, ups=3.05, wpb=28949.9, bsz=952.9, num_updates=257800, lr=6.22814e-05, gnorm=0.477, loss_scale=8, train_wall=33, gb_free=6.5, wall=0
2021-04-06 03:54:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2021-04-06 03:54:28 | INFO | train_inner | epoch 055:   1442 / 4751 loss=4.5, nll_loss=2.894, ppl=7.43, wps=86967, ups=3, wpb=29029.4, bsz=973, num_updates=257900, lr=6.22693e-05, gnorm=0.47, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 03:55:01 | INFO | train_inner | epoch 055:   1542 / 4751 loss=4.451, nll_loss=2.838, ppl=7.15, wps=87867.1, ups=3.02, wpb=29047.2, bsz=952.7, num_updates=258000, lr=6.22573e-05, gnorm=0.472, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-06 03:55:34 | INFO | train_inner | epoch 055:   1642 / 4751 loss=4.488, nll_loss=2.88, ppl=7.36, wps=88078.8, ups=3.03, wpb=29076.1, bsz=943, num_updates=258100, lr=6.22452e-05, gnorm=0.475, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 03:56:07 | INFO | train_inner | epoch 055:   1742 / 4751 loss=4.526, nll_loss=2.923, ppl=7.59, wps=88441.2, ups=3.04, wpb=29140.2, bsz=940.5, num_updates=258200, lr=6.22332e-05, gnorm=0.483, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 03:56:20 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-06 03:56:40 | INFO | train_inner | epoch 055:   1843 / 4751 loss=4.509, nll_loss=2.903, ppl=7.48, wps=87056.9, ups=3.01, wpb=28935.8, bsz=954.3, num_updates=258300, lr=6.22211e-05, gnorm=0.472, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 03:57:13 | INFO | train_inner | epoch 055:   1943 / 4751 loss=4.587, nll_loss=2.991, ppl=7.95, wps=87702, ups=3.04, wpb=28802.8, bsz=925, num_updates=258400, lr=6.22091e-05, gnorm=0.486, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 03:57:46 | INFO | train_inner | epoch 055:   2043 / 4751 loss=4.492, nll_loss=2.885, ppl=7.39, wps=87724, ups=3.03, wpb=28953.2, bsz=976.2, num_updates=258500, lr=6.2197e-05, gnorm=0.48, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 03:58:19 | INFO | train_inner | epoch 055:   2143 / 4751 loss=4.56, nll_loss=2.961, ppl=7.79, wps=88768, ups=3.05, wpb=29092.4, bsz=937.3, num_updates=258600, lr=6.2185e-05, gnorm=0.48, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 03:58:52 | INFO | train_inner | epoch 055:   2243 / 4751 loss=4.538, nll_loss=2.937, ppl=7.66, wps=86500.9, ups=3.02, wpb=28635.4, bsz=920.9, num_updates=258700, lr=6.2173e-05, gnorm=0.486, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 03:59:25 | INFO | train_inner | epoch 055:   2343 / 4751 loss=4.453, nll_loss=2.841, ppl=7.16, wps=87945.6, ups=3.02, wpb=29108.2, bsz=957, num_updates=258800, lr=6.2161e-05, gnorm=0.474, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 03:59:58 | INFO | train_inner | epoch 055:   2443 / 4751 loss=4.505, nll_loss=2.899, ppl=7.46, wps=87507.8, ups=3.03, wpb=28902.2, bsz=926.1, num_updates=258900, lr=6.2149e-05, gnorm=0.475, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 04:00:31 | INFO | train_inner | epoch 055:   2543 / 4751 loss=4.52, nll_loss=2.916, ppl=7.55, wps=87527.8, ups=3.04, wpb=28815.5, bsz=963, num_updates=259000, lr=6.2137e-05, gnorm=0.475, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-06 04:01:04 | INFO | train_inner | epoch 055:   2643 / 4751 loss=4.573, nll_loss=2.976, ppl=7.87, wps=87844.6, ups=3.04, wpb=28859.3, bsz=919.8, num_updates=259100, lr=6.2125e-05, gnorm=0.486, loss_scale=2, train_wall=33, gb_free=5.9, wall=0
2021-04-06 04:01:37 | INFO | train_inner | epoch 055:   2743 / 4751 loss=4.588, nll_loss=2.993, ppl=7.96, wps=87242.6, ups=3.03, wpb=28821, bsz=919.2, num_updates=259200, lr=6.2113e-05, gnorm=0.495, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 04:02:09 | INFO | train_inner | epoch 055:   2843 / 4751 loss=4.526, nll_loss=2.922, ppl=7.58, wps=88242, ups=3.04, wpb=29009, bsz=941.3, num_updates=259300, lr=6.2101e-05, gnorm=0.479, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 04:02:43 | INFO | train_inner | epoch 055:   2943 / 4751 loss=4.504, nll_loss=2.899, ppl=7.46, wps=86701.9, ups=2.97, wpb=29221.7, bsz=960.1, num_updates=259400, lr=6.2089e-05, gnorm=0.475, loss_scale=2, train_wall=34, gb_free=6.3, wall=0
2021-04-06 04:03:16 | INFO | train_inner | epoch 055:   3043 / 4751 loss=4.499, nll_loss=2.892, ppl=7.42, wps=87935.6, ups=3.02, wpb=29080.4, bsz=954.2, num_updates=259500, lr=6.20771e-05, gnorm=0.474, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 04:03:49 | INFO | train_inner | epoch 055:   3143 / 4751 loss=4.538, nll_loss=2.936, ppl=7.65, wps=87941.6, ups=3.03, wpb=28987.3, bsz=949, num_updates=259600, lr=6.20651e-05, gnorm=0.477, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 04:04:22 | INFO | train_inner | epoch 055:   3243 / 4751 loss=4.507, nll_loss=2.901, ppl=7.47, wps=88200.2, ups=3.03, wpb=29150.1, bsz=944.2, num_updates=259700, lr=6.20532e-05, gnorm=0.474, loss_scale=2, train_wall=33, gb_free=6.6, wall=0
2021-04-06 04:04:55 | INFO | train_inner | epoch 055:   3343 / 4751 loss=4.516, nll_loss=2.911, ppl=7.52, wps=87787.5, ups=3.03, wpb=29013.6, bsz=933.7, num_updates=259800, lr=6.20412e-05, gnorm=0.482, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-06 04:05:28 | INFO | train_inner | epoch 055:   3443 / 4751 loss=4.485, nll_loss=2.877, ppl=7.34, wps=89427, ups=3.06, wpb=29264.9, bsz=937, num_updates=259900, lr=6.20293e-05, gnorm=0.476, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 04:06:01 | INFO | train_inner | epoch 055:   3543 / 4751 loss=4.508, nll_loss=2.903, ppl=7.48, wps=88893.3, ups=3.06, wpb=29084, bsz=936.6, num_updates=260000, lr=6.20174e-05, gnorm=0.473, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 04:06:34 | INFO | train_inner | epoch 055:   3643 / 4751 loss=4.478, nll_loss=2.869, ppl=7.31, wps=88067.9, ups=3.04, wpb=28992.5, bsz=957.9, num_updates=260100, lr=6.20054e-05, gnorm=0.472, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 04:07:07 | INFO | train_inner | epoch 055:   3743 / 4751 loss=4.523, nll_loss=2.92, ppl=7.57, wps=87737, ups=3.04, wpb=28863.9, bsz=953.4, num_updates=260200, lr=6.19935e-05, gnorm=0.478, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 04:07:40 | INFO | train_inner | epoch 055:   3843 / 4751 loss=4.495, nll_loss=2.888, ppl=7.4, wps=87378.3, ups=3.02, wpb=28917.4, bsz=965.5, num_updates=260300, lr=6.19816e-05, gnorm=0.476, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 04:08:13 | INFO | train_inner | epoch 055:   3943 / 4751 loss=4.493, nll_loss=2.886, ppl=7.39, wps=88524.2, ups=3.03, wpb=29213, bsz=983.5, num_updates=260400, lr=6.19697e-05, gnorm=0.478, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-06 04:08:46 | INFO | train_inner | epoch 055:   4043 / 4751 loss=4.492, nll_loss=2.884, ppl=7.38, wps=87474.6, ups=3.04, wpb=28764.3, bsz=942.3, num_updates=260500, lr=6.19578e-05, gnorm=0.478, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 04:09:18 | INFO | train_inner | epoch 055:   4143 / 4751 loss=4.466, nll_loss=2.855, ppl=7.24, wps=87874.2, ups=3.04, wpb=28877.1, bsz=932, num_updates=260600, lr=6.19459e-05, gnorm=0.476, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 04:09:51 | INFO | train_inner | epoch 055:   4243 / 4751 loss=4.447, nll_loss=2.834, ppl=7.13, wps=87128.8, ups=3.03, wpb=28795.5, bsz=964.2, num_updates=260700, lr=6.19341e-05, gnorm=0.47, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 04:10:24 | INFO | train_inner | epoch 055:   4343 / 4751 loss=4.522, nll_loss=2.919, ppl=7.56, wps=87873.8, ups=3.04, wpb=28930.3, bsz=962.2, num_updates=260800, lr=6.19222e-05, gnorm=0.484, loss_scale=4, train_wall=33, gb_free=5.9, wall=0
2021-04-06 04:10:57 | INFO | train_inner | epoch 055:   4443 / 4751 loss=4.56, nll_loss=2.962, ppl=7.79, wps=87971.8, ups=3.05, wpb=28888.7, bsz=948.8, num_updates=260900, lr=6.19103e-05, gnorm=0.483, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 04:11:30 | INFO | train_inner | epoch 055:   4543 / 4751 loss=4.492, nll_loss=2.885, ppl=7.39, wps=88739.2, ups=3.03, wpb=29330.2, bsz=961.4, num_updates=261000, lr=6.18984e-05, gnorm=0.471, loss_scale=4, train_wall=33, gb_free=6, wall=0
2021-04-06 04:12:03 | INFO | train_inner | epoch 055:   4643 / 4751 loss=4.515, nll_loss=2.912, ppl=7.53, wps=88157.7, ups=3.04, wpb=28989.6, bsz=935.2, num_updates=261100, lr=6.18866e-05, gnorm=0.475, loss_scale=4, train_wall=33, gb_free=6.5, wall=0
2021-04-06 04:12:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-06 04:12:36 | INFO | train_inner | epoch 055:   4744 / 4751 loss=4.549, nll_loss=2.95, ppl=7.73, wps=86078.9, ups=3.01, wpb=28626.8, bsz=954, num_updates=261200, lr=6.18747e-05, gnorm=0.478, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-06 04:12:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-06 04:12:40 | INFO | valid | epoch 055 | valid on 'valid' subset | loss 4.162 | nll_loss 2.388 | ppl 5.23 | wps 201668 | wpb 10489.1 | bsz 375 | num_updates 261207 | best_loss 4.148
2021-04-06 04:12:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 55 @ 261207 updates
2021-04-06 04:12:40 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-06 04:12:46 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-06 04:12:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt (epoch 55 @ 261207 updates, score 4.162) (writing took 6.569852624088526 seconds)
2021-04-06 04:12:46 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2021-04-06 04:12:46 | INFO | train | epoch 055 | loss 4.509 | nll_loss 2.904 | ppl 7.49 | wps 87329.4 | ups 3.01 | wpb 28968 | bsz 946.5 | num_updates 261207 | lr 6.18739e-05 | gnorm 0.477 | loss_scale 2 | train_wall 1559 | gb_free 6.1 | wall 0
2021-04-06 04:12:47 | INFO | fairseq.trainer | begin training epoch 56
2021-04-06 04:12:47 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-06 04:13:18 | INFO | train_inner | epoch 056:     93 / 4751 loss=4.45, nll_loss=2.837, ppl=7.14, wps=69220.5, ups=2.39, wpb=28993.1, bsz=929.3, num_updates=261300, lr=6.18629e-05, gnorm=0.473, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 04:13:52 | INFO | train_inner | epoch 056:    193 / 4751 loss=4.493, nll_loss=2.884, ppl=7.38, wps=86693.2, ups=3.01, wpb=28769.7, bsz=938.1, num_updates=261400, lr=6.18511e-05, gnorm=0.479, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 04:14:25 | INFO | train_inner | epoch 056:    293 / 4751 loss=4.448, nll_loss=2.834, ppl=7.13, wps=87894.4, ups=3.02, wpb=29091.8, bsz=919.5, num_updates=261500, lr=6.18392e-05, gnorm=0.47, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 04:14:58 | INFO | train_inner | epoch 056:    393 / 4751 loss=4.496, nll_loss=2.888, ppl=7.4, wps=87678.7, ups=3.04, wpb=28873.3, bsz=937, num_updates=261600, lr=6.18274e-05, gnorm=0.479, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 04:15:31 | INFO | train_inner | epoch 056:    493 / 4751 loss=4.477, nll_loss=2.867, ppl=7.3, wps=88353.8, ups=3.03, wpb=29157, bsz=959.1, num_updates=261700, lr=6.18156e-05, gnorm=0.48, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 04:15:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-04-06 04:16:04 | INFO | train_inner | epoch 056:    594 / 4751 loss=4.505, nll_loss=2.899, ppl=7.46, wps=86154.1, ups=3.01, wpb=28651.2, bsz=950.8, num_updates=261800, lr=6.18038e-05, gnorm=0.48, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 04:16:37 | INFO | train_inner | epoch 056:    694 / 4751 loss=4.499, nll_loss=2.892, ppl=7.42, wps=87808.2, ups=3.03, wpb=29026.8, bsz=957.5, num_updates=261900, lr=6.1792e-05, gnorm=0.479, loss_scale=1, train_wall=33, gb_free=6.4, wall=0
2021-04-06 04:17:10 | INFO | train_inner | epoch 056:    794 / 4751 loss=4.503, nll_loss=2.896, ppl=7.44, wps=88467.3, ups=3.05, wpb=29032.7, bsz=941.4, num_updates=262000, lr=6.17802e-05, gnorm=0.476, loss_scale=1, train_wall=33, gb_free=6.5, wall=0
2021-04-06 04:17:43 | INFO | train_inner | epoch 056:    894 / 4751 loss=4.51, nll_loss=2.904, ppl=7.49, wps=87678.9, ups=3.04, wpb=28854.9, bsz=936.6, num_updates=262100, lr=6.17684e-05, gnorm=0.481, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 04:18:15 | INFO | train_inner | epoch 056:    994 / 4751 loss=4.51, nll_loss=2.905, ppl=7.49, wps=90099.8, ups=3.05, wpb=29500.7, bsz=947.6, num_updates=262200, lr=6.17566e-05, gnorm=0.478, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 04:18:48 | INFO | train_inner | epoch 056:   1094 / 4751 loss=4.505, nll_loss=2.899, ppl=7.46, wps=88130.8, ups=3.04, wpb=28985.2, bsz=952.5, num_updates=262300, lr=6.17449e-05, gnorm=0.48, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 04:19:21 | INFO | train_inner | epoch 056:   1194 / 4751 loss=4.565, nll_loss=2.967, ppl=7.82, wps=87842.6, ups=3.04, wpb=28936.1, bsz=956.6, num_updates=262400, lr=6.17331e-05, gnorm=0.485, loss_scale=1, train_wall=33, gb_free=6.5, wall=0
2021-04-06 04:19:54 | INFO | train_inner | epoch 056:   1294 / 4751 loss=4.49, nll_loss=2.882, ppl=7.37, wps=88396.6, ups=3.04, wpb=29061.4, bsz=944.9, num_updates=262500, lr=6.17213e-05, gnorm=0.473, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 04:20:27 | INFO | train_inner | epoch 056:   1394 / 4751 loss=4.477, nll_loss=2.868, ppl=7.3, wps=88108.5, ups=3.03, wpb=29097.9, bsz=987, num_updates=262600, lr=6.17096e-05, gnorm=0.473, loss_scale=1, train_wall=33, gb_free=6, wall=0
2021-04-06 04:21:00 | INFO | train_inner | epoch 056:   1494 / 4751 loss=4.472, nll_loss=2.861, ppl=7.27, wps=88460, ups=3.04, wpb=29133.7, bsz=956, num_updates=262700, lr=6.16978e-05, gnorm=0.476, loss_scale=1, train_wall=33, gb_free=6.4, wall=0
2021-04-06 04:21:33 | INFO | train_inner | epoch 056:   1594 / 4751 loss=4.5, nll_loss=2.893, ppl=7.43, wps=87138.3, ups=3.02, wpb=28893.8, bsz=967, num_updates=262800, lr=6.16861e-05, gnorm=0.478, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 04:22:07 | INFO | train_inner | epoch 056:   1694 / 4751 loss=4.526, nll_loss=2.922, ppl=7.58, wps=85463.1, ups=2.94, wpb=29036.1, bsz=926.6, num_updates=262900, lr=6.16744e-05, gnorm=0.477, loss_scale=1, train_wall=34, gb_free=6.2, wall=0
2021-04-06 04:22:40 | INFO | train_inner | epoch 056:   1794 / 4751 loss=4.545, nll_loss=2.944, ppl=7.69, wps=89001.5, ups=3.05, wpb=29145.4, bsz=939.2, num_updates=263000, lr=6.16626e-05, gnorm=0.479, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 04:23:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
2021-04-06 04:23:13 | INFO | train_inner | epoch 056:   1895 / 4751 loss=4.506, nll_loss=2.901, ppl=7.47, wps=86438.2, ups=3.02, wpb=28589.2, bsz=951.5, num_updates=263100, lr=6.16509e-05, gnorm=0.486, loss_scale=0.5, train_wall=33, gb_free=6.4, wall=0
2021-04-06 04:23:46 | INFO | train_inner | epoch 056:   1995 / 4751 loss=4.523, nll_loss=2.92, ppl=7.57, wps=88114.3, ups=3.03, wpb=29047.7, bsz=934.1, num_updates=263200, lr=6.16392e-05, gnorm=0.489, loss_scale=0.5, train_wall=33, gb_free=6.4, wall=0
2021-04-06 04:24:19 | INFO | train_inner | epoch 056:   2095 / 4751 loss=4.594, nll_loss=3, ppl=8, wps=86284.1, ups=3.02, wpb=28557.3, bsz=937.9, num_updates=263300, lr=6.16275e-05, gnorm=0.478, loss_scale=0.5, train_wall=33, gb_free=6.5, wall=0
2021-04-06 04:24:52 | INFO | train_inner | epoch 056:   2195 / 4751 loss=4.52, nll_loss=2.916, ppl=7.55, wps=88230.8, ups=3.04, wpb=28997.4, bsz=963.4, num_updates=263400, lr=6.16158e-05, gnorm=0.47, loss_scale=0.5, train_wall=33, gb_free=6.1, wall=0
2021-04-06 04:25:25 | INFO | train_inner | epoch 056:   2295 / 4751 loss=4.458, nll_loss=2.846, ppl=7.19, wps=88091.4, ups=3.03, wpb=29031.2, bsz=972.5, num_updates=263500, lr=6.16041e-05, gnorm=0.478, loss_scale=0.5, train_wall=33, gb_free=6.1, wall=0
2021-04-06 04:25:58 | INFO | train_inner | epoch 056:   2395 / 4751 loss=4.535, nll_loss=2.932, ppl=7.63, wps=89102.4, ups=3.05, wpb=29250.1, bsz=907.4, num_updates=263600, lr=6.15924e-05, gnorm=0.479, loss_scale=0.5, train_wall=33, gb_free=6.1, wall=0
2021-04-06 04:26:31 | INFO | train_inner | epoch 056:   2495 / 4751 loss=4.481, nll_loss=2.873, ppl=7.32, wps=87158, ups=3.04, wpb=28715.5, bsz=939.2, num_updates=263700, lr=6.15807e-05, gnorm=0.482, loss_scale=0.5, train_wall=33, gb_free=6.1, wall=0
2021-04-06 04:27:04 | INFO | train_inner | epoch 056:   2595 / 4751 loss=4.448, nll_loss=2.836, ppl=7.14, wps=87883.7, ups=3.02, wpb=29080.8, bsz=974.9, num_updates=263800, lr=6.15691e-05, gnorm=0.471, loss_scale=0.5, train_wall=33, gb_free=6.2, wall=0
2021-04-06 04:27:37 | INFO | train_inner | epoch 056:   2695 / 4751 loss=4.558, nll_loss=2.959, ppl=7.78, wps=87928.1, ups=3.04, wpb=28920, bsz=947.3, num_updates=263900, lr=6.15574e-05, gnorm=0.48, loss_scale=0.5, train_wall=33, gb_free=6.1, wall=0
2021-04-06 04:28:09 | INFO | train_inner | epoch 056:   2795 / 4751 loss=4.509, nll_loss=2.904, ppl=7.48, wps=87633.2, ups=3.05, wpb=28752.2, bsz=950.2, num_updates=264000, lr=6.15457e-05, gnorm=0.484, loss_scale=0.5, train_wall=33, gb_free=6.2, wall=0
2021-04-06 04:28:42 | INFO | train_inner | epoch 056:   2895 / 4751 loss=4.559, nll_loss=2.959, ppl=7.78, wps=88351.4, ups=3.06, wpb=28830.9, bsz=905.9, num_updates=264100, lr=6.15341e-05, gnorm=0.478, loss_scale=0.5, train_wall=32, gb_free=6.3, wall=0
2021-04-06 04:29:15 | INFO | train_inner | epoch 056:   2995 / 4751 loss=4.461, nll_loss=2.849, ppl=7.21, wps=88692.2, ups=3.06, wpb=29027.2, bsz=947.4, num_updates=264200, lr=6.15224e-05, gnorm=0.475, loss_scale=0.5, train_wall=33, gb_free=6.2, wall=0
2021-04-06 04:29:48 | INFO | train_inner | epoch 056:   3095 / 4751 loss=4.546, nll_loss=2.945, ppl=7.7, wps=87501, ups=3.04, wpb=28814.6, bsz=920.5, num_updates=264300, lr=6.15108e-05, gnorm=0.482, loss_scale=0.5, train_wall=33, gb_free=6, wall=0
2021-04-06 04:30:20 | INFO | train_inner | epoch 056:   3195 / 4751 loss=4.522, nll_loss=2.919, ppl=7.56, wps=89182.8, ups=3.05, wpb=29215, bsz=963.3, num_updates=264400, lr=6.14992e-05, gnorm=0.476, loss_scale=0.5, train_wall=33, gb_free=6.2, wall=0
2021-04-06 04:30:53 | INFO | train_inner | epoch 056:   3295 / 4751 loss=4.539, nll_loss=2.937, ppl=7.66, wps=87333.1, ups=3.04, wpb=28745.6, bsz=917.6, num_updates=264500, lr=6.14875e-05, gnorm=0.479, loss_scale=0.5, train_wall=33, gb_free=6.5, wall=0
2021-04-06 04:31:26 | INFO | train_inner | epoch 056:   3395 / 4751 loss=4.506, nll_loss=2.901, ppl=7.47, wps=88276.6, ups=3.03, wpb=29108.6, bsz=974.6, num_updates=264600, lr=6.14759e-05, gnorm=0.478, loss_scale=0.5, train_wall=33, gb_free=6.8, wall=0
2021-04-06 04:31:59 | INFO | train_inner | epoch 056:   3495 / 4751 loss=4.504, nll_loss=2.899, ppl=7.46, wps=88307.8, ups=3.03, wpb=29128.9, bsz=969.4, num_updates=264700, lr=6.14643e-05, gnorm=0.477, loss_scale=0.5, train_wall=33, gb_free=6.3, wall=0
2021-04-06 04:32:32 | INFO | train_inner | epoch 056:   3595 / 4751 loss=4.525, nll_loss=2.922, ppl=7.58, wps=88129.5, ups=3.04, wpb=28949.6, bsz=960.2, num_updates=264800, lr=6.14527e-05, gnorm=0.478, loss_scale=0.5, train_wall=33, gb_free=6.2, wall=0
2021-04-06 04:33:05 | INFO | train_inner | epoch 056:   3695 / 4751 loss=4.535, nll_loss=2.933, ppl=7.64, wps=89068.3, ups=3.05, wpb=29160.9, bsz=933.4, num_updates=264900, lr=6.14411e-05, gnorm=0.479, loss_scale=0.5, train_wall=33, gb_free=6.3, wall=0
2021-04-06 04:33:38 | INFO | train_inner | epoch 056:   3795 / 4751 loss=4.563, nll_loss=2.965, ppl=7.81, wps=88757, ups=3.05, wpb=29090.1, bsz=947.4, num_updates=265000, lr=6.14295e-05, gnorm=0.482, loss_scale=0.5, train_wall=33, gb_free=6.6, wall=0
2021-04-06 04:34:11 | INFO | train_inner | epoch 056:   3895 / 4751 loss=4.519, nll_loss=2.916, ppl=7.55, wps=87568.4, ups=3.04, wpb=28792.8, bsz=949.9, num_updates=265100, lr=6.14179e-05, gnorm=0.483, loss_scale=0.5, train_wall=33, gb_free=6.5, wall=0
2021-04-06 04:34:43 | INFO | train_inner | epoch 056:   3995 / 4751 loss=4.517, nll_loss=2.912, ppl=7.53, wps=87181.6, ups=3.04, wpb=28658.9, bsz=935, num_updates=265200, lr=6.14063e-05, gnorm=0.477, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 04:35:16 | INFO | train_inner | epoch 056:   4095 / 4751 loss=4.471, nll_loss=2.861, ppl=7.26, wps=88474, ups=3.05, wpb=28968.3, bsz=935.9, num_updates=265300, lr=6.13948e-05, gnorm=0.473, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 04:35:49 | INFO | train_inner | epoch 056:   4195 / 4751 loss=4.519, nll_loss=2.916, ppl=7.55, wps=88626.5, ups=3.03, wpb=29220.1, bsz=975.7, num_updates=265400, lr=6.13832e-05, gnorm=0.479, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 04:36:22 | INFO | train_inner | epoch 056:   4295 / 4751 loss=4.495, nll_loss=2.888, ppl=7.4, wps=88323.2, ups=3.04, wpb=29069, bsz=946, num_updates=265500, lr=6.13716e-05, gnorm=0.473, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 04:36:55 | INFO | train_inner | epoch 056:   4395 / 4751 loss=4.523, nll_loss=2.92, ppl=7.57, wps=86525.5, ups=3.03, wpb=28582.7, bsz=968.3, num_updates=265600, lr=6.13601e-05, gnorm=0.481, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 04:37:28 | INFO | train_inner | epoch 056:   4495 / 4751 loss=4.463, nll_loss=2.852, ppl=7.22, wps=87653.9, ups=3.03, wpb=28934.5, bsz=926.3, num_updates=265700, lr=6.13485e-05, gnorm=0.477, loss_scale=1, train_wall=33, gb_free=6.4, wall=0
2021-04-06 04:38:01 | INFO | train_inner | epoch 056:   4595 / 4751 loss=4.468, nll_loss=2.857, ppl=7.25, wps=88396, ups=3.03, wpb=29197.1, bsz=951.9, num_updates=265800, lr=6.1337e-05, gnorm=0.472, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 04:38:34 | INFO | train_inner | epoch 056:   4695 / 4751 loss=4.501, nll_loss=2.895, ppl=7.44, wps=87405.3, ups=3.04, wpb=28727.9, bsz=938.6, num_updates=265900, lr=6.13255e-05, gnorm=0.489, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 04:38:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-06 04:38:54 | INFO | valid | epoch 056 | valid on 'valid' subset | loss 4.144 | nll_loss 2.38 | ppl 5.21 | wps 200513 | wpb 10489.1 | bsz 375 | num_updates 265956 | best_loss 4.144
2021-04-06 04:38:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 56 @ 265956 updates
2021-04-06 04:38:54 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-06 04:39:00 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-06 04:39:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt (epoch 56 @ 265956 updates, score 4.144) (writing took 12.929831553250551 seconds)
2021-04-06 04:39:07 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2021-04-06 04:39:07 | INFO | train | epoch 056 | loss 4.508 | nll_loss 2.902 | ppl 7.48 | wps 87061.5 | ups 3.01 | wpb 28969 | bsz 946.7 | num_updates 265956 | lr 6.1319e-05 | gnorm 0.478 | loss_scale 1 | train_wall 1558 | gb_free 6.5 | wall 0
2021-04-06 04:39:07 | INFO | fairseq.trainer | begin training epoch 57
2021-04-06 04:39:07 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-06 04:39:22 | INFO | train_inner | epoch 057:     44 / 4751 loss=4.525, nll_loss=2.922, ppl=7.58, wps=59575.6, ups=2.07, wpb=28722.6, bsz=958.2, num_updates=266000, lr=6.13139e-05, gnorm=0.486, loss_scale=1, train_wall=33, gb_free=6.5, wall=0
2021-04-06 04:39:55 | INFO | train_inner | epoch 057:    144 / 4751 loss=4.468, nll_loss=2.857, ppl=7.24, wps=88044.1, ups=3.04, wpb=28986.4, bsz=936.8, num_updates=266100, lr=6.13024e-05, gnorm=0.478, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 04:40:28 | INFO | train_inner | epoch 057:    244 / 4751 loss=4.548, nll_loss=2.948, ppl=7.72, wps=87537.6, ups=3.05, wpb=28731.1, bsz=938.1, num_updates=266200, lr=6.12909e-05, gnorm=0.485, loss_scale=1, train_wall=33, gb_free=6.5, wall=0
2021-04-06 04:41:01 | INFO | train_inner | epoch 057:    344 / 4751 loss=4.527, nll_loss=2.923, ppl=7.59, wps=88356.9, ups=3.04, wpb=29081.5, bsz=935, num_updates=266300, lr=6.12794e-05, gnorm=0.478, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 04:41:34 | INFO | train_inner | epoch 057:    444 / 4751 loss=4.513, nll_loss=2.907, ppl=7.5, wps=87801, ups=3.02, wpb=29061, bsz=920.3, num_updates=266400, lr=6.12679e-05, gnorm=0.484, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 04:42:07 | INFO | train_inner | epoch 057:    544 / 4751 loss=4.471, nll_loss=2.861, ppl=7.26, wps=87823.7, ups=3.03, wpb=29014.6, bsz=940.2, num_updates=266500, lr=6.12564e-05, gnorm=0.475, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 04:42:40 | INFO | train_inner | epoch 057:    644 / 4751 loss=4.523, nll_loss=2.919, ppl=7.56, wps=87729.4, ups=3.04, wpb=28876.4, bsz=916.5, num_updates=266600, lr=6.12449e-05, gnorm=0.483, loss_scale=1, train_wall=33, gb_free=6, wall=0
2021-04-06 04:43:13 | INFO | train_inner | epoch 057:    744 / 4751 loss=4.492, nll_loss=2.884, ppl=7.38, wps=87260.3, ups=3.03, wpb=28768.8, bsz=941.4, num_updates=266700, lr=6.12334e-05, gnorm=0.48, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 04:43:46 | INFO | train_inner | epoch 057:    844 / 4751 loss=4.472, nll_loss=2.861, ppl=7.27, wps=87013.2, ups=3, wpb=29040.1, bsz=968.5, num_updates=266800, lr=6.12219e-05, gnorm=0.477, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 04:44:19 | INFO | train_inner | epoch 057:    944 / 4751 loss=4.558, nll_loss=2.959, ppl=7.78, wps=88740.9, ups=3.06, wpb=28999.4, bsz=928.8, num_updates=266900, lr=6.12105e-05, gnorm=0.505, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 04:44:52 | INFO | train_inner | epoch 057:   1044 / 4751 loss=4.462, nll_loss=2.851, ppl=7.21, wps=87964.4, ups=3.03, wpb=29018.8, bsz=959.4, num_updates=267000, lr=6.1199e-05, gnorm=0.474, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 04:45:25 | INFO | train_inner | epoch 057:   1144 / 4751 loss=4.496, nll_loss=2.889, ppl=7.41, wps=88777, ups=3.05, wpb=29147, bsz=946.2, num_updates=267100, lr=6.11875e-05, gnorm=0.476, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 04:45:58 | INFO | train_inner | epoch 057:   1244 / 4751 loss=4.502, nll_loss=2.896, ppl=7.44, wps=87725.8, ups=3.04, wpb=28877.5, bsz=944.1, num_updates=267200, lr=6.11761e-05, gnorm=0.482, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 04:46:31 | INFO | train_inner | epoch 057:   1344 / 4751 loss=4.486, nll_loss=2.878, ppl=7.35, wps=88399.1, ups=3.02, wpb=29278.9, bsz=965.4, num_updates=267300, lr=6.11647e-05, gnorm=0.474, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 04:47:04 | INFO | train_inner | epoch 057:   1444 / 4751 loss=4.54, nll_loss=2.939, ppl=7.67, wps=88512.5, ups=3.05, wpb=29067.2, bsz=950.7, num_updates=267400, lr=6.11532e-05, gnorm=0.482, loss_scale=2, train_wall=33, gb_free=6.6, wall=0
2021-04-06 04:47:37 | INFO | train_inner | epoch 057:   1544 / 4751 loss=4.457, nll_loss=2.846, ppl=7.19, wps=86991.4, ups=3.02, wpb=28824.9, bsz=955.6, num_updates=267500, lr=6.11418e-05, gnorm=0.479, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 04:48:10 | INFO | train_inner | epoch 057:   1644 / 4751 loss=4.498, nll_loss=2.892, ppl=7.42, wps=87337.4, ups=3.03, wpb=28869.1, bsz=939.2, num_updates=267600, lr=6.11304e-05, gnorm=0.485, loss_scale=2, train_wall=33, gb_free=5.9, wall=0
2021-04-06 04:48:43 | INFO | train_inner | epoch 057:   1744 / 4751 loss=4.516, nll_loss=2.912, ppl=7.52, wps=89274.7, ups=3.04, wpb=29347.5, bsz=908.6, num_updates=267700, lr=6.11189e-05, gnorm=0.478, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 04:49:16 | INFO | train_inner | epoch 057:   1844 / 4751 loss=4.527, nll_loss=2.925, ppl=7.59, wps=86582.4, ups=3.01, wpb=28723.8, bsz=975.3, num_updates=267800, lr=6.11075e-05, gnorm=0.481, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 04:49:49 | INFO | train_inner | epoch 057:   1944 / 4751 loss=4.484, nll_loss=2.876, ppl=7.34, wps=88650, ups=3.04, wpb=29163, bsz=966.5, num_updates=267900, lr=6.10961e-05, gnorm=0.474, loss_scale=2, train_wall=33, gb_free=6.6, wall=0
2021-04-06 04:50:22 | INFO | train_inner | epoch 057:   2044 / 4751 loss=4.531, nll_loss=2.929, ppl=7.62, wps=86353.2, ups=3, wpb=28764.1, bsz=968.8, num_updates=268000, lr=6.10847e-05, gnorm=0.479, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 04:50:55 | INFO | train_inner | epoch 057:   2144 / 4751 loss=4.506, nll_loss=2.9, ppl=7.47, wps=88369, ups=3.03, wpb=29147.5, bsz=953.4, num_updates=268100, lr=6.10733e-05, gnorm=0.474, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 04:51:28 | INFO | train_inner | epoch 057:   2244 / 4751 loss=4.441, nll_loss=2.827, ppl=7.1, wps=87739.9, ups=3.02, wpb=29073.6, bsz=974.6, num_updates=268200, lr=6.10619e-05, gnorm=0.472, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-06 04:52:01 | INFO | train_inner | epoch 057:   2344 / 4751 loss=4.52, nll_loss=2.916, ppl=7.55, wps=88118.6, ups=3.03, wpb=29067, bsz=973.8, num_updates=268300, lr=6.10506e-05, gnorm=0.485, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-06 04:52:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-04-06 04:52:34 | INFO | train_inner | epoch 057:   2445 / 4751 loss=4.479, nll_loss=2.871, ppl=7.31, wps=86769.6, ups=3, wpb=28883.1, bsz=957.8, num_updates=268400, lr=6.10392e-05, gnorm=0.48, loss_scale=1, train_wall=33, gb_free=6, wall=0
2021-04-06 04:53:07 | INFO | train_inner | epoch 057:   2545 / 4751 loss=4.482, nll_loss=2.874, ppl=7.33, wps=87148.8, ups=3.03, wpb=28729.7, bsz=953.6, num_updates=268500, lr=6.10278e-05, gnorm=0.483, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 04:53:40 | INFO | train_inner | epoch 057:   2645 / 4751 loss=4.589, nll_loss=2.993, ppl=7.96, wps=88494.6, ups=3.06, wpb=28920.4, bsz=894.4, num_updates=268600, lr=6.10165e-05, gnorm=0.484, loss_scale=1, train_wall=33, gb_free=5.9, wall=0
2021-04-06 04:54:13 | INFO | train_inner | epoch 057:   2745 / 4751 loss=4.551, nll_loss=2.951, ppl=7.73, wps=88401.4, ups=3.04, wpb=29040, bsz=910.2, num_updates=268700, lr=6.10051e-05, gnorm=0.483, loss_scale=1, train_wall=33, gb_free=6, wall=0
2021-04-06 04:54:46 | INFO | train_inner | epoch 057:   2845 / 4751 loss=4.469, nll_loss=2.859, ppl=7.25, wps=87128.5, ups=3.02, wpb=28820.1, bsz=986, num_updates=268800, lr=6.09938e-05, gnorm=0.474, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 04:55:20 | INFO | train_inner | epoch 057:   2945 / 4751 loss=4.529, nll_loss=2.926, ppl=7.6, wps=86333.3, ups=2.97, wpb=29045.9, bsz=957.3, num_updates=268900, lr=6.09824e-05, gnorm=0.485, loss_scale=1, train_wall=34, gb_free=6.3, wall=0
2021-04-06 04:55:53 | INFO | train_inner | epoch 057:   3045 / 4751 loss=4.482, nll_loss=2.873, ppl=7.32, wps=87802.6, ups=3.02, wpb=29050.2, bsz=935, num_updates=269000, lr=6.09711e-05, gnorm=0.479, loss_scale=1, train_wall=33, gb_free=5.9, wall=0
2021-04-06 04:56:26 | INFO | train_inner | epoch 057:   3145 / 4751 loss=4.501, nll_loss=2.895, ppl=7.44, wps=86642.2, ups=3.04, wpb=28527.6, bsz=931.6, num_updates=269100, lr=6.09597e-05, gnorm=0.489, loss_scale=1, train_wall=33, gb_free=6.4, wall=0
2021-04-06 04:56:59 | INFO | train_inner | epoch 057:   3245 / 4751 loss=4.501, nll_loss=2.896, ppl=7.44, wps=87512.2, ups=3.02, wpb=28961.4, bsz=976.7, num_updates=269200, lr=6.09484e-05, gnorm=0.48, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 04:57:32 | INFO | train_inner | epoch 057:   3345 / 4751 loss=4.511, nll_loss=2.907, ppl=7.5, wps=87787.3, ups=3.04, wpb=28912, bsz=962, num_updates=269300, lr=6.09371e-05, gnorm=0.481, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 04:58:05 | INFO | train_inner | epoch 057:   3445 / 4751 loss=4.55, nll_loss=2.95, ppl=7.73, wps=88167.5, ups=3.05, wpb=28901.1, bsz=933.8, num_updates=269400, lr=6.09258e-05, gnorm=0.478, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 04:58:37 | INFO | train_inner | epoch 057:   3545 / 4751 loss=4.493, nll_loss=2.886, ppl=7.39, wps=88343.1, ups=3.05, wpb=28985.2, bsz=940.8, num_updates=269500, lr=6.09145e-05, gnorm=0.477, loss_scale=1, train_wall=33, gb_free=6.4, wall=0
2021-04-06 04:59:10 | INFO | train_inner | epoch 057:   3645 / 4751 loss=4.5, nll_loss=2.894, ppl=7.43, wps=89320.9, ups=3.04, wpb=29344, bsz=988.2, num_updates=269600, lr=6.09032e-05, gnorm=0.476, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 04:59:43 | INFO | train_inner | epoch 057:   3745 / 4751 loss=4.5, nll_loss=2.894, ppl=7.43, wps=88110.7, ups=3.04, wpb=28992.7, bsz=955, num_updates=269700, lr=6.08919e-05, gnorm=0.472, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 05:00:16 | INFO | train_inner | epoch 057:   3845 / 4751 loss=4.509, nll_loss=2.903, ppl=7.48, wps=88171.9, ups=3.03, wpb=29078.3, bsz=943.1, num_updates=269800, lr=6.08806e-05, gnorm=0.473, loss_scale=1, train_wall=33, gb_free=6.5, wall=0
2021-04-06 05:00:49 | INFO | train_inner | epoch 057:   3945 / 4751 loss=4.493, nll_loss=2.886, ppl=7.39, wps=88072.2, ups=3.03, wpb=29047.1, bsz=955.9, num_updates=269900, lr=6.08693e-05, gnorm=0.477, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 05:01:22 | INFO | train_inner | epoch 057:   4045 / 4751 loss=4.496, nll_loss=2.89, ppl=7.41, wps=88005.7, ups=3.04, wpb=28940.6, bsz=932.8, num_updates=270000, lr=6.08581e-05, gnorm=0.478, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 05:01:55 | INFO | train_inner | epoch 057:   4145 / 4751 loss=4.543, nll_loss=2.942, ppl=7.68, wps=87017.3, ups=3.02, wpb=28825.3, bsz=914.8, num_updates=270100, lr=6.08468e-05, gnorm=0.481, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 05:02:28 | INFO | train_inner | epoch 057:   4245 / 4751 loss=4.503, nll_loss=2.897, ppl=7.45, wps=88152.9, ups=3.04, wpb=28995, bsz=928.1, num_updates=270200, lr=6.08355e-05, gnorm=0.483, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 05:03:01 | INFO | train_inner | epoch 057:   4345 / 4751 loss=4.481, nll_loss=2.872, ppl=7.32, wps=88456.5, ups=3.03, wpb=29214.5, bsz=945.1, num_updates=270300, lr=6.08243e-05, gnorm=0.472, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 05:03:34 | INFO | train_inner | epoch 057:   4445 / 4751 loss=4.497, nll_loss=2.891, ppl=7.42, wps=88703.9, ups=3.04, wpb=29143.6, bsz=950.1, num_updates=270400, lr=6.0813e-05, gnorm=0.477, loss_scale=1, train_wall=33, gb_free=6, wall=0
2021-04-06 05:04:07 | INFO | train_inner | epoch 057:   4545 / 4751 loss=4.548, nll_loss=2.948, ppl=7.72, wps=87968.7, ups=3.04, wpb=28917.5, bsz=952.3, num_updates=270500, lr=6.08018e-05, gnorm=0.484, loss_scale=2, train_wall=33, gb_free=6.6, wall=0
2021-04-06 05:04:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-04-06 05:04:40 | INFO | train_inner | epoch 057:   4646 / 4751 loss=4.507, nll_loss=2.902, ppl=7.47, wps=86724.6, ups=3.02, wpb=28678.9, bsz=948.2, num_updates=270600, lr=6.07906e-05, gnorm=0.482, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 05:05:13 | INFO | train_inner | epoch 057:   4746 / 4751 loss=4.54, nll_loss=2.939, ppl=7.67, wps=88424.6, ups=3.05, wpb=29035.8, bsz=933.5, num_updates=270700, lr=6.07793e-05, gnorm=0.478, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 05:05:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-06 05:05:15 | INFO | valid | epoch 057 | valid on 'valid' subset | loss 4.149 | nll_loss 2.378 | ppl 5.2 | wps 208648 | wpb 10489.1 | bsz 375 | num_updates 270705 | best_loss 4.144
2021-04-06 05:05:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 57 @ 270705 updates
2021-04-06 05:05:15 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-06 05:05:22 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-06 05:05:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt (epoch 57 @ 270705 updates, score 4.149) (writing took 6.38883088901639 seconds)
2021-04-06 05:05:22 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2021-04-06 05:05:22 | INFO | train | epoch 057 | loss 4.506 | nll_loss 2.901 | ppl 7.47 | wps 87336.9 | ups 3.01 | wpb 28967.9 | bsz 946.7 | num_updates 270705 | lr 6.07788e-05 | gnorm 0.48 | loss_scale 1 | train_wall 1559 | gb_free 6.4 | wall 0
2021-04-06 05:05:22 | INFO | fairseq.trainer | begin training epoch 58
2021-04-06 05:05:22 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-06 05:05:54 | INFO | train_inner | epoch 058:     95 / 4751 loss=4.538, nll_loss=2.936, ppl=7.65, wps=68651, ups=2.4, wpb=28593.2, bsz=928.7, num_updates=270800, lr=6.07681e-05, gnorm=0.48, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 05:06:27 | INFO | train_inner | epoch 058:    195 / 4751 loss=4.516, nll_loss=2.912, ppl=7.53, wps=87683.4, ups=3.05, wpb=28714.9, bsz=969, num_updates=270900, lr=6.07569e-05, gnorm=0.488, loss_scale=1, train_wall=33, gb_free=6.4, wall=0
2021-04-06 05:07:00 | INFO | train_inner | epoch 058:    295 / 4751 loss=4.452, nll_loss=2.839, ppl=7.16, wps=88755.1, ups=3.04, wpb=29169.9, bsz=975.2, num_updates=271000, lr=6.07457e-05, gnorm=0.473, loss_scale=1, train_wall=33, gb_free=6.4, wall=0
2021-04-06 05:07:33 | INFO | train_inner | epoch 058:    395 / 4751 loss=4.506, nll_loss=2.899, ppl=7.46, wps=88614.4, ups=3.03, wpb=29202.5, bsz=914.2, num_updates=271100, lr=6.07345e-05, gnorm=0.478, loss_scale=1, train_wall=33, gb_free=6.8, wall=0
2021-04-06 05:08:06 | INFO | train_inner | epoch 058:    495 / 4751 loss=4.482, nll_loss=2.873, ppl=7.33, wps=87646.5, ups=3.02, wpb=29003, bsz=960.7, num_updates=271200, lr=6.07233e-05, gnorm=0.48, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 05:08:39 | INFO | train_inner | epoch 058:    595 / 4751 loss=4.542, nll_loss=2.94, ppl=7.68, wps=88810.8, ups=3.06, wpb=29010.5, bsz=936.2, num_updates=271300, lr=6.07121e-05, gnorm=0.488, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 05:09:12 | INFO | train_inner | epoch 058:    695 / 4751 loss=4.487, nll_loss=2.879, ppl=7.35, wps=87221.4, ups=3.02, wpb=28877.8, bsz=931.9, num_updates=271400, lr=6.07009e-05, gnorm=0.478, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 05:09:45 | INFO | train_inner | epoch 058:    795 / 4751 loss=4.51, nll_loss=2.905, ppl=7.49, wps=87967.1, ups=3.03, wpb=29054.7, bsz=975.1, num_updates=271500, lr=6.06897e-05, gnorm=0.487, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 05:10:18 | INFO | train_inner | epoch 058:    895 / 4751 loss=4.463, nll_loss=2.851, ppl=7.21, wps=88945.9, ups=3.03, wpb=29371.1, bsz=922.8, num_updates=271600, lr=6.06785e-05, gnorm=0.474, loss_scale=1, train_wall=33, gb_free=6.4, wall=0
2021-04-06 05:10:51 | INFO | train_inner | epoch 058:    995 / 4751 loss=4.474, nll_loss=2.864, ppl=7.28, wps=87735.6, ups=3.03, wpb=28946.9, bsz=914.4, num_updates=271700, lr=6.06674e-05, gnorm=0.481, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 05:11:24 | INFO | train_inner | epoch 058:   1095 / 4751 loss=4.478, nll_loss=2.868, ppl=7.3, wps=87948.2, ups=3.04, wpb=28886.1, bsz=946, num_updates=271800, lr=6.06562e-05, gnorm=0.479, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 05:11:57 | INFO | train_inner | epoch 058:   1195 / 4751 loss=4.48, nll_loss=2.871, ppl=7.32, wps=88369.9, ups=3.04, wpb=29090, bsz=932.3, num_updates=271900, lr=6.06451e-05, gnorm=0.47, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 05:12:29 | INFO | train_inner | epoch 058:   1295 / 4751 loss=4.457, nll_loss=2.845, ppl=7.18, wps=88916.7, ups=3.04, wpb=29237.7, bsz=942.1, num_updates=272000, lr=6.06339e-05, gnorm=0.476, loss_scale=1, train_wall=33, gb_free=6, wall=0
2021-04-06 05:13:03 | INFO | train_inner | epoch 058:   1395 / 4751 loss=4.52, nll_loss=2.916, ppl=7.55, wps=87205, ups=3.02, wpb=28867.7, bsz=931.4, num_updates=272100, lr=6.06228e-05, gnorm=0.489, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 05:13:36 | INFO | train_inner | epoch 058:   1495 / 4751 loss=4.534, nll_loss=2.932, ppl=7.63, wps=86158.7, ups=2.97, wpb=28987.8, bsz=908.2, num_updates=272200, lr=6.06116e-05, gnorm=0.476, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 05:14:09 | INFO | train_inner | epoch 058:   1595 / 4751 loss=4.477, nll_loss=2.868, ppl=7.3, wps=88865.9, ups=3.05, wpb=29168, bsz=976, num_updates=272300, lr=6.06005e-05, gnorm=0.474, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 05:14:42 | INFO | train_inner | epoch 058:   1695 / 4751 loss=4.524, nll_loss=2.92, ppl=7.57, wps=87885.4, ups=3.05, wpb=28815.5, bsz=901.9, num_updates=272400, lr=6.05894e-05, gnorm=0.485, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 05:15:15 | INFO | train_inner | epoch 058:   1795 / 4751 loss=4.483, nll_loss=2.875, ppl=7.34, wps=87594.4, ups=3.02, wpb=29011.5, bsz=951.6, num_updates=272500, lr=6.05783e-05, gnorm=0.515, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 05:15:48 | INFO | train_inner | epoch 058:   1895 / 4751 loss=4.527, nll_loss=2.924, ppl=7.59, wps=87868.6, ups=3.04, wpb=28907.4, bsz=935.6, num_updates=272600, lr=6.05671e-05, gnorm=0.479, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 05:16:21 | INFO | train_inner | epoch 058:   1995 / 4751 loss=4.448, nll_loss=2.835, ppl=7.14, wps=86814.7, ups=3.02, wpb=28713.2, bsz=961.8, num_updates=272700, lr=6.0556e-05, gnorm=0.483, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 05:16:54 | INFO | train_inner | epoch 058:   2095 / 4751 loss=4.512, nll_loss=2.907, ppl=7.5, wps=88480.9, ups=3.05, wpb=28994.8, bsz=947.4, num_updates=272800, lr=6.05449e-05, gnorm=0.485, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 05:17:26 | INFO | train_inner | epoch 058:   2195 / 4751 loss=4.498, nll_loss=2.891, ppl=7.42, wps=87636.6, ups=3.05, wpb=28754.2, bsz=948.9, num_updates=272900, lr=6.05338e-05, gnorm=0.479, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 05:17:59 | INFO | train_inner | epoch 058:   2295 / 4751 loss=4.525, nll_loss=2.922, ppl=7.58, wps=88019, ups=3.05, wpb=28875.5, bsz=940.4, num_updates=273000, lr=6.05228e-05, gnorm=0.479, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-06 05:18:32 | INFO | train_inner | epoch 058:   2395 / 4751 loss=4.475, nll_loss=2.866, ppl=7.29, wps=88045.7, ups=3.03, wpb=29012.9, bsz=970.2, num_updates=273100, lr=6.05117e-05, gnorm=0.483, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 05:19:05 | INFO | train_inner | epoch 058:   2495 / 4751 loss=4.53, nll_loss=2.928, ppl=7.61, wps=87837.1, ups=3.04, wpb=28925.5, bsz=952.5, num_updates=273200, lr=6.05006e-05, gnorm=0.484, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 05:19:38 | INFO | train_inner | epoch 058:   2595 / 4751 loss=4.492, nll_loss=2.885, ppl=7.39, wps=87862.4, ups=3.01, wpb=29147.3, bsz=941.4, num_updates=273300, lr=6.04895e-05, gnorm=0.475, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 05:20:11 | INFO | train_inner | epoch 058:   2695 / 4751 loss=4.472, nll_loss=2.862, ppl=7.27, wps=88230.6, ups=3.04, wpb=29066.7, bsz=974.6, num_updates=273400, lr=6.04785e-05, gnorm=0.475, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 05:20:44 | INFO | train_inner | epoch 058:   2795 / 4751 loss=4.52, nll_loss=2.916, ppl=7.55, wps=86887.8, ups=3.01, wpb=28859.7, bsz=948.2, num_updates=273500, lr=6.04674e-05, gnorm=0.482, loss_scale=2, train_wall=33, gb_free=6.7, wall=0
2021-04-06 05:21:17 | INFO | train_inner | epoch 058:   2895 / 4751 loss=4.478, nll_loss=2.869, ppl=7.3, wps=88759.1, ups=3.03, wpb=29296, bsz=966.2, num_updates=273600, lr=6.04564e-05, gnorm=0.476, loss_scale=2, train_wall=33, gb_free=6.7, wall=0
2021-04-06 05:21:50 | INFO | train_inner | epoch 058:   2995 / 4751 loss=4.532, nll_loss=2.93, ppl=7.62, wps=88983, ups=3.05, wpb=29197.7, bsz=949.7, num_updates=273700, lr=6.04453e-05, gnorm=0.487, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 05:22:23 | INFO | train_inner | epoch 058:   3095 / 4751 loss=4.529, nll_loss=2.926, ppl=7.6, wps=87284.2, ups=3.04, wpb=28690.3, bsz=935.7, num_updates=273800, lr=6.04343e-05, gnorm=0.484, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 05:22:56 | INFO | train_inner | epoch 058:   3195 / 4751 loss=4.555, nll_loss=2.956, ppl=7.76, wps=88022.8, ups=3.05, wpb=28860.1, bsz=939, num_updates=273900, lr=6.04232e-05, gnorm=0.489, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-06 05:23:29 | INFO | train_inner | epoch 058:   3295 / 4751 loss=4.474, nll_loss=2.864, ppl=7.28, wps=86960.3, ups=3, wpb=28953.5, bsz=963.4, num_updates=274000, lr=6.04122e-05, gnorm=0.486, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 05:24:02 | INFO | train_inner | epoch 058:   3395 / 4751 loss=4.571, nll_loss=2.974, ppl=7.86, wps=87933.8, ups=3.04, wpb=28938.5, bsz=964.6, num_updates=274100, lr=6.04012e-05, gnorm=0.486, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 05:24:35 | INFO | train_inner | epoch 058:   3495 / 4751 loss=4.554, nll_loss=2.955, ppl=7.76, wps=87878.5, ups=3.02, wpb=29065.5, bsz=954.8, num_updates=274200, lr=6.03902e-05, gnorm=0.483, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 05:25:08 | INFO | train_inner | epoch 058:   3595 / 4751 loss=4.512, nll_loss=2.907, ppl=7.5, wps=88408, ups=3.05, wpb=28955.4, bsz=954.2, num_updates=274300, lr=6.03792e-05, gnorm=0.478, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 05:25:41 | INFO | train_inner | epoch 058:   3695 / 4751 loss=4.519, nll_loss=2.915, ppl=7.54, wps=87427.5, ups=3.03, wpb=28899, bsz=930.9, num_updates=274400, lr=6.03682e-05, gnorm=0.483, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 05:26:14 | INFO | train_inner | epoch 058:   3795 / 4751 loss=4.506, nll_loss=2.9, ppl=7.46, wps=87969.2, ups=3.04, wpb=28976.3, bsz=941.4, num_updates=274500, lr=6.03572e-05, gnorm=0.479, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 05:26:47 | INFO | train_inner | epoch 058:   3895 / 4751 loss=4.489, nll_loss=2.882, ppl=7.37, wps=87570.2, ups=3.03, wpb=28882.3, bsz=947, num_updates=274600, lr=6.03462e-05, gnorm=0.479, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 05:27:20 | INFO | train_inner | epoch 058:   3995 / 4751 loss=4.538, nll_loss=2.937, ppl=7.66, wps=87953.9, ups=3.04, wpb=28923.8, bsz=988.9, num_updates=274700, lr=6.03352e-05, gnorm=0.486, loss_scale=4, train_wall=33, gb_free=6, wall=0
2021-04-06 05:27:53 | INFO | train_inner | epoch 058:   4095 / 4751 loss=4.472, nll_loss=2.862, ppl=7.27, wps=87338.2, ups=3, wpb=29103.1, bsz=991.2, num_updates=274800, lr=6.03242e-05, gnorm=0.476, loss_scale=4, train_wall=33, gb_free=6.4, wall=0
2021-04-06 05:28:26 | INFO | train_inner | epoch 058:   4195 / 4751 loss=4.473, nll_loss=2.863, ppl=7.28, wps=87154.9, ups=3.03, wpb=28754.7, bsz=931.1, num_updates=274900, lr=6.03132e-05, gnorm=0.48, loss_scale=4, train_wall=33, gb_free=6.7, wall=0
2021-04-06 05:28:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-06 05:28:59 | INFO | train_inner | epoch 058:   4296 / 4751 loss=4.467, nll_loss=2.857, ppl=7.25, wps=85842.6, ups=3, wpb=28614.5, bsz=979.7, num_updates=275000, lr=6.03023e-05, gnorm=0.479, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 05:29:32 | INFO | train_inner | epoch 058:   4396 / 4751 loss=4.524, nll_loss=2.92, ppl=7.57, wps=87773.4, ups=3.04, wpb=28896.4, bsz=919.2, num_updates=275100, lr=6.02913e-05, gnorm=0.493, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 05:30:05 | INFO | train_inner | epoch 058:   4496 / 4751 loss=4.511, nll_loss=2.907, ppl=7.5, wps=88762.6, ups=3.04, wpb=29162.9, bsz=925.2, num_updates=275200, lr=6.02804e-05, gnorm=0.477, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 05:30:38 | INFO | train_inner | epoch 058:   4596 / 4751 loss=4.517, nll_loss=2.913, ppl=7.53, wps=88211.8, ups=3.04, wpb=28978.9, bsz=943.8, num_updates=275300, lr=6.02694e-05, gnorm=0.492, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 05:31:11 | INFO | train_inner | epoch 058:   4696 / 4751 loss=4.544, nll_loss=2.943, ppl=7.69, wps=88213.2, ups=3.05, wpb=28955.1, bsz=922, num_updates=275400, lr=6.02585e-05, gnorm=0.48, loss_scale=2, train_wall=33, gb_free=6.8, wall=0
2021-04-06 05:31:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-06 05:31:30 | INFO | valid | epoch 058 | valid on 'valid' subset | loss 4.14 | nll_loss 2.373 | ppl 5.18 | wps 208462 | wpb 10489.1 | bsz 375 | num_updates 275455 | best_loss 4.14
2021-04-06 05:31:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 58 @ 275455 updates
2021-04-06 05:31:30 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-06 05:31:36 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-06 05:31:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt (epoch 58 @ 275455 updates, score 4.14) (writing took 13.02586529403925 seconds)
2021-04-06 05:31:43 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2021-04-06 05:31:43 | INFO | train | epoch 058 | loss 4.504 | nll_loss 2.898 | ppl 7.46 | wps 87016.3 | ups 3 | wpb 28968.6 | bsz 947.1 | num_updates 275455 | lr 6.02524e-05 | gnorm 0.482 | loss_scale 2 | train_wall 1559 | gb_free 6.6 | wall 0
2021-04-06 05:31:43 | INFO | fairseq.trainer | begin training epoch 59
2021-04-06 05:31:43 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-06 05:31:59 | INFO | train_inner | epoch 059:     45 / 4751 loss=4.501, nll_loss=2.896, ppl=7.44, wps=59996.4, ups=2.07, wpb=28940.5, bsz=955.7, num_updates=275500, lr=6.02475e-05, gnorm=0.476, loss_scale=2, train_wall=32, gb_free=6.2, wall=0
2021-04-06 05:32:32 | INFO | train_inner | epoch 059:    145 / 4751 loss=4.476, nll_loss=2.866, ppl=7.29, wps=88186.2, ups=3.01, wpb=29311.3, bsz=940.6, num_updates=275600, lr=6.02366e-05, gnorm=0.477, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 05:33:05 | INFO | train_inner | epoch 059:    245 / 4751 loss=4.485, nll_loss=2.876, ppl=7.34, wps=87425.9, ups=3.03, wpb=28845.4, bsz=937.7, num_updates=275700, lr=6.02257e-05, gnorm=0.48, loss_scale=2, train_wall=33, gb_free=6.6, wall=0
2021-04-06 05:33:38 | INFO | train_inner | epoch 059:    345 / 4751 loss=4.46, nll_loss=2.848, ppl=7.2, wps=87980.3, ups=3.04, wpb=28954.4, bsz=995.6, num_updates=275800, lr=6.02147e-05, gnorm=0.479, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 05:34:11 | INFO | train_inner | epoch 059:    445 / 4751 loss=4.492, nll_loss=2.884, ppl=7.38, wps=87677.7, ups=3.04, wpb=28878.7, bsz=946.4, num_updates=275900, lr=6.02038e-05, gnorm=0.487, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-06 05:34:44 | INFO | train_inner | epoch 059:    545 / 4751 loss=4.473, nll_loss=2.863, ppl=7.28, wps=87953.4, ups=3.04, wpb=28917.2, bsz=951.6, num_updates=276000, lr=6.01929e-05, gnorm=0.485, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 05:35:17 | INFO | train_inner | epoch 059:    645 / 4751 loss=4.464, nll_loss=2.853, ppl=7.23, wps=87084.6, ups=3.01, wpb=28929.5, bsz=943.6, num_updates=276100, lr=6.0182e-05, gnorm=0.478, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-06 05:35:50 | INFO | train_inner | epoch 059:    745 / 4751 loss=4.556, nll_loss=2.957, ppl=7.76, wps=88483, ups=3.03, wpb=29154.5, bsz=926.4, num_updates=276200, lr=6.01711e-05, gnorm=0.486, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 05:36:23 | INFO | train_inner | epoch 059:    845 / 4751 loss=4.48, nll_loss=2.871, ppl=7.31, wps=88274.1, ups=3.05, wpb=28979.6, bsz=934.4, num_updates=276300, lr=6.01602e-05, gnorm=0.475, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 05:36:56 | INFO | train_inner | epoch 059:    945 / 4751 loss=4.453, nll_loss=2.841, ppl=7.16, wps=87774, ups=3.01, wpb=29129, bsz=953.8, num_updates=276400, lr=6.01494e-05, gnorm=0.476, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-06 05:37:30 | INFO | train_inner | epoch 059:   1045 / 4751 loss=4.531, nll_loss=2.929, ppl=7.61, wps=86975.4, ups=3, wpb=28980.9, bsz=969, num_updates=276500, lr=6.01385e-05, gnorm=0.487, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 05:38:03 | INFO | train_inner | epoch 059:   1145 / 4751 loss=4.528, nll_loss=2.925, ppl=7.59, wps=88011.7, ups=3.03, wpb=29023.8, bsz=967.1, num_updates=276600, lr=6.01276e-05, gnorm=0.487, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 05:38:36 | INFO | train_inner | epoch 059:   1245 / 4751 loss=4.517, nll_loss=2.912, ppl=7.53, wps=87220.8, ups=3.02, wpb=28870.5, bsz=918.1, num_updates=276700, lr=6.01167e-05, gnorm=0.476, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 05:39:09 | INFO | train_inner | epoch 059:   1345 / 4751 loss=4.488, nll_loss=2.88, ppl=7.36, wps=88126.2, ups=3.02, wpb=29178.5, bsz=944.7, num_updates=276800, lr=6.01059e-05, gnorm=0.479, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 05:39:42 | INFO | train_inner | epoch 059:   1445 / 4751 loss=4.496, nll_loss=2.889, ppl=7.41, wps=87701.6, ups=3.05, wpb=28727.7, bsz=939.4, num_updates=276900, lr=6.0095e-05, gnorm=0.506, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 05:40:14 | INFO | train_inner | epoch 059:   1545 / 4751 loss=4.558, nll_loss=2.958, ppl=7.77, wps=88324.1, ups=3.04, wpb=29065.8, bsz=903.2, num_updates=277000, lr=6.00842e-05, gnorm=0.483, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-06 05:40:47 | INFO | train_inner | epoch 059:   1645 / 4751 loss=4.498, nll_loss=2.892, ppl=7.42, wps=88192.9, ups=3.04, wpb=29045.8, bsz=905, num_updates=277100, lr=6.00733e-05, gnorm=0.478, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 05:41:21 | INFO | train_inner | epoch 059:   1745 / 4751 loss=4.557, nll_loss=2.958, ppl=7.77, wps=87200.6, ups=3.02, wpb=28854.8, bsz=899.8, num_updates=277200, lr=6.00625e-05, gnorm=0.483, loss_scale=4, train_wall=33, gb_free=6.4, wall=0
2021-04-06 05:41:53 | INFO | train_inner | epoch 059:   1845 / 4751 loss=4.501, nll_loss=2.895, ppl=7.44, wps=88459.5, ups=3.05, wpb=29047.6, bsz=928, num_updates=277300, lr=6.00517e-05, gnorm=0.479, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 05:42:26 | INFO | train_inner | epoch 059:   1945 / 4751 loss=4.526, nll_loss=2.923, ppl=7.58, wps=87045, ups=3.03, wpb=28745.3, bsz=940.1, num_updates=277400, lr=6.00408e-05, gnorm=0.487, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-06 05:42:59 | INFO | train_inner | epoch 059:   2045 / 4751 loss=4.483, nll_loss=2.874, ppl=7.33, wps=88077.6, ups=3.04, wpb=28991.9, bsz=1014.7, num_updates=277500, lr=6.003e-05, gnorm=0.488, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 05:43:33 | INFO | train_inner | epoch 059:   2145 / 4751 loss=4.425, nll_loss=2.809, ppl=7.01, wps=87103.8, ups=3.01, wpb=28963.2, bsz=961.6, num_updates=277600, lr=6.00192e-05, gnorm=0.473, loss_scale=4, train_wall=33, gb_free=6.4, wall=0
2021-04-06 05:44:05 | INFO | train_inner | epoch 059:   2245 / 4751 loss=4.453, nll_loss=2.841, ppl=7.17, wps=87932.2, ups=3.04, wpb=28944, bsz=958.4, num_updates=277700, lr=6.00084e-05, gnorm=0.475, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 05:44:38 | INFO | train_inner | epoch 059:   2345 / 4751 loss=4.499, nll_loss=2.893, ppl=7.43, wps=88099.7, ups=3.03, wpb=29061.3, bsz=964, num_updates=277800, lr=5.99976e-05, gnorm=0.483, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 05:45:11 | INFO | train_inner | epoch 059:   2445 / 4751 loss=4.516, nll_loss=2.912, ppl=7.53, wps=87804, ups=3.04, wpb=28844.4, bsz=963.4, num_updates=277900, lr=5.99868e-05, gnorm=0.492, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-06 05:45:44 | INFO | train_inner | epoch 059:   2545 / 4751 loss=4.48, nll_loss=2.871, ppl=7.32, wps=87165.4, ups=3.03, wpb=28810.2, bsz=939.1, num_updates=278000, lr=5.9976e-05, gnorm=0.481, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 05:46:17 | INFO | train_inner | epoch 059:   2645 / 4751 loss=4.495, nll_loss=2.889, ppl=7.41, wps=87578.9, ups=3.03, wpb=28888.1, bsz=935.9, num_updates=278100, lr=5.99652e-05, gnorm=0.48, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 05:46:50 | INFO | train_inner | epoch 059:   2745 / 4751 loss=4.502, nll_loss=2.896, ppl=7.44, wps=87979.7, ups=3.03, wpb=29017.4, bsz=968.1, num_updates=278200, lr=5.99545e-05, gnorm=0.482, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-06 05:47:23 | INFO | train_inner | epoch 059:   2845 / 4751 loss=4.482, nll_loss=2.874, ppl=7.33, wps=86800.4, ups=3.02, wpb=28754.8, bsz=935.4, num_updates=278300, lr=5.99437e-05, gnorm=0.484, loss_scale=4, train_wall=33, gb_free=6, wall=0
2021-04-06 05:47:56 | INFO | train_inner | epoch 059:   2945 / 4751 loss=4.549, nll_loss=2.949, ppl=7.72, wps=89247.5, ups=3.04, wpb=29329.9, bsz=957.2, num_updates=278400, lr=5.99329e-05, gnorm=0.474, loss_scale=4, train_wall=33, gb_free=6.7, wall=0
2021-04-06 05:48:29 | INFO | train_inner | epoch 059:   3045 / 4751 loss=4.545, nll_loss=2.944, ppl=7.7, wps=87499.2, ups=3.06, wpb=28640.3, bsz=915.8, num_updates=278500, lr=5.99222e-05, gnorm=0.485, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 05:49:02 | INFO | train_inner | epoch 059:   3145 / 4751 loss=4.503, nll_loss=2.897, ppl=7.45, wps=87822.3, ups=3.02, wpb=29091.3, bsz=953.2, num_updates=278600, lr=5.99114e-05, gnorm=0.48, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-06 05:49:35 | INFO | train_inner | epoch 059:   3245 / 4751 loss=4.563, nll_loss=2.965, ppl=7.81, wps=86687.3, ups=3.04, wpb=28508.6, bsz=957.1, num_updates=278700, lr=5.99006e-05, gnorm=0.493, loss_scale=4, train_wall=33, gb_free=6, wall=0
2021-04-06 05:50:08 | INFO | train_inner | epoch 059:   3345 / 4751 loss=4.539, nll_loss=2.938, ppl=7.67, wps=88499.7, ups=3.04, wpb=29064.1, bsz=953, num_updates=278800, lr=5.98899e-05, gnorm=0.485, loss_scale=4, train_wall=33, gb_free=6.6, wall=0
2021-04-06 05:50:41 | INFO | train_inner | epoch 059:   3445 / 4751 loss=4.568, nll_loss=2.971, ppl=7.84, wps=88404.6, ups=3.05, wpb=28998.1, bsz=941.4, num_updates=278900, lr=5.98792e-05, gnorm=0.484, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 05:51:14 | INFO | train_inner | epoch 059:   3545 / 4751 loss=4.501, nll_loss=2.895, ppl=7.44, wps=87527.1, ups=3.04, wpb=28837.7, bsz=947.8, num_updates=279000, lr=5.98684e-05, gnorm=0.486, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-06 05:51:47 | INFO | train_inner | epoch 059:   3645 / 4751 loss=4.462, nll_loss=2.851, ppl=7.21, wps=86127.1, ups=2.96, wpb=29084.3, bsz=984.3, num_updates=279100, lr=5.98577e-05, gnorm=0.475, loss_scale=8, train_wall=34, gb_free=6.5, wall=0
2021-04-06 05:52:20 | INFO | train_inner | epoch 059:   3745 / 4751 loss=4.514, nll_loss=2.91, ppl=7.52, wps=87381.1, ups=3.03, wpb=28878.4, bsz=942.6, num_updates=279200, lr=5.9847e-05, gnorm=0.483, loss_scale=8, train_wall=33, gb_free=6.4, wall=0
2021-04-06 05:52:54 | INFO | train_inner | epoch 059:   3845 / 4751 loss=4.473, nll_loss=2.864, ppl=7.28, wps=87105.8, ups=3.03, wpb=28789.4, bsz=983.8, num_updates=279300, lr=5.98363e-05, gnorm=0.48, loss_scale=8, train_wall=33, gb_free=6.1, wall=0
2021-04-06 05:53:26 | INFO | train_inner | epoch 059:   3945 / 4751 loss=4.514, nll_loss=2.91, ppl=7.51, wps=89077.8, ups=3.05, wpb=29244.2, bsz=935.6, num_updates=279400, lr=5.98256e-05, gnorm=0.477, loss_scale=8, train_wall=33, gb_free=6.4, wall=0
2021-04-06 05:53:59 | INFO | train_inner | epoch 059:   4045 / 4751 loss=4.53, nll_loss=2.927, ppl=7.61, wps=87512, ups=3.03, wpb=28907.9, bsz=938.4, num_updates=279500, lr=5.98149e-05, gnorm=0.487, loss_scale=8, train_wall=33, gb_free=6.2, wall=0
2021-04-06 05:54:32 | INFO | train_inner | epoch 059:   4145 / 4751 loss=4.442, nll_loss=2.828, ppl=7.1, wps=88018.1, ups=3.02, wpb=29151.2, bsz=974.6, num_updates=279600, lr=5.98042e-05, gnorm=0.483, loss_scale=8, train_wall=33, gb_free=6.4, wall=0
2021-04-06 05:55:05 | INFO | train_inner | epoch 059:   4245 / 4751 loss=4.481, nll_loss=2.872, ppl=7.32, wps=88171.7, ups=3.04, wpb=28983.1, bsz=942, num_updates=279700, lr=5.97935e-05, gnorm=0.479, loss_scale=8, train_wall=33, gb_free=6.3, wall=0
2021-04-06 05:55:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2021-04-06 05:55:38 | INFO | train_inner | epoch 059:   4346 / 4751 loss=4.555, nll_loss=2.957, ppl=7.76, wps=88202.9, ups=3.02, wpb=29194.2, bsz=932, num_updates=279800, lr=5.97828e-05, gnorm=0.479, loss_scale=4, train_wall=33, gb_free=6.4, wall=0
2021-04-06 05:56:11 | INFO | train_inner | epoch 059:   4446 / 4751 loss=4.502, nll_loss=2.896, ppl=7.45, wps=88441.1, ups=3.04, wpb=29048.9, bsz=950.6, num_updates=279900, lr=5.97721e-05, gnorm=0.48, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-06 05:56:44 | INFO | train_inner | epoch 059:   4546 / 4751 loss=4.494, nll_loss=2.887, ppl=7.4, wps=87283, ups=3.03, wpb=28851.9, bsz=950.7, num_updates=280000, lr=5.97614e-05, gnorm=0.479, loss_scale=4, train_wall=33, gb_free=6, wall=0
2021-04-06 05:57:17 | INFO | train_inner | epoch 059:   4646 / 4751 loss=4.522, nll_loss=2.919, ppl=7.57, wps=88428.6, ups=3.04, wpb=29133.7, bsz=944.6, num_updates=280100, lr=5.97508e-05, gnorm=0.482, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-06 05:57:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-06 05:57:51 | INFO | train_inner | epoch 059:   4747 / 4751 loss=4.512, nll_loss=2.907, ppl=7.5, wps=86611.9, ups=2.99, wpb=28973.5, bsz=944.2, num_updates=280200, lr=5.97401e-05, gnorm=0.481, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-06 05:57:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-06 05:57:53 | INFO | valid | epoch 059 | valid on 'valid' subset | loss 4.15 | nll_loss 2.38 | ppl 5.2 | wps 178372 | wpb 10489.1 | bsz 375 | num_updates 280204 | best_loss 4.14
2021-04-06 05:57:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 59 @ 280204 updates
2021-04-06 05:57:53 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-06 05:58:00 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-06 05:58:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt (epoch 59 @ 280204 updates, score 4.15) (writing took 6.365451741963625 seconds)
2021-04-06 05:58:00 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)
2021-04-06 05:58:00 | INFO | train | epoch 059 | loss 4.503 | nll_loss 2.897 | ppl 7.45 | wps 87262.2 | ups 3.01 | wpb 28968.5 | bsz 947.2 | num_updates 280204 | lr 5.97397e-05 | gnorm 0.482 | loss_scale 2 | train_wall 1561 | gb_free 7.7 | wall 0
2021-04-06 05:58:00 | INFO | fairseq.trainer | begin training epoch 60
2021-04-06 05:58:00 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-06 05:58:32 | INFO | train_inner | epoch 060:     96 / 4751 loss=4.433, nll_loss=2.818, ppl=7.05, wps=69195.3, ups=2.4, wpb=28782.2, bsz=935.6, num_updates=280300, lr=5.97294e-05, gnorm=0.485, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 05:59:05 | INFO | train_inner | epoch 060:    196 / 4751 loss=4.487, nll_loss=2.878, ppl=7.35, wps=88336.7, ups=3.05, wpb=28999.2, bsz=929.9, num_updates=280400, lr=5.97188e-05, gnorm=0.477, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 05:59:38 | INFO | train_inner | epoch 060:    296 / 4751 loss=4.524, nll_loss=2.921, ppl=7.57, wps=86881.9, ups=3.03, wpb=28704.1, bsz=945.6, num_updates=280500, lr=5.97081e-05, gnorm=0.485, loss_scale=2, train_wall=33, gb_free=6.8, wall=0
2021-04-06 06:00:11 | INFO | train_inner | epoch 060:    396 / 4751 loss=4.552, nll_loss=2.952, ppl=7.74, wps=87772.3, ups=3.05, wpb=28809.2, bsz=939, num_updates=280600, lr=5.96975e-05, gnorm=0.488, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 06:00:44 | INFO | train_inner | epoch 060:    496 / 4751 loss=4.498, nll_loss=2.891, ppl=7.42, wps=87489.9, ups=3.02, wpb=28998.8, bsz=982.4, num_updates=280700, lr=5.96869e-05, gnorm=0.481, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 06:01:17 | INFO | train_inner | epoch 060:    596 / 4751 loss=4.473, nll_loss=2.863, ppl=7.28, wps=87215.1, ups=3.04, wpb=28679.4, bsz=969.6, num_updates=280800, lr=5.96762e-05, gnorm=0.483, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 06:01:50 | INFO | train_inner | epoch 060:    696 / 4751 loss=4.479, nll_loss=2.87, ppl=7.31, wps=87704.3, ups=3.04, wpb=28869, bsz=957, num_updates=280900, lr=5.96656e-05, gnorm=0.48, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 06:02:23 | INFO | train_inner | epoch 060:    796 / 4751 loss=4.485, nll_loss=2.877, ppl=7.34, wps=87754.4, ups=3.05, wpb=28800.7, bsz=941.2, num_updates=281000, lr=5.9655e-05, gnorm=0.477, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 06:02:56 | INFO | train_inner | epoch 060:    896 / 4751 loss=4.54, nll_loss=2.939, ppl=7.67, wps=88432.6, ups=3.03, wpb=29165.8, bsz=944.2, num_updates=281100, lr=5.96444e-05, gnorm=0.486, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 06:03:29 | INFO | train_inner | epoch 060:    996 / 4751 loss=4.519, nll_loss=2.915, ppl=7.54, wps=87477.2, ups=3.04, wpb=28814.5, bsz=954.6, num_updates=281200, lr=5.96338e-05, gnorm=0.487, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 06:04:02 | INFO | train_inner | epoch 060:   1096 / 4751 loss=4.426, nll_loss=2.809, ppl=7.01, wps=88639.4, ups=3.04, wpb=29161.8, bsz=925.4, num_updates=281300, lr=5.96232e-05, gnorm=0.475, loss_scale=2, train_wall=33, gb_free=6.6, wall=0
2021-04-06 06:04:35 | INFO | train_inner | epoch 060:   1196 / 4751 loss=4.597, nll_loss=3.003, ppl=8.02, wps=86719.4, ups=3.03, wpb=28666.6, bsz=921.2, num_updates=281400, lr=5.96126e-05, gnorm=0.499, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-06 06:05:07 | INFO | train_inner | epoch 060:   1296 / 4751 loss=4.565, nll_loss=2.967, ppl=7.82, wps=88702.6, ups=3.06, wpb=28985.3, bsz=915.1, num_updates=281500, lr=5.9602e-05, gnorm=0.488, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 06:05:40 | INFO | train_inner | epoch 060:   1396 / 4751 loss=4.555, nll_loss=2.956, ppl=7.76, wps=87119.9, ups=3.04, wpb=28661.9, bsz=924.1, num_updates=281600, lr=5.95914e-05, gnorm=0.485, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 06:06:13 | INFO | train_inner | epoch 060:   1496 / 4751 loss=4.416, nll_loss=2.799, ppl=6.96, wps=87837.6, ups=3.03, wpb=29015.2, bsz=956, num_updates=281700, lr=5.95808e-05, gnorm=0.478, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 06:06:46 | INFO | train_inner | epoch 060:   1596 / 4751 loss=4.46, nll_loss=2.849, ppl=7.2, wps=88029.6, ups=3.03, wpb=29024.8, bsz=975.2, num_updates=281800, lr=5.95703e-05, gnorm=0.476, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 06:07:19 | INFO | train_inner | epoch 060:   1696 / 4751 loss=4.511, nll_loss=2.906, ppl=7.5, wps=88928.8, ups=3.05, wpb=29136.9, bsz=926.5, num_updates=281900, lr=5.95597e-05, gnorm=0.486, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 06:07:52 | INFO | train_inner | epoch 060:   1796 / 4751 loss=4.499, nll_loss=2.893, ppl=7.43, wps=88349.3, ups=3.04, wpb=29065.2, bsz=979.9, num_updates=282000, lr=5.95491e-05, gnorm=0.488, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 06:08:25 | INFO | train_inner | epoch 060:   1896 / 4751 loss=4.502, nll_loss=2.896, ppl=7.44, wps=87900, ups=3.03, wpb=29033.8, bsz=916.1, num_updates=282100, lr=5.95386e-05, gnorm=0.483, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 06:08:58 | INFO | train_inner | epoch 060:   1996 / 4751 loss=4.519, nll_loss=2.915, ppl=7.54, wps=88121.2, ups=3.04, wpb=28943, bsz=946.7, num_updates=282200, lr=5.9528e-05, gnorm=0.485, loss_scale=4, train_wall=33, gb_free=6.6, wall=0
2021-04-06 06:09:31 | INFO | train_inner | epoch 060:   2096 / 4751 loss=4.508, nll_loss=2.903, ppl=7.48, wps=86991.8, ups=3, wpb=28982.8, bsz=959.4, num_updates=282300, lr=5.95175e-05, gnorm=0.481, loss_scale=4, train_wall=33, gb_free=6.8, wall=0
2021-04-06 06:10:04 | INFO | train_inner | epoch 060:   2196 / 4751 loss=4.507, nll_loss=2.902, ppl=7.47, wps=87885.6, ups=3.02, wpb=29091.7, bsz=952.2, num_updates=282400, lr=5.95069e-05, gnorm=0.486, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-06 06:10:37 | INFO | train_inner | epoch 060:   2296 / 4751 loss=4.47, nll_loss=2.86, ppl=7.26, wps=87415.8, ups=3.02, wpb=28988.1, bsz=983.4, num_updates=282500, lr=5.94964e-05, gnorm=0.479, loss_scale=4, train_wall=33, gb_free=6.4, wall=0
2021-04-06 06:11:10 | INFO | train_inner | epoch 060:   2396 / 4751 loss=4.511, nll_loss=2.906, ppl=7.5, wps=87016.6, ups=3.02, wpb=28801.7, bsz=940.2, num_updates=282600, lr=5.94859e-05, gnorm=0.486, loss_scale=4, train_wall=33, gb_free=6.4, wall=0
2021-04-06 06:11:44 | INFO | train_inner | epoch 060:   2496 / 4751 loss=4.442, nll_loss=2.828, ppl=7.1, wps=87438.3, ups=3.02, wpb=28954.5, bsz=979, num_updates=282700, lr=5.94754e-05, gnorm=0.492, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-06 06:12:17 | INFO | train_inner | epoch 060:   2596 / 4751 loss=4.489, nll_loss=2.881, ppl=7.37, wps=87391.4, ups=3.03, wpb=28817.4, bsz=968.6, num_updates=282800, lr=5.94648e-05, gnorm=0.485, loss_scale=4, train_wall=33, gb_free=5.9, wall=0
2021-04-06 06:12:43 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-06 06:12:50 | INFO | train_inner | epoch 060:   2697 / 4751 loss=4.507, nll_loss=2.902, ppl=7.47, wps=87819.9, ups=3.04, wpb=28934.6, bsz=940.6, num_updates=282900, lr=5.94543e-05, gnorm=0.478, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-06 06:13:23 | INFO | train_inner | epoch 060:   2797 / 4751 loss=4.456, nll_loss=2.844, ppl=7.18, wps=87771.5, ups=3.02, wpb=29045, bsz=926.6, num_updates=283000, lr=5.94438e-05, gnorm=0.476, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 06:13:56 | INFO | train_inner | epoch 060:   2897 / 4751 loss=4.49, nll_loss=2.883, ppl=7.38, wps=87162.2, ups=3.03, wpb=28755.7, bsz=932, num_updates=283100, lr=5.94333e-05, gnorm=0.487, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-06 06:14:29 | INFO | train_inner | epoch 060:   2997 / 4751 loss=4.541, nll_loss=2.941, ppl=7.68, wps=88079.3, ups=3.02, wpb=29117.9, bsz=935.9, num_updates=283200, lr=5.94228e-05, gnorm=0.479, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 06:15:02 | INFO | train_inner | epoch 060:   3097 / 4751 loss=4.519, nll_loss=2.915, ppl=7.54, wps=85457, ups=2.98, wpb=28656.3, bsz=963.1, num_updates=283300, lr=5.94123e-05, gnorm=0.485, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 06:15:35 | INFO | train_inner | epoch 060:   3197 / 4751 loss=4.546, nll_loss=2.945, ppl=7.7, wps=88585, ups=3.05, wpb=29057.2, bsz=907.9, num_updates=283400, lr=5.94019e-05, gnorm=0.492, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 06:16:08 | INFO | train_inner | epoch 060:   3297 / 4751 loss=4.493, nll_loss=2.886, ppl=7.39, wps=88985.5, ups=3.04, wpb=29296, bsz=968.3, num_updates=283500, lr=5.93914e-05, gnorm=0.474, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 06:16:41 | INFO | train_inner | epoch 060:   3397 / 4751 loss=4.473, nll_loss=2.863, ppl=7.28, wps=88930.8, ups=3.03, wpb=29362.9, bsz=958.4, num_updates=283600, lr=5.93809e-05, gnorm=0.47, loss_scale=2, train_wall=33, gb_free=6.6, wall=0
2021-04-06 06:17:14 | INFO | train_inner | epoch 060:   3497 / 4751 loss=4.5, nll_loss=2.894, ppl=7.43, wps=88132.9, ups=3.03, wpb=29065.6, bsz=956.1, num_updates=283700, lr=5.93704e-05, gnorm=0.488, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 06:17:47 | INFO | train_inner | epoch 060:   3597 / 4751 loss=4.562, nll_loss=2.964, ppl=7.8, wps=87815.9, ups=3.03, wpb=28975.3, bsz=927.5, num_updates=283800, lr=5.936e-05, gnorm=0.48, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 06:18:20 | INFO | train_inner | epoch 060:   3697 / 4751 loss=4.526, nll_loss=2.923, ppl=7.59, wps=88287.4, ups=3.04, wpb=29010, bsz=973.6, num_updates=283900, lr=5.93495e-05, gnorm=0.482, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-06 06:18:53 | INFO | train_inner | epoch 060:   3797 / 4751 loss=4.472, nll_loss=2.862, ppl=7.27, wps=87640.6, ups=3.04, wpb=28875.7, bsz=929.1, num_updates=284000, lr=5.93391e-05, gnorm=0.485, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 06:19:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-04-06 06:19:26 | INFO | train_inner | epoch 060:   3898 / 4751 loss=4.489, nll_loss=2.881, ppl=7.37, wps=87570.9, ups=3.01, wpb=29079.9, bsz=953.6, num_updates=284100, lr=5.93286e-05, gnorm=0.486, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 06:19:59 | INFO | train_inner | epoch 060:   3998 / 4751 loss=4.488, nll_loss=2.88, ppl=7.36, wps=88332.2, ups=3.03, wpb=29189.4, bsz=946.7, num_updates=284200, lr=5.93182e-05, gnorm=0.481, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 06:20:32 | INFO | train_inner | epoch 060:   4098 / 4751 loss=4.471, nll_loss=2.861, ppl=7.27, wps=88442.7, ups=3.04, wpb=29115.7, bsz=972.8, num_updates=284300, lr=5.93078e-05, gnorm=0.484, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 06:21:05 | INFO | train_inner | epoch 060:   4198 / 4751 loss=4.503, nll_loss=2.898, ppl=7.45, wps=87518.9, ups=3.02, wpb=28962.4, bsz=943.9, num_updates=284400, lr=5.92973e-05, gnorm=0.481, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 06:21:38 | INFO | train_inner | epoch 060:   4298 / 4751 loss=4.555, nll_loss=2.957, ppl=7.76, wps=87262.8, ups=3.04, wpb=28691.1, bsz=951.1, num_updates=284500, lr=5.92869e-05, gnorm=0.495, loss_scale=1, train_wall=33, gb_free=6, wall=0
2021-04-06 06:22:11 | INFO | train_inner | epoch 060:   4398 / 4751 loss=4.472, nll_loss=2.862, ppl=7.27, wps=87849.1, ups=3.01, wpb=29157.3, bsz=932.1, num_updates=284600, lr=5.92765e-05, gnorm=0.478, loss_scale=1, train_wall=33, gb_free=7, wall=0
2021-04-06 06:22:44 | INFO | train_inner | epoch 060:   4498 / 4751 loss=4.516, nll_loss=2.912, ppl=7.53, wps=88247.6, ups=3.03, wpb=29157.5, bsz=920.3, num_updates=284700, lr=5.92661e-05, gnorm=0.481, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 06:23:17 | INFO | train_inner | epoch 060:   4598 / 4751 loss=4.497, nll_loss=2.891, ppl=7.42, wps=87281.2, ups=3.02, wpb=28875.2, bsz=954.1, num_updates=284800, lr=5.92557e-05, gnorm=0.488, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 06:23:50 | INFO | train_inner | epoch 060:   4698 / 4751 loss=4.508, nll_loss=2.903, ppl=7.48, wps=88927, ups=3.04, wpb=29240, bsz=924.5, num_updates=284900, lr=5.92453e-05, gnorm=0.487, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 06:24:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-06 06:24:09 | INFO | valid | epoch 060 | valid on 'valid' subset | loss 4.145 | nll_loss 2.375 | ppl 5.19 | wps 200666 | wpb 10489.1 | bsz 375 | num_updates 284953 | best_loss 4.14
2021-04-06 06:24:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 60 @ 284953 updates
2021-04-06 06:24:09 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-06 06:24:15 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-06 06:24:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt (epoch 60 @ 284953 updates, score 4.145) (writing took 6.1275746412575245 seconds)
2021-04-06 06:24:15 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)
2021-04-06 06:24:15 | INFO | train | epoch 060 | loss 4.501 | nll_loss 2.895 | ppl 7.44 | wps 87342.1 | ups 3.01 | wpb 28969.5 | bsz 946.7 | num_updates 284953 | lr 5.92398e-05 | gnorm 0.483 | loss_scale 1 | train_wall 1560 | gb_free 6.2 | wall 0
2021-04-06 06:24:15 | INFO | fairseq.trainer | begin training epoch 61
2021-04-06 06:24:15 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-06 06:24:31 | INFO | train_inner | epoch 061:     47 / 4751 loss=4.497, nll_loss=2.89, ppl=7.41, wps=69238.7, ups=2.41, wpb=28673.7, bsz=952, num_updates=285000, lr=5.92349e-05, gnorm=0.489, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 06:25:04 | INFO | train_inner | epoch 061:    147 / 4751 loss=4.468, nll_loss=2.857, ppl=7.25, wps=88422.3, ups=3.06, wpb=28936.5, bsz=952.5, num_updates=285100, lr=5.92245e-05, gnorm=0.482, loss_scale=1, train_wall=33, gb_free=6, wall=0
2021-04-06 06:25:37 | INFO | train_inner | epoch 061:    247 / 4751 loss=4.468, nll_loss=2.857, ppl=7.25, wps=88414, ups=3.04, wpb=29039.9, bsz=933.1, num_updates=285200, lr=5.92141e-05, gnorm=0.472, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 06:26:10 | INFO | train_inner | epoch 061:    347 / 4751 loss=4.493, nll_loss=2.886, ppl=7.39, wps=89065.5, ups=3.04, wpb=29310.8, bsz=954.8, num_updates=285300, lr=5.92037e-05, gnorm=0.489, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 06:26:43 | INFO | train_inner | epoch 061:    447 / 4751 loss=4.479, nll_loss=2.87, ppl=7.31, wps=87442.4, ups=3.02, wpb=28942, bsz=956.5, num_updates=285400, lr=5.91934e-05, gnorm=0.484, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 06:27:16 | INFO | train_inner | epoch 061:    547 / 4751 loss=4.543, nll_loss=2.942, ppl=7.68, wps=87741.7, ups=3.04, wpb=28889.1, bsz=935.9, num_updates=285500, lr=5.9183e-05, gnorm=0.483, loss_scale=1, train_wall=33, gb_free=6.4, wall=0
2021-04-06 06:27:49 | INFO | train_inner | epoch 061:    647 / 4751 loss=4.507, nll_loss=2.901, ppl=7.47, wps=89377.3, ups=3.07, wpb=29102.6, bsz=923.4, num_updates=285600, lr=5.91726e-05, gnorm=0.482, loss_scale=1, train_wall=32, gb_free=6.2, wall=0
2021-04-06 06:28:21 | INFO | train_inner | epoch 061:    747 / 4751 loss=4.528, nll_loss=2.925, ppl=7.59, wps=87450.2, ups=3.05, wpb=28669.2, bsz=932.6, num_updates=285700, lr=5.91623e-05, gnorm=0.485, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 06:28:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
2021-04-06 06:28:55 | INFO | train_inner | epoch 061:    848 / 4751 loss=4.467, nll_loss=2.857, ppl=7.24, wps=86382.9, ups=3, wpb=28799.2, bsz=953.4, num_updates=285800, lr=5.91519e-05, gnorm=0.484, loss_scale=0.5, train_wall=33, gb_free=6.3, wall=0
2021-04-06 06:29:27 | INFO | train_inner | epoch 061:    948 / 4751 loss=4.511, nll_loss=2.906, ppl=7.49, wps=90037.4, ups=3.05, wpb=29485, bsz=948.8, num_updates=285900, lr=5.91416e-05, gnorm=0.476, loss_scale=0.5, train_wall=33, gb_free=6.3, wall=0
2021-04-06 06:30:00 | INFO | train_inner | epoch 061:   1048 / 4751 loss=4.513, nll_loss=2.908, ppl=7.5, wps=88091.3, ups=3.04, wpb=29003.5, bsz=913.5, num_updates=286000, lr=5.91312e-05, gnorm=0.487, loss_scale=0.5, train_wall=33, gb_free=6.4, wall=0
2021-04-06 06:30:33 | INFO | train_inner | epoch 061:   1148 / 4751 loss=4.481, nll_loss=2.872, ppl=7.32, wps=87848.1, ups=3.04, wpb=28909.5, bsz=932.5, num_updates=286100, lr=5.91209e-05, gnorm=0.482, loss_scale=0.5, train_wall=33, gb_free=6.1, wall=0
2021-04-06 06:31:06 | INFO | train_inner | epoch 061:   1248 / 4751 loss=4.467, nll_loss=2.856, ppl=7.24, wps=88550.9, ups=3.05, wpb=29016.9, bsz=968, num_updates=286200, lr=5.91106e-05, gnorm=0.478, loss_scale=0.5, train_wall=33, gb_free=6.2, wall=0
2021-04-06 06:31:39 | INFO | train_inner | epoch 061:   1348 / 4751 loss=4.502, nll_loss=2.896, ppl=7.44, wps=88273.7, ups=3.03, wpb=29131.6, bsz=959.6, num_updates=286300, lr=5.91003e-05, gnorm=0.483, loss_scale=0.5, train_wall=33, gb_free=6.2, wall=0
2021-04-06 06:32:12 | INFO | train_inner | epoch 061:   1448 / 4751 loss=4.465, nll_loss=2.854, ppl=7.23, wps=88436.4, ups=3.05, wpb=28987.4, bsz=960, num_updates=286400, lr=5.90899e-05, gnorm=0.478, loss_scale=0.5, train_wall=33, gb_free=6.3, wall=0
2021-04-06 06:32:45 | INFO | train_inner | epoch 061:   1548 / 4751 loss=4.525, nll_loss=2.922, ppl=7.58, wps=88857.5, ups=3.05, wpb=29118.3, bsz=920.1, num_updates=286500, lr=5.90796e-05, gnorm=0.488, loss_scale=0.5, train_wall=33, gb_free=6.1, wall=0
2021-04-06 06:33:17 | INFO | train_inner | epoch 061:   1648 / 4751 loss=4.469, nll_loss=2.859, ppl=7.25, wps=87332.5, ups=3.04, wpb=28720.4, bsz=950.9, num_updates=286600, lr=5.90693e-05, gnorm=0.497, loss_scale=0.5, train_wall=33, gb_free=6.3, wall=0
2021-04-06 06:33:50 | INFO | train_inner | epoch 061:   1748 / 4751 loss=4.54, nll_loss=2.939, ppl=7.67, wps=87746.9, ups=3.03, wpb=28929.1, bsz=937.8, num_updates=286700, lr=5.9059e-05, gnorm=0.486, loss_scale=0.5, train_wall=33, gb_free=6.2, wall=0
2021-04-06 06:34:24 | INFO | train_inner | epoch 061:   1848 / 4751 loss=4.436, nll_loss=2.821, ppl=7.07, wps=86946.1, ups=3.02, wpb=28793, bsz=957, num_updates=286800, lr=5.90487e-05, gnorm=0.474, loss_scale=0.5, train_wall=33, gb_free=6.2, wall=0
2021-04-06 06:34:56 | INFO | train_inner | epoch 061:   1948 / 4751 loss=4.489, nll_loss=2.881, ppl=7.37, wps=87806.9, ups=3.04, wpb=28856.9, bsz=970.8, num_updates=286900, lr=5.90384e-05, gnorm=0.487, loss_scale=0.5, train_wall=33, gb_free=6, wall=0
2021-04-06 06:35:29 | INFO | train_inner | epoch 061:   2048 / 4751 loss=4.561, nll_loss=2.962, ppl=7.79, wps=87427.9, ups=3.04, wpb=28799.1, bsz=924.8, num_updates=287000, lr=5.90281e-05, gnorm=0.492, loss_scale=0.5, train_wall=33, gb_free=6.1, wall=0
2021-04-06 06:36:02 | INFO | train_inner | epoch 061:   2148 / 4751 loss=4.507, nll_loss=2.902, ppl=7.47, wps=86583.5, ups=3.02, wpb=28650.8, bsz=912.4, num_updates=287100, lr=5.90179e-05, gnorm=0.481, loss_scale=0.5, train_wall=33, gb_free=6.1, wall=0
2021-04-06 06:36:36 | INFO | train_inner | epoch 061:   2248 / 4751 loss=4.491, nll_loss=2.884, ppl=7.38, wps=87294.3, ups=3.01, wpb=28976.4, bsz=944.9, num_updates=287200, lr=5.90076e-05, gnorm=0.486, loss_scale=0.5, train_wall=33, gb_free=6.4, wall=0
2021-04-06 06:37:08 | INFO | train_inner | epoch 061:   2348 / 4751 loss=4.525, nll_loss=2.922, ppl=7.58, wps=88311.9, ups=3.05, wpb=28942.8, bsz=919.8, num_updates=287300, lr=5.89973e-05, gnorm=0.482, loss_scale=0.5, train_wall=33, gb_free=6.4, wall=0
2021-04-06 06:37:42 | INFO | train_inner | epoch 061:   2448 / 4751 loss=4.477, nll_loss=2.867, ppl=7.3, wps=87019.2, ups=3.02, wpb=28793.5, bsz=948.7, num_updates=287400, lr=5.8987e-05, gnorm=0.483, loss_scale=0.5, train_wall=33, gb_free=5.9, wall=0
2021-04-06 06:38:15 | INFO | train_inner | epoch 061:   2548 / 4751 loss=4.503, nll_loss=2.897, ppl=7.45, wps=87333.1, ups=3.02, wpb=28924.3, bsz=954.9, num_updates=287500, lr=5.89768e-05, gnorm=0.479, loss_scale=0.5, train_wall=33, gb_free=6.3, wall=0
2021-04-06 06:38:48 | INFO | train_inner | epoch 061:   2648 / 4751 loss=4.487, nll_loss=2.88, ppl=7.36, wps=88010.9, ups=3.04, wpb=28979.1, bsz=975.6, num_updates=287600, lr=5.89665e-05, gnorm=0.48, loss_scale=0.5, train_wall=33, gb_free=6.2, wall=0
2021-04-06 06:39:20 | INFO | train_inner | epoch 061:   2748 / 4751 loss=4.513, nll_loss=2.909, ppl=7.51, wps=88694.3, ups=3.04, wpb=29186.7, bsz=916.4, num_updates=287700, lr=5.89563e-05, gnorm=0.479, loss_scale=0.5, train_wall=33, gb_free=6.7, wall=0
2021-04-06 06:39:54 | INFO | train_inner | epoch 061:   2848 / 4751 loss=4.522, nll_loss=2.919, ppl=7.56, wps=87081.8, ups=3.02, wpb=28832.2, bsz=932.5, num_updates=287800, lr=5.8946e-05, gnorm=0.489, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 06:40:27 | INFO | train_inner | epoch 061:   2948 / 4751 loss=4.564, nll_loss=2.966, ppl=7.81, wps=87060.3, ups=3.03, wpb=28742.6, bsz=939.5, num_updates=287900, lr=5.89358e-05, gnorm=0.517, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 06:40:59 | INFO | train_inner | epoch 061:   3048 / 4751 loss=4.564, nll_loss=2.966, ppl=7.82, wps=88022.4, ups=3.05, wpb=28836.9, bsz=956.6, num_updates=288000, lr=5.89256e-05, gnorm=0.484, loss_scale=1, train_wall=33, gb_free=6.4, wall=0
2021-04-06 06:41:32 | INFO | train_inner | epoch 061:   3148 / 4751 loss=4.523, nll_loss=2.92, ppl=7.57, wps=88484.5, ups=3.05, wpb=29049.9, bsz=934.4, num_updates=288100, lr=5.89153e-05, gnorm=0.488, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 06:42:05 | INFO | train_inner | epoch 061:   3248 / 4751 loss=4.528, nll_loss=2.926, ppl=7.6, wps=87369.4, ups=3.04, wpb=28701, bsz=946.1, num_updates=288200, lr=5.89051e-05, gnorm=0.486, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 06:42:39 | INFO | train_inner | epoch 061:   3348 / 4751 loss=4.487, nll_loss=2.88, ppl=7.36, wps=86608.9, ups=2.97, wpb=29169.2, bsz=985.7, num_updates=288300, lr=5.88949e-05, gnorm=0.483, loss_scale=1, train_wall=34, gb_free=6.4, wall=0
2021-04-06 06:43:12 | INFO | train_inner | epoch 061:   3448 / 4751 loss=4.482, nll_loss=2.874, ppl=7.33, wps=88534.9, ups=3.04, wpb=29108.3, bsz=977.8, num_updates=288400, lr=5.88847e-05, gnorm=0.49, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 06:43:45 | INFO | train_inner | epoch 061:   3548 / 4751 loss=4.49, nll_loss=2.883, ppl=7.38, wps=88277.2, ups=3.03, wpb=29141.1, bsz=959.7, num_updates=288500, lr=5.88745e-05, gnorm=0.478, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 06:44:17 | INFO | train_inner | epoch 061:   3648 / 4751 loss=4.497, nll_loss=2.891, ppl=7.42, wps=88460.9, ups=3.05, wpb=28978.6, bsz=932.8, num_updates=288600, lr=5.88643e-05, gnorm=0.482, loss_scale=1, train_wall=33, gb_free=6.4, wall=0
2021-04-06 06:44:50 | INFO | train_inner | epoch 061:   3748 / 4751 loss=4.463, nll_loss=2.853, ppl=7.22, wps=87871.7, ups=3.04, wpb=28952.2, bsz=957.6, num_updates=288700, lr=5.88541e-05, gnorm=0.478, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 06:45:23 | INFO | train_inner | epoch 061:   3848 / 4751 loss=4.47, nll_loss=2.86, ppl=7.26, wps=88502.9, ups=3.03, wpb=29165.8, bsz=962.5, num_updates=288800, lr=5.88439e-05, gnorm=0.482, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 06:45:56 | INFO | train_inner | epoch 061:   3948 / 4751 loss=4.445, nll_loss=2.832, ppl=7.12, wps=87943.3, ups=3.01, wpb=29191.2, bsz=937.9, num_updates=288900, lr=5.88337e-05, gnorm=0.479, loss_scale=1, train_wall=33, gb_free=6.5, wall=0
2021-04-06 06:46:29 | INFO | train_inner | epoch 061:   4048 / 4751 loss=4.548, nll_loss=2.949, ppl=7.72, wps=87597.8, ups=3.05, wpb=28715.9, bsz=969.8, num_updates=289000, lr=5.88235e-05, gnorm=0.488, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 06:47:02 | INFO | train_inner | epoch 061:   4148 / 4751 loss=4.504, nll_loss=2.898, ppl=7.45, wps=88372.5, ups=3.04, wpb=29114.6, bsz=927.7, num_updates=289100, lr=5.88134e-05, gnorm=0.491, loss_scale=1, train_wall=33, gb_free=6, wall=0
2021-04-06 06:47:35 | INFO | train_inner | epoch 061:   4248 / 4751 loss=4.508, nll_loss=2.903, ppl=7.48, wps=88297.3, ups=3.03, wpb=29137.8, bsz=958, num_updates=289200, lr=5.88032e-05, gnorm=0.486, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 06:48:08 | INFO | train_inner | epoch 061:   4348 / 4751 loss=4.483, nll_loss=2.875, ppl=7.34, wps=87679.8, ups=3.02, wpb=28986.7, bsz=951.4, num_updates=289300, lr=5.8793e-05, gnorm=0.479, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 06:48:41 | INFO | train_inner | epoch 061:   4448 / 4751 loss=4.485, nll_loss=2.877, ppl=7.35, wps=88352, ups=3.04, wpb=29045.9, bsz=934.6, num_updates=289400, lr=5.87829e-05, gnorm=0.487, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 06:49:14 | INFO | train_inner | epoch 061:   4548 / 4751 loss=4.466, nll_loss=2.855, ppl=7.24, wps=88127, ups=3.03, wpb=29098.9, bsz=984.3, num_updates=289500, lr=5.87727e-05, gnorm=0.485, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 06:49:47 | INFO | train_inner | epoch 061:   4648 / 4751 loss=4.528, nll_loss=2.926, ppl=7.6, wps=87935.5, ups=3.04, wpb=28902.6, bsz=954.9, num_updates=289600, lr=5.87626e-05, gnorm=0.494, loss_scale=1, train_wall=33, gb_free=6, wall=0
2021-04-06 06:50:20 | INFO | train_inner | epoch 061:   4748 / 4751 loss=4.51, nll_loss=2.905, ppl=7.49, wps=88414.6, ups=3.04, wpb=29074.9, bsz=939.8, num_updates=289700, lr=5.87524e-05, gnorm=0.486, loss_scale=1, train_wall=33, gb_free=6.5, wall=0
2021-04-06 06:50:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-06 06:50:22 | INFO | valid | epoch 061 | valid on 'valid' subset | loss 4.144 | nll_loss 2.372 | ppl 5.18 | wps 211146 | wpb 10489.1 | bsz 375 | num_updates 289703 | best_loss 4.14
2021-04-06 06:50:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 61 @ 289703 updates
2021-04-06 06:50:22 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-06 06:50:28 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-06 06:50:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt (epoch 61 @ 289703 updates, score 4.144) (writing took 6.1185740530490875 seconds)
2021-04-06 06:50:28 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)
2021-04-06 06:50:28 | INFO | train | epoch 061 | loss 4.499 | nll_loss 2.893 | ppl 7.43 | wps 87456.6 | ups 3.02 | wpb 28968.2 | bsz 946.9 | num_updates 289703 | lr 5.87521e-05 | gnorm 0.485 | loss_scale 1 | train_wall 1558 | gb_free 6.5 | wall 0
2021-04-06 06:50:28 | INFO | fairseq.trainer | begin training epoch 62
2021-04-06 06:50:28 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-06 06:51:01 | INFO | train_inner | epoch 062:     97 / 4751 loss=4.456, nll_loss=2.844, ppl=7.18, wps=69680.8, ups=2.41, wpb=28894.9, bsz=927.6, num_updates=289800, lr=5.87423e-05, gnorm=0.482, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 06:51:34 | INFO | train_inner | epoch 062:    197 / 4751 loss=4.531, nll_loss=2.929, ppl=7.62, wps=88059.5, ups=3.04, wpb=28945.1, bsz=954.5, num_updates=289900, lr=5.87321e-05, gnorm=0.484, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 06:52:07 | INFO | train_inner | epoch 062:    297 / 4751 loss=4.478, nll_loss=2.868, ppl=7.3, wps=86752.3, ups=3.02, wpb=28766.6, bsz=955.2, num_updates=290000, lr=5.8722e-05, gnorm=0.486, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-06 06:52:40 | INFO | train_inner | epoch 062:    397 / 4751 loss=4.521, nll_loss=2.918, ppl=7.56, wps=88610.3, ups=3.04, wpb=29126.5, bsz=934.2, num_updates=290100, lr=5.87119e-05, gnorm=0.487, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-06 06:53:13 | INFO | train_inner | epoch 062:    497 / 4751 loss=4.501, nll_loss=2.895, ppl=7.44, wps=87814.1, ups=3.04, wpb=28921, bsz=937.8, num_updates=290200, lr=5.87018e-05, gnorm=0.492, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 06:53:46 | INFO | train_inner | epoch 062:    597 / 4751 loss=4.504, nll_loss=2.899, ppl=7.46, wps=88598.4, ups=3.04, wpb=29149, bsz=939.6, num_updates=290300, lr=5.86917e-05, gnorm=0.479, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 06:54:19 | INFO | train_inner | epoch 062:    697 / 4751 loss=4.551, nll_loss=2.952, ppl=7.74, wps=86604.6, ups=3.02, wpb=28682.9, bsz=951.7, num_updates=290400, lr=5.86816e-05, gnorm=0.492, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 06:54:52 | INFO | train_inner | epoch 062:    797 / 4751 loss=4.45, nll_loss=2.836, ppl=7.14, wps=87769, ups=3.03, wpb=28983.4, bsz=948.7, num_updates=290500, lr=5.86715e-05, gnorm=0.478, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 06:55:25 | INFO | train_inner | epoch 062:    897 / 4751 loss=4.424, nll_loss=2.809, ppl=7.01, wps=88656.3, ups=3.04, wpb=29184.5, bsz=980.1, num_updates=290600, lr=5.86614e-05, gnorm=0.481, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 06:55:58 | INFO | train_inner | epoch 062:    997 / 4751 loss=4.448, nll_loss=2.835, ppl=7.14, wps=88263.5, ups=3.04, wpb=29024.3, bsz=942.2, num_updates=290700, lr=5.86513e-05, gnorm=0.479, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 06:56:31 | INFO | train_inner | epoch 062:   1097 / 4751 loss=4.51, nll_loss=2.905, ppl=7.49, wps=88745.4, ups=3.05, wpb=29128, bsz=939, num_updates=290800, lr=5.86412e-05, gnorm=0.482, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 06:57:04 | INFO | train_inner | epoch 062:   1197 / 4751 loss=4.471, nll_loss=2.86, ppl=7.26, wps=88643.2, ups=3.04, wpb=29163.2, bsz=912.3, num_updates=290900, lr=5.86311e-05, gnorm=0.479, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 06:57:37 | INFO | train_inner | epoch 062:   1297 / 4751 loss=4.484, nll_loss=2.876, ppl=7.34, wps=87392.7, ups=3.02, wpb=28958.1, bsz=957.4, num_updates=291000, lr=5.8621e-05, gnorm=0.49, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 06:58:10 | INFO | train_inner | epoch 062:   1397 / 4751 loss=4.467, nll_loss=2.856, ppl=7.24, wps=87477.4, ups=3.03, wpb=28914.6, bsz=970.2, num_updates=291100, lr=5.8611e-05, gnorm=0.484, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 06:58:43 | INFO | train_inner | epoch 062:   1497 / 4751 loss=4.482, nll_loss=2.873, ppl=7.33, wps=87173.9, ups=3.02, wpb=28869.9, bsz=922.6, num_updates=291200, lr=5.86009e-05, gnorm=0.482, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 06:59:16 | INFO | train_inner | epoch 062:   1597 / 4751 loss=4.485, nll_loss=2.877, ppl=7.35, wps=88586.2, ups=3.04, wpb=29120.5, bsz=985.8, num_updates=291300, lr=5.85908e-05, gnorm=0.49, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 06:59:49 | INFO | train_inner | epoch 062:   1697 / 4751 loss=4.502, nll_loss=2.896, ppl=7.44, wps=88304.2, ups=3.02, wpb=29196.2, bsz=917.5, num_updates=291400, lr=5.85808e-05, gnorm=0.487, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 07:00:22 | INFO | train_inner | epoch 062:   1797 / 4751 loss=4.518, nll_loss=2.915, ppl=7.54, wps=88463, ups=3.03, wpb=29157.5, bsz=945.4, num_updates=291500, lr=5.85707e-05, gnorm=0.482, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-06 07:00:55 | INFO | train_inner | epoch 062:   1897 / 4751 loss=4.524, nll_loss=2.921, ppl=7.57, wps=87452.6, ups=3.02, wpb=28969.4, bsz=915.4, num_updates=291600, lr=5.85607e-05, gnorm=0.482, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 07:01:28 | INFO | train_inner | epoch 062:   1997 / 4751 loss=4.529, nll_loss=2.927, ppl=7.61, wps=87705.7, ups=3.03, wpb=28944.3, bsz=920.3, num_updates=291700, lr=5.85507e-05, gnorm=0.483, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 07:02:01 | INFO | train_inner | epoch 062:   2097 / 4751 loss=4.47, nll_loss=2.861, ppl=7.26, wps=88277.1, ups=3.04, wpb=29064.3, bsz=993.2, num_updates=291800, lr=5.85406e-05, gnorm=0.5, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-06 07:02:34 | INFO | train_inner | epoch 062:   2197 / 4751 loss=4.467, nll_loss=2.857, ppl=7.24, wps=88321, ups=3.03, wpb=29117.4, bsz=942.7, num_updates=291900, lr=5.85306e-05, gnorm=0.484, loss_scale=4, train_wall=33, gb_free=6.5, wall=0
2021-04-06 07:03:07 | INFO | train_inner | epoch 062:   2297 / 4751 loss=4.537, nll_loss=2.936, ppl=7.65, wps=88144.4, ups=3.05, wpb=28912.3, bsz=919.7, num_updates=292000, lr=5.85206e-05, gnorm=0.492, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 07:03:40 | INFO | train_inner | epoch 062:   2397 / 4751 loss=4.528, nll_loss=2.926, ppl=7.6, wps=87840.2, ups=3.05, wpb=28812.8, bsz=954.1, num_updates=292100, lr=5.85106e-05, gnorm=0.492, loss_scale=4, train_wall=33, gb_free=6, wall=0
2021-04-06 07:04:13 | INFO | train_inner | epoch 062:   2497 / 4751 loss=4.498, nll_loss=2.892, ppl=7.42, wps=85817.8, ups=2.97, wpb=28907.7, bsz=943.9, num_updates=292200, lr=5.85005e-05, gnorm=0.483, loss_scale=4, train_wall=34, gb_free=6.1, wall=0
2021-04-06 07:04:46 | INFO | train_inner | epoch 062:   2597 / 4751 loss=4.49, nll_loss=2.882, ppl=7.37, wps=87538.1, ups=3.03, wpb=28909.4, bsz=922.9, num_updates=292300, lr=5.84905e-05, gnorm=0.482, loss_scale=4, train_wall=33, gb_free=6, wall=0
2021-04-06 07:05:19 | INFO | train_inner | epoch 062:   2697 / 4751 loss=4.526, nll_loss=2.923, ppl=7.58, wps=88383.2, ups=3.06, wpb=28880.2, bsz=946.4, num_updates=292400, lr=5.84805e-05, gnorm=0.482, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 07:05:52 | INFO | train_inner | epoch 062:   2797 / 4751 loss=4.45, nll_loss=2.837, ppl=7.15, wps=88452.8, ups=3.02, wpb=29280.3, bsz=955, num_updates=292500, lr=5.84705e-05, gnorm=0.486, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 07:06:25 | INFO | train_inner | epoch 062:   2897 / 4751 loss=4.493, nll_loss=2.886, ppl=7.39, wps=87402.8, ups=3.05, wpb=28668.7, bsz=962.8, num_updates=292600, lr=5.84605e-05, gnorm=0.484, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 07:06:58 | INFO | train_inner | epoch 062:   2997 / 4751 loss=4.505, nll_loss=2.9, ppl=7.46, wps=88094.7, ups=3.04, wpb=28994.5, bsz=967.2, num_updates=292700, lr=5.84506e-05, gnorm=0.481, loss_scale=4, train_wall=33, gb_free=6.5, wall=0
2021-04-06 07:07:31 | INFO | train_inner | epoch 062:   3097 / 4751 loss=4.541, nll_loss=2.94, ppl=7.68, wps=88222.4, ups=3.04, wpb=29051.9, bsz=943.8, num_updates=292800, lr=5.84406e-05, gnorm=0.485, loss_scale=4, train_wall=33, gb_free=6.5, wall=0
2021-04-06 07:07:34 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-06 07:08:04 | INFO | train_inner | epoch 062:   3198 / 4751 loss=4.465, nll_loss=2.855, ppl=7.23, wps=86294.3, ups=2.98, wpb=28936.4, bsz=943.6, num_updates=292900, lr=5.84306e-05, gnorm=0.487, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-06 07:08:37 | INFO | train_inner | epoch 062:   3298 / 4751 loss=4.458, nll_loss=2.846, ppl=7.19, wps=87968.1, ups=3.03, wpb=29030.8, bsz=967.7, num_updates=293000, lr=5.84206e-05, gnorm=0.488, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 07:09:10 | INFO | train_inner | epoch 062:   3398 / 4751 loss=4.437, nll_loss=2.823, ppl=7.07, wps=87918.2, ups=3.01, wpb=29186.7, bsz=949.5, num_updates=293100, lr=5.84107e-05, gnorm=0.472, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 07:09:43 | INFO | train_inner | epoch 062:   3498 / 4751 loss=4.561, nll_loss=2.962, ppl=7.79, wps=88015.1, ups=3.05, wpb=28851.2, bsz=950.3, num_updates=293200, lr=5.84007e-05, gnorm=0.497, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 07:10:16 | INFO | train_inner | epoch 062:   3598 / 4751 loss=4.495, nll_loss=2.889, ppl=7.41, wps=89023.1, ups=3.04, wpb=29239.9, bsz=969.4, num_updates=293300, lr=5.83907e-05, gnorm=0.482, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 07:10:49 | INFO | train_inner | epoch 062:   3698 / 4751 loss=4.51, nll_loss=2.905, ppl=7.49, wps=87897.3, ups=3.03, wpb=28979.9, bsz=927, num_updates=293400, lr=5.83808e-05, gnorm=0.484, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 07:11:22 | INFO | train_inner | epoch 062:   3798 / 4751 loss=4.49, nll_loss=2.883, ppl=7.38, wps=87864.9, ups=3.01, wpb=29152.9, bsz=927.6, num_updates=293500, lr=5.83708e-05, gnorm=0.484, loss_scale=2, train_wall=33, gb_free=6.6, wall=0
2021-04-06 07:11:55 | INFO | train_inner | epoch 062:   3898 / 4751 loss=4.51, nll_loss=2.905, ppl=7.49, wps=87652.2, ups=3.05, wpb=28743.4, bsz=935.2, num_updates=293600, lr=5.83609e-05, gnorm=0.489, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 07:12:28 | INFO | train_inner | epoch 062:   3998 / 4751 loss=4.53, nll_loss=2.928, ppl=7.61, wps=87818.9, ups=3.04, wpb=28864.7, bsz=920.1, num_updates=293700, lr=5.8351e-05, gnorm=0.486, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 07:13:01 | INFO | train_inner | epoch 062:   4098 / 4751 loss=4.542, nll_loss=2.941, ppl=7.68, wps=87576.7, ups=3.04, wpb=28786.8, bsz=946.6, num_updates=293800, lr=5.8341e-05, gnorm=0.492, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 07:13:34 | INFO | train_inner | epoch 062:   4198 / 4751 loss=4.479, nll_loss=2.87, ppl=7.31, wps=88447.7, ups=3.04, wpb=29071.9, bsz=973.8, num_updates=293900, lr=5.83311e-05, gnorm=0.492, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 07:14:07 | INFO | train_inner | epoch 062:   4298 / 4751 loss=4.535, nll_loss=2.934, ppl=7.64, wps=86696.8, ups=3.02, wpb=28662.4, bsz=955.4, num_updates=294000, lr=5.83212e-05, gnorm=0.487, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 07:14:39 | INFO | train_inner | epoch 062:   4398 / 4751 loss=4.52, nll_loss=2.917, ppl=7.55, wps=87710.8, ups=3.05, wpb=28771.2, bsz=953.4, num_updates=294100, lr=5.83113e-05, gnorm=0.489, loss_scale=2, train_wall=33, gb_free=6.6, wall=0
2021-04-06 07:15:12 | INFO | train_inner | epoch 062:   4498 / 4751 loss=4.477, nll_loss=2.868, ppl=7.3, wps=88404.3, ups=3.04, wpb=29033, bsz=971.7, num_updates=294200, lr=5.83014e-05, gnorm=0.48, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-06 07:15:45 | INFO | train_inner | epoch 062:   4598 / 4751 loss=4.484, nll_loss=2.877, ppl=7.35, wps=86911.3, ups=3.02, wpb=28818.6, bsz=958.7, num_updates=294300, lr=5.82915e-05, gnorm=0.484, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 07:16:19 | INFO | train_inner | epoch 062:   4698 / 4751 loss=4.544, nll_loss=2.944, ppl=7.7, wps=87781.9, ups=3.02, wpb=29027.5, bsz=974.5, num_updates=294400, lr=5.82816e-05, gnorm=0.511, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 07:16:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-06 07:16:37 | INFO | valid | epoch 062 | valid on 'valid' subset | loss 4.147 | nll_loss 2.379 | ppl 5.2 | wps 191518 | wpb 10489.1 | bsz 375 | num_updates 294453 | best_loss 4.14
2021-04-06 07:16:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 62 @ 294453 updates
2021-04-06 07:16:37 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-06 07:16:44 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-06 07:16:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt (epoch 62 @ 294453 updates, score 4.147) (writing took 6.670822288841009 seconds)
2021-04-06 07:16:44 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)
2021-04-06 07:16:44 | INFO | train | epoch 062 | loss 4.498 | nll_loss 2.891 | ppl 7.42 | wps 87335.4 | ups 3.01 | wpb 28968.9 | bsz 947.3 | num_updates 294453 | lr 5.82763e-05 | gnorm 0.486 | loss_scale 2 | train_wall 1560 | gb_free 6.2 | wall 0
2021-04-06 07:16:44 | INFO | fairseq.trainer | begin training epoch 63
2021-04-06 07:16:44 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-06 07:17:01 | INFO | train_inner | epoch 063:     47 / 4751 loss=4.467, nll_loss=2.857, ppl=7.25, wps=68145.3, ups=2.38, wpb=28614.3, bsz=955.4, num_updates=294500, lr=5.82717e-05, gnorm=0.488, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 07:17:34 | INFO | train_inner | epoch 063:    147 / 4751 loss=4.453, nll_loss=2.84, ppl=7.16, wps=87333.3, ups=3.03, wpb=28846.7, bsz=945.8, num_updates=294600, lr=5.82618e-05, gnorm=0.491, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 07:18:06 | INFO | train_inner | epoch 063:    247 / 4751 loss=4.479, nll_loss=2.869, ppl=7.31, wps=87582.8, ups=3.04, wpb=28799.3, bsz=924.1, num_updates=294700, lr=5.82519e-05, gnorm=0.48, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 07:18:39 | INFO | train_inner | epoch 063:    347 / 4751 loss=4.502, nll_loss=2.896, ppl=7.44, wps=87805.9, ups=3.05, wpb=28758.6, bsz=970.5, num_updates=294800, lr=5.8242e-05, gnorm=0.492, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-06 07:19:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-06 07:19:12 | INFO | train_inner | epoch 063:    448 / 4751 loss=4.52, nll_loss=2.916, ppl=7.55, wps=87751.6, ups=3.04, wpb=28827.6, bsz=919.9, num_updates=294900, lr=5.82321e-05, gnorm=0.491, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 07:19:45 | INFO | train_inner | epoch 063:    548 / 4751 loss=4.471, nll_loss=2.861, ppl=7.27, wps=87703.2, ups=3.03, wpb=28913, bsz=946.6, num_updates=295000, lr=5.82223e-05, gnorm=0.486, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 07:20:18 | INFO | train_inner | epoch 063:    648 / 4751 loss=4.47, nll_loss=2.86, ppl=7.26, wps=88424.1, ups=3.04, wpb=29110.7, bsz=981.2, num_updates=295100, lr=5.82124e-05, gnorm=0.479, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 07:20:51 | INFO | train_inner | epoch 063:    748 / 4751 loss=4.496, nll_loss=2.889, ppl=7.41, wps=88948.1, ups=3.04, wpb=29225.9, bsz=940.7, num_updates=295200, lr=5.82025e-05, gnorm=0.485, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 07:21:24 | INFO | train_inner | epoch 063:    848 / 4751 loss=4.476, nll_loss=2.867, ppl=7.3, wps=87634.3, ups=3.05, wpb=28712.6, bsz=930.5, num_updates=295300, lr=5.81927e-05, gnorm=0.488, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 07:21:57 | INFO | train_inner | epoch 063:    948 / 4751 loss=4.466, nll_loss=2.856, ppl=7.24, wps=88576.2, ups=3.02, wpb=29305.3, bsz=968.6, num_updates=295400, lr=5.81828e-05, gnorm=0.489, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 07:22:30 | INFO | train_inner | epoch 063:   1048 / 4751 loss=4.476, nll_loss=2.868, ppl=7.3, wps=88469, ups=3.03, wpb=29164.4, bsz=942.2, num_updates=295500, lr=5.8173e-05, gnorm=0.48, loss_scale=2, train_wall=33, gb_free=5.9, wall=0
2021-04-06 07:23:03 | INFO | train_inner | epoch 063:   1148 / 4751 loss=4.475, nll_loss=2.865, ppl=7.29, wps=86474.8, ups=3.02, wpb=28658.1, bsz=897.5, num_updates=295600, lr=5.81631e-05, gnorm=0.486, loss_scale=2, train_wall=33, gb_free=6.6, wall=0
2021-04-06 07:23:36 | INFO | train_inner | epoch 063:   1248 / 4751 loss=4.473, nll_loss=2.864, ppl=7.28, wps=88492.8, ups=3.03, wpb=29170.4, bsz=967.9, num_updates=295700, lr=5.81533e-05, gnorm=0.481, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-06 07:24:09 | INFO | train_inner | epoch 063:   1348 / 4751 loss=4.525, nll_loss=2.922, ppl=7.58, wps=87360, ups=3.04, wpb=28697.5, bsz=920.2, num_updates=295800, lr=5.81435e-05, gnorm=0.49, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 07:24:41 | INFO | train_inner | epoch 063:   1448 / 4751 loss=4.51, nll_loss=2.905, ppl=7.49, wps=88520.8, ups=3.05, wpb=29069.5, bsz=956.9, num_updates=295900, lr=5.81336e-05, gnorm=0.493, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 07:25:14 | INFO | train_inner | epoch 063:   1548 / 4751 loss=4.486, nll_loss=2.878, ppl=7.35, wps=88122, ups=3.05, wpb=28903.9, bsz=926.7, num_updates=296000, lr=5.81238e-05, gnorm=0.482, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 07:25:47 | INFO | train_inner | epoch 063:   1648 / 4751 loss=4.486, nll_loss=2.878, ppl=7.35, wps=88080.5, ups=3.03, wpb=29048.1, bsz=925.4, num_updates=296100, lr=5.8114e-05, gnorm=0.481, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-06 07:26:20 | INFO | train_inner | epoch 063:   1748 / 4751 loss=4.512, nll_loss=2.907, ppl=7.5, wps=88698.9, ups=3.04, wpb=29180, bsz=951, num_updates=296200, lr=5.81042e-05, gnorm=0.493, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 07:26:53 | INFO | train_inner | epoch 063:   1848 / 4751 loss=4.478, nll_loss=2.869, ppl=7.31, wps=87667.8, ups=3.04, wpb=28809.6, bsz=944.2, num_updates=296300, lr=5.80944e-05, gnorm=0.484, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 07:27:26 | INFO | train_inner | epoch 063:   1948 / 4751 loss=4.491, nll_loss=2.884, ppl=7.38, wps=88316.6, ups=3.03, wpb=29149.8, bsz=965.9, num_updates=296400, lr=5.80846e-05, gnorm=0.485, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-06 07:27:59 | INFO | train_inner | epoch 063:   2048 / 4751 loss=4.521, nll_loss=2.918, ppl=7.56, wps=87222.9, ups=3.05, wpb=28571.5, bsz=957.8, num_updates=296500, lr=5.80748e-05, gnorm=0.497, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 07:28:32 | INFO | train_inner | epoch 063:   2148 / 4751 loss=4.502, nll_loss=2.896, ppl=7.45, wps=86319.4, ups=3.03, wpb=28504.5, bsz=952.2, num_updates=296600, lr=5.8065e-05, gnorm=0.49, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 07:29:05 | INFO | train_inner | epoch 063:   2248 / 4751 loss=4.467, nll_loss=2.857, ppl=7.24, wps=88503.8, ups=3.02, wpb=29262.7, bsz=967.9, num_updates=296700, lr=5.80552e-05, gnorm=0.483, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 07:29:38 | INFO | train_inner | epoch 063:   2348 / 4751 loss=4.489, nll_loss=2.881, ppl=7.37, wps=88302.3, ups=3.04, wpb=29049.2, bsz=946.1, num_updates=296800, lr=5.80454e-05, gnorm=0.487, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 07:30:11 | INFO | train_inner | epoch 063:   2448 / 4751 loss=4.527, nll_loss=2.924, ppl=7.59, wps=87115.5, ups=3, wpb=29022, bsz=937.5, num_updates=296900, lr=5.80357e-05, gnorm=0.49, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 07:30:44 | INFO | train_inner | epoch 063:   2548 / 4751 loss=4.533, nll_loss=2.931, ppl=7.63, wps=87999.4, ups=3.05, wpb=28824.1, bsz=941.8, num_updates=297000, lr=5.80259e-05, gnorm=0.494, loss_scale=4, train_wall=33, gb_free=6.5, wall=0
2021-04-06 07:31:17 | INFO | train_inner | epoch 063:   2648 / 4751 loss=4.539, nll_loss=2.939, ppl=7.67, wps=88847.4, ups=3.05, wpb=29161, bsz=975.1, num_updates=297100, lr=5.80161e-05, gnorm=0.489, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 07:31:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-06 07:31:50 | INFO | train_inner | epoch 063:   2749 / 4751 loss=4.52, nll_loss=2.917, ppl=7.56, wps=87876.1, ups=3.01, wpb=29164, bsz=921.8, num_updates=297200, lr=5.80064e-05, gnorm=0.488, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 07:32:23 | INFO | train_inner | epoch 063:   2849 / 4751 loss=4.535, nll_loss=2.934, ppl=7.64, wps=88568.3, ups=3.03, wpb=29201.5, bsz=911.9, num_updates=297300, lr=5.79966e-05, gnorm=0.481, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-06 07:32:56 | INFO | train_inner | epoch 063:   2949 / 4751 loss=4.49, nll_loss=2.883, ppl=7.37, wps=87876.9, ups=3.03, wpb=29019.8, bsz=945.1, num_updates=297400, lr=5.79869e-05, gnorm=0.486, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-06 07:33:29 | INFO | train_inner | epoch 063:   3049 / 4751 loss=4.465, nll_loss=2.855, ppl=7.23, wps=87766.4, ups=3.02, wpb=29071.2, bsz=963.8, num_updates=297500, lr=5.79771e-05, gnorm=0.483, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 07:34:02 | INFO | train_inner | epoch 063:   3149 / 4751 loss=4.522, nll_loss=2.919, ppl=7.56, wps=88161.7, ups=3.04, wpb=28995.5, bsz=919.5, num_updates=297600, lr=5.79674e-05, gnorm=0.507, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 07:34:35 | INFO | train_inner | epoch 063:   3249 / 4751 loss=4.461, nll_loss=2.85, ppl=7.21, wps=87929.6, ups=3.03, wpb=29037.2, bsz=925, num_updates=297700, lr=5.79576e-05, gnorm=0.481, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 07:35:08 | INFO | train_inner | epoch 063:   3349 / 4751 loss=4.538, nll_loss=2.938, ppl=7.66, wps=87979, ups=3.04, wpb=28909.4, bsz=930.2, num_updates=297800, lr=5.79479e-05, gnorm=0.487, loss_scale=2, train_wall=33, gb_free=6.6, wall=0
2021-04-06 07:35:42 | INFO | train_inner | epoch 063:   3449 / 4751 loss=4.49, nll_loss=2.883, ppl=7.38, wps=84514.9, ups=2.95, wpb=28628.2, bsz=964.6, num_updates=297900, lr=5.79382e-05, gnorm=0.484, loss_scale=2, train_wall=34, gb_free=6.2, wall=0
2021-04-06 07:36:14 | INFO | train_inner | epoch 063:   3549 / 4751 loss=4.532, nll_loss=2.93, ppl=7.62, wps=88657.2, ups=3.05, wpb=29078.4, bsz=961.9, num_updates=298000, lr=5.79284e-05, gnorm=0.486, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 07:36:47 | INFO | train_inner | epoch 063:   3649 / 4751 loss=4.527, nll_loss=2.925, ppl=7.6, wps=88054, ups=3.05, wpb=28913.9, bsz=960.7, num_updates=298100, lr=5.79187e-05, gnorm=0.489, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 07:37:20 | INFO | train_inner | epoch 063:   3749 / 4751 loss=4.502, nll_loss=2.896, ppl=7.44, wps=88204.9, ups=3.05, wpb=28942, bsz=941, num_updates=298200, lr=5.7909e-05, gnorm=0.484, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 07:37:53 | INFO | train_inner | epoch 063:   3849 / 4751 loss=4.46, nll_loss=2.848, ppl=7.2, wps=87636.9, ups=3.03, wpb=28940.1, bsz=967.9, num_updates=298300, lr=5.78993e-05, gnorm=0.478, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 07:38:26 | INFO | train_inner | epoch 063:   3949 / 4751 loss=4.444, nll_loss=2.831, ppl=7.12, wps=87882, ups=3.02, wpb=29128.6, bsz=968.2, num_updates=298400, lr=5.78896e-05, gnorm=0.483, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 07:38:59 | INFO | train_inner | epoch 063:   4049 / 4751 loss=4.54, nll_loss=2.939, ppl=7.67, wps=87602.2, ups=3.04, wpb=28861.2, bsz=914.4, num_updates=298500, lr=5.78799e-05, gnorm=0.486, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 07:39:32 | INFO | train_inner | epoch 063:   4149 / 4751 loss=4.536, nll_loss=2.935, ppl=7.64, wps=88646.2, ups=3.04, wpb=29187.1, bsz=940, num_updates=298600, lr=5.78702e-05, gnorm=0.485, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 07:40:05 | INFO | train_inner | epoch 063:   4249 / 4751 loss=4.539, nll_loss=2.939, ppl=7.67, wps=87793.7, ups=3.04, wpb=28854.5, bsz=958.2, num_updates=298700, lr=5.78605e-05, gnorm=0.496, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 07:40:38 | INFO | train_inner | epoch 063:   4349 / 4751 loss=4.499, nll_loss=2.894, ppl=7.43, wps=88387.7, ups=3.03, wpb=29134.7, bsz=946.1, num_updates=298800, lr=5.78508e-05, gnorm=0.482, loss_scale=2, train_wall=33, gb_free=6.9, wall=0
2021-04-06 07:41:11 | INFO | train_inner | epoch 063:   4449 / 4751 loss=4.495, nll_loss=2.888, ppl=7.4, wps=87959.2, ups=3.02, wpb=29086.1, bsz=936.7, num_updates=298900, lr=5.78412e-05, gnorm=0.482, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 07:41:44 | INFO | train_inner | epoch 063:   4549 / 4751 loss=4.463, nll_loss=2.853, ppl=7.22, wps=87879.5, ups=3.03, wpb=29047.9, bsz=966.7, num_updates=299000, lr=5.78315e-05, gnorm=0.487, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 07:42:17 | INFO | train_inner | epoch 063:   4649 / 4751 loss=4.474, nll_loss=2.866, ppl=7.29, wps=88177.5, ups=3.05, wpb=28926.7, bsz=963.6, num_updates=299100, lr=5.78218e-05, gnorm=0.484, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 07:42:50 | INFO | train_inner | epoch 063:   4749 / 4751 loss=4.514, nll_loss=2.91, ppl=7.52, wps=87278.8, ups=3.05, wpb=28661.4, bsz=971.1, num_updates=299200, lr=5.78122e-05, gnorm=0.494, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 07:42:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-06 07:42:51 | INFO | valid | epoch 063 | valid on 'valid' subset | loss 4.149 | nll_loss 2.379 | ppl 5.2 | wps 188174 | wpb 10489.1 | bsz 375 | num_updates 299202 | best_loss 4.14
2021-04-06 07:42:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 63 @ 299202 updates
2021-04-06 07:42:51 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-06 07:42:58 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-06 07:42:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt (epoch 63 @ 299202 updates, score 4.149) (writing took 6.09390365332365 seconds)
2021-04-06 07:42:58 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)
2021-04-06 07:42:58 | INFO | train | epoch 063 | loss 4.496 | nll_loss 2.89 | ppl 7.41 | wps 87408.1 | ups 3.02 | wpb 28968.3 | bsz 946.9 | num_updates 299202 | lr 5.7812e-05 | gnorm 0.487 | loss_scale 2 | train_wall 1558 | gb_free 6.3 | wall 0
2021-04-06 07:42:58 | INFO | fairseq.trainer | begin training epoch 64
2021-04-06 07:42:58 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-06 07:43:31 | INFO | train_inner | epoch 064:     98 / 4751 loss=4.536, nll_loss=2.935, ppl=7.65, wps=68942.3, ups=2.42, wpb=28516.1, bsz=974.7, num_updates=299300, lr=5.78025e-05, gnorm=0.498, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 07:44:04 | INFO | train_inner | epoch 064:    198 / 4751 loss=4.486, nll_loss=2.878, ppl=7.35, wps=88880.8, ups=3.04, wpb=29270.8, bsz=949.3, num_updates=299400, lr=5.77928e-05, gnorm=0.489, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 07:44:37 | INFO | train_inner | epoch 064:    298 / 4751 loss=4.465, nll_loss=2.853, ppl=7.23, wps=87226.9, ups=3.05, wpb=28615.5, bsz=929.9, num_updates=299500, lr=5.77832e-05, gnorm=0.486, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 07:45:10 | INFO | train_inner | epoch 064:    398 / 4751 loss=4.514, nll_loss=2.91, ppl=7.51, wps=88408.5, ups=3.05, wpb=28967.3, bsz=951.4, num_updates=299600, lr=5.77736e-05, gnorm=0.483, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-06 07:45:42 | INFO | train_inner | epoch 064:    498 / 4751 loss=4.465, nll_loss=2.854, ppl=7.23, wps=87594.4, ups=3.03, wpb=28876.8, bsz=950.7, num_updates=299700, lr=5.77639e-05, gnorm=0.488, loss_scale=4, train_wall=33, gb_free=6.4, wall=0
2021-04-06 07:46:16 | INFO | train_inner | epoch 064:    598 / 4751 loss=4.457, nll_loss=2.845, ppl=7.19, wps=87665.2, ups=3.02, wpb=29014.2, bsz=975.4, num_updates=299800, lr=5.77543e-05, gnorm=0.481, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 07:46:49 | INFO | train_inner | epoch 064:    698 / 4751 loss=4.459, nll_loss=2.847, ppl=7.19, wps=88291.3, ups=3.03, wpb=29126.5, bsz=977.9, num_updates=299900, lr=5.77447e-05, gnorm=0.481, loss_scale=4, train_wall=33, gb_free=6.4, wall=0
2021-04-06 07:47:22 | INFO | train_inner | epoch 064:    798 / 4751 loss=4.468, nll_loss=2.857, ppl=7.25, wps=87757.8, ups=3.02, wpb=29019.4, bsz=934.4, num_updates=300000, lr=5.7735e-05, gnorm=0.482, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 07:47:55 | INFO | train_inner | epoch 064:    898 / 4751 loss=4.512, nll_loss=2.908, ppl=7.5, wps=88141.7, ups=3.02, wpb=29198, bsz=975.6, num_updates=300100, lr=5.77254e-05, gnorm=0.48, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 07:48:28 | INFO | train_inner | epoch 064:    998 / 4751 loss=4.532, nll_loss=2.93, ppl=7.62, wps=87959.6, ups=3.05, wpb=28858, bsz=908.6, num_updates=300200, lr=5.77158e-05, gnorm=0.491, loss_scale=4, train_wall=33, gb_free=6.7, wall=0
2021-04-06 07:49:01 | INFO | train_inner | epoch 064:   1098 / 4751 loss=4.49, nll_loss=2.882, ppl=7.37, wps=87912.5, ups=3.02, wpb=29083.9, bsz=943, num_updates=300300, lr=5.77062e-05, gnorm=0.489, loss_scale=4, train_wall=33, gb_free=6.4, wall=0
2021-04-06 07:49:34 | INFO | train_inner | epoch 064:   1198 / 4751 loss=4.502, nll_loss=2.896, ppl=7.44, wps=87173.1, ups=3.03, wpb=28771.6, bsz=961.3, num_updates=300400, lr=5.76966e-05, gnorm=0.486, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 07:50:07 | INFO | train_inner | epoch 064:   1298 / 4751 loss=4.523, nll_loss=2.92, ppl=7.57, wps=88355.4, ups=3.04, wpb=29043.7, bsz=949.8, num_updates=300500, lr=5.7687e-05, gnorm=0.491, loss_scale=4, train_wall=33, gb_free=6.4, wall=0
2021-04-06 07:50:40 | INFO | train_inner | epoch 064:   1398 / 4751 loss=4.489, nll_loss=2.881, ppl=7.37, wps=87294.5, ups=3.03, wpb=28809.9, bsz=913.7, num_updates=300600, lr=5.76774e-05, gnorm=0.482, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 07:51:12 | INFO | train_inner | epoch 064:   1498 / 4751 loss=4.498, nll_loss=2.892, ppl=7.42, wps=88174.6, ups=3.04, wpb=28984.2, bsz=962.2, num_updates=300700, lr=5.76678e-05, gnorm=0.484, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 07:51:45 | INFO | train_inner | epoch 064:   1598 / 4751 loss=4.488, nll_loss=2.88, ppl=7.36, wps=88172.9, ups=3.05, wpb=28932.6, bsz=944.9, num_updates=300800, lr=5.76582e-05, gnorm=0.491, loss_scale=4, train_wall=33, gb_free=6.7, wall=0
2021-04-06 07:52:18 | INFO | train_inner | epoch 064:   1698 / 4751 loss=4.426, nll_loss=2.81, ppl=7.01, wps=86802, ups=3.02, wpb=28765.2, bsz=949.3, num_updates=300900, lr=5.76486e-05, gnorm=0.486, loss_scale=4, train_wall=33, gb_free=6, wall=0
2021-04-06 07:52:51 | INFO | train_inner | epoch 064:   1798 / 4751 loss=4.471, nll_loss=2.861, ppl=7.27, wps=87629.6, ups=3.03, wpb=28939.2, bsz=948.3, num_updates=301000, lr=5.7639e-05, gnorm=0.483, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 07:53:24 | INFO | train_inner | epoch 064:   1898 / 4751 loss=4.5, nll_loss=2.894, ppl=7.44, wps=88301.1, ups=3.05, wpb=28959, bsz=968.6, num_updates=301100, lr=5.76295e-05, gnorm=0.489, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 07:53:57 | INFO | train_inner | epoch 064:   1998 / 4751 loss=4.508, nll_loss=2.903, ppl=7.48, wps=87392.2, ups=3.02, wpb=28924.7, bsz=943.1, num_updates=301200, lr=5.76199e-05, gnorm=0.49, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 07:54:30 | INFO | train_inner | epoch 064:   2098 / 4751 loss=4.512, nll_loss=2.907, ppl=7.5, wps=88008.3, ups=3.04, wpb=28984.7, bsz=960, num_updates=301300, lr=5.76103e-05, gnorm=0.491, loss_scale=8, train_wall=33, gb_free=6, wall=0
2021-04-06 07:55:03 | INFO | train_inner | epoch 064:   2198 / 4751 loss=4.441, nll_loss=2.827, ppl=7.1, wps=87734.4, ups=3.03, wpb=28992.1, bsz=953.8, num_updates=301400, lr=5.76008e-05, gnorm=0.48, loss_scale=8, train_wall=33, gb_free=6.1, wall=0
2021-04-06 07:55:36 | INFO | train_inner | epoch 064:   2298 / 4751 loss=4.513, nll_loss=2.909, ppl=7.51, wps=87307.9, ups=3.04, wpb=28762.3, bsz=967.3, num_updates=301500, lr=5.75912e-05, gnorm=0.489, loss_scale=8, train_wall=33, gb_free=6.2, wall=0
2021-04-06 07:56:09 | INFO | train_inner | epoch 064:   2398 / 4751 loss=4.527, nll_loss=2.924, ppl=7.59, wps=87918.4, ups=3.04, wpb=28911.4, bsz=938.7, num_updates=301600, lr=5.75817e-05, gnorm=0.487, loss_scale=8, train_wall=33, gb_free=6.3, wall=0
2021-04-06 07:56:17 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2021-04-06 07:56:42 | INFO | train_inner | epoch 064:   2499 / 4751 loss=4.533, nll_loss=2.932, ppl=7.63, wps=87276, ups=3.03, wpb=28769.4, bsz=928.3, num_updates=301700, lr=5.75721e-05, gnorm=0.493, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 07:56:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-06 07:57:16 | INFO | train_inner | epoch 064:   2600 / 4751 loss=4.475, nll_loss=2.866, ppl=7.29, wps=85004.9, ups=2.97, wpb=28611, bsz=931.5, num_updates=301800, lr=5.75626e-05, gnorm=0.496, loss_scale=2, train_wall=34, gb_free=6, wall=0
2021-04-06 07:57:49 | INFO | train_inner | epoch 064:   2700 / 4751 loss=4.45, nll_loss=2.838, ppl=7.15, wps=88101.4, ups=3.02, wpb=29132.9, bsz=925.2, num_updates=301900, lr=5.75531e-05, gnorm=0.476, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 07:58:22 | INFO | train_inner | epoch 064:   2800 / 4751 loss=4.486, nll_loss=2.878, ppl=7.35, wps=87357.7, ups=3.04, wpb=28757.3, bsz=922.9, num_updates=302000, lr=5.75435e-05, gnorm=0.498, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 07:58:55 | INFO | train_inner | epoch 064:   2900 / 4751 loss=4.475, nll_loss=2.866, ppl=7.29, wps=88062.5, ups=3.04, wpb=28962.1, bsz=975.9, num_updates=302100, lr=5.7534e-05, gnorm=0.49, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 07:59:27 | INFO | train_inner | epoch 064:   3000 / 4751 loss=4.533, nll_loss=2.931, ppl=7.63, wps=87407.6, ups=3.05, wpb=28696.2, bsz=971.3, num_updates=302200, lr=5.75245e-05, gnorm=0.491, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 08:00:00 | INFO | train_inner | epoch 064:   3100 / 4751 loss=4.533, nll_loss=2.932, ppl=7.63, wps=89101.5, ups=3.06, wpb=29149.2, bsz=972.1, num_updates=302300, lr=5.7515e-05, gnorm=0.492, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 08:00:34 | INFO | train_inner | epoch 064:   3200 / 4751 loss=4.488, nll_loss=2.88, ppl=7.36, wps=84895.4, ups=2.96, wpb=28720.6, bsz=924.8, num_updates=302400, lr=5.75055e-05, gnorm=0.49, loss_scale=2, train_wall=34, gb_free=6.8, wall=0
2021-04-06 08:01:07 | INFO | train_inner | epoch 064:   3300 / 4751 loss=4.507, nll_loss=2.902, ppl=7.47, wps=87831.2, ups=3.02, wpb=29077.6, bsz=941, num_updates=302500, lr=5.7496e-05, gnorm=0.486, loss_scale=2, train_wall=33, gb_free=5.4, wall=0
2021-04-06 08:01:40 | INFO | train_inner | epoch 064:   3400 / 4751 loss=4.513, nll_loss=2.909, ppl=7.51, wps=87222.4, ups=3.04, wpb=28669.6, bsz=922.7, num_updates=302600, lr=5.74865e-05, gnorm=0.49, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 08:02:13 | INFO | train_inner | epoch 064:   3500 / 4751 loss=4.521, nll_loss=2.917, ppl=7.56, wps=87836.2, ups=3.05, wpb=28823.8, bsz=943, num_updates=302700, lr=5.7477e-05, gnorm=0.496, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 08:02:46 | INFO | train_inner | epoch 064:   3600 / 4751 loss=4.529, nll_loss=2.927, ppl=7.6, wps=86976.3, ups=3.04, wpb=28619.1, bsz=927.3, num_updates=302800, lr=5.74675e-05, gnorm=0.49, loss_scale=2, train_wall=33, gb_free=6.8, wall=0
2021-04-06 08:03:19 | INFO | train_inner | epoch 064:   3700 / 4751 loss=4.539, nll_loss=2.938, ppl=7.67, wps=88509.7, ups=3.03, wpb=29202.8, bsz=954.9, num_updates=302900, lr=5.7458e-05, gnorm=0.487, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 08:03:52 | INFO | train_inner | epoch 064:   3800 / 4751 loss=4.479, nll_loss=2.87, ppl=7.31, wps=87797.9, ups=3.02, wpb=29081.9, bsz=951.3, num_updates=303000, lr=5.74485e-05, gnorm=0.482, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 08:04:25 | INFO | train_inner | epoch 064:   3900 / 4751 loss=4.5, nll_loss=2.895, ppl=7.44, wps=89220.8, ups=3.05, wpb=29300.7, bsz=911.8, num_updates=303100, lr=5.7439e-05, gnorm=0.484, loss_scale=2, train_wall=33, gb_free=5.9, wall=0
2021-04-06 08:04:57 | INFO | train_inner | epoch 064:   4000 / 4751 loss=4.484, nll_loss=2.876, ppl=7.34, wps=88615.9, ups=3.05, wpb=29009.4, bsz=976, num_updates=303200, lr=5.74295e-05, gnorm=0.489, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 08:05:30 | INFO | train_inner | epoch 064:   4100 / 4751 loss=4.451, nll_loss=2.839, ppl=7.15, wps=88884.9, ups=3.03, wpb=29365.5, bsz=902, num_updates=303300, lr=5.74201e-05, gnorm=0.479, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 08:06:03 | INFO | train_inner | epoch 064:   4200 / 4751 loss=4.471, nll_loss=2.861, ppl=7.26, wps=87431.4, ups=3.02, wpb=28924.8, bsz=921.4, num_updates=303400, lr=5.74106e-05, gnorm=0.491, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 08:06:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-04-06 08:06:37 | INFO | train_inner | epoch 064:   4301 / 4751 loss=4.531, nll_loss=2.93, ppl=7.62, wps=88251.4, ups=3.01, wpb=29327, bsz=960.6, num_updates=303500, lr=5.74012e-05, gnorm=0.488, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 08:07:10 | INFO | train_inner | epoch 064:   4401 / 4751 loss=4.501, nll_loss=2.896, ppl=7.44, wps=88098.3, ups=3.03, wpb=29060.1, bsz=950.6, num_updates=303600, lr=5.73917e-05, gnorm=0.486, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 08:07:43 | INFO | train_inner | epoch 064:   4501 / 4751 loss=4.532, nll_loss=2.931, ppl=7.63, wps=88859, ups=3.04, wpb=29201.8, bsz=947.4, num_updates=303700, lr=5.73823e-05, gnorm=0.485, loss_scale=1, train_wall=33, gb_free=6.5, wall=0
2021-04-06 08:08:16 | INFO | train_inner | epoch 064:   4601 / 4751 loss=4.48, nll_loss=2.872, ppl=7.32, wps=88582.1, ups=3.02, wpb=29296, bsz=948.5, num_updates=303800, lr=5.73728e-05, gnorm=0.479, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 08:08:49 | INFO | train_inner | epoch 064:   4701 / 4751 loss=4.481, nll_loss=2.873, ppl=7.33, wps=88323.8, ups=3.02, wpb=29207.7, bsz=937.4, num_updates=303900, lr=5.73634e-05, gnorm=0.492, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 08:09:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-06 08:09:06 | INFO | valid | epoch 064 | valid on 'valid' subset | loss 4.136 | nll_loss 2.366 | ppl 5.15 | wps 191233 | wpb 10489.1 | bsz 375 | num_updates 303950 | best_loss 4.136
2021-04-06 08:09:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 64 @ 303950 updates
2021-04-06 08:09:06 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-06 08:09:13 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-06 08:09:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt (epoch 64 @ 303950 updates, score 4.136) (writing took 13.51637877523899 seconds)
2021-04-06 08:09:20 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)
2021-04-06 08:09:20 | INFO | train | epoch 064 | loss 4.495 | nll_loss 2.888 | ppl 7.4 | wps 86925.4 | ups 3 | wpb 28968 | bsz 946.4 | num_updates 303950 | lr 5.73587e-05 | gnorm 0.487 | loss_scale 1 | train_wall 1559 | gb_free 6.3 | wall 0
2021-04-06 08:09:20 | INFO | fairseq.trainer | begin training epoch 65
2021-04-06 08:09:20 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-06 08:09:37 | INFO | train_inner | epoch 065:     50 / 4751 loss=4.483, nll_loss=2.875, ppl=7.33, wps=59215.5, ups=2.05, wpb=28869.1, bsz=933.4, num_updates=304000, lr=5.73539e-05, gnorm=0.487, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 08:10:10 | INFO | train_inner | epoch 065:    150 / 4751 loss=4.489, nll_loss=2.882, ppl=7.37, wps=89473.8, ups=3.08, wpb=29095.1, bsz=933.3, num_updates=304100, lr=5.73445e-05, gnorm=0.486, loss_scale=1, train_wall=32, gb_free=6.1, wall=0
2021-04-06 08:10:43 | INFO | train_inner | epoch 065:    250 / 4751 loss=4.444, nll_loss=2.831, ppl=7.11, wps=86254.1, ups=3.03, wpb=28513.5, bsz=944.3, num_updates=304200, lr=5.73351e-05, gnorm=0.487, loss_scale=1, train_wall=33, gb_free=6.4, wall=0
2021-04-06 08:11:16 | INFO | train_inner | epoch 065:    350 / 4751 loss=4.507, nll_loss=2.901, ppl=7.47, wps=89531.5, ups=3.06, wpb=29220, bsz=963.8, num_updates=304300, lr=5.73257e-05, gnorm=0.489, loss_scale=1, train_wall=32, gb_free=6.3, wall=0
2021-04-06 08:11:49 | INFO | train_inner | epoch 065:    450 / 4751 loss=4.46, nll_loss=2.848, ppl=7.2, wps=87927.6, ups=3.04, wpb=28954.5, bsz=946.9, num_updates=304400, lr=5.73162e-05, gnorm=0.488, loss_scale=1, train_wall=33, gb_free=6, wall=0
2021-04-06 08:12:22 | INFO | train_inner | epoch 065:    550 / 4751 loss=4.468, nll_loss=2.858, ppl=7.25, wps=88111.5, ups=3.01, wpb=29277.5, bsz=975.9, num_updates=304500, lr=5.73068e-05, gnorm=0.48, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 08:12:55 | INFO | train_inner | epoch 065:    650 / 4751 loss=4.481, nll_loss=2.872, ppl=7.32, wps=89201.4, ups=3.05, wpb=29237.9, bsz=978.5, num_updates=304600, lr=5.72974e-05, gnorm=0.482, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 08:13:28 | INFO | train_inner | epoch 065:    750 / 4751 loss=4.505, nll_loss=2.9, ppl=7.46, wps=87153.8, ups=3.03, wpb=28718.2, bsz=926.6, num_updates=304700, lr=5.7288e-05, gnorm=0.492, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 08:14:01 | INFO | train_inner | epoch 065:    850 / 4751 loss=4.532, nll_loss=2.93, ppl=7.62, wps=85401.5, ups=3.03, wpb=28231.5, bsz=954, num_updates=304800, lr=5.72786e-05, gnorm=0.508, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 08:14:34 | INFO | train_inner | epoch 065:    950 / 4751 loss=4.503, nll_loss=2.898, ppl=7.45, wps=87178.8, ups=3.02, wpb=28863.5, bsz=946.3, num_updates=304900, lr=5.72692e-05, gnorm=0.494, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 08:15:07 | INFO | train_inner | epoch 065:   1050 / 4751 loss=4.456, nll_loss=2.844, ppl=7.18, wps=87330.3, ups=3.02, wpb=28935.7, bsz=967.8, num_updates=305000, lr=5.72598e-05, gnorm=0.493, loss_scale=1, train_wall=33, gb_free=6, wall=0
2021-04-06 08:15:40 | INFO | train_inner | epoch 065:   1150 / 4751 loss=4.497, nll_loss=2.89, ppl=7.41, wps=87484.7, ups=3.03, wpb=28904.8, bsz=932.5, num_updates=305100, lr=5.72504e-05, gnorm=0.493, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 08:16:13 | INFO | train_inner | epoch 065:   1250 / 4751 loss=4.569, nll_loss=2.971, ppl=7.84, wps=87600.5, ups=3.06, wpb=28671.8, bsz=917.1, num_updates=305200, lr=5.72411e-05, gnorm=0.499, loss_scale=1, train_wall=33, gb_free=6.5, wall=0
2021-04-06 08:16:45 | INFO | train_inner | epoch 065:   1350 / 4751 loss=4.462, nll_loss=2.851, ppl=7.22, wps=88635.1, ups=3.04, wpb=29127.4, bsz=954.3, num_updates=305300, lr=5.72317e-05, gnorm=0.49, loss_scale=1, train_wall=33, gb_free=6, wall=0
2021-04-06 08:17:18 | INFO | train_inner | epoch 065:   1450 / 4751 loss=4.488, nll_loss=2.88, ppl=7.36, wps=88737.1, ups=3.04, wpb=29233.6, bsz=959.9, num_updates=305400, lr=5.72223e-05, gnorm=0.483, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 08:17:52 | INFO | train_inner | epoch 065:   1550 / 4751 loss=4.452, nll_loss=2.84, ppl=7.16, wps=88370.5, ups=3.02, wpb=29281.6, bsz=959.9, num_updates=305500, lr=5.7213e-05, gnorm=0.485, loss_scale=1, train_wall=33, gb_free=6.4, wall=0
2021-04-06 08:18:25 | INFO | train_inner | epoch 065:   1650 / 4751 loss=4.559, nll_loss=2.961, ppl=7.79, wps=87995.1, ups=3.04, wpb=28992.8, bsz=970.8, num_updates=305600, lr=5.72036e-05, gnorm=0.489, loss_scale=2, train_wall=33, gb_free=6.6, wall=0
2021-04-06 08:18:57 | INFO | train_inner | epoch 065:   1750 / 4751 loss=4.451, nll_loss=2.84, ppl=7.16, wps=87888.5, ups=3.04, wpb=28928.2, bsz=964.6, num_updates=305700, lr=5.71942e-05, gnorm=0.483, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 08:19:30 | INFO | train_inner | epoch 065:   1850 / 4751 loss=4.535, nll_loss=2.933, ppl=7.64, wps=87893.4, ups=3.04, wpb=28909.1, bsz=925.7, num_updates=305800, lr=5.71849e-05, gnorm=0.487, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 08:20:03 | INFO | train_inner | epoch 065:   1950 / 4751 loss=4.51, nll_loss=2.905, ppl=7.49, wps=88242.7, ups=3.04, wpb=29029.9, bsz=964.4, num_updates=305900, lr=5.71755e-05, gnorm=0.489, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-06 08:20:36 | INFO | train_inner | epoch 065:   2050 / 4751 loss=4.507, nll_loss=2.902, ppl=7.47, wps=88065.1, ups=3.05, wpb=28913.7, bsz=920.5, num_updates=306000, lr=5.71662e-05, gnorm=0.488, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 08:21:09 | INFO | train_inner | epoch 065:   2150 / 4751 loss=4.505, nll_loss=2.9, ppl=7.46, wps=87433.9, ups=3.02, wpb=28999.6, bsz=945.6, num_updates=306100, lr=5.71569e-05, gnorm=0.484, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-06 08:21:42 | INFO | train_inner | epoch 065:   2250 / 4751 loss=4.496, nll_loss=2.889, ppl=7.41, wps=88083.8, ups=3.05, wpb=28906.1, bsz=954.6, num_updates=306200, lr=5.71475e-05, gnorm=0.49, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 08:22:15 | INFO | train_inner | epoch 065:   2350 / 4751 loss=4.493, nll_loss=2.886, ppl=7.39, wps=89018.9, ups=3.05, wpb=29194.9, bsz=931.4, num_updates=306300, lr=5.71382e-05, gnorm=0.495, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 08:22:48 | INFO | train_inner | epoch 065:   2450 / 4751 loss=4.465, nll_loss=2.854, ppl=7.23, wps=88674.6, ups=3.05, wpb=29104.8, bsz=924.6, num_updates=306400, lr=5.71289e-05, gnorm=0.481, loss_scale=2, train_wall=33, gb_free=6.9, wall=0
2021-04-06 08:23:21 | INFO | train_inner | epoch 065:   2550 / 4751 loss=4.445, nll_loss=2.832, ppl=7.12, wps=88824.1, ups=3.04, wpb=29215.3, bsz=966.5, num_updates=306500, lr=5.71195e-05, gnorm=0.493, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 08:23:54 | INFO | train_inner | epoch 065:   2650 / 4751 loss=4.521, nll_loss=2.918, ppl=7.56, wps=87442.8, ups=3.03, wpb=28840, bsz=968.5, num_updates=306600, lr=5.71102e-05, gnorm=0.487, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 08:24:26 | INFO | train_inner | epoch 065:   2750 / 4751 loss=4.49, nll_loss=2.883, ppl=7.38, wps=88135.9, ups=3.03, wpb=29062.6, bsz=931, num_updates=306700, lr=5.71009e-05, gnorm=0.484, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 08:24:59 | INFO | train_inner | epoch 065:   2850 / 4751 loss=4.487, nll_loss=2.879, ppl=7.36, wps=88341.3, ups=3.04, wpb=29055.8, bsz=969.4, num_updates=306800, lr=5.70916e-05, gnorm=0.487, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 08:25:33 | INFO | train_inner | epoch 065:   2950 / 4751 loss=4.424, nll_loss=2.808, ppl=7, wps=88192.8, ups=3.01, wpb=29283.2, bsz=981.2, num_updates=306900, lr=5.70823e-05, gnorm=0.48, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 08:26:05 | INFO | train_inner | epoch 065:   3050 / 4751 loss=4.523, nll_loss=2.92, ppl=7.57, wps=87663, ups=3.06, wpb=28691.4, bsz=930, num_updates=307000, lr=5.7073e-05, gnorm=0.501, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 08:26:39 | INFO | train_inner | epoch 065:   3150 / 4751 loss=4.468, nll_loss=2.858, ppl=7.25, wps=86435.3, ups=2.98, wpb=28995.3, bsz=978.2, num_updates=307100, lr=5.70637e-05, gnorm=0.487, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-06 08:27:12 | INFO | train_inner | epoch 065:   3250 / 4751 loss=4.518, nll_loss=2.915, ppl=7.54, wps=88563.3, ups=3.04, wpb=29166.2, bsz=926.3, num_updates=307200, lr=5.70544e-05, gnorm=0.489, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 08:27:45 | INFO | train_inner | epoch 065:   3350 / 4751 loss=4.53, nll_loss=2.928, ppl=7.61, wps=88101.1, ups=3.03, wpb=29033.7, bsz=938.6, num_updates=307300, lr=5.70451e-05, gnorm=0.496, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 08:28:18 | INFO | train_inner | epoch 065:   3450 / 4751 loss=4.495, nll_loss=2.889, ppl=7.41, wps=87540.9, ups=3.04, wpb=28779.4, bsz=943.8, num_updates=307400, lr=5.70359e-05, gnorm=0.492, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-06 08:28:50 | INFO | train_inner | epoch 065:   3550 / 4751 loss=4.517, nll_loss=2.913, ppl=7.53, wps=87791.8, ups=3.05, wpb=28804.9, bsz=939.8, num_updates=307500, lr=5.70266e-05, gnorm=0.488, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-06 08:29:24 | INFO | train_inner | epoch 065:   3650 / 4751 loss=4.507, nll_loss=2.902, ppl=7.47, wps=86640.8, ups=3, wpb=28891.9, bsz=912.4, num_updates=307600, lr=5.70173e-05, gnorm=0.498, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 08:29:28 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-06 08:29:58 | INFO | train_inner | epoch 065:   3751 / 4751 loss=4.453, nll_loss=2.842, ppl=7.17, wps=85394.3, ups=2.95, wpb=28918, bsz=962.9, num_updates=307700, lr=5.70081e-05, gnorm=0.49, loss_scale=2, train_wall=34, gb_free=6.2, wall=0
2021-04-06 08:30:31 | INFO | train_inner | epoch 065:   3851 / 4751 loss=4.507, nll_loss=2.903, ppl=7.48, wps=88219.3, ups=3.04, wpb=29015.9, bsz=946.2, num_updates=307800, lr=5.69988e-05, gnorm=0.489, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 08:31:04 | INFO | train_inner | epoch 065:   3951 / 4751 loss=4.496, nll_loss=2.89, ppl=7.41, wps=88338.3, ups=3.03, wpb=29127.3, bsz=927.2, num_updates=307900, lr=5.69895e-05, gnorm=0.49, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-06 08:31:37 | INFO | train_inner | epoch 065:   4051 / 4751 loss=4.507, nll_loss=2.902, ppl=7.47, wps=88270.5, ups=3.03, wpb=29116.6, bsz=944.6, num_updates=308000, lr=5.69803e-05, gnorm=0.488, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 08:32:09 | INFO | train_inner | epoch 065:   4151 / 4751 loss=4.549, nll_loss=2.95, ppl=7.73, wps=87360.4, ups=3.03, wpb=28785.8, bsz=909.6, num_updates=308100, lr=5.6971e-05, gnorm=0.496, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 08:32:42 | INFO | train_inner | epoch 065:   4251 / 4751 loss=4.461, nll_loss=2.851, ppl=7.21, wps=87974.5, ups=3.04, wpb=28920.3, bsz=944.6, num_updates=308200, lr=5.69618e-05, gnorm=0.483, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 08:33:15 | INFO | train_inner | epoch 065:   4351 / 4751 loss=4.538, nll_loss=2.937, ppl=7.66, wps=86839.3, ups=3.02, wpb=28739.9, bsz=931.3, num_updates=308300, lr=5.69526e-05, gnorm=0.493, loss_scale=2, train_wall=33, gb_free=6.7, wall=0
2021-04-06 08:33:48 | INFO | train_inner | epoch 065:   4451 / 4751 loss=4.458, nll_loss=2.847, ppl=7.2, wps=88622, ups=3.04, wpb=29154.5, bsz=965.9, num_updates=308400, lr=5.69433e-05, gnorm=0.485, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 08:34:21 | INFO | train_inner | epoch 065:   4551 / 4751 loss=4.546, nll_loss=2.946, ppl=7.71, wps=88102.5, ups=3.04, wpb=28971.3, bsz=917.9, num_updates=308500, lr=5.69341e-05, gnorm=0.486, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 08:34:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-04-06 08:34:55 | INFO | train_inner | epoch 065:   4652 / 4751 loss=4.447, nll_loss=2.835, ppl=7.14, wps=86691.4, ups=3, wpb=28869.6, bsz=965.7, num_updates=308600, lr=5.69249e-05, gnorm=0.489, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 08:35:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-06 08:35:28 | INFO | valid | epoch 065 | valid on 'valid' subset | loss 4.136 | nll_loss 2.364 | ppl 5.15 | wps 204983 | wpb 10489.1 | bsz 375 | num_updates 308699 | best_loss 4.136
2021-04-06 08:35:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 65 @ 308699 updates
2021-04-06 08:35:28 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-06 08:35:34 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-06 08:35:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt (epoch 65 @ 308699 updates, score 4.136) (writing took 12.752362914383411 seconds)
2021-04-06 08:35:41 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)
2021-04-06 08:35:41 | INFO | train | epoch 065 | loss 4.493 | nll_loss 2.886 | ppl 7.39 | wps 87002 | ups 3 | wpb 28968.4 | bsz 946.7 | num_updates 308699 | lr 5.69157e-05 | gnorm 0.489 | loss_scale 1 | train_wall 1559 | gb_free 6.4 | wall 0
2021-04-06 08:35:41 | INFO | fairseq.trainer | begin training epoch 66
2021-04-06 08:35:41 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-06 08:35:43 | INFO | train_inner | epoch 066:      1 / 4751 loss=4.463, nll_loss=2.853, ppl=7.22, wps=60117.3, ups=2.07, wpb=28978.2, bsz=943.7, num_updates=308700, lr=5.69156e-05, gnorm=0.486, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 08:36:16 | INFO | train_inner | epoch 066:    101 / 4751 loss=4.484, nll_loss=2.876, ppl=7.34, wps=87305.9, ups=3.05, wpb=28660.7, bsz=950.4, num_updates=308800, lr=5.69064e-05, gnorm=0.489, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 08:36:48 | INFO | train_inner | epoch 066:    201 / 4751 loss=4.496, nll_loss=2.889, ppl=7.41, wps=87863.1, ups=3.05, wpb=28846.1, bsz=942.6, num_updates=308900, lr=5.68972e-05, gnorm=0.489, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 08:37:21 | INFO | train_inner | epoch 066:    301 / 4751 loss=4.528, nll_loss=2.926, ppl=7.6, wps=87781.2, ups=3.07, wpb=28590.5, bsz=933.3, num_updates=309000, lr=5.6888e-05, gnorm=0.491, loss_scale=1, train_wall=32, gb_free=6.2, wall=0
2021-04-06 08:37:54 | INFO | train_inner | epoch 066:    401 / 4751 loss=4.442, nll_loss=2.828, ppl=7.1, wps=88613.3, ups=3.05, wpb=29052.5, bsz=948.6, num_updates=309100, lr=5.68788e-05, gnorm=0.485, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 08:38:26 | INFO | train_inner | epoch 066:    501 / 4751 loss=4.509, nll_loss=2.904, ppl=7.48, wps=89394.5, ups=3.05, wpb=29272.3, bsz=960, num_updates=309200, lr=5.68696e-05, gnorm=0.492, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 08:38:59 | INFO | train_inner | epoch 066:    601 / 4751 loss=4.463, nll_loss=2.852, ppl=7.22, wps=87268, ups=3.03, wpb=28767.3, bsz=926.6, num_updates=309300, lr=5.68604e-05, gnorm=0.486, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 08:39:33 | INFO | train_inner | epoch 066:    701 / 4751 loss=4.446, nll_loss=2.833, ppl=7.12, wps=88121.6, ups=3.02, wpb=29174.9, bsz=977.4, num_updates=309400, lr=5.68512e-05, gnorm=0.519, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 08:40:06 | INFO | train_inner | epoch 066:    801 / 4751 loss=4.484, nll_loss=2.876, ppl=7.34, wps=88528.2, ups=3.03, wpb=29241.2, bsz=988.6, num_updates=309500, lr=5.6842e-05, gnorm=0.494, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 08:40:38 | INFO | train_inner | epoch 066:    901 / 4751 loss=4.521, nll_loss=2.918, ppl=7.56, wps=87935.8, ups=3.04, wpb=28909.8, bsz=893.3, num_updates=309600, lr=5.68329e-05, gnorm=0.495, loss_scale=1, train_wall=33, gb_free=6.5, wall=0
2021-04-06 08:41:11 | INFO | train_inner | epoch 066:   1001 / 4751 loss=4.466, nll_loss=2.856, ppl=7.24, wps=88373.2, ups=3.04, wpb=29089.9, bsz=968, num_updates=309700, lr=5.68237e-05, gnorm=0.486, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 08:41:44 | INFO | train_inner | epoch 066:   1101 / 4751 loss=4.479, nll_loss=2.87, ppl=7.31, wps=88345.3, ups=3.04, wpb=29025, bsz=958.8, num_updates=309800, lr=5.68145e-05, gnorm=0.487, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 08:42:17 | INFO | train_inner | epoch 066:   1201 / 4751 loss=4.461, nll_loss=2.85, ppl=7.21, wps=88971.7, ups=3.03, wpb=29362.9, bsz=982.4, num_updates=309900, lr=5.68053e-05, gnorm=0.486, loss_scale=1, train_wall=33, gb_free=6.7, wall=0
2021-04-06 08:42:50 | INFO | train_inner | epoch 066:   1301 / 4751 loss=4.532, nll_loss=2.931, ppl=7.62, wps=87634, ups=3.04, wpb=28849.5, bsz=941.4, num_updates=310000, lr=5.67962e-05, gnorm=0.491, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 08:43:23 | INFO | train_inner | epoch 066:   1401 / 4751 loss=4.489, nll_loss=2.881, ppl=7.37, wps=88031.1, ups=3.04, wpb=28984.6, bsz=926.5, num_updates=310100, lr=5.6787e-05, gnorm=0.491, loss_scale=1, train_wall=33, gb_free=6.5, wall=0
2021-04-06 08:43:56 | INFO | train_inner | epoch 066:   1501 / 4751 loss=4.449, nll_loss=2.836, ppl=7.14, wps=88028.8, ups=3.03, wpb=29044.5, bsz=945.2, num_updates=310200, lr=5.67779e-05, gnorm=0.506, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 08:44:29 | INFO | train_inner | epoch 066:   1601 / 4751 loss=4.444, nll_loss=2.831, ppl=7.12, wps=87635.6, ups=3.02, wpb=29064, bsz=945.4, num_updates=310300, lr=5.67687e-05, gnorm=0.486, loss_scale=1, train_wall=33, gb_free=6, wall=0
2021-04-06 08:45:02 | INFO | train_inner | epoch 066:   1701 / 4751 loss=4.446, nll_loss=2.833, ppl=7.13, wps=87666.5, ups=3.03, wpb=28960.8, bsz=952.1, num_updates=310400, lr=5.67596e-05, gnorm=0.482, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 08:45:35 | INFO | train_inner | epoch 066:   1801 / 4751 loss=4.523, nll_loss=2.919, ppl=7.56, wps=86478.7, ups=3.02, wpb=28600.8, bsz=933, num_updates=310500, lr=5.67504e-05, gnorm=0.497, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 08:46:09 | INFO | train_inner | epoch 066:   1901 / 4751 loss=4.564, nll_loss=2.966, ppl=7.81, wps=86843.1, ups=3.01, wpb=28817.9, bsz=927.7, num_updates=310600, lr=5.67413e-05, gnorm=0.503, loss_scale=1, train_wall=33, gb_free=6, wall=0
2021-04-06 08:46:42 | INFO | train_inner | epoch 066:   2001 / 4751 loss=4.495, nll_loss=2.888, ppl=7.4, wps=87531.3, ups=3.02, wpb=28951.3, bsz=950.2, num_updates=310700, lr=5.67322e-05, gnorm=0.49, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 08:47:15 | INFO | train_inner | epoch 066:   2101 / 4751 loss=4.477, nll_loss=2.868, ppl=7.3, wps=85623.3, ups=2.97, wpb=28842.2, bsz=952.1, num_updates=310800, lr=5.6723e-05, gnorm=0.487, loss_scale=2, train_wall=34, gb_free=6.2, wall=0
2021-04-06 08:47:48 | INFO | train_inner | epoch 066:   2201 / 4751 loss=4.503, nll_loss=2.898, ppl=7.45, wps=87969.2, ups=3.05, wpb=28876.1, bsz=970.1, num_updates=310900, lr=5.67139e-05, gnorm=0.496, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 08:48:21 | INFO | train_inner | epoch 066:   2301 / 4751 loss=4.466, nll_loss=2.856, ppl=7.24, wps=88371, ups=3.03, wpb=29150.6, bsz=926.1, num_updates=311000, lr=5.67048e-05, gnorm=0.485, loss_scale=2, train_wall=33, gb_free=6.6, wall=0
2021-04-06 08:48:54 | INFO | train_inner | epoch 066:   2401 / 4751 loss=4.492, nll_loss=2.885, ppl=7.39, wps=88364.2, ups=3.04, wpb=29109.3, bsz=938.8, num_updates=311100, lr=5.66957e-05, gnorm=0.484, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 08:49:27 | INFO | train_inner | epoch 066:   2501 / 4751 loss=4.492, nll_loss=2.885, ppl=7.39, wps=87892.1, ups=3.05, wpb=28838.1, bsz=945.1, num_updates=311200, lr=5.66866e-05, gnorm=0.492, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 08:50:00 | INFO | train_inner | epoch 066:   2601 / 4751 loss=4.517, nll_loss=2.914, ppl=7.53, wps=88725.4, ups=3.04, wpb=29180.4, bsz=950.2, num_updates=311300, lr=5.66775e-05, gnorm=0.488, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 08:50:33 | INFO | train_inner | epoch 066:   2701 / 4751 loss=4.456, nll_loss=2.844, ppl=7.18, wps=87451.7, ups=3.02, wpb=29000.2, bsz=933.8, num_updates=311400, lr=5.66684e-05, gnorm=0.487, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 08:51:06 | INFO | train_inner | epoch 066:   2801 / 4751 loss=4.525, nll_loss=2.922, ppl=7.58, wps=88341.4, ups=3.04, wpb=29020.6, bsz=919.4, num_updates=311500, lr=5.66593e-05, gnorm=0.5, loss_scale=2, train_wall=33, gb_free=6.6, wall=0
2021-04-06 08:51:39 | INFO | train_inner | epoch 066:   2901 / 4751 loss=4.469, nll_loss=2.859, ppl=7.25, wps=89508.8, ups=3.04, wpb=29446.9, bsz=957.7, num_updates=311600, lr=5.66502e-05, gnorm=0.478, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 08:52:11 | INFO | train_inner | epoch 066:   3001 / 4751 loss=4.534, nll_loss=2.933, ppl=7.63, wps=88267.4, ups=3.05, wpb=28945.7, bsz=943.5, num_updates=311700, lr=5.66411e-05, gnorm=0.512, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 08:52:44 | INFO | train_inner | epoch 066:   3101 / 4751 loss=4.514, nll_loss=2.91, ppl=7.51, wps=88165.1, ups=3.03, wpb=29093.5, bsz=939.6, num_updates=311800, lr=5.6632e-05, gnorm=0.487, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 08:53:17 | INFO | train_inner | epoch 066:   3201 / 4751 loss=4.515, nll_loss=2.911, ppl=7.52, wps=87854.2, ups=3.04, wpb=28907.6, bsz=937.1, num_updates=311900, lr=5.66229e-05, gnorm=0.493, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 08:53:50 | INFO | train_inner | epoch 066:   3301 / 4751 loss=4.485, nll_loss=2.878, ppl=7.35, wps=88406.4, ups=3.04, wpb=29044.3, bsz=962.8, num_updates=312000, lr=5.66139e-05, gnorm=0.486, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 08:54:23 | INFO | train_inner | epoch 066:   3401 / 4751 loss=4.492, nll_loss=2.886, ppl=7.39, wps=87862.8, ups=3.03, wpb=28986.3, bsz=943.7, num_updates=312100, lr=5.66048e-05, gnorm=0.487, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 08:54:56 | INFO | train_inner | epoch 066:   3501 / 4751 loss=4.468, nll_loss=2.858, ppl=7.25, wps=87653.4, ups=3.03, wpb=28891.5, bsz=960.2, num_updates=312200, lr=5.65957e-05, gnorm=0.489, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 08:55:29 | INFO | train_inner | epoch 066:   3601 / 4751 loss=4.494, nll_loss=2.888, ppl=7.4, wps=87758.4, ups=3.04, wpb=28849.8, bsz=946.2, num_updates=312300, lr=5.65867e-05, gnorm=0.489, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 08:56:02 | INFO | train_inner | epoch 066:   3701 / 4751 loss=4.473, nll_loss=2.865, ppl=7.28, wps=88396.8, ups=3.02, wpb=29243.5, bsz=989.9, num_updates=312400, lr=5.65776e-05, gnorm=0.484, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 08:56:35 | INFO | train_inner | epoch 066:   3801 / 4751 loss=4.484, nll_loss=2.876, ppl=7.34, wps=86709.3, ups=3.03, wpb=28581.5, bsz=923.5, num_updates=312500, lr=5.65685e-05, gnorm=0.492, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-06 08:57:08 | INFO | train_inner | epoch 066:   3901 / 4751 loss=4.494, nll_loss=2.887, ppl=7.4, wps=87757.4, ups=3.03, wpb=28995.9, bsz=959, num_updates=312600, lr=5.65595e-05, gnorm=0.492, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 08:57:41 | INFO | train_inner | epoch 066:   4001 / 4751 loss=4.53, nll_loss=2.928, ppl=7.61, wps=87079.3, ups=3.03, wpb=28749.5, bsz=932.1, num_updates=312700, lr=5.65504e-05, gnorm=0.495, loss_scale=4, train_wall=33, gb_free=6.5, wall=0
2021-04-06 08:58:14 | INFO | train_inner | epoch 066:   4101 / 4751 loss=4.507, nll_loss=2.902, ppl=7.48, wps=87863.8, ups=3.05, wpb=28789.4, bsz=956.8, num_updates=312800, lr=5.65414e-05, gnorm=0.494, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 08:58:47 | INFO | train_inner | epoch 066:   4201 / 4751 loss=4.483, nll_loss=2.875, ppl=7.34, wps=87048.6, ups=3, wpb=28992.9, bsz=936.5, num_updates=312900, lr=5.65324e-05, gnorm=0.492, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 08:59:20 | INFO | train_inner | epoch 066:   4301 / 4751 loss=4.483, nll_loss=2.875, ppl=7.33, wps=88716.7, ups=3.04, wpb=29148, bsz=951.6, num_updates=313000, lr=5.65233e-05, gnorm=0.491, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-06 08:59:53 | INFO | train_inner | epoch 066:   4401 / 4751 loss=4.499, nll_loss=2.893, ppl=7.43, wps=88259.3, ups=3.03, wpb=29105.9, bsz=943.1, num_updates=313100, lr=5.65143e-05, gnorm=0.493, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-06 09:00:26 | INFO | train_inner | epoch 066:   4501 / 4751 loss=4.49, nll_loss=2.883, ppl=7.38, wps=87422.7, ups=3.03, wpb=28858.8, bsz=961.7, num_updates=313200, lr=5.65053e-05, gnorm=0.496, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 09:00:59 | INFO | train_inner | epoch 066:   4601 / 4751 loss=4.469, nll_loss=2.859, ppl=7.25, wps=88606.4, ups=3.03, wpb=29215.7, bsz=981.9, num_updates=313300, lr=5.64963e-05, gnorm=0.483, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 09:01:32 | INFO | train_inner | epoch 066:   4701 / 4751 loss=4.587, nll_loss=2.993, ppl=7.96, wps=87644.4, ups=3.06, wpb=28612.5, bsz=926.1, num_updates=313400, lr=5.64873e-05, gnorm=0.499, loss_scale=4, train_wall=33, gb_free=6.6, wall=0
2021-04-06 09:01:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-06 09:01:49 | INFO | valid | epoch 066 | valid on 'valid' subset | loss 4.148 | nll_loss 2.378 | ppl 5.2 | wps 188959 | wpb 10489.1 | bsz 375 | num_updates 313450 | best_loss 4.136
2021-04-06 09:01:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 66 @ 313450 updates
2021-04-06 09:01:49 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-06 09:01:56 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-06 09:01:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt (epoch 66 @ 313450 updates, score 4.148) (writing took 6.4252116195857525 seconds)
2021-04-06 09:01:56 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)
2021-04-06 09:01:56 | INFO | train | epoch 066 | loss 4.492 | nll_loss 2.885 | ppl 7.39 | wps 87408.5 | ups 3.02 | wpb 28968.3 | bsz 947.4 | num_updates 313450 | lr 5.64828e-05 | gnorm 0.491 | loss_scale 4 | train_wall 1559 | gb_free 6.5 | wall 0
2021-04-06 09:01:56 | INFO | fairseq.trainer | begin training epoch 67
2021-04-06 09:01:56 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-06 09:02:13 | INFO | train_inner | epoch 067:     50 / 4751 loss=4.503, nll_loss=2.898, ppl=7.45, wps=68825.9, ups=2.4, wpb=28633.2, bsz=939.4, num_updates=313500, lr=5.64782e-05, gnorm=0.488, loss_scale=4, train_wall=32, gb_free=6.4, wall=0
2021-04-06 09:02:46 | INFO | train_inner | epoch 067:    150 / 4751 loss=4.503, nll_loss=2.897, ppl=7.45, wps=87808, ups=3.04, wpb=28905.5, bsz=928.8, num_updates=313600, lr=5.64692e-05, gnorm=0.492, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 09:03:19 | INFO | train_inner | epoch 067:    250 / 4751 loss=4.538, nll_loss=2.937, ppl=7.66, wps=88064.3, ups=3.05, wpb=28844.4, bsz=917.1, num_updates=313700, lr=5.64602e-05, gnorm=0.493, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 09:03:52 | INFO | train_inner | epoch 067:    350 / 4751 loss=4.482, nll_loss=2.873, ppl=7.32, wps=87012.1, ups=3.02, wpb=28797.6, bsz=950.6, num_updates=313800, lr=5.64512e-05, gnorm=0.486, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 09:04:25 | INFO | train_inner | epoch 067:    450 / 4751 loss=4.479, nll_loss=2.871, ppl=7.31, wps=87946, ups=3.03, wpb=28985.9, bsz=998.5, num_updates=313900, lr=5.64423e-05, gnorm=0.49, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 09:04:58 | INFO | train_inner | epoch 067:    550 / 4751 loss=4.475, nll_loss=2.865, ppl=7.28, wps=88784.3, ups=3.04, wpb=29216.5, bsz=913.4, num_updates=314000, lr=5.64333e-05, gnorm=0.479, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-06 09:05:31 | INFO | train_inner | epoch 067:    650 / 4751 loss=4.457, nll_loss=2.845, ppl=7.19, wps=88228.6, ups=3.03, wpb=29117.4, bsz=930.6, num_updates=314100, lr=5.64243e-05, gnorm=0.493, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 09:06:04 | INFO | train_inner | epoch 067:    750 / 4751 loss=4.529, nll_loss=2.927, ppl=7.6, wps=87457.1, ups=3.04, wpb=28766.1, bsz=907.3, num_updates=314200, lr=5.64153e-05, gnorm=0.494, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-06 09:06:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-06 09:06:37 | INFO | train_inner | epoch 067:    851 / 4751 loss=4.461, nll_loss=2.85, ppl=7.21, wps=86562.6, ups=2.98, wpb=29008.5, bsz=963.2, num_updates=314300, lr=5.64063e-05, gnorm=0.491, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 09:07:10 | INFO | train_inner | epoch 067:    951 / 4751 loss=4.409, nll_loss=2.791, ppl=6.92, wps=87774.8, ups=3.03, wpb=28924.3, bsz=945.1, num_updates=314400, lr=5.63974e-05, gnorm=0.478, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 09:07:43 | INFO | train_inner | epoch 067:   1051 / 4751 loss=4.488, nll_loss=2.881, ppl=7.37, wps=87368.1, ups=3.01, wpb=29014.8, bsz=949, num_updates=314500, lr=5.63884e-05, gnorm=0.488, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 09:08:16 | INFO | train_inner | epoch 067:   1151 / 4751 loss=4.48, nll_loss=2.871, ppl=7.32, wps=87048.3, ups=3.03, wpb=28732.7, bsz=915.4, num_updates=314600, lr=5.63794e-05, gnorm=0.489, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 09:08:49 | INFO | train_inner | epoch 067:   1251 / 4751 loss=4.446, nll_loss=2.834, ppl=7.13, wps=88917.8, ups=3.04, wpb=29230.3, bsz=979, num_updates=314700, lr=5.63705e-05, gnorm=0.484, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 09:09:23 | INFO | train_inner | epoch 067:   1351 / 4751 loss=4.48, nll_loss=2.871, ppl=7.32, wps=87086.9, ups=3.02, wpb=28884.5, bsz=952.2, num_updates=314800, lr=5.63615e-05, gnorm=0.49, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 09:09:56 | INFO | train_inner | epoch 067:   1451 / 4751 loss=4.525, nll_loss=2.923, ppl=7.58, wps=87649.2, ups=3.02, wpb=29059.9, bsz=926.9, num_updates=314900, lr=5.63526e-05, gnorm=0.492, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 09:10:29 | INFO | train_inner | epoch 067:   1551 / 4751 loss=4.52, nll_loss=2.916, ppl=7.55, wps=87432.2, ups=3.03, wpb=28886.4, bsz=914.5, num_updates=315000, lr=5.63436e-05, gnorm=0.494, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 09:11:02 | INFO | train_inner | epoch 067:   1651 / 4751 loss=4.521, nll_loss=2.917, ppl=7.55, wps=88166.5, ups=3.05, wpb=28908, bsz=939.3, num_updates=315100, lr=5.63347e-05, gnorm=0.492, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 09:11:35 | INFO | train_inner | epoch 067:   1751 / 4751 loss=4.478, nll_loss=2.869, ppl=7.31, wps=87002.4, ups=3.03, wpb=28761, bsz=952.8, num_updates=315200, lr=5.63257e-05, gnorm=0.494, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 09:12:07 | INFO | train_inner | epoch 067:   1851 / 4751 loss=4.483, nll_loss=2.875, ppl=7.34, wps=87619, ups=3.04, wpb=28845.2, bsz=966.7, num_updates=315300, lr=5.63168e-05, gnorm=0.496, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 09:12:40 | INFO | train_inner | epoch 067:   1951 / 4751 loss=4.496, nll_loss=2.889, ppl=7.41, wps=89027.6, ups=3.05, wpb=29220.6, bsz=939.4, num_updates=315400, lr=5.63079e-05, gnorm=0.488, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 09:13:13 | INFO | train_inner | epoch 067:   2051 / 4751 loss=4.432, nll_loss=2.817, ppl=7.05, wps=86701.6, ups=3.02, wpb=28685.9, bsz=930.7, num_updates=315500, lr=5.6299e-05, gnorm=0.487, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 09:13:46 | INFO | train_inner | epoch 067:   2151 / 4751 loss=4.47, nll_loss=2.86, ppl=7.26, wps=88677.5, ups=3.04, wpb=29166.7, bsz=949.8, num_updates=315600, lr=5.629e-05, gnorm=0.483, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 09:14:19 | INFO | train_inner | epoch 067:   2251 / 4751 loss=4.496, nll_loss=2.891, ppl=7.42, wps=87349.9, ups=3.03, wpb=28822.3, bsz=998.7, num_updates=315700, lr=5.62811e-05, gnorm=0.494, loss_scale=2, train_wall=33, gb_free=6.9, wall=0
2021-04-06 09:14:52 | INFO | train_inner | epoch 067:   2351 / 4751 loss=4.525, nll_loss=2.923, ppl=7.58, wps=88324.3, ups=3.05, wpb=28986.4, bsz=920.4, num_updates=315800, lr=5.62722e-05, gnorm=0.496, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 09:15:25 | INFO | train_inner | epoch 067:   2451 / 4751 loss=4.474, nll_loss=2.865, ppl=7.28, wps=88252.5, ups=3.04, wpb=29067.9, bsz=964.6, num_updates=315900, lr=5.62633e-05, gnorm=0.487, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 09:15:58 | INFO | train_inner | epoch 067:   2551 / 4751 loss=4.493, nll_loss=2.886, ppl=7.39, wps=89164.1, ups=3.07, wpb=29053.6, bsz=971, num_updates=316000, lr=5.62544e-05, gnorm=0.49, loss_scale=2, train_wall=32, gb_free=6.1, wall=0
2021-04-06 09:16:31 | INFO | train_inner | epoch 067:   2651 / 4751 loss=4.492, nll_loss=2.885, ppl=7.39, wps=87581.8, ups=3.03, wpb=28936.2, bsz=941.9, num_updates=316100, lr=5.62455e-05, gnorm=0.49, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-06 09:16:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-04-06 09:17:04 | INFO | train_inner | epoch 067:   2752 / 4751 loss=4.512, nll_loss=2.909, ppl=7.51, wps=86329, ups=3, wpb=28789.4, bsz=937, num_updates=316200, lr=5.62366e-05, gnorm=0.506, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 09:17:37 | INFO | train_inner | epoch 067:   2852 / 4751 loss=4.476, nll_loss=2.867, ppl=7.3, wps=88819.6, ups=3.03, wpb=29282.4, bsz=985, num_updates=316300, lr=5.62277e-05, gnorm=0.486, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 09:18:10 | INFO | train_inner | epoch 067:   2952 / 4751 loss=4.482, nll_loss=2.875, ppl=7.34, wps=87771, ups=3.03, wpb=28945.2, bsz=989.8, num_updates=316400, lr=5.62188e-05, gnorm=0.491, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 09:18:43 | INFO | train_inner | epoch 067:   3052 / 4751 loss=4.472, nll_loss=2.863, ppl=7.27, wps=88213.4, ups=3.03, wpb=29093.9, bsz=978.9, num_updates=316500, lr=5.62099e-05, gnorm=0.485, loss_scale=1, train_wall=33, gb_free=6.4, wall=0
2021-04-06 09:19:16 | INFO | train_inner | epoch 067:   3152 / 4751 loss=4.508, nll_loss=2.904, ppl=7.49, wps=88016.2, ups=3.04, wpb=28975.4, bsz=960.9, num_updates=316600, lr=5.62011e-05, gnorm=0.491, loss_scale=1, train_wall=33, gb_free=6.5, wall=0
2021-04-06 09:19:49 | INFO | train_inner | epoch 067:   3252 / 4751 loss=4.476, nll_loss=2.867, ppl=7.3, wps=87460.8, ups=3.03, wpb=28873.8, bsz=923.2, num_updates=316700, lr=5.61922e-05, gnorm=0.492, loss_scale=1, train_wall=33, gb_free=6, wall=0
2021-04-06 09:20:22 | INFO | train_inner | epoch 067:   3352 / 4751 loss=4.444, nll_loss=2.831, ppl=7.12, wps=87930.5, ups=3.02, wpb=29077.4, bsz=947, num_updates=316800, lr=5.61833e-05, gnorm=0.489, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 09:20:55 | INFO | train_inner | epoch 067:   3452 / 4751 loss=4.457, nll_loss=2.846, ppl=7.19, wps=87680.8, ups=3.03, wpb=28967.8, bsz=955.8, num_updates=316900, lr=5.61745e-05, gnorm=0.484, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 09:21:28 | INFO | train_inner | epoch 067:   3552 / 4751 loss=4.482, nll_loss=2.874, ppl=7.33, wps=87906.8, ups=3.04, wpb=28878.5, bsz=966.9, num_updates=317000, lr=5.61656e-05, gnorm=0.488, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 09:22:01 | INFO | train_inner | epoch 067:   3652 / 4751 loss=4.488, nll_loss=2.881, ppl=7.37, wps=87939, ups=3.04, wpb=28914.6, bsz=936.2, num_updates=317100, lr=5.61567e-05, gnorm=0.492, loss_scale=1, train_wall=33, gb_free=6.4, wall=0
2021-04-06 09:22:33 | INFO | train_inner | epoch 067:   3752 / 4751 loss=4.556, nll_loss=2.958, ppl=7.77, wps=88247.2, ups=3.05, wpb=28925.1, bsz=938.9, num_updates=317200, lr=5.61479e-05, gnorm=0.495, loss_scale=1, train_wall=33, gb_free=6.6, wall=0
2021-04-06 09:23:06 | INFO | train_inner | epoch 067:   3852 / 4751 loss=4.556, nll_loss=2.957, ppl=7.77, wps=88618.6, ups=3.04, wpb=29143.6, bsz=923, num_updates=317300, lr=5.6139e-05, gnorm=0.495, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 09:23:39 | INFO | train_inner | epoch 067:   3952 / 4751 loss=4.492, nll_loss=2.886, ppl=7.39, wps=87929.7, ups=3.04, wpb=28958.6, bsz=941, num_updates=317400, lr=5.61302e-05, gnorm=0.484, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 09:24:12 | INFO | train_inner | epoch 067:   4052 / 4751 loss=4.558, nll_loss=2.96, ppl=7.78, wps=88495.2, ups=3.06, wpb=28922.9, bsz=945.7, num_updates=317500, lr=5.61214e-05, gnorm=0.496, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 09:24:45 | INFO | train_inner | epoch 067:   4152 / 4751 loss=4.426, nll_loss=2.811, ppl=7.02, wps=89063.9, ups=3.04, wpb=29291.3, bsz=958.4, num_updates=317600, lr=5.61125e-05, gnorm=0.482, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 09:25:18 | INFO | train_inner | epoch 067:   4252 / 4751 loss=4.527, nll_loss=2.925, ppl=7.59, wps=86241.2, ups=2.99, wpb=28860.4, bsz=908.8, num_updates=317700, lr=5.61037e-05, gnorm=0.494, loss_scale=1, train_wall=33, gb_free=6.6, wall=0
2021-04-06 09:25:51 | INFO | train_inner | epoch 067:   4352 / 4751 loss=4.501, nll_loss=2.896, ppl=7.44, wps=88348.5, ups=3.05, wpb=28995.6, bsz=945, num_updates=317800, lr=5.60949e-05, gnorm=0.489, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 09:26:24 | INFO | train_inner | epoch 067:   4452 / 4751 loss=4.494, nll_loss=2.887, ppl=7.4, wps=88460.7, ups=3.05, wpb=29038, bsz=922.3, num_updates=317900, lr=5.6086e-05, gnorm=0.488, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 09:26:57 | INFO | train_inner | epoch 067:   4552 / 4751 loss=4.505, nll_loss=2.901, ppl=7.47, wps=88103.6, ups=3.03, wpb=29085.5, bsz=968.1, num_updates=318000, lr=5.60772e-05, gnorm=0.49, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 09:27:30 | INFO | train_inner | epoch 067:   4652 / 4751 loss=4.469, nll_loss=2.86, ppl=7.26, wps=88734.7, ups=3.05, wpb=29059.4, bsz=970.8, num_updates=318100, lr=5.60684e-05, gnorm=0.484, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 09:28:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-06 09:28:03 | INFO | valid | epoch 067 | valid on 'valid' subset | loss 4.146 | nll_loss 2.375 | ppl 5.19 | wps 190429 | wpb 10489.1 | bsz 375 | num_updates 318199 | best_loss 4.136
2021-04-06 09:28:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 67 @ 318199 updates
2021-04-06 09:28:03 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-06 09:28:10 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-06 09:28:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt (epoch 67 @ 318199 updates, score 4.146) (writing took 6.144610099494457 seconds)
2021-04-06 09:28:10 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)
2021-04-06 09:28:10 | INFO | train | epoch 067 | loss 4.49 | nll_loss 2.883 | ppl 7.38 | wps 87400.4 | ups 3.02 | wpb 28968.1 | bsz 946.7 | num_updates 318199 | lr 5.60597e-05 | gnorm 0.49 | loss_scale 1 | train_wall 1559 | gb_free 6.3 | wall 0
2021-04-06 09:28:10 | INFO | fairseq.trainer | begin training epoch 68
2021-04-06 09:28:10 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-06 09:28:11 | INFO | train_inner | epoch 068:      1 / 4751 loss=4.529, nll_loss=2.927, ppl=7.6, wps=69148.9, ups=2.41, wpb=28714, bsz=919.9, num_updates=318200, lr=5.60596e-05, gnorm=0.492, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 09:28:44 | INFO | train_inner | epoch 068:    101 / 4751 loss=4.46, nll_loss=2.849, ppl=7.21, wps=88156.3, ups=3.06, wpb=28814.7, bsz=943.3, num_updates=318300, lr=5.60508e-05, gnorm=0.489, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 09:29:17 | INFO | train_inner | epoch 068:    201 / 4751 loss=4.527, nll_loss=2.925, ppl=7.59, wps=87716.7, ups=3.05, wpb=28803, bsz=938.2, num_updates=318400, lr=5.6042e-05, gnorm=0.499, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 09:29:50 | INFO | train_inner | epoch 068:    301 / 4751 loss=4.444, nll_loss=2.831, ppl=7.11, wps=87986.6, ups=3.02, wpb=29087.9, bsz=950.1, num_updates=318500, lr=5.60332e-05, gnorm=0.489, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-06 09:30:23 | INFO | train_inner | epoch 068:    401 / 4751 loss=4.436, nll_loss=2.822, ppl=7.07, wps=86998, ups=3.02, wpb=28836, bsz=959.3, num_updates=318600, lr=5.60244e-05, gnorm=0.488, loss_scale=2, train_wall=33, gb_free=6.7, wall=0
2021-04-06 09:30:56 | INFO | train_inner | epoch 068:    501 / 4751 loss=4.472, nll_loss=2.863, ppl=7.27, wps=86617.3, ups=3.03, wpb=28558.7, bsz=945.5, num_updates=318700, lr=5.60156e-05, gnorm=0.492, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 09:31:29 | INFO | train_inner | epoch 068:    601 / 4751 loss=4.522, nll_loss=2.919, ppl=7.56, wps=87318.4, ups=3.05, wpb=28651.9, bsz=940.9, num_updates=318800, lr=5.60068e-05, gnorm=0.504, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-06 09:32:02 | INFO | train_inner | epoch 068:    701 / 4751 loss=4.487, nll_loss=2.879, ppl=7.36, wps=88407.6, ups=3.04, wpb=29062.6, bsz=912.6, num_updates=318900, lr=5.5998e-05, gnorm=0.49, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 09:32:34 | INFO | train_inner | epoch 068:    801 / 4751 loss=4.469, nll_loss=2.859, ppl=7.25, wps=88829.6, ups=3.06, wpb=29037.9, bsz=981, num_updates=319000, lr=5.59893e-05, gnorm=0.486, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 09:33:07 | INFO | train_inner | epoch 068:    901 / 4751 loss=4.446, nll_loss=2.833, ppl=7.13, wps=88962, ups=3.03, wpb=29313.1, bsz=958.9, num_updates=319100, lr=5.59805e-05, gnorm=0.487, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-06 09:33:40 | INFO | train_inner | epoch 068:   1001 / 4751 loss=4.515, nll_loss=2.911, ppl=7.52, wps=88049.7, ups=3.03, wpb=29063.2, bsz=904.3, num_updates=319200, lr=5.59717e-05, gnorm=0.487, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 09:34:13 | INFO | train_inner | epoch 068:   1101 / 4751 loss=4.446, nll_loss=2.833, ppl=7.13, wps=88513.4, ups=3.03, wpb=29219.4, bsz=949.7, num_updates=319300, lr=5.59629e-05, gnorm=0.486, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 09:34:46 | INFO | train_inner | epoch 068:   1201 / 4751 loss=4.537, nll_loss=2.936, ppl=7.65, wps=88014.7, ups=3.03, wpb=29016.7, bsz=957.4, num_updates=319400, lr=5.59542e-05, gnorm=0.491, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 09:35:19 | INFO | train_inner | epoch 068:   1301 / 4751 loss=4.48, nll_loss=2.872, ppl=7.32, wps=88181.3, ups=3.04, wpb=29046.1, bsz=968.1, num_updates=319500, lr=5.59454e-05, gnorm=0.494, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 09:35:52 | INFO | train_inner | epoch 068:   1401 / 4751 loss=4.487, nll_loss=2.88, ppl=7.36, wps=88296.8, ups=3.04, wpb=29069.8, bsz=937.1, num_updates=319600, lr=5.59367e-05, gnorm=0.494, loss_scale=2, train_wall=33, gb_free=6.7, wall=0
2021-04-06 09:36:25 | INFO | train_inner | epoch 068:   1501 / 4751 loss=4.484, nll_loss=2.876, ppl=7.34, wps=88213.2, ups=3.05, wpb=28917.2, bsz=953, num_updates=319700, lr=5.59279e-05, gnorm=0.488, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 09:36:58 | INFO | train_inner | epoch 068:   1601 / 4751 loss=4.501, nll_loss=2.895, ppl=7.44, wps=88185, ups=3.03, wpb=29087, bsz=930.2, num_updates=319800, lr=5.59192e-05, gnorm=0.49, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-06 09:37:31 | INFO | train_inner | epoch 068:   1701 / 4751 loss=4.454, nll_loss=2.842, ppl=7.17, wps=88265.7, ups=3.03, wpb=29126.5, bsz=946.4, num_updates=319900, lr=5.59104e-05, gnorm=0.493, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 09:38:04 | INFO | train_inner | epoch 068:   1801 / 4751 loss=4.444, nll_loss=2.831, ppl=7.12, wps=87906.5, ups=3.04, wpb=28874.6, bsz=947.8, num_updates=320000, lr=5.59017e-05, gnorm=0.488, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 09:38:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-04-06 09:38:37 | INFO | train_inner | epoch 068:   1902 / 4751 loss=4.486, nll_loss=2.878, ppl=7.35, wps=86529.4, ups=2.99, wpb=28954, bsz=937.7, num_updates=320100, lr=5.5893e-05, gnorm=0.486, loss_scale=1, train_wall=33, gb_free=6, wall=0
2021-04-06 09:39:10 | INFO | train_inner | epoch 068:   2002 / 4751 loss=4.485, nll_loss=2.877, ppl=7.35, wps=88170.6, ups=3.03, wpb=29087.8, bsz=985.8, num_updates=320200, lr=5.58842e-05, gnorm=0.485, loss_scale=1, train_wall=33, gb_free=6.6, wall=0
2021-04-06 09:39:43 | INFO | train_inner | epoch 068:   2102 / 4751 loss=4.484, nll_loss=2.877, ppl=7.34, wps=88002.2, ups=3.03, wpb=29000.3, bsz=941.2, num_updates=320300, lr=5.58755e-05, gnorm=0.488, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 09:40:16 | INFO | train_inner | epoch 068:   2202 / 4751 loss=4.429, nll_loss=2.814, ppl=7.03, wps=87019.9, ups=3.02, wpb=28850.7, bsz=944.6, num_updates=320400, lr=5.58668e-05, gnorm=0.487, loss_scale=1, train_wall=33, gb_free=6.4, wall=0
2021-04-06 09:40:49 | INFO | train_inner | epoch 068:   2302 / 4751 loss=4.548, nll_loss=2.949, ppl=7.72, wps=88858.6, ups=3.05, wpb=29148.8, bsz=932.2, num_updates=320500, lr=5.58581e-05, gnorm=0.496, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 09:41:22 | INFO | train_inner | epoch 068:   2402 / 4751 loss=4.536, nll_loss=2.935, ppl=7.65, wps=87416.6, ups=3.05, wpb=28700.5, bsz=946.6, num_updates=320600, lr=5.58494e-05, gnorm=0.498, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 09:41:55 | INFO | train_inner | epoch 068:   2502 / 4751 loss=4.457, nll_loss=2.846, ppl=7.19, wps=88022.6, ups=3.02, wpb=29145.8, bsz=947.2, num_updates=320700, lr=5.58407e-05, gnorm=0.49, loss_scale=1, train_wall=33, gb_free=5.9, wall=0
2021-04-06 09:42:28 | INFO | train_inner | epoch 068:   2602 / 4751 loss=4.478, nll_loss=2.87, ppl=7.31, wps=87636.3, ups=3.01, wpb=29087.7, bsz=953.4, num_updates=320800, lr=5.5832e-05, gnorm=0.488, loss_scale=1, train_wall=33, gb_free=6.9, wall=0
2021-04-06 09:42:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
2021-04-06 09:43:01 | INFO | train_inner | epoch 068:   2703 / 4751 loss=4.474, nll_loss=2.865, ppl=7.28, wps=87564.1, ups=3.03, wpb=28921.2, bsz=949.9, num_updates=320900, lr=5.58233e-05, gnorm=0.489, loss_scale=0.5, train_wall=33, gb_free=6.1, wall=0
2021-04-06 09:43:34 | INFO | train_inner | epoch 068:   2803 / 4751 loss=4.5, nll_loss=2.895, ppl=7.44, wps=88704.6, ups=3.05, wpb=29100.5, bsz=950, num_updates=321000, lr=5.58146e-05, gnorm=0.49, loss_scale=0.5, train_wall=33, gb_free=6.4, wall=0
2021-04-06 09:44:07 | INFO | train_inner | epoch 068:   2903 / 4751 loss=4.508, nll_loss=2.903, ppl=7.48, wps=87924.9, ups=3.04, wpb=28877.5, bsz=945.2, num_updates=321100, lr=5.58059e-05, gnorm=0.497, loss_scale=0.5, train_wall=33, gb_free=6.5, wall=0
2021-04-06 09:44:40 | INFO | train_inner | epoch 068:   3003 / 4751 loss=4.494, nll_loss=2.888, ppl=7.4, wps=86902.5, ups=3.02, wpb=28774.4, bsz=947.7, num_updates=321200, lr=5.57972e-05, gnorm=0.494, loss_scale=0.5, train_wall=33, gb_free=6.2, wall=0
2021-04-06 09:45:13 | INFO | train_inner | epoch 068:   3103 / 4751 loss=4.514, nll_loss=2.91, ppl=7.51, wps=89007.2, ups=3.03, wpb=29342, bsz=955.2, num_updates=321300, lr=5.57885e-05, gnorm=0.495, loss_scale=0.5, train_wall=33, gb_free=6.2, wall=0
2021-04-06 09:45:46 | INFO | train_inner | epoch 068:   3203 / 4751 loss=4.508, nll_loss=2.903, ppl=7.48, wps=88259.7, ups=3.05, wpb=28944.7, bsz=936.8, num_updates=321400, lr=5.57798e-05, gnorm=0.496, loss_scale=0.5, train_wall=33, gb_free=6.3, wall=0
2021-04-06 09:46:19 | INFO | train_inner | epoch 068:   3303 / 4751 loss=4.53, nll_loss=2.928, ppl=7.61, wps=87229.3, ups=3.03, wpb=28759.1, bsz=939, num_updates=321500, lr=5.57711e-05, gnorm=0.503, loss_scale=0.5, train_wall=33, gb_free=6.4, wall=0
2021-04-06 09:46:52 | INFO | train_inner | epoch 068:   3403 / 4751 loss=4.501, nll_loss=2.895, ppl=7.44, wps=86659.3, ups=3.03, wpb=28624.9, bsz=946.2, num_updates=321600, lr=5.57625e-05, gnorm=0.493, loss_scale=0.5, train_wall=33, gb_free=6.3, wall=0
2021-04-06 09:47:24 | INFO | train_inner | epoch 068:   3503 / 4751 loss=4.534, nll_loss=2.932, ppl=7.63, wps=88697.2, ups=3.06, wpb=28982.1, bsz=926.8, num_updates=321700, lr=5.57538e-05, gnorm=0.493, loss_scale=0.5, train_wall=33, gb_free=6.1, wall=0
2021-04-06 09:47:57 | INFO | train_inner | epoch 068:   3603 / 4751 loss=4.469, nll_loss=2.859, ppl=7.26, wps=87630.7, ups=3.03, wpb=28912.7, bsz=954, num_updates=321800, lr=5.57451e-05, gnorm=0.486, loss_scale=0.5, train_wall=33, gb_free=6.3, wall=0
2021-04-06 09:48:30 | INFO | train_inner | epoch 068:   3703 / 4751 loss=4.533, nll_loss=2.932, ppl=7.63, wps=87430.3, ups=3.05, wpb=28704.8, bsz=943.2, num_updates=321900, lr=5.57365e-05, gnorm=0.493, loss_scale=0.5, train_wall=33, gb_free=6.3, wall=0
2021-04-06 09:49:04 | INFO | train_inner | epoch 068:   3803 / 4751 loss=4.464, nll_loss=2.854, ppl=7.23, wps=86206.7, ups=2.98, wpb=28953.2, bsz=973.3, num_updates=322000, lr=5.57278e-05, gnorm=0.49, loss_scale=0.5, train_wall=33, gb_free=7.1, wall=0
2021-04-06 09:49:37 | INFO | train_inner | epoch 068:   3903 / 4751 loss=4.494, nll_loss=2.888, ppl=7.4, wps=87071.8, ups=3, wpb=28992.8, bsz=925.9, num_updates=322100, lr=5.57192e-05, gnorm=0.493, loss_scale=0.5, train_wall=33, gb_free=6.2, wall=0
2021-04-06 09:50:10 | INFO | train_inner | epoch 068:   4003 / 4751 loss=4.431, nll_loss=2.816, ppl=7.04, wps=88473.8, ups=3.03, wpb=29193.5, bsz=935, num_updates=322200, lr=5.57105e-05, gnorm=0.484, loss_scale=0.5, train_wall=33, gb_free=6.2, wall=0
2021-04-06 09:50:43 | INFO | train_inner | epoch 068:   4103 / 4751 loss=4.56, nll_loss=2.962, ppl=7.79, wps=88348.8, ups=3.05, wpb=28957.8, bsz=955.2, num_updates=322300, lr=5.57019e-05, gnorm=0.492, loss_scale=0.5, train_wall=33, gb_free=6.6, wall=0
2021-04-06 09:51:16 | INFO | train_inner | epoch 068:   4203 / 4751 loss=4.491, nll_loss=2.885, ppl=7.39, wps=88150.2, ups=3.03, wpb=29073.5, bsz=945.2, num_updates=322400, lr=5.56932e-05, gnorm=0.492, loss_scale=0.5, train_wall=33, gb_free=6.2, wall=0
2021-04-06 09:51:49 | INFO | train_inner | epoch 068:   4303 / 4751 loss=4.526, nll_loss=2.924, ppl=7.59, wps=87387.1, ups=3.02, wpb=28891, bsz=960.8, num_updates=322500, lr=5.56846e-05, gnorm=0.494, loss_scale=0.5, train_wall=33, gb_free=6.2, wall=0
2021-04-06 09:52:22 | INFO | train_inner | epoch 068:   4403 / 4751 loss=4.51, nll_loss=2.906, ppl=7.5, wps=88116.7, ups=3.03, wpb=29046, bsz=967.2, num_updates=322600, lr=5.5676e-05, gnorm=0.488, loss_scale=0.5, train_wall=33, gb_free=6.3, wall=0
2021-04-06 09:52:55 | INFO | train_inner | epoch 068:   4503 / 4751 loss=4.469, nll_loss=2.86, ppl=7.26, wps=87986.2, ups=3.02, wpb=29107.3, bsz=975.5, num_updates=322700, lr=5.56673e-05, gnorm=0.492, loss_scale=0.5, train_wall=33, gb_free=6, wall=0
2021-04-06 09:53:28 | INFO | train_inner | epoch 068:   4603 / 4751 loss=4.502, nll_loss=2.896, ppl=7.44, wps=89025.4, ups=3.06, wpb=29064.5, bsz=916.5, num_updates=322800, lr=5.56587e-05, gnorm=0.488, loss_scale=0.5, train_wall=33, gb_free=6, wall=0
2021-04-06 09:54:01 | INFO | train_inner | epoch 068:   4703 / 4751 loss=4.484, nll_loss=2.877, ppl=7.34, wps=86872.7, ups=3.03, wpb=28703.9, bsz=928.8, num_updates=322900, lr=5.56501e-05, gnorm=0.499, loss_scale=0.5, train_wall=33, gb_free=6.1, wall=0
2021-04-06 09:54:16 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-06 09:54:18 | INFO | valid | epoch 068 | valid on 'valid' subset | loss 4.129 | nll_loss 2.36 | ppl 5.13 | wps 209544 | wpb 10489.1 | bsz 375 | num_updates 322948 | best_loss 4.129
2021-04-06 09:54:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 68 @ 322948 updates
2021-04-06 09:54:18 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-06 09:54:24 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-06 09:54:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt (epoch 68 @ 322948 updates, score 4.129) (writing took 13.508468326181173 seconds)
2021-04-06 09:54:31 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)
2021-04-06 09:54:31 | INFO | train | epoch 068 | loss 4.489 | nll_loss 2.882 | ppl 7.37 | wps 86986.7 | ups 3 | wpb 28968.1 | bsz 946.7 | num_updates 322948 | lr 5.5646e-05 | gnorm 0.491 | loss_scale 1 | train_wall 1559 | gb_free 6.4 | wall 0
2021-04-06 09:54:31 | INFO | fairseq.trainer | begin training epoch 69
2021-04-06 09:54:31 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-06 09:54:49 | INFO | train_inner | epoch 069:     52 / 4751 loss=4.484, nll_loss=2.876, ppl=7.34, wps=59372.6, ups=2.05, wpb=28910.7, bsz=933.8, num_updates=323000, lr=5.56415e-05, gnorm=0.497, loss_scale=1, train_wall=32, gb_free=6.1, wall=0
2021-04-06 09:55:22 | INFO | train_inner | epoch 069:    152 / 4751 loss=4.494, nll_loss=2.887, ppl=7.4, wps=88067.7, ups=3.05, wpb=28854, bsz=929.8, num_updates=323100, lr=5.56329e-05, gnorm=0.494, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 09:55:55 | INFO | train_inner | epoch 069:    252 / 4751 loss=4.449, nll_loss=2.836, ppl=7.14, wps=87177.7, ups=3.01, wpb=28965.6, bsz=955, num_updates=323200, lr=5.56243e-05, gnorm=0.488, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 09:56:28 | INFO | train_inner | epoch 069:    352 / 4751 loss=4.511, nll_loss=2.907, ppl=7.5, wps=87529.4, ups=3.05, wpb=28653.1, bsz=917.5, num_updates=323300, lr=5.56157e-05, gnorm=0.497, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 09:57:01 | INFO | train_inner | epoch 069:    452 / 4751 loss=4.465, nll_loss=2.854, ppl=7.23, wps=86648.3, ups=3.02, wpb=28705.4, bsz=927.2, num_updates=323400, lr=5.56071e-05, gnorm=0.494, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 09:57:34 | INFO | train_inner | epoch 069:    552 / 4751 loss=4.5, nll_loss=2.894, ppl=7.43, wps=87983.1, ups=3.04, wpb=28983.5, bsz=931.8, num_updates=323500, lr=5.55985e-05, gnorm=0.493, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 09:58:07 | INFO | train_inner | epoch 069:    652 / 4751 loss=4.446, nll_loss=2.833, ppl=7.12, wps=88948.1, ups=3.05, wpb=29202.2, bsz=977.3, num_updates=323600, lr=5.55899e-05, gnorm=0.522, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 09:58:40 | INFO | train_inner | epoch 069:    752 / 4751 loss=4.453, nll_loss=2.842, ppl=7.17, wps=87814.5, ups=3.02, wpb=29040.1, bsz=986.9, num_updates=323700, lr=5.55813e-05, gnorm=0.491, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 09:59:13 | INFO | train_inner | epoch 069:    852 / 4751 loss=4.44, nll_loss=2.827, ppl=7.1, wps=88235.8, ups=3.03, wpb=29141.5, bsz=946.1, num_updates=323800, lr=5.55727e-05, gnorm=0.488, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 09:59:46 | INFO | train_inner | epoch 069:    952 / 4751 loss=4.475, nll_loss=2.867, ppl=7.29, wps=88410, ups=3.03, wpb=29139.4, bsz=978.6, num_updates=323900, lr=5.55641e-05, gnorm=0.49, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 10:00:19 | INFO | train_inner | epoch 069:   1052 / 4751 loss=4.426, nll_loss=2.811, ppl=7.02, wps=87776, ups=3.02, wpb=29081, bsz=981.2, num_updates=324000, lr=5.55556e-05, gnorm=0.485, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 10:00:52 | INFO | train_inner | epoch 069:   1152 / 4751 loss=4.53, nll_loss=2.928, ppl=7.61, wps=88776.6, ups=3.04, wpb=29157.1, bsz=950.5, num_updates=324100, lr=5.5547e-05, gnorm=0.49, loss_scale=1, train_wall=33, gb_free=5.7, wall=0
2021-04-06 10:01:25 | INFO | train_inner | epoch 069:   1252 / 4751 loss=4.45, nll_loss=2.837, ppl=7.14, wps=88298.1, ups=3.04, wpb=29069.2, bsz=962.6, num_updates=324200, lr=5.55384e-05, gnorm=0.491, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 10:01:58 | INFO | train_inner | epoch 069:   1352 / 4751 loss=4.469, nll_loss=2.859, ppl=7.25, wps=87442, ups=3.02, wpb=28932.5, bsz=968.8, num_updates=324300, lr=5.55299e-05, gnorm=0.494, loss_scale=1, train_wall=33, gb_free=6.6, wall=0
2021-04-06 10:02:31 | INFO | train_inner | epoch 069:   1452 / 4751 loss=4.466, nll_loss=2.856, ppl=7.24, wps=87233.9, ups=3.01, wpb=28986, bsz=940.6, num_updates=324400, lr=5.55213e-05, gnorm=0.485, loss_scale=1, train_wall=33, gb_free=6, wall=0
2021-04-06 10:03:04 | INFO | train_inner | epoch 069:   1552 / 4751 loss=4.485, nll_loss=2.877, ppl=7.35, wps=88220.7, ups=3.05, wpb=28961.2, bsz=973.8, num_updates=324500, lr=5.55127e-05, gnorm=0.521, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 10:03:37 | INFO | train_inner | epoch 069:   1652 / 4751 loss=4.459, nll_loss=2.848, ppl=7.2, wps=88442.5, ups=3.05, wpb=28990.6, bsz=944.6, num_updates=324600, lr=5.55042e-05, gnorm=0.491, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 10:04:10 | INFO | train_inner | epoch 069:   1752 / 4751 loss=4.438, nll_loss=2.824, ppl=7.08, wps=87365.4, ups=3.02, wpb=28897.3, bsz=1002, num_updates=324700, lr=5.54956e-05, gnorm=0.486, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 10:04:43 | INFO | train_inner | epoch 069:   1852 / 4751 loss=4.473, nll_loss=2.864, ppl=7.28, wps=88423.8, ups=3.04, wpb=29076.8, bsz=948.2, num_updates=324800, lr=5.54871e-05, gnorm=0.493, loss_scale=1, train_wall=33, gb_free=6, wall=0
2021-04-06 10:05:16 | INFO | train_inner | epoch 069:   1952 / 4751 loss=4.518, nll_loss=2.915, ppl=7.54, wps=87636.8, ups=3.03, wpb=28913.1, bsz=945, num_updates=324900, lr=5.54786e-05, gnorm=0.499, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 10:05:49 | INFO | train_inner | epoch 069:   2052 / 4751 loss=4.526, nll_loss=2.924, ppl=7.59, wps=88328.9, ups=3.05, wpb=28919.4, bsz=931.7, num_updates=325000, lr=5.547e-05, gnorm=0.493, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 10:06:22 | INFO | train_inner | epoch 069:   2152 / 4751 loss=4.53, nll_loss=2.928, ppl=7.61, wps=88312.6, ups=3.04, wpb=29026.5, bsz=950.4, num_updates=325100, lr=5.54615e-05, gnorm=0.496, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 10:06:54 | INFO | train_inner | epoch 069:   2252 / 4751 loss=4.454, nll_loss=2.843, ppl=7.17, wps=88135.3, ups=3.04, wpb=28946.7, bsz=963.6, num_updates=325200, lr=5.5453e-05, gnorm=0.485, loss_scale=2, train_wall=33, gb_free=6.6, wall=0
2021-04-06 10:07:27 | INFO | train_inner | epoch 069:   2352 / 4751 loss=4.468, nll_loss=2.858, ppl=7.25, wps=86862.9, ups=3.03, wpb=28652.8, bsz=940, num_updates=325300, lr=5.54444e-05, gnorm=0.489, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 10:08:01 | INFO | train_inner | epoch 069:   2452 / 4751 loss=4.456, nll_loss=2.845, ppl=7.18, wps=87842.3, ups=3.01, wpb=29150, bsz=930.9, num_updates=325400, lr=5.54359e-05, gnorm=0.488, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 10:08:33 | INFO | train_inner | epoch 069:   2552 / 4751 loss=4.487, nll_loss=2.879, ppl=7.36, wps=88688.2, ups=3.04, wpb=29138.4, bsz=933.3, num_updates=325500, lr=5.54274e-05, gnorm=0.49, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 10:09:06 | INFO | train_inner | epoch 069:   2652 / 4751 loss=4.507, nll_loss=2.902, ppl=7.48, wps=87701.8, ups=3.03, wpb=28914.3, bsz=942.9, num_updates=325600, lr=5.54189e-05, gnorm=0.49, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 10:09:39 | INFO | train_inner | epoch 069:   2752 / 4751 loss=4.47, nll_loss=2.861, ppl=7.27, wps=87430.7, ups=3.03, wpb=28852.2, bsz=978.9, num_updates=325700, lr=5.54104e-05, gnorm=0.489, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 10:10:12 | INFO | train_inner | epoch 069:   2852 / 4751 loss=4.563, nll_loss=2.965, ppl=7.81, wps=87456.9, ups=3.03, wpb=28837.8, bsz=937.9, num_updates=325800, lr=5.54019e-05, gnorm=0.495, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 10:10:45 | INFO | train_inner | epoch 069:   2952 / 4751 loss=4.54, nll_loss=2.939, ppl=7.67, wps=87994.2, ups=3.03, wpb=29008.6, bsz=924, num_updates=325900, lr=5.53934e-05, gnorm=0.494, loss_scale=2, train_wall=33, gb_free=6.7, wall=0
2021-04-06 10:11:18 | INFO | train_inner | epoch 069:   3052 / 4751 loss=4.504, nll_loss=2.899, ppl=7.46, wps=88492.1, ups=3.04, wpb=29143, bsz=923.3, num_updates=326000, lr=5.53849e-05, gnorm=0.489, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 10:11:51 | INFO | train_inner | epoch 069:   3152 / 4751 loss=4.422, nll_loss=2.806, ppl=7, wps=89094.6, ups=3.03, wpb=29383.5, bsz=977.1, num_updates=326100, lr=5.53764e-05, gnorm=0.485, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-06 10:12:24 | INFO | train_inner | epoch 069:   3252 / 4751 loss=4.495, nll_loss=2.888, ppl=7.4, wps=87287.5, ups=3.04, wpb=28730.9, bsz=957.4, num_updates=326200, lr=5.53679e-05, gnorm=0.521, loss_scale=2, train_wall=33, gb_free=6.7, wall=0
2021-04-06 10:12:57 | INFO | train_inner | epoch 069:   3352 / 4751 loss=4.424, nll_loss=2.808, ppl=7.01, wps=88055.6, ups=3.04, wpb=28989.1, bsz=949.3, num_updates=326300, lr=5.53594e-05, gnorm=0.487, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 10:13:30 | INFO | train_inner | epoch 069:   3452 / 4751 loss=4.509, nll_loss=2.904, ppl=7.49, wps=87528.2, ups=3.04, wpb=28800.6, bsz=915.4, num_updates=326400, lr=5.53509e-05, gnorm=0.496, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 10:14:03 | INFO | train_inner | epoch 069:   3552 / 4751 loss=4.504, nll_loss=2.898, ppl=7.46, wps=87667, ups=3.05, wpb=28787.3, bsz=962.8, num_updates=326500, lr=5.53425e-05, gnorm=0.491, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 10:14:36 | INFO | train_inner | epoch 069:   3652 / 4751 loss=4.494, nll_loss=2.887, ppl=7.4, wps=89409, ups=3.05, wpb=29323.6, bsz=922, num_updates=326600, lr=5.5334e-05, gnorm=0.493, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 10:15:09 | INFO | train_inner | epoch 069:   3752 / 4751 loss=4.532, nll_loss=2.931, ppl=7.63, wps=87489.7, ups=3.03, wpb=28848, bsz=941, num_updates=326700, lr=5.53255e-05, gnorm=0.494, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 10:15:41 | INFO | train_inner | epoch 069:   3852 / 4751 loss=4.51, nll_loss=2.906, ppl=7.49, wps=88972.1, ups=3.04, wpb=29230.5, bsz=927.7, num_updates=326800, lr=5.5317e-05, gnorm=0.493, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 10:16:15 | INFO | train_inner | epoch 069:   3952 / 4751 loss=4.548, nll_loss=2.948, ppl=7.72, wps=87408.3, ups=3, wpb=29134.1, bsz=918.1, num_updates=326900, lr=5.53086e-05, gnorm=0.489, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 10:16:48 | INFO | train_inner | epoch 069:   4052 / 4751 loss=4.489, nll_loss=2.882, ppl=7.37, wps=88045.9, ups=3.04, wpb=28949.7, bsz=928.5, num_updates=327000, lr=5.53001e-05, gnorm=0.494, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 10:17:21 | INFO | train_inner | epoch 069:   4152 / 4751 loss=4.527, nll_loss=2.925, ppl=7.6, wps=88333.4, ups=3.03, wpb=29165.4, bsz=953.6, num_updates=327100, lr=5.52917e-05, gnorm=0.497, loss_scale=4, train_wall=33, gb_free=6.4, wall=0
2021-04-06 10:17:54 | INFO | train_inner | epoch 069:   4252 / 4751 loss=4.558, nll_loss=2.96, ppl=7.78, wps=87043.7, ups=3.04, wpb=28665, bsz=919.9, num_updates=327200, lr=5.52832e-05, gnorm=0.501, loss_scale=4, train_wall=33, gb_free=6.4, wall=0
2021-04-06 10:18:27 | INFO | train_inner | epoch 069:   4352 / 4751 loss=4.443, nll_loss=2.831, ppl=7.11, wps=87620.7, ups=3.01, wpb=29066.3, bsz=971, num_updates=327300, lr=5.52748e-05, gnorm=0.488, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 10:19:00 | INFO | train_inner | epoch 069:   4452 / 4751 loss=4.535, nll_loss=2.934, ppl=7.64, wps=87864.6, ups=3.03, wpb=28981.2, bsz=938.9, num_updates=327400, lr=5.52663e-05, gnorm=0.491, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 10:19:33 | INFO | train_inner | epoch 069:   4552 / 4751 loss=4.445, nll_loss=2.833, ppl=7.13, wps=88078.1, ups=3.04, wpb=28926.1, bsz=980.6, num_updates=327500, lr=5.52579e-05, gnorm=0.49, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 10:20:06 | INFO | train_inner | epoch 069:   4652 / 4751 loss=4.486, nll_loss=2.879, ppl=7.36, wps=87225, ups=3.02, wpb=28848.9, bsz=941.4, num_updates=327600, lr=5.52495e-05, gnorm=0.499, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 10:20:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-06 10:20:39 | INFO | valid | epoch 069 | valid on 'valid' subset | loss 4.137 | nll_loss 2.369 | ppl 5.17 | wps 197620 | wpb 10489.1 | bsz 375 | num_updates 327699 | best_loss 4.129
2021-04-06 10:20:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 69 @ 327699 updates
2021-04-06 10:20:39 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-06 10:20:45 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-06 10:20:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt (epoch 69 @ 327699 updates, score 4.137) (writing took 6.157039433717728 seconds)
2021-04-06 10:20:45 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)
2021-04-06 10:20:45 | INFO | train | epoch 069 | loss 4.488 | nll_loss 2.88 | ppl 7.36 | wps 87421.8 | ups 3.02 | wpb 28968.3 | bsz 947.4 | num_updates 327699 | lr 5.52411e-05 | gnorm 0.494 | loss_scale 4 | train_wall 1559 | gb_free 6.3 | wall 0
2021-04-06 10:20:46 | INFO | fairseq.trainer | begin training epoch 70
2021-04-06 10:20:46 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-06 10:20:47 | INFO | train_inner | epoch 070:      1 / 4751 loss=4.538, nll_loss=2.937, ppl=7.66, wps=68633.1, ups=2.42, wpb=28418.5, bsz=912.5, num_updates=327700, lr=5.5241e-05, gnorm=0.498, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 10:21:20 | INFO | train_inner | epoch 070:    101 / 4751 loss=4.477, nll_loss=2.868, ppl=7.3, wps=88691, ups=3.03, wpb=29240, bsz=943.6, num_updates=327800, lr=5.52326e-05, gnorm=0.498, loss_scale=4, train_wall=33, gb_free=6.7, wall=0
2021-04-06 10:21:53 | INFO | train_inner | epoch 070:    201 / 4751 loss=4.451, nll_loss=2.839, ppl=7.16, wps=87261.2, ups=3.02, wpb=28861.2, bsz=993.8, num_updates=327900, lr=5.52242e-05, gnorm=0.503, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 10:22:26 | INFO | train_inner | epoch 070:    301 / 4751 loss=4.48, nll_loss=2.872, ppl=7.32, wps=87980.7, ups=3.04, wpb=28963.8, bsz=979.6, num_updates=328000, lr=5.52158e-05, gnorm=0.489, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 10:22:59 | INFO | train_inner | epoch 070:    401 / 4751 loss=4.495, nll_loss=2.889, ppl=7.41, wps=87451.5, ups=3.03, wpb=28821.9, bsz=953.8, num_updates=328100, lr=5.52073e-05, gnorm=0.507, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 10:23:32 | INFO | train_inner | epoch 070:    501 / 4751 loss=4.524, nll_loss=2.921, ppl=7.58, wps=86252.4, ups=3.01, wpb=28644.2, bsz=929.4, num_updates=328200, lr=5.51989e-05, gnorm=0.504, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 10:24:05 | INFO | train_inner | epoch 070:    601 / 4751 loss=4.477, nll_loss=2.868, ppl=7.3, wps=88267.7, ups=3.04, wpb=29004.7, bsz=933.3, num_updates=328300, lr=5.51905e-05, gnorm=0.493, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 10:24:38 | INFO | train_inner | epoch 070:    701 / 4751 loss=4.495, nll_loss=2.888, ppl=7.4, wps=88487.6, ups=3.05, wpb=28977.9, bsz=934.5, num_updates=328400, lr=5.51821e-05, gnorm=0.491, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 10:25:11 | INFO | train_inner | epoch 070:    801 / 4751 loss=4.454, nll_loss=2.842, ppl=7.17, wps=86898.3, ups=3, wpb=28968, bsz=989, num_updates=328500, lr=5.51737e-05, gnorm=0.493, loss_scale=4, train_wall=33, gb_free=6.6, wall=0
2021-04-06 10:25:44 | INFO | train_inner | epoch 070:    901 / 4751 loss=4.427, nll_loss=2.812, ppl=7.02, wps=88397.3, ups=3.03, wpb=29177.8, bsz=993.9, num_updates=328600, lr=5.51653e-05, gnorm=0.485, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 10:26:18 | INFO | train_inner | epoch 070:   1001 / 4751 loss=4.507, nll_loss=2.902, ppl=7.48, wps=87133, ups=2.98, wpb=29198.8, bsz=928.1, num_updates=328700, lr=5.51569e-05, gnorm=0.491, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-06 10:26:51 | INFO | train_inner | epoch 070:   1101 / 4751 loss=4.479, nll_loss=2.871, ppl=7.31, wps=86840.1, ups=3.01, wpb=28806.6, bsz=937.6, num_updates=328800, lr=5.51485e-05, gnorm=0.498, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 10:27:24 | INFO | train_inner | epoch 070:   1201 / 4751 loss=4.55, nll_loss=2.95, ppl=7.73, wps=87948.6, ups=3.05, wpb=28848.4, bsz=904.2, num_updates=328900, lr=5.51402e-05, gnorm=0.495, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-06 10:27:57 | INFO | train_inner | epoch 070:   1301 / 4751 loss=4.487, nll_loss=2.879, ppl=7.36, wps=88638.2, ups=3.04, wpb=29187.3, bsz=906.5, num_updates=329000, lr=5.51318e-05, gnorm=0.483, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 10:28:29 | INFO | train_inner | epoch 070:   1401 / 4751 loss=4.486, nll_loss=2.879, ppl=7.36, wps=89274.1, ups=3.05, wpb=29295.1, bsz=975.6, num_updates=329100, lr=5.51234e-05, gnorm=0.485, loss_scale=8, train_wall=33, gb_free=5.9, wall=0
2021-04-06 10:28:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2021-04-06 10:29:03 | INFO | train_inner | epoch 070:   1502 / 4751 loss=4.473, nll_loss=2.863, ppl=7.28, wps=86446.7, ups=3, wpb=28839.5, bsz=949.8, num_updates=329200, lr=5.5115e-05, gnorm=0.5, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 10:29:36 | INFO | train_inner | epoch 070:   1602 / 4751 loss=4.518, nll_loss=2.915, ppl=7.54, wps=86347.4, ups=3, wpb=28735, bsz=953.8, num_updates=329300, lr=5.51067e-05, gnorm=0.498, loss_scale=4, train_wall=33, gb_free=6.5, wall=0
2021-04-06 10:30:09 | INFO | train_inner | epoch 070:   1702 / 4751 loss=4.449, nll_loss=2.836, ppl=7.14, wps=87890.2, ups=3.03, wpb=28983.7, bsz=936.3, num_updates=329400, lr=5.50983e-05, gnorm=0.493, loss_scale=4, train_wall=33, gb_free=6.4, wall=0
2021-04-06 10:30:42 | INFO | train_inner | epoch 070:   1802 / 4751 loss=4.467, nll_loss=2.857, ppl=7.25, wps=87465.7, ups=3.03, wpb=28890, bsz=954.9, num_updates=329500, lr=5.50899e-05, gnorm=0.493, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-06 10:31:15 | INFO | train_inner | epoch 070:   1902 / 4751 loss=4.488, nll_loss=2.88, ppl=7.36, wps=88250.1, ups=3.04, wpb=28998.2, bsz=974.7, num_updates=329600, lr=5.50816e-05, gnorm=0.49, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 10:31:48 | INFO | train_inner | epoch 070:   2002 / 4751 loss=4.47, nll_loss=2.86, ppl=7.26, wps=87455.7, ups=3.04, wpb=28769.7, bsz=952.2, num_updates=329700, lr=5.50732e-05, gnorm=0.497, loss_scale=4, train_wall=33, gb_free=6.5, wall=0
2021-04-06 10:32:21 | INFO | train_inner | epoch 070:   2102 / 4751 loss=4.545, nll_loss=2.946, ppl=7.7, wps=87633.3, ups=3.03, wpb=28906.4, bsz=938.4, num_updates=329800, lr=5.50649e-05, gnorm=0.494, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 10:32:54 | INFO | train_inner | epoch 070:   2202 / 4751 loss=4.479, nll_loss=2.871, ppl=7.31, wps=88073, ups=3.04, wpb=29014, bsz=935.3, num_updates=329900, lr=5.50565e-05, gnorm=0.489, loss_scale=4, train_wall=33, gb_free=6.4, wall=0
2021-04-06 10:33:02 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-06 10:33:27 | INFO | train_inner | epoch 070:   2303 / 4751 loss=4.46, nll_loss=2.85, ppl=7.21, wps=87358.8, ups=3, wpb=29088.1, bsz=953.5, num_updates=330000, lr=5.50482e-05, gnorm=0.497, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 10:34:00 | INFO | train_inner | epoch 070:   2403 / 4751 loss=4.465, nll_loss=2.855, ppl=7.24, wps=87527.7, ups=3.01, wpb=29076, bsz=951.4, num_updates=330100, lr=5.50398e-05, gnorm=0.491, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 10:34:33 | INFO | train_inner | epoch 070:   2503 / 4751 loss=4.54, nll_loss=2.939, ppl=7.67, wps=88114.7, ups=3.04, wpb=28990.4, bsz=911.7, num_updates=330200, lr=5.50315e-05, gnorm=0.495, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 10:35:06 | INFO | train_inner | epoch 070:   2603 / 4751 loss=4.502, nll_loss=2.897, ppl=7.45, wps=88014.5, ups=3.05, wpb=28856.7, bsz=944.2, num_updates=330300, lr=5.50232e-05, gnorm=0.501, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 10:35:39 | INFO | train_inner | epoch 070:   2703 / 4751 loss=4.448, nll_loss=2.835, ppl=7.14, wps=88696.5, ups=3.05, wpb=29128, bsz=972.4, num_updates=330400, lr=5.50149e-05, gnorm=0.484, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 10:36:12 | INFO | train_inner | epoch 070:   2803 / 4751 loss=4.449, nll_loss=2.837, ppl=7.15, wps=88421.9, ups=3.04, wpb=29049.9, bsz=955.8, num_updates=330500, lr=5.50065e-05, gnorm=0.495, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 10:36:45 | INFO | train_inner | epoch 070:   2903 / 4751 loss=4.474, nll_loss=2.865, ppl=7.29, wps=88686.1, ups=3.04, wpb=29208.3, bsz=947.4, num_updates=330600, lr=5.49982e-05, gnorm=0.481, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 10:37:18 | INFO | train_inner | epoch 070:   3003 / 4751 loss=4.516, nll_loss=2.912, ppl=7.53, wps=88400.5, ups=3.03, wpb=29141.8, bsz=955.3, num_updates=330700, lr=5.49899e-05, gnorm=0.501, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 10:37:50 | INFO | train_inner | epoch 070:   3103 / 4751 loss=4.498, nll_loss=2.892, ppl=7.42, wps=88221.3, ups=3.04, wpb=29027.7, bsz=922.2, num_updates=330800, lr=5.49816e-05, gnorm=0.49, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 10:38:23 | INFO | train_inner | epoch 070:   3203 / 4751 loss=4.521, nll_loss=2.918, ppl=7.56, wps=88252, ups=3.04, wpb=29004.2, bsz=929.5, num_updates=330900, lr=5.49733e-05, gnorm=0.495, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 10:38:56 | INFO | train_inner | epoch 070:   3303 / 4751 loss=4.491, nll_loss=2.885, ppl=7.38, wps=88152.9, ups=3.05, wpb=28932.6, bsz=946.8, num_updates=331000, lr=5.4965e-05, gnorm=0.493, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 10:39:29 | INFO | train_inner | epoch 070:   3403 / 4751 loss=4.504, nll_loss=2.899, ppl=7.46, wps=87962.9, ups=3.04, wpb=28966.2, bsz=944.4, num_updates=331100, lr=5.49567e-05, gnorm=0.491, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 10:40:02 | INFO | train_inner | epoch 070:   3503 / 4751 loss=4.449, nll_loss=2.837, ppl=7.14, wps=88357, ups=3.03, wpb=29193.5, bsz=951.6, num_updates=331200, lr=5.49484e-05, gnorm=0.491, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 10:40:35 | INFO | train_inner | epoch 070:   3603 / 4751 loss=4.465, nll_loss=2.855, ppl=7.24, wps=88289.2, ups=3.03, wpb=29185.7, bsz=977.7, num_updates=331300, lr=5.49401e-05, gnorm=0.489, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 10:41:08 | INFO | train_inner | epoch 070:   3703 / 4751 loss=4.483, nll_loss=2.875, ppl=7.34, wps=87752.1, ups=3.03, wpb=28956.4, bsz=949.5, num_updates=331400, lr=5.49318e-05, gnorm=0.498, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 10:41:41 | INFO | train_inner | epoch 070:   3803 / 4751 loss=4.506, nll_loss=2.901, ppl=7.47, wps=86651.7, ups=3.03, wpb=28576.7, bsz=901.4, num_updates=331500, lr=5.49235e-05, gnorm=0.5, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 10:42:14 | INFO | train_inner | epoch 070:   3903 / 4751 loss=4.479, nll_loss=2.871, ppl=7.32, wps=88268.7, ups=3.05, wpb=28974.6, bsz=959, num_updates=331600, lr=5.49152e-05, gnorm=0.499, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 10:42:47 | INFO | train_inner | epoch 070:   4003 / 4751 loss=4.472, nll_loss=2.863, ppl=7.28, wps=87601.1, ups=3.04, wpb=28825.6, bsz=987.8, num_updates=331700, lr=5.49069e-05, gnorm=0.498, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 10:43:20 | INFO | train_inner | epoch 070:   4103 / 4751 loss=4.496, nll_loss=2.89, ppl=7.41, wps=87756, ups=3.03, wpb=28943.7, bsz=941.4, num_updates=331800, lr=5.48987e-05, gnorm=0.494, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 10:43:53 | INFO | train_inner | epoch 070:   4203 / 4751 loss=4.514, nll_loss=2.91, ppl=7.52, wps=86475.9, ups=3.02, wpb=28634.7, bsz=911.6, num_updates=331900, lr=5.48904e-05, gnorm=0.494, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 10:44:26 | INFO | train_inner | epoch 070:   4303 / 4751 loss=4.474, nll_loss=2.865, ppl=7.29, wps=88567.5, ups=3.04, wpb=29087.4, bsz=924.9, num_updates=332000, lr=5.48821e-05, gnorm=0.491, loss_scale=4, train_wall=33, gb_free=6, wall=0
2021-04-06 10:44:59 | INFO | train_inner | epoch 070:   4403 / 4751 loss=4.506, nll_loss=2.902, ppl=7.48, wps=87322.3, ups=3.04, wpb=28769.8, bsz=977, num_updates=332100, lr=5.48739e-05, gnorm=0.501, loss_scale=4, train_wall=33, gb_free=6.5, wall=0
2021-04-06 10:45:32 | INFO | train_inner | epoch 070:   4503 / 4751 loss=4.501, nll_loss=2.896, ppl=7.44, wps=87690.3, ups=3.04, wpb=28843.6, bsz=916.4, num_updates=332200, lr=5.48656e-05, gnorm=0.499, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 10:46:04 | INFO | train_inner | epoch 070:   4603 / 4751 loss=4.506, nll_loss=2.901, ppl=7.47, wps=88657.5, ups=3.05, wpb=29093.7, bsz=920.1, num_updates=332300, lr=5.48574e-05, gnorm=0.497, loss_scale=4, train_wall=33, gb_free=6.5, wall=0
2021-04-06 10:46:37 | INFO | train_inner | epoch 070:   4703 / 4751 loss=4.452, nll_loss=2.84, ppl=7.16, wps=88187.4, ups=3.04, wpb=29036.2, bsz=950.8, num_updates=332400, lr=5.48491e-05, gnorm=0.496, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 10:46:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-06 10:46:54 | INFO | valid | epoch 070 | valid on 'valid' subset | loss 4.134 | nll_loss 2.366 | ppl 5.16 | wps 180853 | wpb 10489.1 | bsz 375 | num_updates 332448 | best_loss 4.129
2021-04-06 10:46:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 70 @ 332448 updates
2021-04-06 10:46:54 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-06 10:47:01 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-06 10:47:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt (epoch 70 @ 332448 updates, score 4.134) (writing took 6.526990905404091 seconds)
2021-04-06 10:47:01 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)
2021-04-06 10:47:01 | INFO | train | epoch 070 | loss 4.487 | nll_loss 2.879 | ppl 7.36 | wps 87320.9 | ups 3.01 | wpb 28967.7 | bsz 946.8 | num_updates 332448 | lr 5.48451e-05 | gnorm 0.494 | loss_scale 4 | train_wall 1559 | gb_free 6.3 | wall 0
2021-04-06 10:47:01 | INFO | fairseq.trainer | begin training epoch 71
2021-04-06 10:47:01 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-06 10:47:19 | INFO | train_inner | epoch 071:     52 / 4751 loss=4.537, nll_loss=2.937, ppl=7.66, wps=67648.5, ups=2.39, wpb=28321.5, bsz=908.9, num_updates=332500, lr=5.48408e-05, gnorm=0.502, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-06 10:47:52 | INFO | train_inner | epoch 071:    152 / 4751 loss=4.475, nll_loss=2.865, ppl=7.29, wps=88381.1, ups=3.06, wpb=28890.5, bsz=945.9, num_updates=332600, lr=5.48326e-05, gnorm=0.492, loss_scale=4, train_wall=33, gb_free=6.8, wall=0
2021-04-06 10:48:25 | INFO | train_inner | epoch 071:    252 / 4751 loss=4.474, nll_loss=2.865, ppl=7.28, wps=86231.3, ups=3.03, wpb=28418.2, bsz=939.8, num_updates=332700, lr=5.48244e-05, gnorm=0.504, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-06 10:48:58 | INFO | train_inner | epoch 071:    352 / 4751 loss=4.563, nll_loss=2.965, ppl=7.81, wps=88471.5, ups=3.06, wpb=28952.4, bsz=905.6, num_updates=332800, lr=5.48161e-05, gnorm=0.496, loss_scale=4, train_wall=33, gb_free=6.5, wall=0
2021-04-06 10:49:31 | INFO | train_inner | epoch 071:    452 / 4751 loss=4.514, nll_loss=2.909, ppl=7.51, wps=86887.2, ups=3.01, wpb=28837.1, bsz=927.9, num_updates=332900, lr=5.48079e-05, gnorm=0.501, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 10:50:04 | INFO | train_inner | epoch 071:    552 / 4751 loss=4.485, nll_loss=2.877, ppl=7.35, wps=87702.8, ups=3.03, wpb=28897.5, bsz=939.1, num_updates=333000, lr=5.47997e-05, gnorm=0.491, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 10:50:37 | INFO | train_inner | epoch 071:    652 / 4751 loss=4.464, nll_loss=2.853, ppl=7.23, wps=88084.3, ups=3.04, wpb=28975.1, bsz=949.1, num_updates=333100, lr=5.47914e-05, gnorm=0.494, loss_scale=4, train_wall=33, gb_free=6.5, wall=0
2021-04-06 10:51:09 | INFO | train_inner | epoch 071:    752 / 4751 loss=4.491, nll_loss=2.884, ppl=7.38, wps=88085, ups=3.04, wpb=28932.1, bsz=950.5, num_updates=333200, lr=5.47832e-05, gnorm=0.491, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 10:51:43 | INFO | train_inner | epoch 071:    852 / 4751 loss=4.537, nll_loss=2.935, ppl=7.65, wps=87538.3, ups=3.02, wpb=29009.7, bsz=956.2, num_updates=333300, lr=5.4775e-05, gnorm=0.508, loss_scale=4, train_wall=33, gb_free=6.7, wall=0
2021-04-06 10:52:16 | INFO | train_inner | epoch 071:    952 / 4751 loss=4.429, nll_loss=2.814, ppl=7.03, wps=87375.2, ups=3.02, wpb=28958.4, bsz=958.1, num_updates=333400, lr=5.47668e-05, gnorm=0.492, loss_scale=4, train_wall=33, gb_free=6.5, wall=0
2021-04-06 10:52:49 | INFO | train_inner | epoch 071:   1052 / 4751 loss=4.448, nll_loss=2.836, ppl=7.14, wps=88011.8, ups=3.02, wpb=29125, bsz=955.2, num_updates=333500, lr=5.47586e-05, gnorm=0.492, loss_scale=4, train_wall=33, gb_free=6.4, wall=0
2021-04-06 10:53:22 | INFO | train_inner | epoch 071:   1152 / 4751 loss=4.431, nll_loss=2.817, ppl=7.04, wps=87927, ups=3.03, wpb=29021.8, bsz=970.7, num_updates=333600, lr=5.47504e-05, gnorm=0.491, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 10:53:55 | INFO | train_inner | epoch 071:   1252 / 4751 loss=4.489, nll_loss=2.881, ppl=7.37, wps=87467.7, ups=3.03, wpb=28851.2, bsz=907.1, num_updates=333700, lr=5.47422e-05, gnorm=0.499, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 10:54:28 | INFO | train_inner | epoch 071:   1352 / 4751 loss=4.438, nll_loss=2.824, ppl=7.08, wps=87329, ups=3, wpb=29092.3, bsz=988.6, num_updates=333800, lr=5.4734e-05, gnorm=0.486, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-06 10:55:01 | INFO | train_inner | epoch 071:   1452 / 4751 loss=4.456, nll_loss=2.844, ppl=7.18, wps=87665.3, ups=3.02, wpb=29011.4, bsz=990.1, num_updates=333900, lr=5.47258e-05, gnorm=0.484, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 10:55:34 | INFO | train_inner | epoch 071:   1552 / 4751 loss=4.475, nll_loss=2.866, ppl=7.29, wps=88344.4, ups=3.05, wpb=28931.5, bsz=943, num_updates=334000, lr=5.47176e-05, gnorm=0.498, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 10:56:07 | INFO | train_inner | epoch 071:   1652 / 4751 loss=4.545, nll_loss=2.946, ppl=7.7, wps=87741.7, ups=3.03, wpb=28917.7, bsz=941.5, num_updates=334100, lr=5.47094e-05, gnorm=0.499, loss_scale=8, train_wall=33, gb_free=6.4, wall=0
2021-04-06 10:56:40 | INFO | train_inner | epoch 071:   1752 / 4751 loss=4.442, nll_loss=2.828, ppl=7.1, wps=88710.8, ups=3.04, wpb=29224.5, bsz=952.2, num_updates=334200, lr=5.47012e-05, gnorm=0.483, loss_scale=8, train_wall=33, gb_free=6.2, wall=0
2021-04-06 10:57:13 | INFO | train_inner | epoch 071:   1852 / 4751 loss=4.455, nll_loss=2.843, ppl=7.18, wps=88484.6, ups=3.04, wpb=29130.8, bsz=952, num_updates=334300, lr=5.4693e-05, gnorm=0.496, loss_scale=8, train_wall=33, gb_free=6.4, wall=0
2021-04-06 10:57:46 | INFO | train_inner | epoch 071:   1952 / 4751 loss=4.517, nll_loss=2.914, ppl=7.54, wps=87949.9, ups=3.02, wpb=29089.9, bsz=966.9, num_updates=334400, lr=5.46848e-05, gnorm=0.493, loss_scale=8, train_wall=33, gb_free=6.4, wall=0
2021-04-06 10:58:19 | INFO | train_inner | epoch 071:   2052 / 4751 loss=4.498, nll_loss=2.892, ppl=7.42, wps=86682.3, ups=3.04, wpb=28482.4, bsz=930.6, num_updates=334500, lr=5.46767e-05, gnorm=0.501, loss_scale=8, train_wall=33, gb_free=6.5, wall=0
2021-04-06 10:58:51 | INFO | train_inner | epoch 071:   2152 / 4751 loss=4.539, nll_loss=2.938, ppl=7.67, wps=88706.7, ups=3.06, wpb=29024.9, bsz=939.6, num_updates=334600, lr=5.46685e-05, gnorm=0.497, loss_scale=8, train_wall=33, gb_free=6.6, wall=0
2021-04-06 10:59:25 | INFO | train_inner | epoch 071:   2252 / 4751 loss=4.484, nll_loss=2.876, ppl=7.34, wps=87768.9, ups=3.02, wpb=29082.7, bsz=903.9, num_updates=334700, lr=5.46603e-05, gnorm=0.49, loss_scale=8, train_wall=33, gb_free=5.8, wall=0
2021-04-06 10:59:57 | INFO | train_inner | epoch 071:   2352 / 4751 loss=4.465, nll_loss=2.855, ppl=7.24, wps=88220.6, ups=3.05, wpb=28955, bsz=936.6, num_updates=334800, lr=5.46522e-05, gnorm=0.494, loss_scale=8, train_wall=33, gb_free=6, wall=0
2021-04-06 11:00:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2021-04-06 11:00:31 | INFO | train_inner | epoch 071:   2453 / 4751 loss=4.461, nll_loss=2.85, ppl=7.21, wps=87084.5, ups=3, wpb=29001.2, bsz=939.9, num_updates=334900, lr=5.4644e-05, gnorm=0.49, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 11:00:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-06 11:01:04 | INFO | train_inner | epoch 071:   2554 / 4751 loss=4.496, nll_loss=2.89, ppl=7.41, wps=86744.9, ups=3, wpb=28902.1, bsz=948.5, num_updates=335000, lr=5.46358e-05, gnorm=0.492, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 11:01:37 | INFO | train_inner | epoch 071:   2654 / 4751 loss=4.47, nll_loss=2.861, ppl=7.26, wps=87887.3, ups=3.03, wpb=28997.9, bsz=965, num_updates=335100, lr=5.46277e-05, gnorm=0.494, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 11:02:11 | INFO | train_inner | epoch 071:   2754 / 4751 loss=4.425, nll_loss=2.809, ppl=7.01, wps=86645.4, ups=2.96, wpb=29242.8, bsz=975.2, num_updates=335200, lr=5.46195e-05, gnorm=0.486, loss_scale=2, train_wall=34, gb_free=6.2, wall=0
2021-04-06 11:02:44 | INFO | train_inner | epoch 071:   2854 / 4751 loss=4.473, nll_loss=2.864, ppl=7.28, wps=87553, ups=3.02, wpb=29002.3, bsz=947, num_updates=335300, lr=5.46114e-05, gnorm=0.499, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 11:03:17 | INFO | train_inner | epoch 071:   2954 / 4751 loss=4.518, nll_loss=2.914, ppl=7.54, wps=88432.6, ups=3.04, wpb=29064.4, bsz=925.3, num_updates=335400, lr=5.46032e-05, gnorm=0.5, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 11:03:50 | INFO | train_inner | epoch 071:   3054 / 4751 loss=4.447, nll_loss=2.834, ppl=7.13, wps=86819.1, ups=3.01, wpb=28886.5, bsz=923.6, num_updates=335500, lr=5.45951e-05, gnorm=0.493, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 11:04:23 | INFO | train_inner | epoch 071:   3154 / 4751 loss=4.486, nll_loss=2.88, ppl=7.36, wps=88175.3, ups=3.03, wpb=29113.8, bsz=959.2, num_updates=335600, lr=5.4587e-05, gnorm=0.493, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 11:04:56 | INFO | train_inner | epoch 071:   3254 / 4751 loss=4.496, nll_loss=2.889, ppl=7.41, wps=87987.5, ups=3.03, wpb=29013.5, bsz=937.5, num_updates=335700, lr=5.45788e-05, gnorm=0.493, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 11:05:29 | INFO | train_inner | epoch 071:   3354 / 4751 loss=4.499, nll_loss=2.894, ppl=7.43, wps=87544.9, ups=3.03, wpb=28921.4, bsz=965.4, num_updates=335800, lr=5.45707e-05, gnorm=0.503, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 11:06:02 | INFO | train_inner | epoch 071:   3454 / 4751 loss=4.5, nll_loss=2.895, ppl=7.44, wps=87201.7, ups=3.03, wpb=28813.6, bsz=959.3, num_updates=335900, lr=5.45626e-05, gnorm=0.497, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 11:06:35 | INFO | train_inner | epoch 071:   3554 / 4751 loss=4.492, nll_loss=2.885, ppl=7.39, wps=88773.6, ups=3.05, wpb=29121.3, bsz=969.8, num_updates=336000, lr=5.45545e-05, gnorm=0.496, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 11:07:08 | INFO | train_inner | epoch 071:   3654 / 4751 loss=4.479, nll_loss=2.871, ppl=7.32, wps=87662.5, ups=3.03, wpb=28914.9, bsz=949.4, num_updates=336100, lr=5.45464e-05, gnorm=0.493, loss_scale=2, train_wall=33, gb_free=6.7, wall=0
2021-04-06 11:07:41 | INFO | train_inner | epoch 071:   3754 / 4751 loss=4.529, nll_loss=2.927, ppl=7.61, wps=88257.5, ups=3.05, wpb=28946.4, bsz=963.5, num_updates=336200, lr=5.45382e-05, gnorm=0.512, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 11:08:14 | INFO | train_inner | epoch 071:   3854 / 4751 loss=4.499, nll_loss=2.894, ppl=7.43, wps=87901.8, ups=3.03, wpb=28985, bsz=955.7, num_updates=336300, lr=5.45301e-05, gnorm=0.493, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 11:08:47 | INFO | train_inner | epoch 071:   3954 / 4751 loss=4.507, nll_loss=2.902, ppl=7.47, wps=88166.8, ups=3.04, wpb=29016.8, bsz=929.8, num_updates=336400, lr=5.4522e-05, gnorm=0.5, loss_scale=2, train_wall=33, gb_free=7.1, wall=0
2021-04-06 11:09:20 | INFO | train_inner | epoch 071:   4054 / 4751 loss=4.528, nll_loss=2.927, ppl=7.6, wps=87556.5, ups=3.03, wpb=28923.6, bsz=928.6, num_updates=336500, lr=5.45139e-05, gnorm=0.499, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 11:09:53 | INFO | train_inner | epoch 071:   4154 / 4751 loss=4.445, nll_loss=2.832, ppl=7.12, wps=87226.6, ups=3.03, wpb=28775.7, bsz=950.8, num_updates=336600, lr=5.45058e-05, gnorm=0.491, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 11:10:26 | INFO | train_inner | epoch 071:   4254 / 4751 loss=4.52, nll_loss=2.917, ppl=7.55, wps=87617.9, ups=3.04, wpb=28861.6, bsz=984.2, num_updates=336700, lr=5.44977e-05, gnorm=0.501, loss_scale=2, train_wall=33, gb_free=5.9, wall=0
2021-04-06 11:10:58 | INFO | train_inner | epoch 071:   4354 / 4751 loss=4.482, nll_loss=2.874, ppl=7.33, wps=88660, ups=3.04, wpb=29171.3, bsz=918, num_updates=336800, lr=5.44896e-05, gnorm=0.489, loss_scale=2, train_wall=33, gb_free=5.8, wall=0
2021-04-06 11:11:32 | INFO | train_inner | epoch 071:   4454 / 4751 loss=4.476, nll_loss=2.867, ppl=7.3, wps=87668.4, ups=3.02, wpb=29025.4, bsz=967.5, num_updates=336900, lr=5.44816e-05, gnorm=0.491, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-06 11:12:05 | INFO | train_inner | epoch 071:   4554 / 4751 loss=4.5, nll_loss=2.895, ppl=7.44, wps=88136.2, ups=3.03, wpb=29046.7, bsz=951.2, num_updates=337000, lr=5.44735e-05, gnorm=0.497, loss_scale=2, train_wall=33, gb_free=6.8, wall=0
2021-04-06 11:12:38 | INFO | train_inner | epoch 071:   4654 / 4751 loss=4.464, nll_loss=2.854, ppl=7.23, wps=88709.1, ups=3.03, wpb=29245.1, bsz=947.3, num_updates=337100, lr=5.44654e-05, gnorm=0.483, loss_scale=4, train_wall=33, gb_free=6.4, wall=0
2021-04-06 11:13:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-06 11:13:11 | INFO | valid | epoch 071 | valid on 'valid' subset | loss 4.16 | nll_loss 2.387 | ppl 5.23 | wps 196804 | wpb 10489.1 | bsz 375 | num_updates 337197 | best_loss 4.129
2021-04-06 11:13:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 71 @ 337197 updates
2021-04-06 11:13:11 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-06 11:13:18 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-06 11:13:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt (epoch 71 @ 337197 updates, score 4.16) (writing took 7.639170594513416 seconds)
2021-04-06 11:13:18 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)
2021-04-06 11:13:18 | INFO | train | epoch 071 | loss 4.485 | nll_loss 2.877 | ppl 7.35 | wps 87205.8 | ups 3.01 | wpb 28968.4 | bsz 946.8 | num_updates 337197 | lr 5.44576e-05 | gnorm 0.495 | loss_scale 4 | train_wall 1561 | gb_free 6.6 | wall 0
2021-04-06 11:13:18 | INFO | fairseq.trainer | begin training epoch 72
2021-04-06 11:13:18 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-06 11:13:21 | INFO | train_inner | epoch 072:      3 / 4751 loss=4.477, nll_loss=2.868, ppl=7.3, wps=67435.5, ups=2.32, wpb=29071.7, bsz=927, num_updates=337200, lr=5.44573e-05, gnorm=0.498, loss_scale=4, train_wall=33, gb_free=5.8, wall=0
2021-04-06 11:13:54 | INFO | train_inner | epoch 072:    103 / 4751 loss=4.456, nll_loss=2.845, ppl=7.18, wps=88172.9, ups=3.03, wpb=29093.3, bsz=952.5, num_updates=337300, lr=5.44492e-05, gnorm=0.488, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 11:14:26 | INFO | train_inner | epoch 072:    203 / 4751 loss=4.538, nll_loss=2.937, ppl=7.66, wps=87275.5, ups=3.06, wpb=28510.4, bsz=951.3, num_updates=337400, lr=5.44412e-05, gnorm=0.51, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 11:14:59 | INFO | train_inner | epoch 072:    303 / 4751 loss=4.444, nll_loss=2.831, ppl=7.11, wps=86903.3, ups=3.01, wpb=28827.9, bsz=936.1, num_updates=337500, lr=5.44331e-05, gnorm=0.501, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-06 11:15:33 | INFO | train_inner | epoch 072:    403 / 4751 loss=4.415, nll_loss=2.799, ppl=6.96, wps=88525.6, ups=3.02, wpb=29272.3, bsz=999.4, num_updates=337600, lr=5.4425e-05, gnorm=0.488, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-06 11:15:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-06 11:16:06 | INFO | train_inner | epoch 072:    504 / 4751 loss=4.483, nll_loss=2.875, ppl=7.34, wps=87372.5, ups=3.02, wpb=28974.3, bsz=939, num_updates=337700, lr=5.4417e-05, gnorm=0.498, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 11:16:39 | INFO | train_inner | epoch 072:    604 / 4751 loss=4.421, nll_loss=2.805, ppl=6.99, wps=88153.1, ups=3.03, wpb=29137.3, bsz=931.6, num_updates=337800, lr=5.44089e-05, gnorm=0.482, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 11:17:12 | INFO | train_inner | epoch 072:    704 / 4751 loss=4.462, nll_loss=2.852, ppl=7.22, wps=87980.6, ups=3.03, wpb=29057.2, bsz=943.4, num_updates=337900, lr=5.44009e-05, gnorm=0.49, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 11:17:45 | INFO | train_inner | epoch 072:    804 / 4751 loss=4.522, nll_loss=2.92, ppl=7.57, wps=87810.3, ups=3.04, wpb=28851.8, bsz=943.6, num_updates=338000, lr=5.43928e-05, gnorm=0.497, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 11:18:18 | INFO | train_inner | epoch 072:    904 / 4751 loss=4.491, nll_loss=2.885, ppl=7.38, wps=87831.9, ups=3.03, wpb=29003.6, bsz=970.8, num_updates=338100, lr=5.43848e-05, gnorm=0.492, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 11:18:51 | INFO | train_inner | epoch 072:   1004 / 4751 loss=4.487, nll_loss=2.879, ppl=7.36, wps=87586.2, ups=3.02, wpb=29048.4, bsz=927.8, num_updates=338200, lr=5.43767e-05, gnorm=0.492, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-06 11:19:24 | INFO | train_inner | epoch 072:   1104 / 4751 loss=4.482, nll_loss=2.874, ppl=7.33, wps=88334.4, ups=3.03, wpb=29165.6, bsz=909.9, num_updates=338300, lr=5.43687e-05, gnorm=0.491, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 11:19:57 | INFO | train_inner | epoch 072:   1204 / 4751 loss=4.489, nll_loss=2.881, ppl=7.37, wps=87706.3, ups=3.04, wpb=28896.1, bsz=916.6, num_updates=338400, lr=5.43607e-05, gnorm=0.499, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 11:20:30 | INFO | train_inner | epoch 072:   1304 / 4751 loss=4.504, nll_loss=2.898, ppl=7.45, wps=86931.8, ups=3.04, wpb=28619.7, bsz=923.7, num_updates=338500, lr=5.43526e-05, gnorm=0.499, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 11:21:03 | INFO | train_inner | epoch 072:   1404 / 4751 loss=4.485, nll_loss=2.877, ppl=7.35, wps=87736.7, ups=3.03, wpb=28944.6, bsz=920.6, num_updates=338600, lr=5.43446e-05, gnorm=0.493, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 11:21:36 | INFO | train_inner | epoch 072:   1504 / 4751 loss=4.478, nll_loss=2.87, ppl=7.31, wps=87316, ups=3.02, wpb=28934.4, bsz=968.5, num_updates=338700, lr=5.43366e-05, gnorm=0.494, loss_scale=2, train_wall=33, gb_free=6.6, wall=0
2021-04-06 11:21:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-04-06 11:22:09 | INFO | train_inner | epoch 072:   1605 / 4751 loss=4.526, nll_loss=2.923, ppl=7.59, wps=86528, ups=2.99, wpb=28947.4, bsz=914.6, num_updates=338800, lr=5.43286e-05, gnorm=0.499, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 11:22:42 | INFO | train_inner | epoch 072:   1705 / 4751 loss=4.548, nll_loss=2.948, ppl=7.72, wps=87028.1, ups=3.02, wpb=28787.7, bsz=933.6, num_updates=338900, lr=5.43206e-05, gnorm=0.512, loss_scale=1, train_wall=33, gb_free=6.6, wall=0
2021-04-06 11:23:15 | INFO | train_inner | epoch 072:   1805 / 4751 loss=4.506, nll_loss=2.901, ppl=7.47, wps=87657.2, ups=3.04, wpb=28853, bsz=946, num_updates=339000, lr=5.43125e-05, gnorm=0.499, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 11:23:48 | INFO | train_inner | epoch 072:   1905 / 4751 loss=4.491, nll_loss=2.884, ppl=7.38, wps=88898, ups=3.04, wpb=29269.2, bsz=984.8, num_updates=339100, lr=5.43045e-05, gnorm=0.503, loss_scale=1, train_wall=33, gb_free=6.4, wall=0
2021-04-06 11:24:21 | INFO | train_inner | epoch 072:   2005 / 4751 loss=4.438, nll_loss=2.825, ppl=7.09, wps=86719.6, ups=3, wpb=28881.7, bsz=957.6, num_updates=339200, lr=5.42965e-05, gnorm=0.49, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 11:24:54 | INFO | train_inner | epoch 072:   2105 / 4751 loss=4.452, nll_loss=2.84, ppl=7.16, wps=88951.8, ups=3.04, wpb=29272.7, bsz=936.3, num_updates=339300, lr=5.42885e-05, gnorm=0.491, loss_scale=1, train_wall=33, gb_free=6.4, wall=0
2021-04-06 11:25:27 | INFO | train_inner | epoch 072:   2205 / 4751 loss=4.468, nll_loss=2.859, ppl=7.25, wps=87504.5, ups=3.02, wpb=28937.9, bsz=953.8, num_updates=339400, lr=5.42805e-05, gnorm=0.5, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 11:26:00 | INFO | train_inner | epoch 072:   2305 / 4751 loss=4.485, nll_loss=2.878, ppl=7.35, wps=88559, ups=3.04, wpb=29137.8, bsz=925.2, num_updates=339500, lr=5.42725e-05, gnorm=0.491, loss_scale=1, train_wall=33, gb_free=5.7, wall=0
2021-04-06 11:26:34 | INFO | train_inner | epoch 072:   2405 / 4751 loss=4.468, nll_loss=2.858, ppl=7.25, wps=86096.3, ups=3.01, wpb=28564, bsz=952.3, num_updates=339600, lr=5.42645e-05, gnorm=0.5, loss_scale=1, train_wall=33, gb_free=5.9, wall=0
2021-04-06 11:27:06 | INFO | train_inner | epoch 072:   2505 / 4751 loss=4.517, nll_loss=2.914, ppl=7.54, wps=88414.8, ups=3.04, wpb=29046.5, bsz=963.8, num_updates=339700, lr=5.42566e-05, gnorm=0.496, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 11:27:39 | INFO | train_inner | epoch 072:   2605 / 4751 loss=4.436, nll_loss=2.823, ppl=7.07, wps=88300.1, ups=3.05, wpb=28949.4, bsz=956.2, num_updates=339800, lr=5.42486e-05, gnorm=0.496, loss_scale=1, train_wall=33, gb_free=6.4, wall=0
2021-04-06 11:28:13 | INFO | train_inner | epoch 072:   2705 / 4751 loss=4.514, nll_loss=2.911, ppl=7.52, wps=86939.1, ups=3, wpb=28992.5, bsz=954.9, num_updates=339900, lr=5.42406e-05, gnorm=0.5, loss_scale=1, train_wall=33, gb_free=6.5, wall=0
2021-04-06 11:28:45 | INFO | train_inner | epoch 072:   2805 / 4751 loss=4.533, nll_loss=2.931, ppl=7.63, wps=88203.8, ups=3.04, wpb=28968.6, bsz=918.2, num_updates=340000, lr=5.42326e-05, gnorm=0.499, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 11:29:18 | INFO | train_inner | epoch 072:   2905 / 4751 loss=4.517, nll_loss=2.914, ppl=7.54, wps=88662.2, ups=3.04, wpb=29192.3, bsz=941, num_updates=340100, lr=5.42246e-05, gnorm=0.495, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 11:29:51 | INFO | train_inner | epoch 072:   3005 / 4751 loss=4.396, nll_loss=2.777, ppl=6.86, wps=88198.3, ups=3.03, wpb=29125.8, bsz=1003.3, num_updates=340200, lr=5.42167e-05, gnorm=0.537, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 11:30:24 | INFO | train_inner | epoch 072:   3105 / 4751 loss=4.452, nll_loss=2.841, ppl=7.16, wps=88214.9, ups=3.05, wpb=28935, bsz=977.8, num_updates=340300, lr=5.42087e-05, gnorm=0.497, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 11:30:57 | INFO | train_inner | epoch 072:   3205 / 4751 loss=4.517, nll_loss=2.914, ppl=7.54, wps=87469.7, ups=3.02, wpb=28951.5, bsz=975.1, num_updates=340400, lr=5.42007e-05, gnorm=0.498, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 11:31:30 | INFO | train_inner | epoch 072:   3305 / 4751 loss=4.496, nll_loss=2.89, ppl=7.41, wps=87839.3, ups=3.05, wpb=28805.6, bsz=924.4, num_updates=340500, lr=5.41928e-05, gnorm=0.497, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 11:32:03 | INFO | train_inner | epoch 072:   3405 / 4751 loss=4.527, nll_loss=2.925, ppl=7.6, wps=87633.7, ups=3.03, wpb=28888.8, bsz=912.3, num_updates=340600, lr=5.41848e-05, gnorm=0.497, loss_scale=1, train_wall=33, gb_free=6.5, wall=0
2021-04-06 11:32:36 | INFO | train_inner | epoch 072:   3505 / 4751 loss=4.466, nll_loss=2.856, ppl=7.24, wps=88739.3, ups=3.05, wpb=29107.3, bsz=979.1, num_updates=340700, lr=5.41769e-05, gnorm=0.494, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 11:33:09 | INFO | train_inner | epoch 072:   3605 / 4751 loss=4.502, nll_loss=2.897, ppl=7.45, wps=87959.2, ups=3.05, wpb=28883, bsz=950.2, num_updates=340800, lr=5.41689e-05, gnorm=0.499, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 11:33:41 | INFO | train_inner | epoch 072:   3705 / 4751 loss=4.472, nll_loss=2.863, ppl=7.27, wps=88350.2, ups=3.05, wpb=28984.2, bsz=936.7, num_updates=340900, lr=5.4161e-05, gnorm=0.493, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 11:34:14 | INFO | train_inner | epoch 072:   3805 / 4751 loss=4.489, nll_loss=2.882, ppl=7.37, wps=87095, ups=3.04, wpb=28652.7, bsz=962.3, num_updates=341000, lr=5.4153e-05, gnorm=0.497, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 11:34:47 | INFO | train_inner | epoch 072:   3905 / 4751 loss=4.532, nll_loss=2.93, ppl=7.62, wps=87050.3, ups=3.04, wpb=28588.1, bsz=921.8, num_updates=341100, lr=5.41451e-05, gnorm=0.501, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 11:35:20 | INFO | train_inner | epoch 072:   4005 / 4751 loss=4.492, nll_loss=2.886, ppl=7.39, wps=88064.3, ups=3.04, wpb=28976.9, bsz=969, num_updates=341200, lr=5.41372e-05, gnorm=0.494, loss_scale=2, train_wall=33, gb_free=6.9, wall=0
2021-04-06 11:35:53 | INFO | train_inner | epoch 072:   4105 / 4751 loss=4.46, nll_loss=2.849, ppl=7.21, wps=88365.1, ups=3.02, wpb=29268.2, bsz=928, num_updates=341300, lr=5.41292e-05, gnorm=0.486, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 11:36:26 | INFO | train_inner | epoch 072:   4205 / 4751 loss=4.53, nll_loss=2.928, ppl=7.61, wps=87317, ups=3.02, wpb=28919.3, bsz=949.3, num_updates=341400, lr=5.41213e-05, gnorm=0.496, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 11:36:59 | INFO | train_inner | epoch 072:   4305 / 4751 loss=4.451, nll_loss=2.839, ppl=7.15, wps=88830.5, ups=3.04, wpb=29202.6, bsz=966.3, num_updates=341500, lr=5.41134e-05, gnorm=0.485, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 11:37:32 | INFO | train_inner | epoch 072:   4405 / 4751 loss=4.487, nll_loss=2.88, ppl=7.36, wps=88626.2, ups=3.04, wpb=29141.5, bsz=931.6, num_updates=341600, lr=5.41055e-05, gnorm=0.494, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-06 11:38:05 | INFO | train_inner | epoch 072:   4505 / 4751 loss=4.44, nll_loss=2.827, ppl=7.09, wps=87827.7, ups=3.02, wpb=29067.7, bsz=966.7, num_updates=341700, lr=5.40975e-05, gnorm=0.495, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 11:38:38 | INFO | train_inner | epoch 072:   4605 / 4751 loss=4.487, nll_loss=2.88, ppl=7.36, wps=87070.7, ups=3.02, wpb=28786.6, bsz=931.5, num_updates=341800, lr=5.40896e-05, gnorm=0.496, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-06 11:39:11 | INFO | train_inner | epoch 072:   4705 / 4751 loss=4.508, nll_loss=2.904, ppl=7.49, wps=88091, ups=3.05, wpb=28926.1, bsz=947.6, num_updates=341900, lr=5.40817e-05, gnorm=0.503, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 11:39:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-06 11:39:27 | INFO | valid | epoch 072 | valid on 'valid' subset | loss 4.124 | nll_loss 2.354 | ppl 5.11 | wps 194201 | wpb 10489.1 | bsz 375 | num_updates 341946 | best_loss 4.124
2021-04-06 11:39:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 72 @ 341946 updates
2021-04-06 11:39:27 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-06 11:39:34 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-06 11:39:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt (epoch 72 @ 341946 updates, score 4.124) (writing took 13.187268245965242 seconds)
2021-04-06 11:39:41 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)
2021-04-06 11:39:41 | INFO | train | epoch 072 | loss 4.484 | nll_loss 2.876 | ppl 7.34 | wps 86947.3 | ups 3 | wpb 28968 | bsz 946.9 | num_updates 341946 | lr 5.40781e-05 | gnorm 0.497 | loss_scale 2 | train_wall 1560 | gb_free 6.4 | wall 0
2021-04-06 11:39:41 | INFO | fairseq.trainer | begin training epoch 73
2021-04-06 11:39:41 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-06 11:39:59 | INFO | train_inner | epoch 073:     54 / 4751 loss=4.491, nll_loss=2.884, ppl=7.38, wps=59996.8, ups=2.07, wpb=29000.1, bsz=943.6, num_updates=342000, lr=5.40738e-05, gnorm=0.496, loss_scale=2, train_wall=32, gb_free=6.1, wall=0
2021-04-06 11:40:32 | INFO | train_inner | epoch 073:    154 / 4751 loss=4.491, nll_loss=2.884, ppl=7.38, wps=87783.9, ups=3.05, wpb=28800.7, bsz=969, num_updates=342100, lr=5.40659e-05, gnorm=0.529, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 11:41:05 | INFO | train_inner | epoch 073:    254 / 4751 loss=4.508, nll_loss=2.903, ppl=7.48, wps=88316.3, ups=3.05, wpb=28956.5, bsz=939.2, num_updates=342200, lr=5.4058e-05, gnorm=0.502, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-06 11:41:38 | INFO | train_inner | epoch 073:    354 / 4751 loss=4.463, nll_loss=2.852, ppl=7.22, wps=88561.1, ups=3.04, wpb=29155.6, bsz=984.1, num_updates=342300, lr=5.40501e-05, gnorm=0.495, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 11:42:11 | INFO | train_inner | epoch 073:    454 / 4751 loss=4.508, nll_loss=2.903, ppl=7.48, wps=87475.4, ups=3.02, wpb=28943.5, bsz=928.2, num_updates=342400, lr=5.40422e-05, gnorm=0.495, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 11:42:44 | INFO | train_inner | epoch 073:    554 / 4751 loss=4.453, nll_loss=2.841, ppl=7.16, wps=88720.7, ups=3.04, wpb=29218.7, bsz=959, num_updates=342500, lr=5.40343e-05, gnorm=0.492, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 11:43:17 | INFO | train_inner | epoch 073:    654 / 4751 loss=4.446, nll_loss=2.833, ppl=7.12, wps=88294.8, ups=3.05, wpb=28945.6, bsz=933.4, num_updates=342600, lr=5.40264e-05, gnorm=0.495, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 11:43:50 | INFO | train_inner | epoch 073:    754 / 4751 loss=4.44, nll_loss=2.826, ppl=7.09, wps=88165.6, ups=3.03, wpb=29052.1, bsz=955.4, num_updates=342700, lr=5.40186e-05, gnorm=0.493, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 11:44:23 | INFO | train_inner | epoch 073:    854 / 4751 loss=4.505, nll_loss=2.9, ppl=7.47, wps=88353, ups=3.04, wpb=29097.6, bsz=956.2, num_updates=342800, lr=5.40107e-05, gnorm=0.494, loss_scale=2, train_wall=33, gb_free=6.6, wall=0
2021-04-06 11:44:56 | INFO | train_inner | epoch 073:    954 / 4751 loss=4.517, nll_loss=2.913, ppl=7.53, wps=87949.8, ups=3.04, wpb=28920.4, bsz=932.5, num_updates=342900, lr=5.40028e-05, gnorm=0.511, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-06 11:45:28 | INFO | train_inner | epoch 073:   1054 / 4751 loss=4.511, nll_loss=2.906, ppl=7.5, wps=87925, ups=3.04, wpb=28954.5, bsz=935.2, num_updates=343000, lr=5.39949e-05, gnorm=0.499, loss_scale=4, train_wall=33, gb_free=6.7, wall=0
2021-04-06 11:46:01 | INFO | train_inner | epoch 073:   1154 / 4751 loss=4.483, nll_loss=2.875, ppl=7.34, wps=87886.1, ups=3.03, wpb=29018.6, bsz=947.4, num_updates=343100, lr=5.39871e-05, gnorm=0.504, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-06 11:46:35 | INFO | train_inner | epoch 073:   1254 / 4751 loss=4.499, nll_loss=2.893, ppl=7.43, wps=87368.7, ups=3.03, wpb=28875.8, bsz=915, num_updates=343200, lr=5.39792e-05, gnorm=0.501, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 11:47:07 | INFO | train_inner | epoch 073:   1354 / 4751 loss=4.509, nll_loss=2.904, ppl=7.49, wps=88171.7, ups=3.04, wpb=28977.8, bsz=939.4, num_updates=343300, lr=5.39713e-05, gnorm=0.495, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 11:47:40 | INFO | train_inner | epoch 073:   1454 / 4751 loss=4.456, nll_loss=2.844, ppl=7.18, wps=88139.6, ups=3.02, wpb=29137.7, bsz=976.8, num_updates=343400, lr=5.39635e-05, gnorm=0.494, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 11:48:13 | INFO | train_inner | epoch 073:   1554 / 4751 loss=4.471, nll_loss=2.862, ppl=7.27, wps=87857.4, ups=3.03, wpb=28989.1, bsz=908.7, num_updates=343500, lr=5.39556e-05, gnorm=0.496, loss_scale=4, train_wall=33, gb_free=6.5, wall=0
2021-04-06 11:48:46 | INFO | train_inner | epoch 073:   1654 / 4751 loss=4.462, nll_loss=2.852, ppl=7.22, wps=88119.7, ups=3.02, wpb=29132.5, bsz=951.3, num_updates=343600, lr=5.39478e-05, gnorm=0.5, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 11:49:19 | INFO | train_inner | epoch 073:   1754 / 4751 loss=4.461, nll_loss=2.85, ppl=7.21, wps=88079.1, ups=3.04, wpb=29000.3, bsz=940, num_updates=343700, lr=5.39399e-05, gnorm=0.487, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 11:49:52 | INFO | train_inner | epoch 073:   1854 / 4751 loss=4.46, nll_loss=2.849, ppl=7.21, wps=88024.4, ups=3.04, wpb=28958, bsz=964.1, num_updates=343800, lr=5.39321e-05, gnorm=0.494, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 11:50:25 | INFO | train_inner | epoch 073:   1954 / 4751 loss=4.519, nll_loss=2.916, ppl=7.55, wps=88050.8, ups=3.04, wpb=29008.4, bsz=961.3, num_updates=343900, lr=5.39242e-05, gnorm=0.499, loss_scale=4, train_wall=33, gb_free=6.4, wall=0
2021-04-06 11:50:59 | INFO | train_inner | epoch 073:   2054 / 4751 loss=4.529, nll_loss=2.927, ppl=7.61, wps=85625.5, ups=2.96, wpb=28950.1, bsz=916.7, num_updates=344000, lr=5.39164e-05, gnorm=0.502, loss_scale=4, train_wall=34, gb_free=6.3, wall=0
2021-04-06 11:51:32 | INFO | train_inner | epoch 073:   2154 / 4751 loss=4.499, nll_loss=2.894, ppl=7.43, wps=86892.3, ups=3.02, wpb=28752.3, bsz=946.1, num_updates=344100, lr=5.39086e-05, gnorm=0.515, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 11:52:05 | INFO | train_inner | epoch 073:   2254 / 4751 loss=4.466, nll_loss=2.856, ppl=7.24, wps=87948, ups=3.03, wpb=29066.6, bsz=990.8, num_updates=344200, lr=5.39007e-05, gnorm=0.492, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 11:52:38 | INFO | train_inner | epoch 073:   2354 / 4751 loss=4.461, nll_loss=2.851, ppl=7.22, wps=88114.2, ups=3.03, wpb=29038.8, bsz=978.9, num_updates=344300, lr=5.38929e-05, gnorm=0.499, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 11:53:11 | INFO | train_inner | epoch 073:   2454 / 4751 loss=4.494, nll_loss=2.888, ppl=7.4, wps=88428.6, ups=3.04, wpb=29047.8, bsz=937.6, num_updates=344400, lr=5.38851e-05, gnorm=0.5, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 11:53:44 | INFO | train_inner | epoch 073:   2554 / 4751 loss=4.532, nll_loss=2.931, ppl=7.62, wps=86989.2, ups=3.03, wpb=28667.6, bsz=930.4, num_updates=344500, lr=5.38772e-05, gnorm=0.502, loss_scale=4, train_wall=33, gb_free=6.5, wall=0
2021-04-06 11:54:17 | INFO | train_inner | epoch 073:   2654 / 4751 loss=4.475, nll_loss=2.866, ppl=7.29, wps=87203.7, ups=3.02, wpb=28852.5, bsz=940, num_updates=344600, lr=5.38694e-05, gnorm=0.498, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 11:54:50 | INFO | train_inner | epoch 073:   2754 / 4751 loss=4.471, nll_loss=2.861, ppl=7.27, wps=87735.1, ups=3.03, wpb=28917.2, bsz=938.2, num_updates=344700, lr=5.38616e-05, gnorm=0.495, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 11:55:23 | INFO | train_inner | epoch 073:   2854 / 4751 loss=4.428, nll_loss=2.813, ppl=7.03, wps=88010.7, ups=3.02, wpb=29159.4, bsz=945.6, num_updates=344800, lr=5.38538e-05, gnorm=0.489, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 11:55:56 | INFO | train_inner | epoch 073:   2954 / 4751 loss=4.473, nll_loss=2.863, ppl=7.28, wps=87981.7, ups=3.04, wpb=28969.6, bsz=930.4, num_updates=344900, lr=5.3846e-05, gnorm=0.497, loss_scale=8, train_wall=33, gb_free=6.1, wall=0
2021-04-06 11:56:29 | INFO | train_inner | epoch 073:   3054 / 4751 loss=4.489, nll_loss=2.883, ppl=7.38, wps=88551.8, ups=3.03, wpb=29216.6, bsz=979, num_updates=345000, lr=5.38382e-05, gnorm=0.493, loss_scale=8, train_wall=33, gb_free=6.3, wall=0
2021-04-06 11:57:02 | INFO | train_inner | epoch 073:   3154 / 4751 loss=4.437, nll_loss=2.824, ppl=7.08, wps=87083.6, ups=3.01, wpb=28896.3, bsz=951.4, num_updates=345100, lr=5.38304e-05, gnorm=0.494, loss_scale=8, train_wall=33, gb_free=6.4, wall=0
2021-04-06 11:57:35 | INFO | train_inner | epoch 073:   3254 / 4751 loss=4.508, nll_loss=2.904, ppl=7.48, wps=88788.9, ups=3.05, wpb=29138.7, bsz=942, num_updates=345200, lr=5.38226e-05, gnorm=0.503, loss_scale=8, train_wall=33, gb_free=6.1, wall=0
2021-04-06 11:58:08 | INFO | train_inner | epoch 073:   3354 / 4751 loss=4.436, nll_loss=2.822, ppl=7.07, wps=88416.8, ups=3.03, wpb=29171.1, bsz=990.2, num_updates=345300, lr=5.38148e-05, gnorm=0.491, loss_scale=8, train_wall=33, gb_free=6.3, wall=0
2021-04-06 11:58:41 | INFO | train_inner | epoch 073:   3454 / 4751 loss=4.511, nll_loss=2.907, ppl=7.5, wps=88517.4, ups=3.06, wpb=28958.3, bsz=953.9, num_updates=345400, lr=5.3807e-05, gnorm=0.5, loss_scale=8, train_wall=33, gb_free=6.3, wall=0
2021-04-06 11:59:14 | INFO | train_inner | epoch 073:   3554 / 4751 loss=4.492, nll_loss=2.885, ppl=7.39, wps=88400.8, ups=3.03, wpb=29134.4, bsz=941.1, num_updates=345500, lr=5.37992e-05, gnorm=0.491, loss_scale=8, train_wall=33, gb_free=6.2, wall=0
2021-04-06 11:59:47 | INFO | train_inner | epoch 073:   3654 / 4751 loss=4.55, nll_loss=2.951, ppl=7.73, wps=87030.9, ups=3.05, wpb=28541.6, bsz=929.7, num_updates=345600, lr=5.37914e-05, gnorm=0.509, loss_scale=8, train_wall=33, gb_free=6.2, wall=0
2021-04-06 12:00:19 | INFO | train_inner | epoch 073:   3754 / 4751 loss=4.511, nll_loss=2.908, ppl=7.5, wps=87596.2, ups=3.05, wpb=28753.8, bsz=942.9, num_updates=345700, lr=5.37837e-05, gnorm=0.508, loss_scale=8, train_wall=33, gb_free=6.3, wall=0
2021-04-06 12:00:32 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2021-04-06 12:00:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-06 12:00:53 | INFO | train_inner | epoch 073:   3856 / 4751 loss=4.455, nll_loss=2.844, ppl=7.18, wps=85346, ups=2.94, wpb=28988.8, bsz=947.5, num_updates=345800, lr=5.37759e-05, gnorm=0.494, loss_scale=2, train_wall=34, gb_free=6.2, wall=0
2021-04-06 12:01:26 | INFO | train_inner | epoch 073:   3956 / 4751 loss=4.532, nll_loss=2.931, ppl=7.63, wps=87892, ups=3.04, wpb=28868.1, bsz=921.8, num_updates=345900, lr=5.37681e-05, gnorm=0.502, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 12:01:59 | INFO | train_inner | epoch 073:   4056 / 4751 loss=4.431, nll_loss=2.817, ppl=7.05, wps=87628.9, ups=3.04, wpb=28867.7, bsz=953.2, num_updates=346000, lr=5.37603e-05, gnorm=0.494, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 12:02:32 | INFO | train_inner | epoch 073:   4156 / 4751 loss=4.478, nll_loss=2.87, ppl=7.31, wps=87626.4, ups=3.05, wpb=28767.2, bsz=946.6, num_updates=346100, lr=5.37526e-05, gnorm=0.496, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 12:03:05 | INFO | train_inner | epoch 073:   4256 / 4751 loss=4.446, nll_loss=2.834, ppl=7.13, wps=87608.5, ups=3.03, wpb=28924.5, bsz=927, num_updates=346200, lr=5.37448e-05, gnorm=0.493, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 12:03:38 | INFO | train_inner | epoch 073:   4356 / 4751 loss=4.486, nll_loss=2.879, ppl=7.36, wps=87514.8, ups=3.03, wpb=28870.1, bsz=945.8, num_updates=346300, lr=5.3737e-05, gnorm=0.496, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 12:04:11 | INFO | train_inner | epoch 073:   4456 / 4751 loss=4.463, nll_loss=2.853, ppl=7.23, wps=88165.6, ups=3.04, wpb=29012.1, bsz=969.5, num_updates=346400, lr=5.37293e-05, gnorm=0.494, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-06 12:04:44 | INFO | train_inner | epoch 073:   4556 / 4751 loss=4.463, nll_loss=2.854, ppl=7.23, wps=88078.1, ups=3.04, wpb=28986.8, bsz=970.2, num_updates=346500, lr=5.37215e-05, gnorm=0.498, loss_scale=2, train_wall=33, gb_free=6.6, wall=0
2021-04-06 12:05:17 | INFO | train_inner | epoch 073:   4656 / 4751 loss=4.425, nll_loss=2.811, ppl=7.02, wps=87453.4, ups=3.01, wpb=29032.8, bsz=947.4, num_updates=346600, lr=5.37138e-05, gnorm=0.494, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 12:05:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-06 12:05:49 | INFO | valid | epoch 073 | valid on 'valid' subset | loss 4.136 | nll_loss 2.365 | ppl 5.15 | wps 205349 | wpb 10489.1 | bsz 375 | num_updates 346695 | best_loss 4.124
2021-04-06 12:05:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 73 @ 346695 updates
2021-04-06 12:05:49 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-06 12:05:56 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-06 12:05:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt (epoch 73 @ 346695 updates, score 4.136) (writing took 6.174855932593346 seconds)
2021-04-06 12:05:56 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)
2021-04-06 12:05:56 | INFO | train | epoch 073 | loss 4.483 | nll_loss 2.875 | ppl 7.34 | wps 87351.6 | ups 3.02 | wpb 28968.7 | bsz 947 | num_updates 346695 | lr 5.37064e-05 | gnorm 0.498 | loss_scale 2 | train_wall 1559 | gb_free 6.7 | wall 0
2021-04-06 12:05:56 | INFO | fairseq.trainer | begin training epoch 74
2021-04-06 12:05:56 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-06 12:05:58 | INFO | train_inner | epoch 074:      5 / 4751 loss=4.548, nll_loss=2.949, ppl=7.72, wps=69871, ups=2.41, wpb=29017.9, bsz=900.1, num_updates=346700, lr=5.3706e-05, gnorm=0.498, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-06 12:06:31 | INFO | train_inner | epoch 074:    105 / 4751 loss=4.485, nll_loss=2.877, ppl=7.35, wps=87610.9, ups=3.04, wpb=28851.9, bsz=901.5, num_updates=346800, lr=5.36983e-05, gnorm=0.502, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 12:07:04 | INFO | train_inner | epoch 074:    205 / 4751 loss=4.429, nll_loss=2.814, ppl=7.03, wps=88576.2, ups=3.04, wpb=29104.7, bsz=968.9, num_updates=346900, lr=5.36905e-05, gnorm=0.493, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 12:07:37 | INFO | train_inner | epoch 074:    305 / 4751 loss=4.458, nll_loss=2.847, ppl=7.2, wps=87540.9, ups=3.03, wpb=28884.5, bsz=963.4, num_updates=347000, lr=5.36828e-05, gnorm=0.5, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 12:08:10 | INFO | train_inner | epoch 074:    405 / 4751 loss=4.495, nll_loss=2.889, ppl=7.41, wps=87769.8, ups=3.02, wpb=29077.8, bsz=913, num_updates=347100, lr=5.36751e-05, gnorm=0.497, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-06 12:08:43 | INFO | train_inner | epoch 074:    505 / 4751 loss=4.393, nll_loss=2.774, ppl=6.84, wps=88905.4, ups=3.04, wpb=29232.8, bsz=973.6, num_updates=347200, lr=5.36673e-05, gnorm=0.515, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 12:09:16 | INFO | train_inner | epoch 074:    605 / 4751 loss=4.475, nll_loss=2.866, ppl=7.29, wps=86622.2, ups=3.02, wpb=28701.1, bsz=935, num_updates=347300, lr=5.36596e-05, gnorm=0.499, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 12:09:49 | INFO | train_inner | epoch 074:    705 / 4751 loss=4.528, nll_loss=2.926, ppl=7.6, wps=88352.8, ups=3.04, wpb=29037.2, bsz=942.2, num_updates=347400, lr=5.36519e-05, gnorm=0.502, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 12:10:22 | INFO | train_inner | epoch 074:    805 / 4751 loss=4.532, nll_loss=2.93, ppl=7.62, wps=87789.9, ups=3.04, wpb=28842.1, bsz=948, num_updates=347500, lr=5.36442e-05, gnorm=0.503, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 12:10:55 | INFO | train_inner | epoch 074:    905 / 4751 loss=4.459, nll_loss=2.848, ppl=7.2, wps=88236.9, ups=3.04, wpb=28994.9, bsz=950.2, num_updates=347600, lr=5.36365e-05, gnorm=0.499, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 12:11:28 | INFO | train_inner | epoch 074:   1005 / 4751 loss=4.486, nll_loss=2.878, ppl=7.35, wps=87356.9, ups=3.04, wpb=28716.3, bsz=903.2, num_updates=347700, lr=5.36287e-05, gnorm=0.498, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 12:12:01 | INFO | train_inner | epoch 074:   1105 / 4751 loss=4.438, nll_loss=2.824, ppl=7.08, wps=88275.7, ups=3.01, wpb=29282.2, bsz=947.6, num_updates=347800, lr=5.3621e-05, gnorm=0.492, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 12:12:34 | INFO | train_inner | epoch 074:   1205 / 4751 loss=4.433, nll_loss=2.819, ppl=7.06, wps=87451.1, ups=3.02, wpb=28916.4, bsz=955.1, num_updates=347900, lr=5.36133e-05, gnorm=0.493, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 12:13:07 | INFO | train_inner | epoch 074:   1305 / 4751 loss=4.482, nll_loss=2.874, ppl=7.33, wps=88178, ups=3.03, wpb=29091.9, bsz=964.4, num_updates=348000, lr=5.36056e-05, gnorm=0.498, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 12:13:40 | INFO | train_inner | epoch 074:   1405 / 4751 loss=4.517, nll_loss=2.914, ppl=7.54, wps=88037.9, ups=3.05, wpb=28911.4, bsz=937, num_updates=348100, lr=5.35979e-05, gnorm=0.497, loss_scale=4, train_wall=33, gb_free=6.5, wall=0
2021-04-06 12:14:13 | INFO | train_inner | epoch 074:   1505 / 4751 loss=4.508, nll_loss=2.904, ppl=7.48, wps=87792.1, ups=3.04, wpb=28892.1, bsz=936.9, num_updates=348200, lr=5.35902e-05, gnorm=0.504, loss_scale=4, train_wall=33, gb_free=6.4, wall=0
2021-04-06 12:14:46 | INFO | train_inner | epoch 074:   1605 / 4751 loss=4.485, nll_loss=2.878, ppl=7.35, wps=87802.8, ups=3.05, wpb=28832.9, bsz=957.4, num_updates=348300, lr=5.35825e-05, gnorm=0.494, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 12:15:19 | INFO | train_inner | epoch 074:   1705 / 4751 loss=4.474, nll_loss=2.865, ppl=7.29, wps=88339.4, ups=3.02, wpb=29230.5, bsz=953.7, num_updates=348400, lr=5.35748e-05, gnorm=0.492, loss_scale=4, train_wall=33, gb_free=6.4, wall=0
2021-04-06 12:15:52 | INFO | train_inner | epoch 074:   1805 / 4751 loss=4.479, nll_loss=2.871, ppl=7.31, wps=87484.5, ups=3.04, wpb=28808, bsz=915.2, num_updates=348500, lr=5.35672e-05, gnorm=0.5, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 12:16:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-06 12:16:25 | INFO | train_inner | epoch 074:   1906 / 4751 loss=4.432, nll_loss=2.818, ppl=7.05, wps=88161.3, ups=3.02, wpb=29203.6, bsz=979.8, num_updates=348600, lr=5.35595e-05, gnorm=0.493, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 12:16:58 | INFO | train_inner | epoch 074:   2006 / 4751 loss=4.47, nll_loss=2.861, ppl=7.27, wps=87999.9, ups=3.03, wpb=29022.1, bsz=968, num_updates=348700, lr=5.35518e-05, gnorm=0.495, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 12:17:31 | INFO | train_inner | epoch 074:   2106 / 4751 loss=4.487, nll_loss=2.88, ppl=7.36, wps=87975.9, ups=3.05, wpb=28869, bsz=963.6, num_updates=348800, lr=5.35441e-05, gnorm=0.5, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 12:18:04 | INFO | train_inner | epoch 074:   2206 / 4751 loss=4.508, nll_loss=2.904, ppl=7.49, wps=87789.1, ups=3.04, wpb=28900.5, bsz=926.9, num_updates=348900, lr=5.35364e-05, gnorm=0.505, loss_scale=2, train_wall=33, gb_free=6.8, wall=0
2021-04-06 12:18:37 | INFO | train_inner | epoch 074:   2306 / 4751 loss=4.456, nll_loss=2.845, ppl=7.19, wps=87178.5, ups=3.03, wpb=28809.4, bsz=936.6, num_updates=349000, lr=5.35288e-05, gnorm=0.495, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 12:19:10 | INFO | train_inner | epoch 074:   2406 / 4751 loss=4.456, nll_loss=2.844, ppl=7.18, wps=88070.3, ups=3.03, wpb=29093.9, bsz=974.5, num_updates=349100, lr=5.35211e-05, gnorm=0.492, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 12:19:43 | INFO | train_inner | epoch 074:   2506 / 4751 loss=4.482, nll_loss=2.874, ppl=7.33, wps=88325.4, ups=3.03, wpb=29111.7, bsz=940.6, num_updates=349200, lr=5.35134e-05, gnorm=0.495, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 12:20:16 | INFO | train_inner | epoch 074:   2606 / 4751 loss=4.47, nll_loss=2.861, ppl=7.26, wps=88817.1, ups=3.04, wpb=29248.9, bsz=940.7, num_updates=349300, lr=5.35058e-05, gnorm=0.495, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 12:20:49 | INFO | train_inner | epoch 074:   2706 / 4751 loss=4.486, nll_loss=2.879, ppl=7.36, wps=87570.7, ups=3.03, wpb=28928.2, bsz=926.8, num_updates=349400, lr=5.34981e-05, gnorm=0.5, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 12:21:22 | INFO | train_inner | epoch 074:   2806 / 4751 loss=4.536, nll_loss=2.936, ppl=7.65, wps=87762.3, ups=3.02, wpb=29082.8, bsz=976.1, num_updates=349500, lr=5.34905e-05, gnorm=0.502, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 12:21:55 | INFO | train_inner | epoch 074:   2906 / 4751 loss=4.472, nll_loss=2.863, ppl=7.28, wps=88660.4, ups=3.03, wpb=29216.8, bsz=935.8, num_updates=349600, lr=5.34828e-05, gnorm=0.498, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-06 12:22:28 | INFO | train_inner | epoch 074:   3006 / 4751 loss=4.456, nll_loss=2.845, ppl=7.18, wps=88048.8, ups=3.03, wpb=29079, bsz=980.2, num_updates=349700, lr=5.34752e-05, gnorm=0.499, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 12:23:01 | INFO | train_inner | epoch 074:   3106 / 4751 loss=4.56, nll_loss=2.962, ppl=7.79, wps=85047.5, ups=2.98, wpb=28577, bsz=917.7, num_updates=349800, lr=5.34675e-05, gnorm=0.503, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-06 12:23:34 | INFO | train_inner | epoch 074:   3206 / 4751 loss=4.545, nll_loss=2.945, ppl=7.7, wps=87451.6, ups=3.04, wpb=28811.8, bsz=942.7, num_updates=349900, lr=5.34599e-05, gnorm=0.501, loss_scale=2, train_wall=33, gb_free=6.7, wall=0
2021-04-06 12:24:07 | INFO | train_inner | epoch 074:   3306 / 4751 loss=4.439, nll_loss=2.826, ppl=7.09, wps=87934.6, ups=3.01, wpb=29172.4, bsz=998.9, num_updates=350000, lr=5.34522e-05, gnorm=0.491, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 12:24:40 | INFO | train_inner | epoch 074:   3406 / 4751 loss=4.541, nll_loss=2.941, ppl=7.68, wps=88066.7, ups=3.03, wpb=29032.9, bsz=949.4, num_updates=350100, lr=5.34446e-05, gnorm=0.5, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 12:25:13 | INFO | train_inner | epoch 074:   3506 / 4751 loss=4.516, nll_loss=2.913, ppl=7.53, wps=88389.9, ups=3.04, wpb=29102.4, bsz=959.4, num_updates=350200, lr=5.3437e-05, gnorm=0.497, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 12:25:46 | INFO | train_inner | epoch 074:   3606 / 4751 loss=4.469, nll_loss=2.86, ppl=7.26, wps=87995.8, ups=3.06, wpb=28774, bsz=975.4, num_updates=350300, lr=5.34294e-05, gnorm=0.495, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 12:26:19 | INFO | train_inner | epoch 074:   3706 / 4751 loss=4.446, nll_loss=2.834, ppl=7.13, wps=88729.1, ups=3.05, wpb=29100, bsz=943, num_updates=350400, lr=5.34217e-05, gnorm=0.488, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 12:26:51 | INFO | train_inner | epoch 074:   3806 / 4751 loss=4.534, nll_loss=2.933, ppl=7.64, wps=87897.7, ups=3.06, wpb=28717.4, bsz=908.6, num_updates=350500, lr=5.34141e-05, gnorm=0.501, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-06 12:27:24 | INFO | train_inner | epoch 074:   3906 / 4751 loss=4.46, nll_loss=2.85, ppl=7.21, wps=88656.3, ups=3.05, wpb=29063, bsz=948.1, num_updates=350600, lr=5.34065e-05, gnorm=0.496, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-06 12:27:57 | INFO | train_inner | epoch 074:   4006 / 4751 loss=4.523, nll_loss=2.921, ppl=7.57, wps=88198, ups=3.04, wpb=29004.8, bsz=955.8, num_updates=350700, lr=5.33989e-05, gnorm=0.501, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 12:28:30 | INFO | train_inner | epoch 074:   4106 / 4751 loss=4.474, nll_loss=2.865, ppl=7.29, wps=88221.8, ups=3.04, wpb=29029.6, bsz=931.5, num_updates=350800, lr=5.33913e-05, gnorm=0.499, loss_scale=4, train_wall=33, gb_free=6, wall=0
2021-04-06 12:28:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-06 12:29:03 | INFO | train_inner | epoch 074:   4207 / 4751 loss=4.495, nll_loss=2.889, ppl=7.41, wps=86244.5, ups=3, wpb=28748.4, bsz=937.2, num_updates=350900, lr=5.33837e-05, gnorm=0.49, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-06 12:29:36 | INFO | train_inner | epoch 074:   4307 / 4751 loss=4.458, nll_loss=2.847, ppl=7.2, wps=87279.5, ups=3.04, wpb=28733.1, bsz=925, num_updates=351000, lr=5.33761e-05, gnorm=0.496, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-06 12:30:09 | INFO | train_inner | epoch 074:   4407 / 4751 loss=4.486, nll_loss=2.879, ppl=7.36, wps=87543.4, ups=3.03, wpb=28870.7, bsz=953, num_updates=351100, lr=5.33684e-05, gnorm=0.499, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 12:30:42 | INFO | train_inner | epoch 074:   4507 / 4751 loss=4.455, nll_loss=2.844, ppl=7.18, wps=88795.7, ups=3.04, wpb=29249, bsz=941.2, num_updates=351200, lr=5.33609e-05, gnorm=0.489, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 12:31:15 | INFO | train_inner | epoch 074:   4607 / 4751 loss=4.495, nll_loss=2.89, ppl=7.41, wps=88003.3, ups=3.03, wpb=29005, bsz=965, num_updates=351300, lr=5.33533e-05, gnorm=0.492, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 12:31:48 | INFO | train_inner | epoch 074:   4707 / 4751 loss=4.485, nll_loss=2.879, ppl=7.35, wps=86900.8, ups=3.03, wpb=28646.9, bsz=949.5, num_updates=351400, lr=5.33457e-05, gnorm=0.505, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 12:32:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-06 12:32:04 | INFO | valid | epoch 074 | valid on 'valid' subset | loss 4.13 | nll_loss 2.357 | ppl 5.12 | wps 199572 | wpb 10489.1 | bsz 375 | num_updates 351444 | best_loss 4.124
2021-04-06 12:32:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 74 @ 351444 updates
2021-04-06 12:32:04 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-06 12:32:10 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-06 12:32:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt (epoch 74 @ 351444 updates, score 4.13) (writing took 6.214560717344284 seconds)
2021-04-06 12:32:10 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)
2021-04-06 12:32:10 | INFO | train | epoch 074 | loss 4.481 | nll_loss 2.873 | ppl 7.33 | wps 87374 | ups 3.02 | wpb 28967.6 | bsz 946.9 | num_updates 351444 | lr 5.33423e-05 | gnorm 0.498 | loss_scale 2 | train_wall 1559 | gb_free 6.3 | wall 0
2021-04-06 12:32:10 | INFO | fairseq.trainer | begin training epoch 75
2021-04-06 12:32:10 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-06 12:32:30 | INFO | train_inner | epoch 075:     56 / 4751 loss=4.458, nll_loss=2.846, ppl=7.19, wps=69372.8, ups=2.41, wpb=28807.8, bsz=936.6, num_updates=351500, lr=5.33381e-05, gnorm=0.493, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 12:33:02 | INFO | train_inner | epoch 075:    156 / 4751 loss=4.476, nll_loss=2.867, ppl=7.3, wps=88967, ups=3.06, wpb=29027.4, bsz=951.9, num_updates=351600, lr=5.33305e-05, gnorm=0.503, loss_scale=2, train_wall=32, gb_free=6.2, wall=0
2021-04-06 12:33:35 | INFO | train_inner | epoch 075:    256 / 4751 loss=4.496, nll_loss=2.89, ppl=7.41, wps=87171.3, ups=3.04, wpb=28704.3, bsz=947.1, num_updates=351700, lr=5.33229e-05, gnorm=0.505, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 12:34:08 | INFO | train_inner | epoch 075:    356 / 4751 loss=4.444, nll_loss=2.831, ppl=7.12, wps=88233.3, ups=3.04, wpb=28996.6, bsz=949.9, num_updates=351800, lr=5.33153e-05, gnorm=0.493, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 12:34:41 | INFO | train_inner | epoch 075:    456 / 4751 loss=4.428, nll_loss=2.813, ppl=7.03, wps=88333.7, ups=3.03, wpb=29188.5, bsz=976.8, num_updates=351900, lr=5.33078e-05, gnorm=0.489, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-06 12:35:14 | INFO | train_inner | epoch 075:    556 / 4751 loss=4.485, nll_loss=2.877, ppl=7.35, wps=87844.7, ups=3.02, wpb=29132.7, bsz=954, num_updates=352000, lr=5.33002e-05, gnorm=0.492, loss_scale=2, train_wall=33, gb_free=5.7, wall=0
2021-04-06 12:35:47 | INFO | train_inner | epoch 075:    656 / 4751 loss=4.497, nll_loss=2.891, ppl=7.42, wps=87203.8, ups=3.03, wpb=28805.5, bsz=961.5, num_updates=352100, lr=5.32926e-05, gnorm=0.5, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-06 12:36:20 | INFO | train_inner | epoch 075:    756 / 4751 loss=4.5, nll_loss=2.893, ppl=7.43, wps=86576.5, ups=3.04, wpb=28485.8, bsz=889.2, num_updates=352200, lr=5.3285e-05, gnorm=0.501, loss_scale=2, train_wall=33, gb_free=7, wall=0
2021-04-06 12:36:53 | INFO | train_inner | epoch 075:    856 / 4751 loss=4.451, nll_loss=2.839, ppl=7.16, wps=88139.2, ups=3.05, wpb=28941.7, bsz=970.5, num_updates=352300, lr=5.32775e-05, gnorm=0.499, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 12:37:26 | INFO | train_inner | epoch 075:    956 / 4751 loss=4.5, nll_loss=2.895, ppl=7.44, wps=87544.2, ups=3.03, wpb=28928.6, bsz=925.6, num_updates=352400, lr=5.32699e-05, gnorm=0.499, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 12:37:59 | INFO | train_inner | epoch 075:   1056 / 4751 loss=4.449, nll_loss=2.836, ppl=7.14, wps=88439.4, ups=3.02, wpb=29320.6, bsz=978, num_updates=352500, lr=5.32624e-05, gnorm=0.498, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 12:38:32 | INFO | train_inner | epoch 075:   1156 / 4751 loss=4.521, nll_loss=2.919, ppl=7.56, wps=88024.1, ups=3.03, wpb=29010.4, bsz=949.6, num_updates=352600, lr=5.32548e-05, gnorm=0.501, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 12:39:05 | INFO | train_inner | epoch 075:   1256 / 4751 loss=4.484, nll_loss=2.876, ppl=7.34, wps=88636.8, ups=3.05, wpb=29066.7, bsz=938.9, num_updates=352700, lr=5.32473e-05, gnorm=0.494, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 12:39:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-04-06 12:39:38 | INFO | train_inner | epoch 075:   1357 / 4751 loss=4.486, nll_loss=2.879, ppl=7.35, wps=87077.7, ups=3.01, wpb=28956.4, bsz=938.4, num_updates=352800, lr=5.32397e-05, gnorm=0.513, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 12:40:11 | INFO | train_inner | epoch 075:   1457 / 4751 loss=4.431, nll_loss=2.817, ppl=7.04, wps=88614.9, ups=3.03, wpb=29253.7, bsz=951.8, num_updates=352900, lr=5.32322e-05, gnorm=0.486, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 12:40:44 | INFO | train_inner | epoch 075:   1557 / 4751 loss=4.47, nll_loss=2.861, ppl=7.26, wps=87881.4, ups=3.04, wpb=28883.7, bsz=927.5, num_updates=353000, lr=5.32246e-05, gnorm=0.496, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 12:41:17 | INFO | train_inner | epoch 075:   1657 / 4751 loss=4.454, nll_loss=2.842, ppl=7.17, wps=87783.1, ups=3.02, wpb=29042, bsz=952.6, num_updates=353100, lr=5.32171e-05, gnorm=0.502, loss_scale=1, train_wall=33, gb_free=6.5, wall=0
2021-04-06 12:41:50 | INFO | train_inner | epoch 075:   1757 / 4751 loss=4.479, nll_loss=2.871, ppl=7.31, wps=87685.6, ups=3.03, wpb=28964.3, bsz=945.6, num_updates=353200, lr=5.32096e-05, gnorm=0.5, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 12:42:24 | INFO | train_inner | epoch 075:   1857 / 4751 loss=4.469, nll_loss=2.86, ppl=7.26, wps=85358.7, ups=2.97, wpb=28780.3, bsz=928.1, num_updates=353300, lr=5.3202e-05, gnorm=0.508, loss_scale=1, train_wall=34, gb_free=6, wall=0
2021-04-06 12:42:57 | INFO | train_inner | epoch 075:   1957 / 4751 loss=4.443, nll_loss=2.831, ppl=7.12, wps=87386.1, ups=3.03, wpb=28882.8, bsz=1001.9, num_updates=353400, lr=5.31945e-05, gnorm=0.527, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 12:43:30 | INFO | train_inner | epoch 075:   2057 / 4751 loss=4.473, nll_loss=2.864, ppl=7.28, wps=87102.1, ups=3.03, wpb=28762.9, bsz=954.6, num_updates=353500, lr=5.3187e-05, gnorm=0.498, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 12:44:03 | INFO | train_inner | epoch 075:   2157 / 4751 loss=4.52, nll_loss=2.917, ppl=7.55, wps=88900.6, ups=3.04, wpb=29227, bsz=949.8, num_updates=353600, lr=5.31795e-05, gnorm=0.495, loss_scale=1, train_wall=33, gb_free=6.4, wall=0
2021-04-06 12:44:36 | INFO | train_inner | epoch 075:   2257 / 4751 loss=4.463, nll_loss=2.854, ppl=7.23, wps=87571.7, ups=3.04, wpb=28853.9, bsz=983, num_updates=353700, lr=5.31719e-05, gnorm=0.493, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 12:45:09 | INFO | train_inner | epoch 075:   2357 / 4751 loss=4.486, nll_loss=2.879, ppl=7.36, wps=87263, ups=3, wpb=29074.2, bsz=959.7, num_updates=353800, lr=5.31644e-05, gnorm=0.494, loss_scale=1, train_wall=33, gb_free=6, wall=0
2021-04-06 12:45:42 | INFO | train_inner | epoch 075:   2457 / 4751 loss=4.5, nll_loss=2.894, ppl=7.43, wps=88636.3, ups=3.05, wpb=29074.2, bsz=923.1, num_updates=353900, lr=5.31569e-05, gnorm=0.494, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 12:46:15 | INFO | train_inner | epoch 075:   2557 / 4751 loss=4.498, nll_loss=2.892, ppl=7.43, wps=87662.4, ups=3.03, wpb=28924.5, bsz=962, num_updates=354000, lr=5.31494e-05, gnorm=0.505, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 12:46:48 | INFO | train_inner | epoch 075:   2657 / 4751 loss=4.54, nll_loss=2.939, ppl=7.67, wps=88473.2, ups=3.04, wpb=29097.6, bsz=922.6, num_updates=354100, lr=5.31419e-05, gnorm=0.498, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 12:47:21 | INFO | train_inner | epoch 075:   2757 / 4751 loss=4.493, nll_loss=2.887, ppl=7.4, wps=87448.4, ups=3.04, wpb=28735.2, bsz=940.8, num_updates=354200, lr=5.31344e-05, gnorm=0.505, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 12:47:54 | INFO | train_inner | epoch 075:   2857 / 4751 loss=4.467, nll_loss=2.858, ppl=7.25, wps=88666.5, ups=3.03, wpb=29233.3, bsz=987.8, num_updates=354300, lr=5.31269e-05, gnorm=0.494, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 12:48:27 | INFO | train_inner | epoch 075:   2957 / 4751 loss=4.466, nll_loss=2.856, ppl=7.24, wps=88169.3, ups=3.03, wpb=29098.9, bsz=948.1, num_updates=354400, lr=5.31194e-05, gnorm=0.502, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 12:49:00 | INFO | train_inner | epoch 075:   3057 / 4751 loss=4.489, nll_loss=2.882, ppl=7.37, wps=88042.9, ups=3.03, wpb=29023.7, bsz=964.4, num_updates=354500, lr=5.31119e-05, gnorm=0.499, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 12:49:33 | INFO | train_inner | epoch 075:   3157 / 4751 loss=4.525, nll_loss=2.923, ppl=7.58, wps=88692.3, ups=3.03, wpb=29240.4, bsz=965.1, num_updates=354600, lr=5.31044e-05, gnorm=0.503, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 12:50:06 | INFO | train_inner | epoch 075:   3257 / 4751 loss=4.414, nll_loss=2.798, ppl=6.95, wps=87767.5, ups=3.01, wpb=29110.6, bsz=961.9, num_updates=354700, lr=5.30969e-05, gnorm=0.495, loss_scale=1, train_wall=33, gb_free=6, wall=0
2021-04-06 12:50:39 | INFO | train_inner | epoch 075:   3357 / 4751 loss=4.454, nll_loss=2.843, ppl=7.18, wps=87512.4, ups=3.03, wpb=28928, bsz=954.9, num_updates=354800, lr=5.30894e-05, gnorm=0.496, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 12:51:12 | INFO | train_inner | epoch 075:   3457 / 4751 loss=4.461, nll_loss=2.851, ppl=7.21, wps=87853.8, ups=3.03, wpb=28989.4, bsz=981, num_updates=354900, lr=5.3082e-05, gnorm=0.5, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 12:51:45 | INFO | train_inner | epoch 075:   3557 / 4751 loss=4.518, nll_loss=2.915, ppl=7.54, wps=87380.5, ups=3.04, wpb=28738.2, bsz=903.7, num_updates=355000, lr=5.30745e-05, gnorm=0.509, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 12:52:18 | INFO | train_inner | epoch 075:   3657 / 4751 loss=4.485, nll_loss=2.878, ppl=7.35, wps=87625.9, ups=3.04, wpb=28819.4, bsz=940.4, num_updates=355100, lr=5.3067e-05, gnorm=0.5, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 12:52:51 | INFO | train_inner | epoch 075:   3757 / 4751 loss=4.485, nll_loss=2.878, ppl=7.35, wps=88045.4, ups=3.03, wpb=29036.6, bsz=959.6, num_updates=355200, lr=5.30595e-05, gnorm=0.495, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 12:53:24 | INFO | train_inner | epoch 075:   3857 / 4751 loss=4.423, nll_loss=2.808, ppl=7, wps=87557.6, ups=3.03, wpb=28863.4, bsz=941.1, num_updates=355300, lr=5.30521e-05, gnorm=0.496, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-06 12:53:57 | INFO | train_inner | epoch 075:   3957 / 4751 loss=4.456, nll_loss=2.845, ppl=7.18, wps=87234.3, ups=3.01, wpb=28964.4, bsz=917.4, num_updates=355400, lr=5.30446e-05, gnorm=0.493, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 12:54:30 | INFO | train_inner | epoch 075:   4057 / 4751 loss=4.471, nll_loss=2.862, ppl=7.27, wps=88405.3, ups=3.04, wpb=29066.5, bsz=963, num_updates=355500, lr=5.30372e-05, gnorm=0.494, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 12:55:03 | INFO | train_inner | epoch 075:   4157 / 4751 loss=4.511, nll_loss=2.907, ppl=7.5, wps=87474.1, ups=3.04, wpb=28791.8, bsz=924.2, num_updates=355600, lr=5.30297e-05, gnorm=0.5, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 12:55:35 | INFO | train_inner | epoch 075:   4257 / 4751 loss=4.57, nll_loss=2.974, ppl=7.86, wps=87779.7, ups=3.04, wpb=28831.4, bsz=904.8, num_updates=355700, lr=5.30222e-05, gnorm=0.514, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 12:56:08 | INFO | train_inner | epoch 075:   4357 / 4751 loss=4.49, nll_loss=2.884, ppl=7.38, wps=87695.7, ups=3.05, wpb=28734.2, bsz=943, num_updates=355800, lr=5.30148e-05, gnorm=0.506, loss_scale=2, train_wall=33, gb_free=7, wall=0
2021-04-06 12:56:41 | INFO | train_inner | epoch 075:   4457 / 4751 loss=4.494, nll_loss=2.888, ppl=7.4, wps=88124.5, ups=3.05, wpb=28911.9, bsz=941.5, num_updates=355900, lr=5.30073e-05, gnorm=0.502, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 12:57:14 | INFO | train_inner | epoch 075:   4557 / 4751 loss=4.501, nll_loss=2.896, ppl=7.44, wps=88955.8, ups=3.05, wpb=29196.9, bsz=927, num_updates=356000, lr=5.29999e-05, gnorm=0.501, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 12:57:47 | INFO | train_inner | epoch 075:   4657 / 4751 loss=4.466, nll_loss=2.856, ppl=7.24, wps=87921.7, ups=3.04, wpb=28930.2, bsz=924.9, num_updates=356100, lr=5.29925e-05, gnorm=0.498, loss_scale=2, train_wall=33, gb_free=5.9, wall=0
2021-04-06 12:58:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-06 12:58:19 | INFO | valid | epoch 075 | valid on 'valid' subset | loss 4.131 | nll_loss 2.363 | ppl 5.15 | wps 202601 | wpb 10489.1 | bsz 375 | num_updates 356194 | best_loss 4.124
2021-04-06 12:58:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 75 @ 356194 updates
2021-04-06 12:58:19 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-06 12:58:25 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-06 12:58:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt (epoch 75 @ 356194 updates, score 4.131) (writing took 6.616923041641712 seconds)
2021-04-06 12:58:25 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)
2021-04-06 12:58:25 | INFO | train | epoch 075 | loss 4.48 | nll_loss 2.872 | ppl 7.32 | wps 87340.8 | ups 3.02 | wpb 28968.7 | bsz 947.2 | num_updates 356194 | lr 5.29855e-05 | gnorm 0.5 | loss_scale 2 | train_wall 1559 | gb_free 6.3 | wall 0
2021-04-06 12:58:26 | INFO | fairseq.trainer | begin training epoch 76
2021-04-06 12:58:26 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-06 12:58:29 | INFO | train_inner | epoch 076:      6 / 4751 loss=4.486, nll_loss=2.879, ppl=7.36, wps=68842.6, ups=2.38, wpb=28880.7, bsz=925.7, num_updates=356200, lr=5.2985e-05, gnorm=0.507, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-06 12:59:01 | INFO | train_inner | epoch 076:    106 / 4751 loss=4.437, nll_loss=2.824, ppl=7.08, wps=87996, ups=3.06, wpb=28775.4, bsz=959.5, num_updates=356300, lr=5.29776e-05, gnorm=0.502, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 12:59:34 | INFO | train_inner | epoch 076:    206 / 4751 loss=4.466, nll_loss=2.855, ppl=7.24, wps=88560.8, ups=3.04, wpb=29121.1, bsz=917.9, num_updates=356400, lr=5.29701e-05, gnorm=0.497, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 13:00:07 | INFO | train_inner | epoch 076:    306 / 4751 loss=4.468, nll_loss=2.859, ppl=7.25, wps=87543.2, ups=3.05, wpb=28722.5, bsz=918.2, num_updates=356500, lr=5.29627e-05, gnorm=0.499, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 13:00:40 | INFO | train_inner | epoch 076:    406 / 4751 loss=4.424, nll_loss=2.808, ppl=7, wps=88132.7, ups=3.03, wpb=29102.4, bsz=955.9, num_updates=356600, lr=5.29553e-05, gnorm=0.498, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 13:01:13 | INFO | train_inner | epoch 076:    506 / 4751 loss=4.464, nll_loss=2.853, ppl=7.23, wps=87800.7, ups=3.04, wpb=28846.6, bsz=968.2, num_updates=356700, lr=5.29479e-05, gnorm=0.502, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 13:01:46 | INFO | train_inner | epoch 076:    606 / 4751 loss=4.485, nll_loss=2.877, ppl=7.35, wps=88341.5, ups=3.02, wpb=29222.3, bsz=941.8, num_updates=356800, lr=5.29404e-05, gnorm=0.496, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 13:02:19 | INFO | train_inner | epoch 076:    706 / 4751 loss=4.443, nll_loss=2.83, ppl=7.11, wps=87261.3, ups=3, wpb=29093.3, bsz=968.4, num_updates=356900, lr=5.2933e-05, gnorm=0.498, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 13:02:46 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-06 13:02:52 | INFO | train_inner | epoch 076:    807 / 4751 loss=4.505, nll_loss=2.9, ppl=7.47, wps=87163.3, ups=3.03, wpb=28796.7, bsz=929, num_updates=357000, lr=5.29256e-05, gnorm=0.491, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 13:03:25 | INFO | train_inner | epoch 076:    907 / 4751 loss=4.467, nll_loss=2.857, ppl=7.24, wps=88205.9, ups=3.04, wpb=29018.1, bsz=954.7, num_updates=357100, lr=5.29182e-05, gnorm=0.503, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 13:03:58 | INFO | train_inner | epoch 076:   1007 / 4751 loss=4.475, nll_loss=2.866, ppl=7.29, wps=87912.3, ups=3.03, wpb=29032.9, bsz=946.6, num_updates=357200, lr=5.29108e-05, gnorm=0.501, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 13:04:31 | INFO | train_inner | epoch 076:   1107 / 4751 loss=4.471, nll_loss=2.861, ppl=7.27, wps=87395.4, ups=3.02, wpb=28910, bsz=943.2, num_updates=357300, lr=5.29034e-05, gnorm=0.5, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-06 13:05:04 | INFO | train_inner | epoch 076:   1207 / 4751 loss=4.407, nll_loss=2.789, ppl=6.91, wps=88274.2, ups=3.04, wpb=29006, bsz=951.4, num_updates=357400, lr=5.2896e-05, gnorm=0.493, loss_scale=2, train_wall=33, gb_free=5.9, wall=0
2021-04-06 13:05:37 | INFO | train_inner | epoch 076:   1307 / 4751 loss=4.514, nll_loss=2.91, ppl=7.52, wps=86997, ups=3.04, wpb=28576.2, bsz=972, num_updates=357500, lr=5.28886e-05, gnorm=0.506, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 13:06:10 | INFO | train_inner | epoch 076:   1407 / 4751 loss=4.482, nll_loss=2.875, ppl=7.34, wps=87983.5, ups=3.04, wpb=28922.1, bsz=951.7, num_updates=357600, lr=5.28812e-05, gnorm=0.507, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 13:06:43 | INFO | train_inner | epoch 076:   1507 / 4751 loss=4.413, nll_loss=2.797, ppl=6.95, wps=87775.1, ups=3.03, wpb=29004.9, bsz=952.6, num_updates=357700, lr=5.28738e-05, gnorm=0.504, loss_scale=2, train_wall=33, gb_free=6.9, wall=0
2021-04-06 13:07:16 | INFO | train_inner | epoch 076:   1607 / 4751 loss=4.461, nll_loss=2.851, ppl=7.21, wps=88508.2, ups=3.04, wpb=29136.2, bsz=942.2, num_updates=357800, lr=5.28664e-05, gnorm=0.497, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 13:07:49 | INFO | train_inner | epoch 076:   1707 / 4751 loss=4.486, nll_loss=2.879, ppl=7.35, wps=87937, ups=3.03, wpb=29014.1, bsz=973.1, num_updates=357900, lr=5.2859e-05, gnorm=0.501, loss_scale=2, train_wall=33, gb_free=6.6, wall=0
2021-04-06 13:08:22 | INFO | train_inner | epoch 076:   1807 / 4751 loss=4.446, nll_loss=2.834, ppl=7.13, wps=87854.5, ups=3.04, wpb=28891.1, bsz=976.1, num_updates=358000, lr=5.28516e-05, gnorm=0.495, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 13:08:55 | INFO | train_inner | epoch 076:   1907 / 4751 loss=4.453, nll_loss=2.841, ppl=7.17, wps=88476.9, ups=3.02, wpb=29251.3, bsz=960.6, num_updates=358100, lr=5.28443e-05, gnorm=0.492, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 13:09:28 | INFO | train_inner | epoch 076:   2007 / 4751 loss=4.487, nll_loss=2.88, ppl=7.36, wps=86993.8, ups=3.03, wpb=28686, bsz=953, num_updates=358200, lr=5.28369e-05, gnorm=0.501, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 13:10:01 | INFO | train_inner | epoch 076:   2107 / 4751 loss=4.487, nll_loss=2.88, ppl=7.36, wps=87882.3, ups=3.02, wpb=29099.9, bsz=949.1, num_updates=358300, lr=5.28295e-05, gnorm=0.496, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 13:10:34 | INFO | train_inner | epoch 076:   2207 / 4751 loss=4.497, nll_loss=2.891, ppl=7.42, wps=88016, ups=3.04, wpb=28955.8, bsz=951.8, num_updates=358400, lr=5.28221e-05, gnorm=0.499, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 13:11:07 | INFO | train_inner | epoch 076:   2307 / 4751 loss=4.504, nll_loss=2.899, ppl=7.46, wps=88156.1, ups=3.05, wpb=28932.6, bsz=927.3, num_updates=358500, lr=5.28148e-05, gnorm=0.502, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-06 13:11:40 | INFO | train_inner | epoch 076:   2407 / 4751 loss=4.527, nll_loss=2.924, ppl=7.59, wps=87326.1, ups=3.04, wpb=28680.1, bsz=925.3, num_updates=358600, lr=5.28074e-05, gnorm=0.506, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 13:12:12 | INFO | train_inner | epoch 076:   2507 / 4751 loss=4.514, nll_loss=2.91, ppl=7.52, wps=87784.9, ups=3.04, wpb=28831.2, bsz=919.8, num_updates=358700, lr=5.28e-05, gnorm=0.501, loss_scale=2, train_wall=33, gb_free=6.7, wall=0
2021-04-06 13:12:45 | INFO | train_inner | epoch 076:   2607 / 4751 loss=4.51, nll_loss=2.905, ppl=7.49, wps=88563.1, ups=3.04, wpb=29120.1, bsz=935.3, num_updates=358800, lr=5.27927e-05, gnorm=0.499, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 13:13:19 | INFO | train_inner | epoch 076:   2707 / 4751 loss=4.46, nll_loss=2.849, ppl=7.21, wps=87269.7, ups=3.01, wpb=29024.5, bsz=915.5, num_updates=358900, lr=5.27853e-05, gnorm=0.504, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 13:13:52 | INFO | train_inner | epoch 076:   2807 / 4751 loss=4.466, nll_loss=2.856, ppl=7.24, wps=87465.3, ups=3.02, wpb=28930, bsz=954.5, num_updates=359000, lr=5.2778e-05, gnorm=0.496, loss_scale=2, train_wall=33, gb_free=6.6, wall=0
2021-04-06 13:14:25 | INFO | train_inner | epoch 076:   2907 / 4751 loss=4.474, nll_loss=2.865, ppl=7.29, wps=86729.8, ups=3.01, wpb=28774.7, bsz=934.6, num_updates=359100, lr=5.27706e-05, gnorm=0.5, loss_scale=4, train_wall=33, gb_free=6.4, wall=0
2021-04-06 13:14:58 | INFO | train_inner | epoch 076:   3007 / 4751 loss=4.433, nll_loss=2.819, ppl=7.05, wps=87754.6, ups=3.02, wpb=29064.4, bsz=962.1, num_updates=359200, lr=5.27633e-05, gnorm=0.492, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 13:15:31 | INFO | train_inner | epoch 076:   3107 / 4751 loss=4.542, nll_loss=2.942, ppl=7.68, wps=88068.9, ups=3.05, wpb=28850.8, bsz=920.2, num_updates=359300, lr=5.27559e-05, gnorm=0.495, loss_scale=4, train_wall=33, gb_free=6.4, wall=0
2021-04-06 13:16:04 | INFO | train_inner | epoch 076:   3207 / 4751 loss=4.493, nll_loss=2.887, ppl=7.4, wps=87592.1, ups=3.04, wpb=28793.1, bsz=936, num_updates=359400, lr=5.27486e-05, gnorm=0.498, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 13:16:36 | INFO | train_inner | epoch 076:   3307 / 4751 loss=4.553, nll_loss=2.955, ppl=7.76, wps=88317.4, ups=3.07, wpb=28809.4, bsz=935.8, num_updates=359500, lr=5.27413e-05, gnorm=0.505, loss_scale=4, train_wall=32, gb_free=6.1, wall=0
2021-04-06 13:17:09 | INFO | train_inner | epoch 076:   3407 / 4751 loss=4.528, nll_loss=2.927, ppl=7.6, wps=88517.7, ups=3.06, wpb=28930.7, bsz=934.2, num_updates=359600, lr=5.27339e-05, gnorm=0.51, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 13:17:42 | INFO | train_inner | epoch 076:   3507 / 4751 loss=4.49, nll_loss=2.883, ppl=7.38, wps=87192.7, ups=3.02, wpb=28919.1, bsz=941.9, num_updates=359700, lr=5.27266e-05, gnorm=0.499, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-06 13:18:15 | INFO | train_inner | epoch 076:   3607 / 4751 loss=4.464, nll_loss=2.854, ppl=7.23, wps=89115.3, ups=3.05, wpb=29222.2, bsz=949, num_updates=359800, lr=5.27193e-05, gnorm=0.498, loss_scale=4, train_wall=33, gb_free=6.8, wall=0
2021-04-06 13:18:48 | INFO | train_inner | epoch 076:   3707 / 4751 loss=4.464, nll_loss=2.854, ppl=7.23, wps=87770.4, ups=3.02, wpb=29073.7, bsz=970.6, num_updates=359900, lr=5.27119e-05, gnorm=0.493, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 13:19:21 | INFO | train_inner | epoch 076:   3807 / 4751 loss=4.48, nll_loss=2.873, ppl=7.33, wps=88463.7, ups=3.03, wpb=29196.5, bsz=972.1, num_updates=360000, lr=5.27046e-05, gnorm=0.502, loss_scale=4, train_wall=33, gb_free=6.8, wall=0
2021-04-06 13:19:54 | INFO | train_inner | epoch 076:   3907 / 4751 loss=4.494, nll_loss=2.888, ppl=7.4, wps=86884.9, ups=2.98, wpb=29114.2, bsz=924.3, num_updates=360100, lr=5.26973e-05, gnorm=0.497, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 13:20:27 | INFO | train_inner | epoch 076:   4007 / 4751 loss=4.493, nll_loss=2.887, ppl=7.4, wps=88088.7, ups=3.03, wpb=29086.3, bsz=943.9, num_updates=360200, lr=5.269e-05, gnorm=0.493, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 13:21:00 | INFO | train_inner | epoch 076:   4107 / 4751 loss=4.496, nll_loss=2.891, ppl=7.42, wps=87261.7, ups=3.03, wpb=28795.2, bsz=931.2, num_updates=360300, lr=5.26827e-05, gnorm=0.502, loss_scale=4, train_wall=33, gb_free=6.8, wall=0
2021-04-06 13:21:33 | INFO | train_inner | epoch 076:   4207 / 4751 loss=4.459, nll_loss=2.849, ppl=7.2, wps=88632.1, ups=3.03, wpb=29237, bsz=959.5, num_updates=360400, lr=5.26754e-05, gnorm=0.492, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 13:22:07 | INFO | train_inner | epoch 076:   4307 / 4751 loss=4.49, nll_loss=2.883, ppl=7.38, wps=87170.3, ups=2.99, wpb=29112, bsz=953.4, num_updates=360500, lr=5.26681e-05, gnorm=0.501, loss_scale=4, train_wall=33, gb_free=6.6, wall=0
2021-04-06 13:22:40 | INFO | train_inner | epoch 076:   4407 / 4751 loss=4.505, nll_loss=2.901, ppl=7.47, wps=85893.4, ups=3.01, wpb=28568.7, bsz=942.2, num_updates=360600, lr=5.26608e-05, gnorm=0.513, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-06 13:23:13 | INFO | train_inner | epoch 076:   4507 / 4751 loss=4.419, nll_loss=2.804, ppl=6.98, wps=87613.4, ups=3.02, wpb=29045.1, bsz=1001.9, num_updates=360700, lr=5.26535e-05, gnorm=0.501, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-06 13:23:46 | INFO | train_inner | epoch 076:   4607 / 4751 loss=4.504, nll_loss=2.899, ppl=7.46, wps=88533.7, ups=3.03, wpb=29176, bsz=945.4, num_updates=360800, lr=5.26462e-05, gnorm=0.498, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-06 13:24:19 | INFO | train_inner | epoch 076:   4707 / 4751 loss=4.517, nll_loss=2.914, ppl=7.54, wps=89105.2, ups=3.05, wpb=29175.7, bsz=945.9, num_updates=360900, lr=5.26389e-05, gnorm=0.5, loss_scale=4, train_wall=33, gb_free=6.5, wall=0
2021-04-06 13:24:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-06 13:24:35 | INFO | valid | epoch 076 | valid on 'valid' subset | loss 4.121 | nll_loss 2.353 | ppl 5.11 | wps 199332 | wpb 10489.1 | bsz 375 | num_updates 360944 | best_loss 4.121
2021-04-06 13:24:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 76 @ 360944 updates
2021-04-06 13:24:35 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-06 13:24:41 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-06 13:24:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt (epoch 76 @ 360944 updates, score 4.121) (writing took 12.891230575740337 seconds)
2021-04-06 13:24:48 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)
2021-04-06 13:24:48 | INFO | train | epoch 076 | loss 4.479 | nll_loss 2.871 | ppl 7.31 | wps 86973.4 | ups 3 | wpb 28968.2 | bsz 947.2 | num_updates 360944 | lr 5.26357e-05 | gnorm 0.5 | loss_scale 4 | train_wall 1560 | gb_free 6.9 | wall 0
2021-04-06 13:24:48 | INFO | fairseq.trainer | begin training epoch 77
2021-04-06 13:24:48 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-06 13:25:07 | INFO | train_inner | epoch 077:     56 / 4751 loss=4.419, nll_loss=2.803, ppl=6.98, wps=59741.2, ups=2.07, wpb=28836.5, bsz=949.3, num_updates=361000, lr=5.26316e-05, gnorm=0.502, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 13:25:40 | INFO | train_inner | epoch 077:    156 / 4751 loss=4.481, nll_loss=2.873, ppl=7.33, wps=88090.5, ups=3.04, wpb=28983.1, bsz=945.2, num_updates=361100, lr=5.26243e-05, gnorm=0.5, loss_scale=8, train_wall=33, gb_free=6.2, wall=0
2021-04-06 13:26:13 | INFO | train_inner | epoch 077:    256 / 4751 loss=4.498, nll_loss=2.892, ppl=7.43, wps=88075, ups=3.05, wpb=28871.9, bsz=954.3, num_updates=361200, lr=5.2617e-05, gnorm=0.5, loss_scale=8, train_wall=33, gb_free=6.1, wall=0
2021-04-06 13:26:46 | INFO | train_inner | epoch 077:    356 / 4751 loss=4.507, nll_loss=2.902, ppl=7.48, wps=88244.8, ups=3.06, wpb=28883.7, bsz=945.8, num_updates=361300, lr=5.26097e-05, gnorm=0.506, loss_scale=8, train_wall=33, gb_free=6.4, wall=0
2021-04-06 13:27:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2021-04-06 13:27:19 | INFO | train_inner | epoch 077:    457 / 4751 loss=4.49, nll_loss=2.882, ppl=7.37, wps=88026, ups=3.03, wpb=29095, bsz=918.1, num_updates=361400, lr=5.26024e-05, gnorm=0.498, loss_scale=4, train_wall=33, gb_free=6.6, wall=0
2021-04-06 13:27:52 | INFO | train_inner | epoch 077:    557 / 4751 loss=4.491, nll_loss=2.884, ppl=7.38, wps=87786.5, ups=3.04, wpb=28873.9, bsz=948.6, num_updates=361500, lr=5.25952e-05, gnorm=0.498, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 13:28:25 | INFO | train_inner | epoch 077:    657 / 4751 loss=4.479, nll_loss=2.871, ppl=7.31, wps=87406.6, ups=3.02, wpb=28941.2, bsz=918.1, num_updates=361600, lr=5.25879e-05, gnorm=0.505, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 13:28:58 | INFO | train_inner | epoch 077:    757 / 4751 loss=4.501, nll_loss=2.896, ppl=7.44, wps=87888.6, ups=3.03, wpb=29005, bsz=907, num_updates=361700, lr=5.25806e-05, gnorm=0.501, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 13:29:31 | INFO | train_inner | epoch 077:    857 / 4751 loss=4.481, nll_loss=2.873, ppl=7.32, wps=87888.1, ups=3.05, wpb=28850, bsz=948.1, num_updates=361800, lr=5.25734e-05, gnorm=0.503, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 13:29:52 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-06 13:30:04 | INFO | train_inner | epoch 077:    958 / 4751 loss=4.491, nll_loss=2.884, ppl=7.38, wps=87417.3, ups=3.01, wpb=28996.1, bsz=949.4, num_updates=361900, lr=5.25661e-05, gnorm=0.495, loss_scale=2, train_wall=33, gb_free=7.3, wall=0
2021-04-06 13:30:37 | INFO | train_inner | epoch 077:   1058 / 4751 loss=4.49, nll_loss=2.883, ppl=7.38, wps=88786.6, ups=3.05, wpb=29129.1, bsz=934.3, num_updates=362000, lr=5.25588e-05, gnorm=0.502, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 13:31:10 | INFO | train_inner | epoch 077:   1158 / 4751 loss=4.429, nll_loss=2.815, ppl=7.04, wps=87466.3, ups=3.02, wpb=28921.4, bsz=998.2, num_updates=362100, lr=5.25516e-05, gnorm=0.495, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 13:31:42 | INFO | train_inner | epoch 077:   1258 / 4751 loss=4.478, nll_loss=2.87, ppl=7.31, wps=88936.1, ups=3.06, wpb=29100.4, bsz=931.6, num_updates=362200, lr=5.25443e-05, gnorm=0.503, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 13:32:15 | INFO | train_inner | epoch 077:   1358 / 4751 loss=4.474, nll_loss=2.866, ppl=7.29, wps=86950.7, ups=3.03, wpb=28716.1, bsz=952.4, num_updates=362300, lr=5.25371e-05, gnorm=0.499, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 13:32:48 | INFO | train_inner | epoch 077:   1458 / 4751 loss=4.457, nll_loss=2.846, ppl=7.19, wps=87958.3, ups=3.02, wpb=29157.8, bsz=994.6, num_updates=362400, lr=5.25298e-05, gnorm=0.501, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-06 13:33:22 | INFO | train_inner | epoch 077:   1558 / 4751 loss=4.424, nll_loss=2.809, ppl=7.01, wps=86482, ups=3, wpb=28872.5, bsz=963.5, num_updates=362500, lr=5.25226e-05, gnorm=0.503, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-06 13:33:55 | INFO | train_inner | epoch 077:   1658 / 4751 loss=4.44, nll_loss=2.827, ppl=7.1, wps=88289, ups=3.04, wpb=29067.1, bsz=927, num_updates=362600, lr=5.25153e-05, gnorm=0.494, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 13:34:28 | INFO | train_inner | epoch 077:   1758 / 4751 loss=4.503, nll_loss=2.898, ppl=7.45, wps=87970.4, ups=3.04, wpb=28959.6, bsz=977.3, num_updates=362700, lr=5.25081e-05, gnorm=0.508, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 13:35:01 | INFO | train_inner | epoch 077:   1858 / 4751 loss=4.463, nll_loss=2.852, ppl=7.22, wps=87759.8, ups=3.04, wpb=28822, bsz=939.8, num_updates=362800, lr=5.25009e-05, gnorm=0.505, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 13:35:33 | INFO | train_inner | epoch 077:   1958 / 4751 loss=4.523, nll_loss=2.92, ppl=7.57, wps=88380.2, ups=3.05, wpb=28930.7, bsz=929.2, num_updates=362900, lr=5.24936e-05, gnorm=0.51, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-06 13:36:06 | INFO | train_inner | epoch 077:   2058 / 4751 loss=4.476, nll_loss=2.868, ppl=7.3, wps=87507.6, ups=3.03, wpb=28927.9, bsz=971.6, num_updates=363000, lr=5.24864e-05, gnorm=0.495, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 13:36:39 | INFO | train_inner | epoch 077:   2158 / 4751 loss=4.492, nll_loss=2.886, ppl=7.39, wps=89440.3, ups=3.06, wpb=29235.3, bsz=941.8, num_updates=363100, lr=5.24792e-05, gnorm=0.499, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 13:37:12 | INFO | train_inner | epoch 077:   2258 / 4751 loss=4.449, nll_loss=2.837, ppl=7.15, wps=86978.8, ups=3, wpb=28983.8, bsz=946.5, num_updates=363200, lr=5.24719e-05, gnorm=0.499, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 13:37:45 | INFO | train_inner | epoch 077:   2358 / 4751 loss=4.501, nll_loss=2.895, ppl=7.44, wps=88266.6, ups=3.05, wpb=28949.3, bsz=946.5, num_updates=363300, lr=5.24647e-05, gnorm=0.502, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 13:38:18 | INFO | train_inner | epoch 077:   2458 / 4751 loss=4.448, nll_loss=2.837, ppl=7.14, wps=87340.8, ups=3.02, wpb=28945.7, bsz=975.8, num_updates=363400, lr=5.24575e-05, gnorm=0.503, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-06 13:38:51 | INFO | train_inner | epoch 077:   2558 / 4751 loss=4.502, nll_loss=2.896, ppl=7.45, wps=88224, ups=3.04, wpb=28979.5, bsz=943.8, num_updates=363500, lr=5.24503e-05, gnorm=0.505, loss_scale=2, train_wall=33, gb_free=5.9, wall=0
2021-04-06 13:39:24 | INFO | train_inner | epoch 077:   2658 / 4751 loss=4.416, nll_loss=2.8, ppl=6.96, wps=87620.6, ups=3.03, wpb=28892.6, bsz=909.7, num_updates=363600, lr=5.24431e-05, gnorm=0.493, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 13:39:57 | INFO | train_inner | epoch 077:   2758 / 4751 loss=4.504, nll_loss=2.899, ppl=7.46, wps=88441, ups=3.04, wpb=29071.3, bsz=916.1, num_updates=363700, lr=5.24359e-05, gnorm=0.502, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 13:40:30 | INFO | train_inner | epoch 077:   2858 / 4751 loss=4.498, nll_loss=2.893, ppl=7.43, wps=87231.7, ups=3.03, wpb=28823.5, bsz=953.5, num_updates=363800, lr=5.24286e-05, gnorm=0.508, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-06 13:41:03 | INFO | train_inner | epoch 077:   2958 / 4751 loss=4.447, nll_loss=2.836, ppl=7.14, wps=87404.5, ups=3.05, wpb=28629.6, bsz=953.5, num_updates=363900, lr=5.24214e-05, gnorm=0.496, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-06 13:41:36 | INFO | train_inner | epoch 077:   3058 / 4751 loss=4.435, nll_loss=2.821, ppl=7.07, wps=88136.5, ups=3.03, wpb=29064, bsz=944.6, num_updates=364000, lr=5.24142e-05, gnorm=0.496, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 13:41:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-06 13:42:09 | INFO | train_inner | epoch 077:   3159 / 4751 loss=4.518, nll_loss=2.915, ppl=7.54, wps=87596, ups=3.02, wpb=28962.6, bsz=952.9, num_updates=364100, lr=5.2407e-05, gnorm=0.504, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 13:42:42 | INFO | train_inner | epoch 077:   3259 / 4751 loss=4.544, nll_loss=2.945, ppl=7.7, wps=88179, ups=3.05, wpb=28944.9, bsz=922.2, num_updates=364200, lr=5.23998e-05, gnorm=0.501, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 13:43:15 | INFO | train_inner | epoch 077:   3359 / 4751 loss=4.44, nll_loss=2.827, ppl=7.1, wps=86804.3, ups=3, wpb=28960.6, bsz=963.8, num_updates=364300, lr=5.23927e-05, gnorm=0.498, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 13:43:48 | INFO | train_inner | epoch 077:   3459 / 4751 loss=4.494, nll_loss=2.888, ppl=7.4, wps=88074.7, ups=3.03, wpb=29083.2, bsz=960, num_updates=364400, lr=5.23855e-05, gnorm=0.5, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 13:44:21 | INFO | train_inner | epoch 077:   3559 / 4751 loss=4.414, nll_loss=2.798, ppl=6.95, wps=88678.1, ups=3.04, wpb=29145.2, bsz=965.3, num_updates=364500, lr=5.23783e-05, gnorm=0.497, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-06 13:44:55 | INFO | train_inner | epoch 077:   3659 / 4751 loss=4.422, nll_loss=2.807, ppl=7, wps=86510, ups=2.97, wpb=29112.5, bsz=956.4, num_updates=364600, lr=5.23711e-05, gnorm=0.496, loss_scale=2, train_wall=34, gb_free=6.3, wall=0
2021-04-06 13:45:28 | INFO | train_inner | epoch 077:   3759 / 4751 loss=4.421, nll_loss=2.805, ppl=6.99, wps=87788.4, ups=3.03, wpb=28977.5, bsz=946.4, num_updates=364700, lr=5.23639e-05, gnorm=0.492, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 13:46:01 | INFO | train_inner | epoch 077:   3859 / 4751 loss=4.422, nll_loss=2.807, ppl=7, wps=87681.9, ups=3.03, wpb=28905.6, bsz=976.9, num_updates=364800, lr=5.23567e-05, gnorm=0.497, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 13:46:33 | INFO | train_inner | epoch 077:   3959 / 4751 loss=4.52, nll_loss=2.918, ppl=7.56, wps=87848.4, ups=3.03, wpb=28947.1, bsz=929.4, num_updates=364900, lr=5.23496e-05, gnorm=0.499, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 13:47:06 | INFO | train_inner | epoch 077:   4059 / 4751 loss=4.501, nll_loss=2.897, ppl=7.45, wps=88846.5, ups=3.05, wpb=29168.6, bsz=949.4, num_updates=365000, lr=5.23424e-05, gnorm=0.502, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 13:47:39 | INFO | train_inner | epoch 077:   4159 / 4751 loss=4.463, nll_loss=2.854, ppl=7.23, wps=88174.3, ups=3.03, wpb=29085.5, bsz=961.8, num_updates=365100, lr=5.23352e-05, gnorm=0.5, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 13:48:12 | INFO | train_inner | epoch 077:   4259 / 4751 loss=4.479, nll_loss=2.872, ppl=7.32, wps=87878.1, ups=3.04, wpb=28872.9, bsz=956.7, num_updates=365200, lr=5.23281e-05, gnorm=0.503, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 13:48:45 | INFO | train_inner | epoch 077:   4359 / 4751 loss=4.496, nll_loss=2.891, ppl=7.42, wps=88444, ups=3.03, wpb=29154.5, bsz=937.8, num_updates=365300, lr=5.23209e-05, gnorm=0.5, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-06 13:49:18 | INFO | train_inner | epoch 077:   4459 / 4751 loss=4.529, nll_loss=2.927, ppl=7.61, wps=87885.9, ups=3.04, wpb=28898.3, bsz=928.4, num_updates=365400, lr=5.23137e-05, gnorm=0.507, loss_scale=2, train_wall=33, gb_free=7.7, wall=0
2021-04-06 13:49:51 | INFO | train_inner | epoch 077:   4559 / 4751 loss=4.509, nll_loss=2.905, ppl=7.49, wps=88075.1, ups=3.04, wpb=28970.9, bsz=936.4, num_updates=365500, lr=5.23066e-05, gnorm=0.5, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 13:50:24 | INFO | train_inner | epoch 077:   4659 / 4751 loss=4.531, nll_loss=2.93, ppl=7.62, wps=87262.9, ups=3.05, wpb=28632.4, bsz=948.8, num_updates=365600, lr=5.22994e-05, gnorm=0.508, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 13:50:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-06 13:50:55 | INFO | valid | epoch 077 | valid on 'valid' subset | loss 4.137 | nll_loss 2.366 | ppl 5.15 | wps 204147 | wpb 10489.1 | bsz 375 | num_updates 365692 | best_loss 4.121
2021-04-06 13:50:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 77 @ 365692 updates
2021-04-06 13:50:55 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-06 13:50:59 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-06 13:50:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt (epoch 77 @ 365692 updates, score 4.137) (writing took 3.483868580311537 seconds)
2021-04-06 13:50:59 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)
2021-04-06 13:50:59 | INFO | train | epoch 077 | loss 4.477 | nll_loss 2.869 | ppl 7.31 | wps 87550 | ups 3.02 | wpb 28968.4 | bsz 946.7 | num_updates 365692 | lr 5.22928e-05 | gnorm 0.501 | loss_scale 2 | train_wall 1558 | gb_free 6.3 | wall 0
2021-04-06 13:50:59 | INFO | fairseq.trainer | begin training epoch 78
2021-04-06 13:50:59 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-06 13:51:02 | INFO | train_inner | epoch 078:      8 / 4751 loss=4.501, nll_loss=2.896, ppl=7.44, wps=74709.3, ups=2.58, wpb=28948.3, bsz=916.4, num_updates=365700, lr=5.22923e-05, gnorm=0.505, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 13:51:35 | INFO | train_inner | epoch 078:    108 / 4751 loss=4.478, nll_loss=2.87, ppl=7.31, wps=88882.5, ups=3.03, wpb=29344.1, bsz=984.9, num_updates=365800, lr=5.22851e-05, gnorm=0.498, loss_scale=2, train_wall=33, gb_free=7, wall=0
2021-04-06 13:52:08 | INFO | train_inner | epoch 078:    208 / 4751 loss=4.526, nll_loss=2.924, ppl=7.59, wps=88428.2, ups=3.05, wpb=29031.3, bsz=941, num_updates=365900, lr=5.2278e-05, gnorm=0.498, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 13:52:41 | INFO | train_inner | epoch 078:    308 / 4751 loss=4.452, nll_loss=2.841, ppl=7.16, wps=88961.6, ups=3.04, wpb=29252, bsz=952.2, num_updates=366000, lr=5.22708e-05, gnorm=0.498, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 13:53:14 | INFO | train_inner | epoch 078:    408 / 4751 loss=4.509, nll_loss=2.905, ppl=7.49, wps=87684.9, ups=3.03, wpb=28957.5, bsz=941.8, num_updates=366100, lr=5.22637e-05, gnorm=0.501, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 13:53:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-06 13:53:47 | INFO | train_inner | epoch 078:    509 / 4751 loss=4.514, nll_loss=2.911, ppl=7.52, wps=87019.9, ups=3.01, wpb=28901.6, bsz=944, num_updates=366200, lr=5.22566e-05, gnorm=0.501, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 13:54:21 | INFO | train_inner | epoch 078:    609 / 4751 loss=4.488, nll_loss=2.88, ppl=7.36, wps=87561.5, ups=3.02, wpb=29041, bsz=923.3, num_updates=366300, lr=5.22494e-05, gnorm=0.498, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 13:54:54 | INFO | train_inner | epoch 078:    709 / 4751 loss=4.451, nll_loss=2.839, ppl=7.16, wps=87891.8, ups=3.02, wpb=29140.8, bsz=934.8, num_updates=366400, lr=5.22423e-05, gnorm=0.493, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 13:55:27 | INFO | train_inner | epoch 078:    809 / 4751 loss=4.479, nll_loss=2.871, ppl=7.32, wps=86946.7, ups=3.02, wpb=28802.9, bsz=952.7, num_updates=366500, lr=5.22352e-05, gnorm=0.504, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 13:56:00 | INFO | train_inner | epoch 078:    909 / 4751 loss=4.538, nll_loss=2.938, ppl=7.66, wps=88133.3, ups=3.04, wpb=28978.6, bsz=930.1, num_updates=366600, lr=5.2228e-05, gnorm=0.506, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 13:56:33 | INFO | train_inner | epoch 078:   1009 / 4751 loss=4.474, nll_loss=2.865, ppl=7.28, wps=88122.2, ups=3.02, wpb=29148, bsz=940, num_updates=366700, lr=5.22209e-05, gnorm=0.499, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 13:57:06 | INFO | train_inner | epoch 078:   1109 / 4751 loss=4.441, nll_loss=2.828, ppl=7.1, wps=86938.8, ups=2.99, wpb=29038.3, bsz=969.5, num_updates=366800, lr=5.22138e-05, gnorm=0.504, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 13:57:39 | INFO | train_inner | epoch 078:   1209 / 4751 loss=4.456, nll_loss=2.846, ppl=7.19, wps=87528, ups=3.03, wpb=28842.6, bsz=977.8, num_updates=366900, lr=5.22067e-05, gnorm=0.5, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 13:58:12 | INFO | train_inner | epoch 078:   1309 / 4751 loss=4.474, nll_loss=2.865, ppl=7.29, wps=86505.4, ups=3.03, wpb=28549.9, bsz=951.5, num_updates=367000, lr=5.21996e-05, gnorm=0.504, loss_scale=2, train_wall=33, gb_free=6.7, wall=0
2021-04-06 13:58:45 | INFO | train_inner | epoch 078:   1409 / 4751 loss=4.51, nll_loss=2.906, ppl=7.49, wps=88343.8, ups=3.05, wpb=29011, bsz=954.8, num_updates=367100, lr=5.21925e-05, gnorm=0.504, loss_scale=2, train_wall=33, gb_free=6.7, wall=0
2021-04-06 13:59:18 | INFO | train_inner | epoch 078:   1509 / 4751 loss=4.5, nll_loss=2.895, ppl=7.44, wps=88456.8, ups=3.05, wpb=28998, bsz=947.4, num_updates=367200, lr=5.21854e-05, gnorm=0.502, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 13:59:51 | INFO | train_inner | epoch 078:   1609 / 4751 loss=4.411, nll_loss=2.795, ppl=6.94, wps=88314.5, ups=3.03, wpb=29189.6, bsz=987.6, num_updates=367300, lr=5.21783e-05, gnorm=0.517, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 14:00:24 | INFO | train_inner | epoch 078:   1709 / 4751 loss=4.494, nll_loss=2.888, ppl=7.4, wps=88518.6, ups=3.05, wpb=28996.3, bsz=922.6, num_updates=367400, lr=5.21712e-05, gnorm=0.503, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-06 14:00:56 | INFO | train_inner | epoch 078:   1809 / 4751 loss=4.457, nll_loss=2.846, ppl=7.19, wps=87834.2, ups=3.04, wpb=28878.6, bsz=962.3, num_updates=367500, lr=5.21641e-05, gnorm=0.502, loss_scale=2, train_wall=33, gb_free=6.7, wall=0
2021-04-06 14:01:29 | INFO | train_inner | epoch 078:   1909 / 4751 loss=4.488, nll_loss=2.881, ppl=7.37, wps=88009, ups=3.04, wpb=28968.5, bsz=927.3, num_updates=367600, lr=5.2157e-05, gnorm=0.504, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 14:02:02 | INFO | train_inner | epoch 078:   2009 / 4751 loss=4.507, nll_loss=2.902, ppl=7.48, wps=88424.2, ups=3.05, wpb=28983.3, bsz=939.5, num_updates=367700, lr=5.21499e-05, gnorm=0.499, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 14:02:35 | INFO | train_inner | epoch 078:   2109 / 4751 loss=4.484, nll_loss=2.876, ppl=7.34, wps=87275.3, ups=3.03, wpb=28784, bsz=926.6, num_updates=367800, lr=5.21428e-05, gnorm=0.503, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 14:03:08 | INFO | train_inner | epoch 078:   2209 / 4751 loss=4.386, nll_loss=2.766, ppl=6.8, wps=88643.6, ups=3.03, wpb=29264.5, bsz=987.6, num_updates=367900, lr=5.21357e-05, gnorm=0.498, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 14:03:41 | INFO | train_inner | epoch 078:   2309 / 4751 loss=4.477, nll_loss=2.869, ppl=7.3, wps=87394.8, ups=3.04, wpb=28709.6, bsz=935.8, num_updates=368000, lr=5.21286e-05, gnorm=0.502, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 14:04:14 | INFO | train_inner | epoch 078:   2409 / 4751 loss=4.49, nll_loss=2.884, ppl=7.38, wps=88177.8, ups=3.02, wpb=29166.5, bsz=927.1, num_updates=368100, lr=5.21215e-05, gnorm=0.502, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 14:04:47 | INFO | train_inner | epoch 078:   2509 / 4751 loss=4.455, nll_loss=2.843, ppl=7.18, wps=87938, ups=3.04, wpb=28931.3, bsz=929.3, num_updates=368200, lr=5.21144e-05, gnorm=0.495, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 14:05:20 | INFO | train_inner | epoch 078:   2609 / 4751 loss=4.492, nll_loss=2.885, ppl=7.39, wps=88477.1, ups=3.04, wpb=29067.3, bsz=935.6, num_updates=368300, lr=5.21074e-05, gnorm=0.501, loss_scale=4, train_wall=33, gb_free=6, wall=0
2021-04-06 14:05:53 | INFO | train_inner | epoch 078:   2709 / 4751 loss=4.457, nll_loss=2.847, ppl=7.19, wps=88348, ups=3.03, wpb=29186.7, bsz=974.4, num_updates=368400, lr=5.21003e-05, gnorm=0.497, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-06 14:06:26 | INFO | train_inner | epoch 078:   2809 / 4751 loss=4.442, nll_loss=2.829, ppl=7.11, wps=88129.3, ups=3.03, wpb=29044.6, bsz=976.8, num_updates=368500, lr=5.20932e-05, gnorm=0.498, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-06 14:06:59 | INFO | train_inner | epoch 078:   2909 / 4751 loss=4.494, nll_loss=2.888, ppl=7.4, wps=88481.7, ups=3.04, wpb=29103.8, bsz=969.8, num_updates=368600, lr=5.20862e-05, gnorm=0.501, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 14:07:32 | INFO | train_inner | epoch 078:   3009 / 4751 loss=4.481, nll_loss=2.873, ppl=7.33, wps=87464.3, ups=3.02, wpb=28962.2, bsz=934, num_updates=368700, lr=5.20791e-05, gnorm=0.499, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 14:08:05 | INFO | train_inner | epoch 078:   3109 / 4751 loss=4.489, nll_loss=2.883, ppl=7.38, wps=87789.6, ups=3.03, wpb=28949.5, bsz=927, num_updates=368800, lr=5.2072e-05, gnorm=0.501, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 14:08:38 | INFO | train_inner | epoch 078:   3209 / 4751 loss=4.506, nll_loss=2.902, ppl=7.47, wps=88653.3, ups=3.05, wpb=29070.6, bsz=931.8, num_updates=368900, lr=5.2065e-05, gnorm=0.499, loss_scale=4, train_wall=33, gb_free=6, wall=0
2021-04-06 14:09:10 | INFO | train_inner | epoch 078:   3309 / 4751 loss=4.476, nll_loss=2.868, ppl=7.3, wps=87505.3, ups=3.05, wpb=28675.4, bsz=924, num_updates=369000, lr=5.20579e-05, gnorm=0.502, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 14:09:43 | INFO | train_inner | epoch 078:   3409 / 4751 loss=4.489, nll_loss=2.883, ppl=7.38, wps=88497.8, ups=3.05, wpb=29011.8, bsz=977.7, num_updates=369100, lr=5.20509e-05, gnorm=0.505, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 14:10:16 | INFO | train_inner | epoch 078:   3509 / 4751 loss=4.425, nll_loss=2.81, ppl=7.01, wps=87451.5, ups=3.03, wpb=28860.7, bsz=947.4, num_updates=369200, lr=5.20438e-05, gnorm=0.501, loss_scale=4, train_wall=33, gb_free=6, wall=0
2021-04-06 14:10:49 | INFO | train_inner | epoch 078:   3609 / 4751 loss=4.437, nll_loss=2.824, ppl=7.08, wps=86883, ups=3.02, wpb=28815.6, bsz=958.3, num_updates=369300, lr=5.20368e-05, gnorm=0.503, loss_scale=4, train_wall=33, gb_free=6.4, wall=0
2021-04-06 14:11:22 | INFO | train_inner | epoch 078:   3709 / 4751 loss=4.476, nll_loss=2.868, ppl=7.3, wps=86680.4, ups=3.02, wpb=28689.3, bsz=926.1, num_updates=369400, lr=5.20297e-05, gnorm=0.503, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-06 14:11:55 | INFO | train_inner | epoch 078:   3809 / 4751 loss=4.474, nll_loss=2.866, ppl=7.29, wps=89123.2, ups=3.03, wpb=29433.3, bsz=939.3, num_updates=369500, lr=5.20227e-05, gnorm=0.496, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 14:12:28 | INFO | train_inner | epoch 078:   3909 / 4751 loss=4.459, nll_loss=2.848, ppl=7.2, wps=87721.9, ups=3.05, wpb=28794.1, bsz=903.3, num_updates=369600, lr=5.20156e-05, gnorm=0.507, loss_scale=4, train_wall=33, gb_free=6, wall=0
2021-04-06 14:13:02 | INFO | train_inner | epoch 078:   4009 / 4751 loss=4.477, nll_loss=2.87, ppl=7.31, wps=85996, ups=2.97, wpb=28955.9, bsz=978.2, num_updates=369700, lr=5.20086e-05, gnorm=0.506, loss_scale=4, train_wall=34, gb_free=6.2, wall=0
2021-04-06 14:13:35 | INFO | train_inner | epoch 078:   4109 / 4751 loss=4.528, nll_loss=2.927, ppl=7.6, wps=87642.5, ups=3.05, wpb=28709.9, bsz=934.2, num_updates=369800, lr=5.20016e-05, gnorm=0.504, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 14:14:08 | INFO | train_inner | epoch 078:   4209 / 4751 loss=4.528, nll_loss=2.927, ppl=7.61, wps=87868.5, ups=3.05, wpb=28833.7, bsz=954.2, num_updates=369900, lr=5.19946e-05, gnorm=0.516, loss_scale=4, train_wall=33, gb_free=6.5, wall=0
2021-04-06 14:14:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-06 14:14:41 | INFO | train_inner | epoch 078:   4310 / 4751 loss=4.444, nll_loss=2.832, ppl=7.12, wps=87691.1, ups=3.01, wpb=29170.4, bsz=972.2, num_updates=370000, lr=5.19875e-05, gnorm=0.496, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 14:15:14 | INFO | train_inner | epoch 078:   4410 / 4751 loss=4.504, nll_loss=2.899, ppl=7.46, wps=87268.7, ups=3.04, wpb=28744.8, bsz=925.8, num_updates=370100, lr=5.19805e-05, gnorm=0.507, loss_scale=2, train_wall=33, gb_free=6.7, wall=0
2021-04-06 14:15:47 | INFO | train_inner | epoch 078:   4510 / 4751 loss=4.52, nll_loss=2.918, ppl=7.56, wps=87842.3, ups=3.05, wpb=28817.8, bsz=926.8, num_updates=370200, lr=5.19735e-05, gnorm=0.501, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 14:16:20 | INFO | train_inner | epoch 078:   4610 / 4751 loss=4.421, nll_loss=2.806, ppl=6.99, wps=87109.1, ups=3.02, wpb=28849.4, bsz=932.7, num_updates=370300, lr=5.19665e-05, gnorm=0.505, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 14:16:53 | INFO | train_inner | epoch 078:   4710 / 4751 loss=4.461, nll_loss=2.851, ppl=7.22, wps=86940.1, ups=3.01, wpb=28868.7, bsz=950.7, num_updates=370400, lr=5.19594e-05, gnorm=0.504, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 14:17:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-06 14:17:08 | INFO | valid | epoch 078 | valid on 'valid' subset | loss 4.119 | nll_loss 2.353 | ppl 5.11 | wps 196271 | wpb 10489.1 | bsz 375 | num_updates 370441 | best_loss 4.119
2021-04-06 14:17:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 78 @ 370441 updates
2021-04-06 14:17:08 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-06 14:17:11 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt
2021-04-06 14:17:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_best.pt (epoch 78 @ 370441 updates, score 4.119) (writing took 6.59612936899066 seconds)
2021-04-06 14:17:14 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)
2021-04-06 14:17:14 | INFO | train | epoch 078 | loss 4.476 | nll_loss 2.868 | ppl 7.3 | wps 87310.1 | ups 3.01 | wpb 28968.1 | bsz 946.8 | num_updates 370441 | lr 5.19566e-05 | gnorm 0.502 | loss_scale 2 | train_wall 1560 | gb_free 6.1 | wall 0
2021-04-06 14:17:14 | INFO | fairseq.trainer | begin training epoch 79
2021-04-06 14:17:14 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-06 14:17:35 | INFO | train_inner | epoch 079:     59 / 4751 loss=4.429, nll_loss=2.815, ppl=7.04, wps=69035.9, ups=2.38, wpb=29033.5, bsz=971.8, num_updates=370500, lr=5.19524e-05, gnorm=0.497, loss_scale=2, train_wall=33, gb_free=6.7, wall=0
2021-04-06 14:18:08 | INFO | train_inner | epoch 079:    159 / 4751 loss=4.436, nll_loss=2.822, ppl=7.07, wps=87819.6, ups=3.03, wpb=29010.1, bsz=924.9, num_updates=370600, lr=5.19454e-05, gnorm=0.499, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 14:18:41 | INFO | train_inner | epoch 079:    259 / 4751 loss=4.499, nll_loss=2.893, ppl=7.43, wps=88124, ups=3.04, wpb=28941, bsz=962.1, num_updates=370700, lr=5.19384e-05, gnorm=0.509, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 14:19:14 | INFO | train_inner | epoch 079:    359 / 4751 loss=4.493, nll_loss=2.886, ppl=7.39, wps=88270.3, ups=3.05, wpb=28914.4, bsz=952.2, num_updates=370800, lr=5.19314e-05, gnorm=0.503, loss_scale=2, train_wall=33, gb_free=6.6, wall=0
2021-04-06 14:19:47 | INFO | train_inner | epoch 079:    459 / 4751 loss=4.456, nll_loss=2.845, ppl=7.18, wps=87190.8, ups=3.02, wpb=28830.4, bsz=930.6, num_updates=370900, lr=5.19244e-05, gnorm=0.499, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 14:20:19 | INFO | train_inner | epoch 079:    559 / 4751 loss=4.457, nll_loss=2.846, ppl=7.19, wps=89711.1, ups=3.06, wpb=29323.1, bsz=937.9, num_updates=371000, lr=5.19174e-05, gnorm=0.495, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 14:20:53 | INFO | train_inner | epoch 079:    659 / 4751 loss=4.448, nll_loss=2.836, ppl=7.14, wps=86222.5, ups=2.96, wpb=29107.3, bsz=963.6, num_updates=371100, lr=5.19104e-05, gnorm=0.497, loss_scale=2, train_wall=34, gb_free=6.4, wall=0
2021-04-06 14:21:26 | INFO | train_inner | epoch 079:    759 / 4751 loss=4.462, nll_loss=2.852, ppl=7.22, wps=88456.4, ups=3.04, wpb=29139.7, bsz=938.5, num_updates=371200, lr=5.19034e-05, gnorm=0.496, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 14:21:59 | INFO | train_inner | epoch 079:    859 / 4751 loss=4.458, nll_loss=2.848, ppl=7.2, wps=87511.5, ups=3.05, wpb=28729, bsz=937, num_updates=371300, lr=5.18964e-05, gnorm=0.501, loss_scale=2, train_wall=33, gb_free=7.8, wall=0
2021-04-06 14:22:32 | INFO | train_inner | epoch 079:    959 / 4751 loss=4.503, nll_loss=2.898, ppl=7.45, wps=88470.8, ups=3.03, wpb=29186.7, bsz=929.2, num_updates=371400, lr=5.18894e-05, gnorm=0.5, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-06 14:22:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-04-06 14:23:05 | INFO | train_inner | epoch 079:   1060 / 4751 loss=4.447, nll_loss=2.835, ppl=7.13, wps=87780.3, ups=3, wpb=29234.8, bsz=982.2, num_updates=371500, lr=5.18825e-05, gnorm=0.5, loss_scale=1, train_wall=33, gb_free=6, wall=0
2021-04-06 14:23:38 | INFO | train_inner | epoch 079:   1160 / 4751 loss=4.521, nll_loss=2.918, ppl=7.56, wps=88278.4, ups=3.04, wpb=29078.8, bsz=934.3, num_updates=371600, lr=5.18755e-05, gnorm=0.508, loss_scale=1, train_wall=33, gb_free=6.5, wall=0
2021-04-06 14:24:11 | INFO | train_inner | epoch 079:   1260 / 4751 loss=4.422, nll_loss=2.807, ppl=7, wps=88076.4, ups=3.03, wpb=29025.2, bsz=982.6, num_updates=371700, lr=5.18685e-05, gnorm=0.519, loss_scale=1, train_wall=33, gb_free=6.5, wall=0
2021-04-06 14:24:44 | INFO | train_inner | epoch 079:   1360 / 4751 loss=4.469, nll_loss=2.859, ppl=7.26, wps=87895.8, ups=3.02, wpb=29098.1, bsz=949.9, num_updates=371800, lr=5.18615e-05, gnorm=0.501, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 14:25:17 | INFO | train_inner | epoch 079:   1460 / 4751 loss=4.467, nll_loss=2.858, ppl=7.25, wps=87116.8, ups=3.03, wpb=28758.3, bsz=949, num_updates=371900, lr=5.18546e-05, gnorm=0.507, loss_scale=1, train_wall=33, gb_free=6, wall=0
2021-04-06 14:25:50 | INFO | train_inner | epoch 079:   1560 / 4751 loss=4.499, nll_loss=2.893, ppl=7.43, wps=87931.2, ups=3.06, wpb=28770.9, bsz=933, num_updates=372000, lr=5.18476e-05, gnorm=0.506, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 14:26:23 | INFO | train_inner | epoch 079:   1660 / 4751 loss=4.492, nll_loss=2.886, ppl=7.39, wps=87027, ups=3.04, wpb=28618.7, bsz=934, num_updates=372100, lr=5.18406e-05, gnorm=0.509, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 14:26:56 | INFO | train_inner | epoch 079:   1760 / 4751 loss=4.469, nll_loss=2.86, ppl=7.26, wps=88708.9, ups=3.05, wpb=29082.5, bsz=967.1, num_updates=372200, lr=5.18337e-05, gnorm=0.5, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 14:27:28 | INFO | train_inner | epoch 079:   1860 / 4751 loss=4.429, nll_loss=2.815, ppl=7.04, wps=88395.1, ups=3.04, wpb=29112, bsz=965.4, num_updates=372300, lr=5.18267e-05, gnorm=0.502, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 14:28:02 | INFO | train_inner | epoch 079:   1960 / 4751 loss=4.502, nll_loss=2.897, ppl=7.45, wps=87319.3, ups=3.03, wpb=28851.4, bsz=944.1, num_updates=372400, lr=5.18197e-05, gnorm=0.507, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 14:28:35 | INFO | train_inner | epoch 079:   2060 / 4751 loss=4.441, nll_loss=2.828, ppl=7.1, wps=87736, ups=3.03, wpb=28984.3, bsz=947.1, num_updates=372500, lr=5.18128e-05, gnorm=0.502, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 14:29:07 | INFO | train_inner | epoch 079:   2160 / 4751 loss=4.472, nll_loss=2.863, ppl=7.27, wps=88382.9, ups=3.05, wpb=28958.7, bsz=936.7, num_updates=372600, lr=5.18058e-05, gnorm=0.5, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 14:29:41 | INFO | train_inner | epoch 079:   2260 / 4751 loss=4.451, nll_loss=2.839, ppl=7.16, wps=87387.9, ups=3.01, wpb=29018, bsz=939.5, num_updates=372700, lr=5.17989e-05, gnorm=0.529, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 14:30:13 | INFO | train_inner | epoch 079:   2360 / 4751 loss=4.52, nll_loss=2.918, ppl=7.56, wps=87334.1, ups=3.05, wpb=28669.8, bsz=960.9, num_updates=372800, lr=5.17919e-05, gnorm=0.51, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 14:30:46 | INFO | train_inner | epoch 079:   2460 / 4751 loss=4.513, nll_loss=2.909, ppl=7.51, wps=87500.1, ups=3.05, wpb=28730, bsz=953.4, num_updates=372900, lr=5.1785e-05, gnorm=0.508, loss_scale=1, train_wall=33, gb_free=6.4, wall=0
2021-04-06 14:31:19 | INFO | train_inner | epoch 079:   2560 / 4751 loss=4.556, nll_loss=2.959, ppl=7.77, wps=87903.9, ups=3.05, wpb=28797.3, bsz=937.2, num_updates=373000, lr=5.1778e-05, gnorm=0.511, loss_scale=1, train_wall=33, gb_free=6.4, wall=0
2021-04-06 14:31:52 | INFO | train_inner | epoch 079:   2660 / 4751 loss=4.478, nll_loss=2.871, ppl=7.31, wps=87673.8, ups=3.04, wpb=28797.3, bsz=945.2, num_updates=373100, lr=5.17711e-05, gnorm=0.502, loss_scale=1, train_wall=33, gb_free=6.4, wall=0
2021-04-06 14:32:25 | INFO | train_inner | epoch 079:   2760 / 4751 loss=4.531, nll_loss=2.93, ppl=7.62, wps=87754.6, ups=3.05, wpb=28817.4, bsz=922, num_updates=373200, lr=5.17642e-05, gnorm=0.505, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 14:32:57 | INFO | train_inner | epoch 079:   2860 / 4751 loss=4.504, nll_loss=2.899, ppl=7.46, wps=88897.7, ups=3.06, wpb=29058.8, bsz=954.9, num_updates=373300, lr=5.17572e-05, gnorm=0.5, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 14:33:30 | INFO | train_inner | epoch 079:   2960 / 4751 loss=4.464, nll_loss=2.854, ppl=7.23, wps=88007.8, ups=3.03, wpb=29001, bsz=942.5, num_updates=373400, lr=5.17503e-05, gnorm=0.498, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 14:34:03 | INFO | train_inner | epoch 079:   3060 / 4751 loss=4.453, nll_loss=2.842, ppl=7.17, wps=88746.5, ups=3.03, wpb=29312.3, bsz=941.8, num_updates=373500, lr=5.17434e-05, gnorm=0.5, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 14:34:36 | INFO | train_inner | epoch 079:   3160 / 4751 loss=4.475, nll_loss=2.867, ppl=7.29, wps=88445.9, ups=3.05, wpb=28963.9, bsz=937.6, num_updates=373600, lr=5.17364e-05, gnorm=0.505, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-06 14:35:09 | INFO | train_inner | epoch 079:   3260 / 4751 loss=4.441, nll_loss=2.828, ppl=7.1, wps=88836.5, ups=3.02, wpb=29412.6, bsz=951.5, num_updates=373700, lr=5.17295e-05, gnorm=0.492, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 14:35:42 | INFO | train_inner | epoch 079:   3360 / 4751 loss=4.499, nll_loss=2.894, ppl=7.43, wps=88315.4, ups=3.04, wpb=29007.2, bsz=928.2, num_updates=373800, lr=5.17226e-05, gnorm=0.5, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 14:36:15 | INFO | train_inner | epoch 079:   3460 / 4751 loss=4.455, nll_loss=2.844, ppl=7.18, wps=86575.1, ups=3.01, wpb=28759.6, bsz=933.8, num_updates=373900, lr=5.17157e-05, gnorm=0.506, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-06 14:36:48 | INFO | train_inner | epoch 079:   3560 / 4751 loss=4.528, nll_loss=2.926, ppl=7.6, wps=88515.2, ups=3.04, wpb=29079.7, bsz=929, num_updates=374000, lr=5.17088e-05, gnorm=0.507, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-06 14:37:21 | INFO | train_inner | epoch 079:   3660 / 4751 loss=4.458, nll_loss=2.847, ppl=7.2, wps=87469, ups=3.02, wpb=28976.4, bsz=930.2, num_updates=374100, lr=5.17019e-05, gnorm=0.501, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 14:37:54 | INFO | train_inner | epoch 079:   3760 / 4751 loss=4.485, nll_loss=2.878, ppl=7.35, wps=87211, ups=3.01, wpb=28941.2, bsz=947.3, num_updates=374200, lr=5.16949e-05, gnorm=0.505, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 14:38:27 | INFO | train_inner | epoch 079:   3860 / 4751 loss=4.481, nll_loss=2.873, ppl=7.33, wps=88071.8, ups=3.04, wpb=28994.8, bsz=941.8, num_updates=374300, lr=5.1688e-05, gnorm=0.497, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 14:39:01 | INFO | train_inner | epoch 079:   3960 / 4751 loss=4.473, nll_loss=2.864, ppl=7.28, wps=87318.8, ups=3, wpb=29074.6, bsz=943.7, num_updates=374400, lr=5.16811e-05, gnorm=0.498, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-06 14:39:34 | INFO | train_inner | epoch 079:   4060 / 4751 loss=4.441, nll_loss=2.828, ppl=7.1, wps=87862.1, ups=3.04, wpb=28938.8, bsz=969.1, num_updates=374500, lr=5.16742e-05, gnorm=0.501, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 14:40:06 | INFO | train_inner | epoch 079:   4160 / 4751 loss=4.452, nll_loss=2.84, ppl=7.16, wps=88191.1, ups=3.03, wpb=29064.6, bsz=946.7, num_updates=374600, lr=5.16673e-05, gnorm=0.501, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 14:40:40 | INFO | train_inner | epoch 079:   4260 / 4751 loss=4.488, nll_loss=2.881, ppl=7.37, wps=87387.8, ups=3.02, wpb=28980.6, bsz=923.7, num_updates=374700, lr=5.16604e-05, gnorm=0.498, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 14:41:13 | INFO | train_inner | epoch 079:   4360 / 4751 loss=4.507, nll_loss=2.903, ppl=7.48, wps=88903.2, ups=3.04, wpb=29215.2, bsz=987.8, num_updates=374800, lr=5.16536e-05, gnorm=0.499, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 14:41:46 | INFO | train_inner | epoch 079:   4460 / 4751 loss=4.462, nll_loss=2.853, ppl=7.22, wps=87780.3, ups=3.02, wpb=29028, bsz=968.8, num_updates=374900, lr=5.16467e-05, gnorm=0.502, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 14:42:18 | INFO | train_inner | epoch 079:   4560 / 4751 loss=4.478, nll_loss=2.871, ppl=7.31, wps=87902.8, ups=3.04, wpb=28896.7, bsz=968.8, num_updates=375000, lr=5.16398e-05, gnorm=0.505, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-06 14:42:51 | INFO | train_inner | epoch 079:   4660 / 4751 loss=4.48, nll_loss=2.872, ppl=7.32, wps=86237.7, ups=3.03, wpb=28419.4, bsz=945.7, num_updates=375100, lr=5.16329e-05, gnorm=0.508, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 14:43:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-06 14:43:23 | INFO | valid | epoch 079 | valid on 'valid' subset | loss 4.128 | nll_loss 2.356 | ppl 5.12 | wps 184916 | wpb 10489.1 | bsz 375 | num_updates 375191 | best_loss 4.119
2021-04-06 14:43:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 79 @ 375191 updates
2021-04-06 14:43:23 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-06 14:43:26 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-06 14:43:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt (epoch 79 @ 375191 updates, score 4.128) (writing took 3.574070192873478 seconds)
2021-04-06 14:43:26 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)
2021-04-06 14:43:26 | INFO | train | epoch 079 | loss 4.475 | nll_loss 2.867 | ppl 7.3 | wps 87524.3 | ups 3.02 | wpb 28968.3 | bsz 947 | num_updates 375191 | lr 5.16266e-05 | gnorm 0.503 | loss_scale 2 | train_wall 1559 | gb_free 6.2 | wall 0
2021-04-06 14:43:26 | INFO | fairseq.trainer | begin training epoch 80
2021-04-06 14:43:26 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-06 14:43:31 | INFO | train_inner | epoch 080:      9 / 4751 loss=4.443, nll_loss=2.831, ppl=7.11, wps=73716.4, ups=2.56, wpb=28811.3, bsz=938.4, num_updates=375200, lr=5.1626e-05, gnorm=0.501, loss_scale=2, train_wall=33, gb_free=5.9, wall=0
2021-04-06 14:44:03 | INFO | train_inner | epoch 080:    109 / 4751 loss=4.462, nll_loss=2.852, ppl=7.22, wps=88104.8, ups=3.04, wpb=28977.8, bsz=921.3, num_updates=375300, lr=5.16191e-05, gnorm=0.503, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 14:44:36 | INFO | train_inner | epoch 080:    209 / 4751 loss=4.445, nll_loss=2.833, ppl=7.13, wps=88445.8, ups=3.04, wpb=29099.3, bsz=945.3, num_updates=375400, lr=5.16123e-05, gnorm=0.497, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 14:45:09 | INFO | train_inner | epoch 080:    309 / 4751 loss=4.488, nll_loss=2.881, ppl=7.37, wps=88239.6, ups=3.02, wpb=29191.7, bsz=971.5, num_updates=375500, lr=5.16054e-05, gnorm=0.502, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 14:45:42 | INFO | train_inner | epoch 080:    409 / 4751 loss=4.48, nll_loss=2.871, ppl=7.32, wps=87714.8, ups=3.04, wpb=28870.3, bsz=908.4, num_updates=375600, lr=5.15985e-05, gnorm=0.5, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-06 14:46:15 | INFO | train_inner | epoch 080:    509 / 4751 loss=4.454, nll_loss=2.842, ppl=7.17, wps=88395.6, ups=3.03, wpb=29176.2, bsz=960.6, num_updates=375700, lr=5.15916e-05, gnorm=0.503, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-06 14:46:48 | INFO | train_inner | epoch 080:    609 / 4751 loss=4.539, nll_loss=2.939, ppl=7.67, wps=88967.1, ups=3.06, wpb=29121.1, bsz=958.7, num_updates=375800, lr=5.15848e-05, gnorm=0.503, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 14:47:21 | INFO | train_inner | epoch 080:    709 / 4751 loss=4.46, nll_loss=2.85, ppl=7.21, wps=87592.1, ups=3.02, wpb=28962.8, bsz=962.6, num_updates=375900, lr=5.15779e-05, gnorm=0.503, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 14:47:54 | INFO | train_inner | epoch 080:    809 / 4751 loss=4.471, nll_loss=2.862, ppl=7.27, wps=88018.3, ups=3.04, wpb=28946, bsz=942.6, num_updates=376000, lr=5.15711e-05, gnorm=0.502, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 14:48:27 | INFO | train_inner | epoch 080:    909 / 4751 loss=4.462, nll_loss=2.852, ppl=7.22, wps=88185, ups=3.03, wpb=29066.9, bsz=937.4, num_updates=376100, lr=5.15642e-05, gnorm=0.501, loss_scale=4, train_wall=33, gb_free=6.4, wall=0
2021-04-06 14:48:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-06 14:49:00 | INFO | train_inner | epoch 080:   1010 / 4751 loss=4.455, nll_loss=2.843, ppl=7.18, wps=87627.8, ups=3.01, wpb=29146.1, bsz=924, num_updates=376200, lr=5.15574e-05, gnorm=0.5, loss_scale=2, train_wall=33, gb_free=6.9, wall=0
2021-04-06 14:49:33 | INFO | train_inner | epoch 080:   1110 / 4751 loss=4.422, nll_loss=2.807, ppl=7, wps=88207.5, ups=3.05, wpb=28885.6, bsz=975.4, num_updates=376300, lr=5.15505e-05, gnorm=0.501, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 14:50:06 | INFO | train_inner | epoch 080:   1210 / 4751 loss=4.477, nll_loss=2.868, ppl=7.3, wps=88222, ups=3.04, wpb=29014.6, bsz=937.6, num_updates=376400, lr=5.15437e-05, gnorm=0.5, loss_scale=2, train_wall=33, gb_free=6.6, wall=0
2021-04-06 14:50:39 | INFO | train_inner | epoch 080:   1310 / 4751 loss=4.515, nll_loss=2.912, ppl=7.53, wps=87055.6, ups=3.03, wpb=28728.3, bsz=960.6, num_updates=376500, lr=5.15368e-05, gnorm=0.509, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 14:51:12 | INFO | train_inner | epoch 080:   1410 / 4751 loss=4.443, nll_loss=2.83, ppl=7.11, wps=88160.1, ups=3.03, wpb=29083.9, bsz=961.2, num_updates=376600, lr=5.153e-05, gnorm=0.498, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 14:51:45 | INFO | train_inner | epoch 080:   1510 / 4751 loss=4.455, nll_loss=2.844, ppl=7.18, wps=88457.5, ups=3.04, wpb=29074.7, bsz=972.6, num_updates=376700, lr=5.15231e-05, gnorm=0.502, loss_scale=2, train_wall=33, gb_free=6.6, wall=0
2021-04-06 14:52:18 | INFO | train_inner | epoch 080:   1610 / 4751 loss=4.439, nll_loss=2.826, ppl=7.09, wps=86947, ups=3.02, wpb=28777.2, bsz=952.5, num_updates=376800, lr=5.15163e-05, gnorm=0.505, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 14:52:51 | INFO | train_inner | epoch 080:   1710 / 4751 loss=4.465, nll_loss=2.855, ppl=7.24, wps=87478.5, ups=3.01, wpb=29051.6, bsz=961.3, num_updates=376900, lr=5.15095e-05, gnorm=0.504, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 14:53:24 | INFO | train_inner | epoch 080:   1810 / 4751 loss=4.498, nll_loss=2.892, ppl=7.42, wps=88243.5, ups=3.04, wpb=29057.8, bsz=960.6, num_updates=377000, lr=5.15026e-05, gnorm=0.51, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 14:53:57 | INFO | train_inner | epoch 080:   1910 / 4751 loss=4.471, nll_loss=2.861, ppl=7.27, wps=88093.4, ups=3.03, wpb=29068, bsz=945.1, num_updates=377100, lr=5.14958e-05, gnorm=0.498, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 14:54:31 | INFO | train_inner | epoch 080:   2010 / 4751 loss=4.489, nll_loss=2.882, ppl=7.37, wps=85970.9, ups=2.97, wpb=28940.7, bsz=950.9, num_updates=377200, lr=5.1489e-05, gnorm=0.503, loss_scale=2, train_wall=34, gb_free=5.9, wall=0
2021-04-06 14:55:03 | INFO | train_inner | epoch 080:   2110 / 4751 loss=4.507, nll_loss=2.902, ppl=7.48, wps=88343, ups=3.05, wpb=28996.5, bsz=953.3, num_updates=377300, lr=5.14821e-05, gnorm=0.513, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 14:55:36 | INFO | train_inner | epoch 080:   2210 / 4751 loss=4.456, nll_loss=2.845, ppl=7.19, wps=87850.6, ups=3.03, wpb=28995.1, bsz=907.8, num_updates=377400, lr=5.14753e-05, gnorm=0.504, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 14:56:09 | INFO | train_inner | epoch 080:   2310 / 4751 loss=4.518, nll_loss=2.915, ppl=7.54, wps=87211.1, ups=3.04, wpb=28652.1, bsz=952, num_updates=377500, lr=5.14685e-05, gnorm=0.516, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 14:56:42 | INFO | train_inner | epoch 080:   2410 / 4751 loss=4.489, nll_loss=2.882, ppl=7.37, wps=88052.4, ups=3.03, wpb=29045, bsz=931.9, num_updates=377600, lr=5.14617e-05, gnorm=0.508, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 14:57:15 | INFO | train_inner | epoch 080:   2510 / 4751 loss=4.44, nll_loss=2.827, ppl=7.1, wps=87012.1, ups=3.03, wpb=28714.5, bsz=950.8, num_updates=377700, lr=5.14549e-05, gnorm=0.505, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 14:57:48 | INFO | train_inner | epoch 080:   2610 / 4751 loss=4.504, nll_loss=2.9, ppl=7.46, wps=87805.1, ups=3.02, wpb=29062.1, bsz=945.1, num_updates=377800, lr=5.14481e-05, gnorm=0.507, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 14:58:21 | INFO | train_inner | epoch 080:   2710 / 4751 loss=4.525, nll_loss=2.924, ppl=7.59, wps=87798.5, ups=3.03, wpb=28994.1, bsz=916.8, num_updates=377900, lr=5.14413e-05, gnorm=0.513, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 14:58:54 | INFO | train_inner | epoch 080:   2810 / 4751 loss=4.488, nll_loss=2.882, ppl=7.37, wps=87549.2, ups=3.04, wpb=28845.4, bsz=940.7, num_updates=378000, lr=5.14344e-05, gnorm=0.505, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 14:59:27 | INFO | train_inner | epoch 080:   2910 / 4751 loss=4.439, nll_loss=2.826, ppl=7.09, wps=88070.2, ups=3.03, wpb=29090.3, bsz=960.4, num_updates=378100, lr=5.14276e-05, gnorm=0.499, loss_scale=2, train_wall=33, gb_free=6.9, wall=0
2021-04-06 15:00:00 | INFO | train_inner | epoch 080:   3010 / 4751 loss=4.483, nll_loss=2.876, ppl=7.34, wps=86894.7, ups=3.04, wpb=28551.2, bsz=957.1, num_updates=378200, lr=5.14208e-05, gnorm=0.507, loss_scale=2, train_wall=33, gb_free=6.7, wall=0
2021-04-06 15:00:34 | INFO | train_inner | epoch 080:   3110 / 4751 loss=4.435, nll_loss=2.822, ppl=7.07, wps=86923.9, ups=3, wpb=28937.1, bsz=957.2, num_updates=378300, lr=5.14141e-05, gnorm=0.504, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 15:01:07 | INFO | train_inner | epoch 080:   3210 / 4751 loss=4.456, nll_loss=2.845, ppl=7.19, wps=88355.2, ups=3.03, wpb=29158.4, bsz=978.5, num_updates=378400, lr=5.14073e-05, gnorm=0.498, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 15:01:39 | INFO | train_inner | epoch 080:   3310 / 4751 loss=4.467, nll_loss=2.858, ppl=7.25, wps=88163.5, ups=3.04, wpb=29039.9, bsz=934.4, num_updates=378500, lr=5.14005e-05, gnorm=0.5, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 15:02:12 | INFO | train_inner | epoch 080:   3410 / 4751 loss=4.51, nll_loss=2.906, ppl=7.49, wps=88537.7, ups=3.05, wpb=29049.3, bsz=911.4, num_updates=378600, lr=5.13937e-05, gnorm=0.502, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 15:02:45 | INFO | train_inner | epoch 080:   3510 / 4751 loss=4.461, nll_loss=2.851, ppl=7.22, wps=87787, ups=3.02, wpb=29110.6, bsz=936.6, num_updates=378700, lr=5.13869e-05, gnorm=0.501, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 15:03:18 | INFO | train_inner | epoch 080:   3610 / 4751 loss=4.463, nll_loss=2.854, ppl=7.23, wps=87553.3, ups=3.03, wpb=28928.7, bsz=942, num_updates=378800, lr=5.13801e-05, gnorm=0.507, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-06 15:03:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-06 15:03:52 | INFO | train_inner | epoch 080:   3711 / 4751 loss=4.438, nll_loss=2.825, ppl=7.08, wps=87092.2, ups=3.02, wpb=28858.3, bsz=928.3, num_updates=378900, lr=5.13733e-05, gnorm=0.507, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 15:04:24 | INFO | train_inner | epoch 080:   3811 / 4751 loss=4.492, nll_loss=2.886, ppl=7.39, wps=88680, ups=3.06, wpb=29015.6, bsz=946.2, num_updates=379000, lr=5.13665e-05, gnorm=0.504, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 15:04:57 | INFO | train_inner | epoch 080:   3911 / 4751 loss=4.457, nll_loss=2.847, ppl=7.19, wps=87711.9, ups=3.04, wpb=28898.7, bsz=978.9, num_updates=379100, lr=5.13598e-05, gnorm=0.499, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 15:05:30 | INFO | train_inner | epoch 080:   4011 / 4751 loss=4.494, nll_loss=2.888, ppl=7.4, wps=87477.6, ups=3.04, wpb=28799.1, bsz=911.6, num_updates=379200, lr=5.1353e-05, gnorm=0.504, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 15:06:03 | INFO | train_inner | epoch 080:   4111 / 4751 loss=4.514, nll_loss=2.911, ppl=7.52, wps=88059.1, ups=3.05, wpb=28876.2, bsz=955.3, num_updates=379300, lr=5.13462e-05, gnorm=0.507, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 15:06:36 | INFO | train_inner | epoch 080:   4211 / 4751 loss=4.522, nll_loss=2.92, ppl=7.57, wps=88570, ups=3.05, wpb=29003.8, bsz=954.4, num_updates=379400, lr=5.13395e-05, gnorm=0.509, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 15:07:09 | INFO | train_inner | epoch 080:   4311 / 4751 loss=4.476, nll_loss=2.868, ppl=7.3, wps=88031.3, ups=3.04, wpb=28966, bsz=949.2, num_updates=379500, lr=5.13327e-05, gnorm=0.516, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 15:07:41 | INFO | train_inner | epoch 080:   4411 / 4751 loss=4.538, nll_loss=2.938, ppl=7.67, wps=88919.3, ups=3.05, wpb=29121.3, bsz=945.4, num_updates=379600, lr=5.13259e-05, gnorm=0.51, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 15:08:14 | INFO | train_inner | epoch 080:   4511 / 4751 loss=4.435, nll_loss=2.822, ppl=7.07, wps=88158.6, ups=3.03, wpb=29053, bsz=952.2, num_updates=379700, lr=5.13192e-05, gnorm=0.503, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 15:08:47 | INFO | train_inner | epoch 080:   4611 / 4751 loss=4.463, nll_loss=2.854, ppl=7.23, wps=87486.1, ups=3.03, wpb=28854.9, bsz=953.1, num_updates=379800, lr=5.13124e-05, gnorm=0.504, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-06 15:09:20 | INFO | train_inner | epoch 080:   4711 / 4751 loss=4.461, nll_loss=2.852, ppl=7.22, wps=88077.6, ups=3.04, wpb=28963.4, bsz=945.1, num_updates=379900, lr=5.13057e-05, gnorm=0.5, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 15:09:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-06 15:09:34 | INFO | valid | epoch 080 | valid on 'valid' subset | loss 4.129 | nll_loss 2.36 | ppl 5.13 | wps 210030 | wpb 10489.1 | bsz 375 | num_updates 379940 | best_loss 4.119
2021-04-06 15:09:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 80 @ 379940 updates
2021-04-06 15:09:34 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-06 15:09:41 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-06 15:09:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt (epoch 80 @ 379940 updates, score 4.129) (writing took 6.144633632153273 seconds)
2021-04-06 15:09:41 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)
2021-04-06 15:09:41 | INFO | train | epoch 080 | loss 4.474 | nll_loss 2.866 | ppl 7.29 | wps 87385.2 | ups 3.02 | wpb 28969 | bsz 946.8 | num_updates 379940 | lr 5.1303e-05 | gnorm 0.504 | loss_scale 2 | train_wall 1559 | gb_free 6.9 | wall 0
2021-04-06 15:09:41 | INFO | fairseq.trainer | begin training epoch 81
2021-04-06 15:09:41 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-06 15:10:02 | INFO | train_inner | epoch 081:     60 / 4751 loss=4.413, nll_loss=2.797, ppl=6.95, wps=69301.5, ups=2.41, wpb=28738.5, bsz=944.8, num_updates=380000, lr=5.12989e-05, gnorm=0.511, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 15:10:34 | INFO | train_inner | epoch 081:    160 / 4751 loss=4.429, nll_loss=2.814, ppl=7.03, wps=89418.7, ups=3.06, wpb=29201.6, bsz=939, num_updates=380100, lr=5.12922e-05, gnorm=0.498, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-06 15:11:07 | INFO | train_inner | epoch 081:    260 / 4751 loss=4.487, nll_loss=2.879, ppl=7.36, wps=87688.8, ups=3.04, wpb=28841.7, bsz=939.5, num_updates=380200, lr=5.12854e-05, gnorm=0.501, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-06 15:11:41 | INFO | train_inner | epoch 081:    360 / 4751 loss=4.481, nll_loss=2.873, ppl=7.33, wps=85825.9, ups=2.99, wpb=28739.7, bsz=937, num_updates=380300, lr=5.12787e-05, gnorm=0.505, loss_scale=2, train_wall=33, gb_free=6.6, wall=0
2021-04-06 15:12:14 | INFO | train_inner | epoch 081:    460 / 4751 loss=4.46, nll_loss=2.85, ppl=7.21, wps=88397, ups=3.03, wpb=29210.8, bsz=991.7, num_updates=380400, lr=5.12719e-05, gnorm=0.5, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 15:12:47 | INFO | train_inner | epoch 081:    560 / 4751 loss=4.529, nll_loss=2.928, ppl=7.61, wps=87181.9, ups=3.03, wpb=28733.3, bsz=945.8, num_updates=380500, lr=5.12652e-05, gnorm=0.515, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 15:13:20 | INFO | train_inner | epoch 081:    660 / 4751 loss=4.461, nll_loss=2.851, ppl=7.21, wps=88077.6, ups=3.04, wpb=28968.5, bsz=926.3, num_updates=380600, lr=5.12585e-05, gnorm=0.504, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 15:13:53 | INFO | train_inner | epoch 081:    760 / 4751 loss=4.451, nll_loss=2.839, ppl=7.15, wps=87640.7, ups=3.03, wpb=28909.1, bsz=953.9, num_updates=380700, lr=5.12517e-05, gnorm=0.501, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 15:14:26 | INFO | train_inner | epoch 081:    860 / 4751 loss=4.473, nll_loss=2.864, ppl=7.28, wps=88249.7, ups=3.03, wpb=29153.2, bsz=921.8, num_updates=380800, lr=5.1245e-05, gnorm=0.504, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 15:14:59 | INFO | train_inner | epoch 081:    960 / 4751 loss=4.45, nll_loss=2.838, ppl=7.15, wps=87100.9, ups=3.02, wpb=28885.2, bsz=951, num_updates=380900, lr=5.12383e-05, gnorm=0.503, loss_scale=4, train_wall=33, gb_free=6.5, wall=0
2021-04-06 15:15:32 | INFO | train_inner | epoch 081:   1060 / 4751 loss=4.488, nll_loss=2.882, ppl=7.37, wps=87855.9, ups=3.05, wpb=28794.8, bsz=929, num_updates=381000, lr=5.12316e-05, gnorm=0.507, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 15:16:05 | INFO | train_inner | epoch 081:   1160 / 4751 loss=4.4, nll_loss=2.781, ppl=6.87, wps=88862.2, ups=3.04, wpb=29266.5, bsz=938.6, num_updates=381100, lr=5.12248e-05, gnorm=0.494, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 15:16:38 | INFO | train_inner | epoch 081:   1260 / 4751 loss=4.489, nll_loss=2.882, ppl=7.37, wps=87395.1, ups=3.02, wpb=28894.2, bsz=921.4, num_updates=381200, lr=5.12181e-05, gnorm=0.507, loss_scale=4, train_wall=33, gb_free=6.4, wall=0
2021-04-06 15:17:11 | INFO | train_inner | epoch 081:   1360 / 4751 loss=4.441, nll_loss=2.828, ppl=7.1, wps=88291.6, ups=3.03, wpb=29102.9, bsz=935.8, num_updates=381300, lr=5.12114e-05, gnorm=0.501, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 15:17:43 | INFO | train_inner | epoch 081:   1460 / 4751 loss=4.474, nll_loss=2.866, ppl=7.29, wps=88739.1, ups=3.04, wpb=29184.3, bsz=970.5, num_updates=381400, lr=5.12047e-05, gnorm=0.505, loss_scale=4, train_wall=33, gb_free=6.5, wall=0
2021-04-06 15:18:16 | INFO | train_inner | epoch 081:   1560 / 4751 loss=4.465, nll_loss=2.855, ppl=7.24, wps=88500.9, ups=3.06, wpb=28924, bsz=968.2, num_updates=381500, lr=5.1198e-05, gnorm=0.502, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 15:18:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-06 15:18:49 | INFO | train_inner | epoch 081:   1661 / 4751 loss=4.466, nll_loss=2.856, ppl=7.24, wps=87052.5, ups=3.01, wpb=28956.6, bsz=926.2, num_updates=381600, lr=5.11913e-05, gnorm=0.504, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 15:19:22 | INFO | train_inner | epoch 081:   1761 / 4751 loss=4.488, nll_loss=2.882, ppl=7.37, wps=88639, ups=3.06, wpb=28989.1, bsz=990, num_updates=381700, lr=5.11846e-05, gnorm=0.502, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 15:19:55 | INFO | train_inner | epoch 081:   1861 / 4751 loss=4.432, nll_loss=2.818, ppl=7.05, wps=87064.3, ups=3, wpb=29059.7, bsz=938.6, num_updates=381800, lr=5.11779e-05, gnorm=0.497, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 15:20:29 | INFO | train_inner | epoch 081:   1961 / 4751 loss=4.434, nll_loss=2.82, ppl=7.06, wps=86821.5, ups=3.02, wpb=28733.6, bsz=917.3, num_updates=381900, lr=5.11711e-05, gnorm=0.509, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 15:21:01 | INFO | train_inner | epoch 081:   2061 / 4751 loss=4.459, nll_loss=2.849, ppl=7.2, wps=87809.3, ups=3.03, wpb=28934, bsz=942.2, num_updates=382000, lr=5.11645e-05, gnorm=0.504, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 15:21:35 | INFO | train_inner | epoch 081:   2161 / 4751 loss=4.483, nll_loss=2.876, ppl=7.34, wps=87259.3, ups=3.02, wpb=28870.6, bsz=951.1, num_updates=382100, lr=5.11578e-05, gnorm=0.515, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-06 15:22:08 | INFO | train_inner | epoch 081:   2261 / 4751 loss=4.426, nll_loss=2.811, ppl=7.02, wps=87573.6, ups=3.03, wpb=28901.2, bsz=954.6, num_updates=382200, lr=5.11511e-05, gnorm=0.5, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 15:22:40 | INFO | train_inner | epoch 081:   2361 / 4751 loss=4.489, nll_loss=2.883, ppl=7.38, wps=88158.1, ups=3.05, wpb=28947.1, bsz=920.2, num_updates=382300, lr=5.11444e-05, gnorm=0.509, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-06 15:23:14 | INFO | train_inner | epoch 081:   2461 / 4751 loss=4.441, nll_loss=2.828, ppl=7.1, wps=86866.1, ups=3.01, wpb=28843, bsz=917.5, num_updates=382400, lr=5.11377e-05, gnorm=0.497, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 15:23:47 | INFO | train_inner | epoch 081:   2561 / 4751 loss=4.518, nll_loss=2.916, ppl=7.55, wps=87116.3, ups=3.03, wpb=28745.8, bsz=979, num_updates=382500, lr=5.1131e-05, gnorm=0.511, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 15:24:20 | INFO | train_inner | epoch 081:   2661 / 4751 loss=4.448, nll_loss=2.837, ppl=7.14, wps=88555, ups=3.03, wpb=29258.7, bsz=970.8, num_updates=382600, lr=5.11243e-05, gnorm=0.499, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 15:24:53 | INFO | train_inner | epoch 081:   2761 / 4751 loss=4.492, nll_loss=2.887, ppl=7.4, wps=88059.5, ups=3.03, wpb=29030.4, bsz=998, num_updates=382700, lr=5.11176e-05, gnorm=0.511, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 15:25:26 | INFO | train_inner | epoch 081:   2861 / 4751 loss=4.473, nll_loss=2.865, ppl=7.29, wps=88165.2, ups=3.04, wpb=29035.9, bsz=969.1, num_updates=382800, lr=5.1111e-05, gnorm=0.497, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 15:25:59 | INFO | train_inner | epoch 081:   2961 / 4751 loss=4.509, nll_loss=2.905, ppl=7.49, wps=87089.1, ups=3.02, wpb=28874.8, bsz=934.9, num_updates=382900, lr=5.11043e-05, gnorm=0.512, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-06 15:26:32 | INFO | train_inner | epoch 081:   3061 / 4751 loss=4.501, nll_loss=2.897, ppl=7.45, wps=87069.1, ups=3.03, wpb=28724.4, bsz=931.9, num_updates=383000, lr=5.10976e-05, gnorm=0.505, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 15:27:05 | INFO | train_inner | epoch 081:   3161 / 4751 loss=4.524, nll_loss=2.923, ppl=7.59, wps=88277, ups=3.04, wpb=29067.4, bsz=976.2, num_updates=383100, lr=5.10909e-05, gnorm=0.515, loss_scale=2, train_wall=33, gb_free=6.6, wall=0
2021-04-06 15:27:38 | INFO | train_inner | epoch 081:   3261 / 4751 loss=4.461, nll_loss=2.851, ppl=7.21, wps=88782, ups=3.04, wpb=29238.4, bsz=958, num_updates=383200, lr=5.10843e-05, gnorm=0.499, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 15:28:10 | INFO | train_inner | epoch 081:   3361 / 4751 loss=4.539, nll_loss=2.939, ppl=7.67, wps=87819.8, ups=3.04, wpb=28878, bsz=939.3, num_updates=383300, lr=5.10776e-05, gnorm=0.516, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-06 15:28:43 | INFO | train_inner | epoch 081:   3461 / 4751 loss=4.524, nll_loss=2.922, ppl=7.58, wps=86535.6, ups=3.03, wpb=28592, bsz=905.4, num_updates=383400, lr=5.1071e-05, gnorm=0.506, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 15:28:53 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-04-06 15:29:17 | INFO | train_inner | epoch 081:   3562 / 4751 loss=4.4, nll_loss=2.782, ppl=6.88, wps=86789, ups=3, wpb=28970.3, bsz=975.4, num_updates=383500, lr=5.10643e-05, gnorm=0.502, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 15:29:50 | INFO | train_inner | epoch 081:   3662 / 4751 loss=4.51, nll_loss=2.906, ppl=7.5, wps=88977.7, ups=3.04, wpb=29296.6, bsz=941.8, num_updates=383600, lr=5.10576e-05, gnorm=0.5, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 15:30:23 | INFO | train_inner | epoch 081:   3762 / 4751 loss=4.478, nll_loss=2.87, ppl=7.31, wps=87954.9, ups=3.03, wpb=29047.1, bsz=929.8, num_updates=383700, lr=5.1051e-05, gnorm=0.5, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 15:30:56 | INFO | train_inner | epoch 081:   3862 / 4751 loss=4.469, nll_loss=2.859, ppl=7.26, wps=87954.1, ups=3.02, wpb=29079.2, bsz=946, num_updates=383800, lr=5.10443e-05, gnorm=0.501, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 15:31:29 | INFO | train_inner | epoch 081:   3962 / 4751 loss=4.484, nll_loss=2.878, ppl=7.35, wps=87698.6, ups=3.05, wpb=28776.4, bsz=970.8, num_updates=383900, lr=5.10377e-05, gnorm=0.508, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 15:32:02 | INFO | train_inner | epoch 081:   4062 / 4751 loss=4.495, nll_loss=2.89, ppl=7.41, wps=87496.8, ups=3.03, wpb=28882, bsz=958.2, num_updates=384000, lr=5.1031e-05, gnorm=0.506, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 15:32:35 | INFO | train_inner | epoch 081:   4162 / 4751 loss=4.457, nll_loss=2.847, ppl=7.19, wps=88636.6, ups=3.04, wpb=29187.1, bsz=962.6, num_updates=384100, lr=5.10244e-05, gnorm=0.501, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 15:33:07 | INFO | train_inner | epoch 081:   4262 / 4751 loss=4.508, nll_loss=2.905, ppl=7.49, wps=89091.7, ups=3.05, wpb=29179.2, bsz=953.5, num_updates=384200, lr=5.10178e-05, gnorm=0.51, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 15:33:40 | INFO | train_inner | epoch 081:   4362 / 4751 loss=4.472, nll_loss=2.863, ppl=7.27, wps=88080.6, ups=3.04, wpb=29003.6, bsz=955.6, num_updates=384300, lr=5.10111e-05, gnorm=0.506, loss_scale=1, train_wall=33, gb_free=6, wall=0
2021-04-06 15:34:13 | INFO | train_inner | epoch 081:   4462 / 4751 loss=4.527, nll_loss=2.926, ppl=7.6, wps=87250.8, ups=3.04, wpb=28741, bsz=909, num_updates=384400, lr=5.10045e-05, gnorm=0.507, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 15:34:46 | INFO | train_inner | epoch 081:   4562 / 4751 loss=4.428, nll_loss=2.814, ppl=7.03, wps=87910.7, ups=3.02, wpb=29085.6, bsz=953.3, num_updates=384500, lr=5.09978e-05, gnorm=0.503, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 15:35:19 | INFO | train_inner | epoch 081:   4662 / 4751 loss=4.458, nll_loss=2.848, ppl=7.2, wps=88744.9, ups=3.05, wpb=29062.7, bsz=943.3, num_updates=384600, lr=5.09912e-05, gnorm=0.501, loss_scale=1, train_wall=33, gb_free=6, wall=0
2021-04-06 15:35:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-06 15:35:49 | INFO | valid | epoch 081 | valid on 'valid' subset | loss 4.134 | nll_loss 2.366 | ppl 5.16 | wps 200587 | wpb 10489.1 | bsz 375 | num_updates 384689 | best_loss 4.119
2021-04-06 15:35:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 81 @ 384689 updates
2021-04-06 15:35:49 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-06 15:35:55 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-06 15:35:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt (epoch 81 @ 384689 updates, score 4.134) (writing took 6.168242808431387 seconds)
2021-04-06 15:35:55 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)
2021-04-06 15:35:55 | INFO | train | epoch 081 | loss 4.473 | nll_loss 2.865 | ppl 7.28 | wps 87361.2 | ups 3.02 | wpb 28967.7 | bsz 946.7 | num_updates 384689 | lr 5.09853e-05 | gnorm 0.504 | loss_scale 1 | train_wall 1559 | gb_free 6.4 | wall 0
2021-04-06 15:35:55 | INFO | fairseq.trainer | begin training epoch 82
2021-04-06 15:35:55 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-06 15:36:00 | INFO | train_inner | epoch 082:     11 / 4751 loss=4.5, nll_loss=2.895, ppl=7.44, wps=69492.7, ups=2.43, wpb=28597, bsz=894.6, num_updates=384700, lr=5.09846e-05, gnorm=0.507, loss_scale=1, train_wall=32, gb_free=6.1, wall=0
2021-04-06 15:36:33 | INFO | train_inner | epoch 082:    111 / 4751 loss=4.477, nll_loss=2.868, ppl=7.3, wps=88413.1, ups=3.05, wpb=29013.3, bsz=952.6, num_updates=384800, lr=5.0978e-05, gnorm=0.505, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 15:37:06 | INFO | train_inner | epoch 082:    211 / 4751 loss=4.435, nll_loss=2.821, ppl=7.07, wps=89071.8, ups=3.04, wpb=29292.4, bsz=979.5, num_updates=384900, lr=5.09713e-05, gnorm=0.494, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 15:37:39 | INFO | train_inner | epoch 082:    311 / 4751 loss=4.495, nll_loss=2.888, ppl=7.4, wps=88182.7, ups=3.04, wpb=28989.2, bsz=923.8, num_updates=385000, lr=5.09647e-05, gnorm=0.506, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 15:38:12 | INFO | train_inner | epoch 082:    411 / 4751 loss=4.408, nll_loss=2.791, ppl=6.92, wps=87607.3, ups=3.03, wpb=28928.8, bsz=1006.9, num_updates=385100, lr=5.09581e-05, gnorm=0.503, loss_scale=1, train_wall=33, gb_free=6, wall=0
2021-04-06 15:38:45 | INFO | train_inner | epoch 082:    511 / 4751 loss=4.393, nll_loss=2.774, ppl=6.84, wps=88764.1, ups=3.04, wpb=29231.5, bsz=976.8, num_updates=385200, lr=5.09515e-05, gnorm=0.496, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 15:39:17 | INFO | train_inner | epoch 082:    611 / 4751 loss=4.489, nll_loss=2.882, ppl=7.37, wps=88472.7, ups=3.06, wpb=28872.5, bsz=946.8, num_updates=385300, lr=5.09449e-05, gnorm=0.507, loss_scale=1, train_wall=32, gb_free=6.4, wall=0
2021-04-06 15:39:50 | INFO | train_inner | epoch 082:    711 / 4751 loss=4.469, nll_loss=2.86, ppl=7.26, wps=87942.3, ups=3.04, wpb=28906.6, bsz=951, num_updates=385400, lr=5.09383e-05, gnorm=0.503, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 15:40:23 | INFO | train_inner | epoch 082:    811 / 4751 loss=4.465, nll_loss=2.855, ppl=7.24, wps=88380.7, ups=3.04, wpb=29119.4, bsz=929.9, num_updates=385500, lr=5.09317e-05, gnorm=0.504, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 15:40:56 | INFO | train_inner | epoch 082:    911 / 4751 loss=4.496, nll_loss=2.89, ppl=7.41, wps=87395, ups=3.03, wpb=28806.8, bsz=943.4, num_updates=385600, lr=5.09251e-05, gnorm=0.507, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 15:41:29 | INFO | train_inner | epoch 082:   1011 / 4751 loss=4.459, nll_loss=2.849, ppl=7.2, wps=88229.2, ups=3.03, wpb=29081.4, bsz=931.8, num_updates=385700, lr=5.09185e-05, gnorm=0.506, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 15:42:02 | INFO | train_inner | epoch 082:   1111 / 4751 loss=4.539, nll_loss=2.939, ppl=7.67, wps=87500.9, ups=3.05, wpb=28659.2, bsz=921.5, num_updates=385800, lr=5.09119e-05, gnorm=0.538, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-06 15:42:35 | INFO | train_inner | epoch 082:   1211 / 4751 loss=4.423, nll_loss=2.808, ppl=7, wps=88272.7, ups=3.03, wpb=29167.2, bsz=957.2, num_updates=385900, lr=5.09053e-05, gnorm=0.5, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 15:43:08 | INFO | train_inner | epoch 082:   1311 / 4751 loss=4.5, nll_loss=2.894, ppl=7.44, wps=87142.9, ups=3.03, wpb=28749, bsz=961.8, num_updates=386000, lr=5.08987e-05, gnorm=0.508, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 15:43:41 | INFO | train_inner | epoch 082:   1411 / 4751 loss=4.464, nll_loss=2.855, ppl=7.23, wps=87668.2, ups=3.03, wpb=28889.9, bsz=953.1, num_updates=386100, lr=5.08921e-05, gnorm=0.5, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 15:44:14 | INFO | train_inner | epoch 082:   1511 / 4751 loss=4.45, nll_loss=2.838, ppl=7.15, wps=88555.3, ups=3.04, wpb=29141.6, bsz=932.6, num_updates=386200, lr=5.08855e-05, gnorm=0.503, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 15:44:47 | INFO | train_inner | epoch 082:   1611 / 4751 loss=4.427, nll_loss=2.813, ppl=7.03, wps=87310.3, ups=3.02, wpb=28957.5, bsz=926.5, num_updates=386300, lr=5.08789e-05, gnorm=0.501, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 15:45:20 | INFO | train_inner | epoch 082:   1711 / 4751 loss=4.495, nll_loss=2.889, ppl=7.41, wps=87153.7, ups=3.02, wpb=28852.3, bsz=950.2, num_updates=386400, lr=5.08723e-05, gnorm=0.513, loss_scale=2, train_wall=33, gb_free=6.6, wall=0
2021-04-06 15:45:53 | INFO | train_inner | epoch 082:   1811 / 4751 loss=4.474, nll_loss=2.866, ppl=7.29, wps=88101.1, ups=3.03, wpb=29047.3, bsz=959.4, num_updates=386500, lr=5.08657e-05, gnorm=0.505, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 15:46:26 | INFO | train_inner | epoch 082:   1911 / 4751 loss=4.433, nll_loss=2.819, ppl=7.06, wps=87736.5, ups=3.02, wpb=29010.4, bsz=974.4, num_updates=386600, lr=5.08591e-05, gnorm=0.504, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 15:46:59 | INFO | train_inner | epoch 082:   2011 / 4751 loss=4.437, nll_loss=2.824, ppl=7.08, wps=87588, ups=3.03, wpb=28909.7, bsz=936.1, num_updates=386700, lr=5.08526e-05, gnorm=0.502, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 15:47:32 | INFO | train_inner | epoch 082:   2111 / 4751 loss=4.502, nll_loss=2.897, ppl=7.45, wps=87577.7, ups=3.02, wpb=28952.3, bsz=933.1, num_updates=386800, lr=5.0846e-05, gnorm=0.508, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 15:48:05 | INFO | train_inner | epoch 082:   2211 / 4751 loss=4.492, nll_loss=2.886, ppl=7.39, wps=87188.7, ups=3, wpb=29032.8, bsz=965.8, num_updates=386900, lr=5.08394e-05, gnorm=0.503, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 15:48:38 | INFO | train_inner | epoch 082:   2311 / 4751 loss=4.425, nll_loss=2.81, ppl=7.01, wps=88429.7, ups=3.05, wpb=28980.3, bsz=968.3, num_updates=387000, lr=5.08329e-05, gnorm=0.5, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 15:49:11 | INFO | train_inner | epoch 082:   2411 / 4751 loss=4.511, nll_loss=2.908, ppl=7.5, wps=88144.2, ups=3.04, wpb=29018.9, bsz=921.1, num_updates=387100, lr=5.08263e-05, gnorm=0.507, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 15:49:44 | INFO | train_inner | epoch 082:   2511 / 4751 loss=4.482, nll_loss=2.874, ppl=7.33, wps=87615.7, ups=3.02, wpb=28986.4, bsz=925.6, num_updates=387200, lr=5.08197e-05, gnorm=0.507, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 15:50:17 | INFO | train_inner | epoch 082:   2611 / 4751 loss=4.489, nll_loss=2.883, ppl=7.38, wps=88391.3, ups=3.05, wpb=28952, bsz=967.3, num_updates=387300, lr=5.08132e-05, gnorm=0.507, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 15:50:50 | INFO | train_inner | epoch 082:   2711 / 4751 loss=4.494, nll_loss=2.888, ppl=7.4, wps=88656, ups=3.04, wpb=29166.9, bsz=952.2, num_updates=387400, lr=5.08066e-05, gnorm=0.5, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 15:51:23 | INFO | train_inner | epoch 082:   2811 / 4751 loss=4.444, nll_loss=2.832, ppl=7.12, wps=87164.5, ups=3.02, wpb=28828.6, bsz=942.4, num_updates=387500, lr=5.08001e-05, gnorm=0.5, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 15:51:56 | INFO | train_inner | epoch 082:   2911 / 4751 loss=4.513, nll_loss=2.91, ppl=7.52, wps=87432.3, ups=3.03, wpb=28885.8, bsz=926.3, num_updates=387600, lr=5.07935e-05, gnorm=0.506, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-06 15:52:11 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-06 15:52:29 | INFO | train_inner | epoch 082:   3012 / 4751 loss=4.446, nll_loss=2.834, ppl=7.13, wps=86716.1, ups=2.99, wpb=28997.6, bsz=944.5, num_updates=387700, lr=5.07869e-05, gnorm=0.499, loss_scale=2, train_wall=33, gb_free=5.8, wall=0
2021-04-06 15:53:02 | INFO | train_inner | epoch 082:   3112 / 4751 loss=4.52, nll_loss=2.917, ppl=7.55, wps=87884, ups=3.03, wpb=28961.7, bsz=921.7, num_updates=387800, lr=5.07804e-05, gnorm=0.505, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 15:53:35 | INFO | train_inner | epoch 082:   3212 / 4751 loss=4.495, nll_loss=2.889, ppl=7.41, wps=88379.1, ups=3.03, wpb=29155, bsz=957.7, num_updates=387900, lr=5.07739e-05, gnorm=0.513, loss_scale=2, train_wall=33, gb_free=6.6, wall=0
2021-04-06 15:54:08 | INFO | train_inner | epoch 082:   3312 / 4751 loss=4.485, nll_loss=2.878, ppl=7.35, wps=88076.8, ups=3.04, wpb=28973.9, bsz=914.5, num_updates=388000, lr=5.07673e-05, gnorm=0.509, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 15:54:41 | INFO | train_inner | epoch 082:   3412 / 4751 loss=4.467, nll_loss=2.859, ppl=7.25, wps=88175.8, ups=3.05, wpb=28872.3, bsz=958.5, num_updates=388100, lr=5.07608e-05, gnorm=0.507, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 15:55:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-04-06 15:55:15 | INFO | train_inner | epoch 082:   3513 / 4751 loss=4.397, nll_loss=2.779, ppl=6.86, wps=86994.3, ups=2.98, wpb=29186.6, bsz=979.9, num_updates=388200, lr=5.07542e-05, gnorm=0.502, loss_scale=1, train_wall=33, gb_free=6.4, wall=0
2021-04-06 15:55:48 | INFO | train_inner | epoch 082:   3613 / 4751 loss=4.464, nll_loss=2.854, ppl=7.23, wps=86354.8, ups=2.96, wpb=29158.4, bsz=962.8, num_updates=388300, lr=5.07477e-05, gnorm=0.501, loss_scale=1, train_wall=34, gb_free=6.2, wall=0
2021-04-06 15:56:21 | INFO | train_inner | epoch 082:   3713 / 4751 loss=4.547, nll_loss=2.948, ppl=7.72, wps=87840.4, ups=3.04, wpb=28887.8, bsz=935.1, num_updates=388400, lr=5.07412e-05, gnorm=0.512, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 15:56:54 | INFO | train_inner | epoch 082:   3813 / 4751 loss=4.486, nll_loss=2.879, ppl=7.36, wps=88145.8, ups=3.05, wpb=28921.1, bsz=954.2, num_updates=388500, lr=5.07346e-05, gnorm=0.506, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 15:57:27 | INFO | train_inner | epoch 082:   3913 / 4751 loss=4.46, nll_loss=2.85, ppl=7.21, wps=86399.9, ups=3.02, wpb=28619.3, bsz=935, num_updates=388600, lr=5.07281e-05, gnorm=0.509, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 15:58:00 | INFO | train_inner | epoch 082:   4013 / 4751 loss=4.473, nll_loss=2.865, ppl=7.28, wps=87962.7, ups=3.04, wpb=28916.8, bsz=942.8, num_updates=388700, lr=5.07216e-05, gnorm=0.505, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 15:58:33 | INFO | train_inner | epoch 082:   4113 / 4751 loss=4.445, nll_loss=2.834, ppl=7.13, wps=87901.4, ups=3.02, wpb=29089.4, bsz=963, num_updates=388800, lr=5.07151e-05, gnorm=0.502, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 15:59:06 | INFO | train_inner | epoch 082:   4213 / 4751 loss=4.432, nll_loss=2.818, ppl=7.05, wps=87182.8, ups=3.02, wpb=28868.9, bsz=951.2, num_updates=388900, lr=5.07085e-05, gnorm=0.501, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 15:59:39 | INFO | train_inner | epoch 082:   4313 / 4751 loss=4.527, nll_loss=2.925, ppl=7.6, wps=88973.3, ups=3.05, wpb=29124.5, bsz=919.4, num_updates=389000, lr=5.0702e-05, gnorm=0.508, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 16:00:12 | INFO | train_inner | epoch 082:   4413 / 4751 loss=4.457, nll_loss=2.846, ppl=7.19, wps=88527.4, ups=3.04, wpb=29106.2, bsz=919.2, num_updates=389100, lr=5.06955e-05, gnorm=0.498, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 16:00:45 | INFO | train_inner | epoch 082:   4513 / 4751 loss=4.504, nll_loss=2.9, ppl=7.46, wps=87919.7, ups=3.03, wpb=28976.4, bsz=951.9, num_updates=389200, lr=5.0689e-05, gnorm=0.509, loss_scale=1, train_wall=33, gb_free=6.5, wall=0
2021-04-06 16:01:18 | INFO | train_inner | epoch 082:   4613 / 4751 loss=4.551, nll_loss=2.953, ppl=7.74, wps=87136.4, ups=3.04, wpb=28701.2, bsz=933.7, num_updates=389300, lr=5.06825e-05, gnorm=0.511, loss_scale=1, train_wall=33, gb_free=6.4, wall=0
2021-04-06 16:01:51 | INFO | train_inner | epoch 082:   4713 / 4751 loss=4.442, nll_loss=2.83, ppl=7.11, wps=87030.7, ups=3.02, wpb=28799.9, bsz=954.3, num_updates=389400, lr=5.0676e-05, gnorm=0.505, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 16:02:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-06 16:02:04 | INFO | valid | epoch 082 | valid on 'valid' subset | loss 4.12 | nll_loss 2.351 | ppl 5.1 | wps 174120 | wpb 10489.1 | bsz 375 | num_updates 389438 | best_loss 4.119
2021-04-06 16:02:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 82 @ 389438 updates
2021-04-06 16:02:04 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-06 16:02:11 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-06 16:02:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt (epoch 82 @ 389438 updates, score 4.12) (writing took 6.596551824361086 seconds)
2021-04-06 16:02:11 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)
2021-04-06 16:02:11 | INFO | train | epoch 082 | loss 4.472 | nll_loss 2.863 | ppl 7.28 | wps 87308.4 | ups 3.01 | wpb 28968.5 | bsz 946.9 | num_updates 389438 | lr 5.06735e-05 | gnorm 0.505 | loss_scale 1 | train_wall 1560 | gb_free 7.2 | wall 0
2021-04-06 16:02:11 | INFO | fairseq.trainer | begin training epoch 83
2021-04-06 16:02:11 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-06 16:02:33 | INFO | train_inner | epoch 083:     62 / 4751 loss=4.496, nll_loss=2.89, ppl=7.41, wps=68758.4, ups=2.38, wpb=28848.1, bsz=933.7, num_updates=389500, lr=5.06695e-05, gnorm=0.511, loss_scale=1, train_wall=33, gb_free=6.4, wall=0
2021-04-06 16:03:06 | INFO | train_inner | epoch 083:    162 / 4751 loss=4.465, nll_loss=2.856, ppl=7.24, wps=88527.2, ups=3.04, wpb=29108.4, bsz=952.6, num_updates=389600, lr=5.0663e-05, gnorm=0.502, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 16:03:39 | INFO | train_inner | epoch 083:    262 / 4751 loss=4.502, nll_loss=2.897, ppl=7.45, wps=88326.1, ups=3.04, wpb=29049.8, bsz=913.8, num_updates=389700, lr=5.06565e-05, gnorm=0.507, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 16:04:12 | INFO | train_inner | epoch 083:    362 / 4751 loss=4.418, nll_loss=2.802, ppl=6.97, wps=88822, ups=3.03, wpb=29341.9, bsz=971.2, num_updates=389800, lr=5.065e-05, gnorm=0.494, loss_scale=1, train_wall=33, gb_free=6, wall=0
2021-04-06 16:04:44 | INFO | train_inner | epoch 083:    462 / 4751 loss=4.472, nll_loss=2.862, ppl=7.27, wps=89032.3, ups=3.06, wpb=29087.6, bsz=934.3, num_updates=389900, lr=5.06435e-05, gnorm=0.503, loss_scale=1, train_wall=33, gb_free=6.4, wall=0
2021-04-06 16:05:17 | INFO | train_inner | epoch 083:    562 / 4751 loss=4.421, nll_loss=2.806, ppl=6.99, wps=90170.6, ups=3.04, wpb=29624.2, bsz=970.7, num_updates=390000, lr=5.0637e-05, gnorm=0.497, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 16:05:50 | INFO | train_inner | epoch 083:    662 / 4751 loss=4.48, nll_loss=2.873, ppl=7.32, wps=88049.8, ups=3.04, wpb=28930.4, bsz=932.4, num_updates=390100, lr=5.06305e-05, gnorm=0.503, loss_scale=1, train_wall=33, gb_free=6.8, wall=0
2021-04-06 16:06:23 | INFO | train_inner | epoch 083:    762 / 4751 loss=4.471, nll_loss=2.862, ppl=7.27, wps=87124.5, ups=3.05, wpb=28582.3, bsz=947.1, num_updates=390200, lr=5.0624e-05, gnorm=0.517, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 16:06:56 | INFO | train_inner | epoch 083:    862 / 4751 loss=4.49, nll_loss=2.883, ppl=7.38, wps=87905.5, ups=3.05, wpb=28843.4, bsz=890.5, num_updates=390300, lr=5.06175e-05, gnorm=0.503, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 16:07:29 | INFO | train_inner | epoch 083:    962 / 4751 loss=4.506, nll_loss=2.902, ppl=7.47, wps=86667, ups=3.03, wpb=28647.8, bsz=923.8, num_updates=390400, lr=5.0611e-05, gnorm=0.524, loss_scale=2, train_wall=33, gb_free=6.5, wall=0
2021-04-06 16:08:02 | INFO | train_inner | epoch 083:   1062 / 4751 loss=4.451, nll_loss=2.84, ppl=7.16, wps=87174.6, ups=3.03, wpb=28777.4, bsz=961.6, num_updates=390500, lr=5.06045e-05, gnorm=0.507, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 16:08:35 | INFO | train_inner | epoch 083:   1162 / 4751 loss=4.381, nll_loss=2.761, ppl=6.78, wps=87816.8, ups=3, wpb=29301.2, bsz=979.6, num_updates=390600, lr=5.05981e-05, gnorm=0.493, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 16:09:08 | INFO | train_inner | epoch 083:   1262 / 4751 loss=4.468, nll_loss=2.859, ppl=7.25, wps=88169.5, ups=3.03, wpb=29068.3, bsz=952.2, num_updates=390700, lr=5.05916e-05, gnorm=0.509, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 16:09:41 | INFO | train_inner | epoch 083:   1362 / 4751 loss=4.475, nll_loss=2.867, ppl=7.29, wps=88024.2, ups=3.02, wpb=29101.6, bsz=944, num_updates=390800, lr=5.05851e-05, gnorm=0.512, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 16:10:14 | INFO | train_inner | epoch 083:   1462 / 4751 loss=4.429, nll_loss=2.815, ppl=7.04, wps=88630.3, ups=3.04, wpb=29192.6, bsz=962.9, num_updates=390900, lr=5.05786e-05, gnorm=0.506, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 16:10:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-04-06 16:10:47 | INFO | train_inner | epoch 083:   1563 / 4751 loss=4.492, nll_loss=2.886, ppl=7.39, wps=86830.8, ups=3, wpb=28968.4, bsz=952.5, num_updates=391000, lr=5.05722e-05, gnorm=0.51, loss_scale=1, train_wall=33, gb_free=6.5, wall=0
2021-04-06 16:11:20 | INFO | train_inner | epoch 083:   1663 / 4751 loss=4.489, nll_loss=2.882, ppl=7.37, wps=88328.4, ups=3.04, wpb=29011, bsz=1003.4, num_updates=391100, lr=5.05657e-05, gnorm=0.509, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 16:11:53 | INFO | train_inner | epoch 083:   1763 / 4751 loss=4.488, nll_loss=2.881, ppl=7.37, wps=88438.8, ups=3.03, wpb=29162.5, bsz=934.4, num_updates=391200, lr=5.05592e-05, gnorm=0.511, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 16:12:26 | INFO | train_inner | epoch 083:   1863 / 4751 loss=4.458, nll_loss=2.847, ppl=7.2, wps=87766, ups=3.03, wpb=28955.2, bsz=946.8, num_updates=391300, lr=5.05528e-05, gnorm=0.505, loss_scale=1, train_wall=33, gb_free=6, wall=0
2021-04-06 16:12:59 | INFO | train_inner | epoch 083:   1963 / 4751 loss=4.473, nll_loss=2.864, ppl=7.28, wps=86717.6, ups=3.02, wpb=28688.2, bsz=944.4, num_updates=391400, lr=5.05463e-05, gnorm=0.521, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 16:13:32 | INFO | train_inner | epoch 083:   2063 / 4751 loss=4.404, nll_loss=2.786, ppl=6.9, wps=88371.9, ups=3.03, wpb=29130.6, bsz=939.8, num_updates=391500, lr=5.05399e-05, gnorm=0.506, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 16:14:05 | INFO | train_inner | epoch 083:   2163 / 4751 loss=4.473, nll_loss=2.864, ppl=7.28, wps=87631.2, ups=3.03, wpb=28906, bsz=975.8, num_updates=391600, lr=5.05334e-05, gnorm=0.508, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 16:14:38 | INFO | train_inner | epoch 083:   2263 / 4751 loss=4.491, nll_loss=2.885, ppl=7.39, wps=86873.6, ups=3.02, wpb=28801.9, bsz=918.2, num_updates=391700, lr=5.0527e-05, gnorm=0.507, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 16:15:12 | INFO | train_inner | epoch 083:   2363 / 4751 loss=4.49, nll_loss=2.884, ppl=7.38, wps=87700.7, ups=3.02, wpb=29055.8, bsz=926.6, num_updates=391800, lr=5.05205e-05, gnorm=0.507, loss_scale=1, train_wall=33, gb_free=6.4, wall=0
2021-04-06 16:15:44 | INFO | train_inner | epoch 083:   2463 / 4751 loss=4.517, nll_loss=2.914, ppl=7.54, wps=87595.3, ups=3.04, wpb=28848.7, bsz=935.4, num_updates=391900, lr=5.05141e-05, gnorm=0.513, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 16:16:17 | INFO | train_inner | epoch 083:   2563 / 4751 loss=4.517, nll_loss=2.915, ppl=7.54, wps=88004.8, ups=3.06, wpb=28796.3, bsz=965.3, num_updates=392000, lr=5.05076e-05, gnorm=0.511, loss_scale=1, train_wall=33, gb_free=6, wall=0
2021-04-06 16:16:50 | INFO | train_inner | epoch 083:   2663 / 4751 loss=4.51, nll_loss=2.906, ppl=7.49, wps=86792.3, ups=3.02, wpb=28760, bsz=910.2, num_updates=392100, lr=5.05012e-05, gnorm=0.509, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 16:17:23 | INFO | train_inner | epoch 083:   2763 / 4751 loss=4.518, nll_loss=2.916, ppl=7.55, wps=87803.2, ups=3.02, wpb=29050.5, bsz=946.7, num_updates=392200, lr=5.04947e-05, gnorm=0.532, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 16:17:56 | INFO | train_inner | epoch 083:   2863 / 4751 loss=4.442, nll_loss=2.83, ppl=7.11, wps=87723.7, ups=3.03, wpb=28978.7, bsz=954.6, num_updates=392300, lr=5.04883e-05, gnorm=0.511, loss_scale=1, train_wall=33, gb_free=6.5, wall=0
2021-04-06 16:18:29 | INFO | train_inner | epoch 083:   2963 / 4751 loss=4.508, nll_loss=2.904, ppl=7.48, wps=86577.9, ups=3.03, wpb=28542.4, bsz=942.6, num_updates=392400, lr=5.04819e-05, gnorm=0.511, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 16:19:02 | INFO | train_inner | epoch 083:   3063 / 4751 loss=4.471, nll_loss=2.862, ppl=7.27, wps=87431.1, ups=3.04, wpb=28773.6, bsz=952.4, num_updates=392500, lr=5.04754e-05, gnorm=0.511, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 16:19:35 | INFO | train_inner | epoch 083:   3163 / 4751 loss=4.499, nll_loss=2.894, ppl=7.43, wps=87720.7, ups=3.03, wpb=28933.5, bsz=929.8, num_updates=392600, lr=5.0469e-05, gnorm=0.504, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 16:20:08 | INFO | train_inner | epoch 083:   3263 / 4751 loss=4.457, nll_loss=2.847, ppl=7.19, wps=87518.5, ups=3.03, wpb=28928.8, bsz=945.2, num_updates=392700, lr=5.04626e-05, gnorm=0.501, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 16:20:41 | INFO | train_inner | epoch 083:   3363 / 4751 loss=4.462, nll_loss=2.853, ppl=7.22, wps=88821.7, ups=3.05, wpb=29105.3, bsz=943.9, num_updates=392800, lr=5.04562e-05, gnorm=0.5, loss_scale=1, train_wall=33, gb_free=6, wall=0
2021-04-06 16:21:14 | INFO | train_inner | epoch 083:   3463 / 4751 loss=4.415, nll_loss=2.799, ppl=6.96, wps=88490.7, ups=3.03, wpb=29167.2, bsz=968.5, num_updates=392900, lr=5.04497e-05, gnorm=0.499, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 16:21:47 | INFO | train_inner | epoch 083:   3563 / 4751 loss=4.466, nll_loss=2.857, ppl=7.24, wps=87653.5, ups=3.04, wpb=28792.4, bsz=927.6, num_updates=393000, lr=5.04433e-05, gnorm=0.502, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 16:22:20 | INFO | train_inner | epoch 083:   3663 / 4751 loss=4.459, nll_loss=2.849, ppl=7.2, wps=87707.4, ups=3.03, wpb=28934.4, bsz=959.5, num_updates=393100, lr=5.04369e-05, gnorm=0.506, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 16:22:53 | INFO | train_inner | epoch 083:   3763 / 4751 loss=4.459, nll_loss=2.849, ppl=7.21, wps=87797.2, ups=3.03, wpb=28991.2, bsz=941.7, num_updates=393200, lr=5.04305e-05, gnorm=0.499, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 16:23:26 | INFO | train_inner | epoch 083:   3863 / 4751 loss=4.494, nll_loss=2.888, ppl=7.4, wps=87309.6, ups=3.04, wpb=28735.6, bsz=954.5, num_updates=393300, lr=5.04241e-05, gnorm=0.511, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 16:23:59 | INFO | train_inner | epoch 083:   3963 / 4751 loss=4.442, nll_loss=2.83, ppl=7.11, wps=87648.2, ups=3.02, wpb=28984.8, bsz=946.6, num_updates=393400, lr=5.04177e-05, gnorm=0.502, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 16:24:32 | INFO | train_inner | epoch 083:   4063 / 4751 loss=4.449, nll_loss=2.838, ppl=7.15, wps=88551.8, ups=3.02, wpb=29336.1, bsz=966.1, num_updates=393500, lr=5.04113e-05, gnorm=0.502, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 16:25:05 | INFO | train_inner | epoch 083:   4163 / 4751 loss=4.408, nll_loss=2.791, ppl=6.92, wps=87975.4, ups=3.01, wpb=29243, bsz=995.1, num_updates=393600, lr=5.04049e-05, gnorm=0.502, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 16:25:38 | INFO | train_inner | epoch 083:   4263 / 4751 loss=4.472, nll_loss=2.863, ppl=7.28, wps=88912.9, ups=3.05, wpb=29132, bsz=946.7, num_updates=393700, lr=5.03985e-05, gnorm=0.513, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 16:26:11 | INFO | train_inner | epoch 083:   4363 / 4751 loss=4.495, nll_loss=2.89, ppl=7.41, wps=88007.3, ups=3.06, wpb=28795, bsz=918.6, num_updates=393800, lr=5.03921e-05, gnorm=0.515, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 16:26:44 | INFO | train_inner | epoch 083:   4463 / 4751 loss=4.501, nll_loss=2.897, ppl=7.45, wps=88316, ups=3.05, wpb=28957.6, bsz=934.3, num_updates=393900, lr=5.03857e-05, gnorm=0.511, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 16:27:17 | INFO | train_inner | epoch 083:   4563 / 4751 loss=4.475, nll_loss=2.867, ppl=7.3, wps=86895.8, ups=2.98, wpb=29164.4, bsz=958.2, num_updates=394000, lr=5.03793e-05, gnorm=0.501, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 16:27:50 | INFO | train_inner | epoch 083:   4663 / 4751 loss=4.52, nll_loss=2.918, ppl=7.56, wps=87049, ups=3.05, wpb=28585.2, bsz=961.8, num_updates=394100, lr=5.03729e-05, gnorm=0.528, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 16:28:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-06 16:28:20 | INFO | valid | epoch 083 | valid on 'valid' subset | loss 4.123 | nll_loss 2.353 | ppl 5.11 | wps 200974 | wpb 10489.1 | bsz 375 | num_updates 394188 | best_loss 4.119
2021-04-06 16:28:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 83 @ 394188 updates
2021-04-06 16:28:20 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-06 16:28:26 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-06 16:28:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt (epoch 83 @ 394188 updates, score 4.123) (writing took 6.048178419470787 seconds)
2021-04-06 16:28:26 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)
2021-04-06 16:28:26 | INFO | train | epoch 083 | loss 4.471 | nll_loss 2.862 | ppl 7.27 | wps 87365.7 | ups 3.02 | wpb 28968.4 | bsz 946.9 | num_updates 394188 | lr 5.03673e-05 | gnorm 0.508 | loss_scale 2 | train_wall 1559 | gb_free 6.7 | wall 0
2021-04-06 16:28:26 | INFO | fairseq.trainer | begin training epoch 84
2021-04-06 16:28:26 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-06 16:28:31 | INFO | train_inner | epoch 084:     12 / 4751 loss=4.51, nll_loss=2.906, ppl=7.5, wps=68866, ups=2.42, wpb=28410.2, bsz=920.9, num_updates=394200, lr=5.03665e-05, gnorm=0.514, loss_scale=2, train_wall=32, gb_free=6.6, wall=0
2021-04-06 16:29:04 | INFO | train_inner | epoch 084:    112 / 4751 loss=4.426, nll_loss=2.811, ppl=7.02, wps=87166.3, ups=3.03, wpb=28779, bsz=936.6, num_updates=394300, lr=5.03601e-05, gnorm=0.504, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 16:29:37 | INFO | train_inner | epoch 084:    212 / 4751 loss=4.461, nll_loss=2.851, ppl=7.22, wps=88721.3, ups=3.05, wpb=29128.2, bsz=962.4, num_updates=394400, lr=5.03537e-05, gnorm=0.505, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 16:30:10 | INFO | train_inner | epoch 084:    312 / 4751 loss=4.452, nll_loss=2.84, ppl=7.16, wps=87479.9, ups=3.05, wpb=28727.5, bsz=974.2, num_updates=394500, lr=5.03473e-05, gnorm=0.509, loss_scale=2, train_wall=33, gb_free=6.7, wall=0
2021-04-06 16:30:43 | INFO | train_inner | epoch 084:    412 / 4751 loss=4.527, nll_loss=2.925, ppl=7.59, wps=85815, ups=2.98, wpb=28825.2, bsz=920.4, num_updates=394600, lr=5.0341e-05, gnorm=0.518, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 16:31:16 | INFO | train_inner | epoch 084:    512 / 4751 loss=4.47, nll_loss=2.861, ppl=7.26, wps=86758.1, ups=3.06, wpb=28391.6, bsz=936.1, num_updates=394700, lr=5.03346e-05, gnorm=0.514, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 16:31:49 | INFO | train_inner | epoch 084:    612 / 4751 loss=4.456, nll_loss=2.845, ppl=7.19, wps=88631.8, ups=3.04, wpb=29201, bsz=943.9, num_updates=394800, lr=5.03282e-05, gnorm=0.501, loss_scale=2, train_wall=33, gb_free=6.6, wall=0
2021-04-06 16:32:22 | INFO | train_inner | epoch 084:    712 / 4751 loss=4.439, nll_loss=2.826, ppl=7.09, wps=87696.9, ups=3.04, wpb=28854.8, bsz=935.8, num_updates=394900, lr=5.03218e-05, gnorm=0.509, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 16:32:55 | INFO | train_inner | epoch 084:    812 / 4751 loss=4.405, nll_loss=2.787, ppl=6.9, wps=88880.8, ups=3.04, wpb=29244.9, bsz=941.9, num_updates=395000, lr=5.03155e-05, gnorm=0.496, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 16:33:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2021-04-06 16:33:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2021-04-06 16:33:29 | INFO | train_inner | epoch 084:    914 / 4751 loss=4.446, nll_loss=2.834, ppl=7.13, wps=86967.1, ups=2.98, wpb=29225, bsz=969.3, num_updates=395100, lr=5.03091e-05, gnorm=0.504, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 16:34:01 | INFO | train_inner | epoch 084:   1014 / 4751 loss=4.466, nll_loss=2.856, ppl=7.24, wps=87489.3, ups=3.04, wpb=28791.9, bsz=922.1, num_updates=395200, lr=5.03027e-05, gnorm=0.505, loss_scale=1, train_wall=33, gb_free=6.5, wall=0
2021-04-06 16:34:34 | INFO | train_inner | epoch 084:   1114 / 4751 loss=4.522, nll_loss=2.92, ppl=7.57, wps=88214.5, ups=3.04, wpb=29047.9, bsz=909.5, num_updates=395300, lr=5.02964e-05, gnorm=0.514, loss_scale=1, train_wall=33, gb_free=6.5, wall=0
2021-04-06 16:35:07 | INFO | train_inner | epoch 084:   1214 / 4751 loss=4.469, nll_loss=2.86, ppl=7.26, wps=87188.4, ups=3.02, wpb=28828.2, bsz=943.8, num_updates=395400, lr=5.029e-05, gnorm=0.504, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 16:35:41 | INFO | train_inner | epoch 084:   1314 / 4751 loss=4.437, nll_loss=2.824, ppl=7.08, wps=88438.5, ups=3.02, wpb=29255.1, bsz=950.2, num_updates=395500, lr=5.02836e-05, gnorm=0.506, loss_scale=1, train_wall=33, gb_free=6, wall=0
2021-04-06 16:36:14 | INFO | train_inner | epoch 084:   1414 / 4751 loss=4.467, nll_loss=2.857, ppl=7.24, wps=86878.9, ups=3, wpb=28970.4, bsz=906.3, num_updates=395600, lr=5.02773e-05, gnorm=0.509, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 16:36:47 | INFO | train_inner | epoch 084:   1514 / 4751 loss=4.47, nll_loss=2.861, ppl=7.27, wps=87412.3, ups=3.03, wpb=28880.1, bsz=928.2, num_updates=395700, lr=5.02709e-05, gnorm=0.514, loss_scale=1, train_wall=33, gb_free=6, wall=0
2021-04-06 16:37:20 | INFO | train_inner | epoch 084:   1614 / 4751 loss=4.474, nll_loss=2.866, ppl=7.29, wps=87923.7, ups=3.05, wpb=28865.5, bsz=979.9, num_updates=395800, lr=5.02646e-05, gnorm=0.508, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 16:37:53 | INFO | train_inner | epoch 084:   1714 / 4751 loss=4.438, nll_loss=2.825, ppl=7.09, wps=88003.3, ups=3.03, wpb=29001.5, bsz=987, num_updates=395900, lr=5.02582e-05, gnorm=0.503, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 16:38:26 | INFO | train_inner | epoch 084:   1814 / 4751 loss=4.496, nll_loss=2.891, ppl=7.42, wps=87162.5, ups=3.04, wpb=28653.8, bsz=919.4, num_updates=396000, lr=5.02519e-05, gnorm=0.514, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 16:38:59 | INFO | train_inner | epoch 084:   1914 / 4751 loss=4.393, nll_loss=2.774, ppl=6.84, wps=88520.4, ups=3.02, wpb=29300.3, bsz=949.1, num_updates=396100, lr=5.02455e-05, gnorm=0.502, loss_scale=1, train_wall=33, gb_free=6.4, wall=0
2021-04-06 16:39:32 | INFO | train_inner | epoch 084:   2014 / 4751 loss=4.542, nll_loss=2.943, ppl=7.69, wps=87823.1, ups=3.04, wpb=28898.8, bsz=933, num_updates=396200, lr=5.02392e-05, gnorm=0.521, loss_scale=1, train_wall=33, gb_free=6, wall=0
2021-04-06 16:40:05 | INFO | train_inner | epoch 084:   2114 / 4751 loss=4.429, nll_loss=2.815, ppl=7.04, wps=87621.8, ups=3.02, wpb=28975.9, bsz=973.4, num_updates=396300, lr=5.02329e-05, gnorm=0.507, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 16:40:38 | INFO | train_inner | epoch 084:   2214 / 4751 loss=4.469, nll_loss=2.86, ppl=7.26, wps=87438.8, ups=3.03, wpb=28817.4, bsz=941.8, num_updates=396400, lr=5.02265e-05, gnorm=0.515, loss_scale=1, train_wall=33, gb_free=6.3, wall=0
2021-04-06 16:41:11 | INFO | train_inner | epoch 084:   2314 / 4751 loss=4.474, nll_loss=2.866, ppl=7.29, wps=87486.4, ups=3.03, wpb=28833.4, bsz=931.8, num_updates=396500, lr=5.02202e-05, gnorm=0.505, loss_scale=1, train_wall=33, gb_free=6.4, wall=0
2021-04-06 16:41:43 | INFO | train_inner | epoch 084:   2414 / 4751 loss=4.489, nll_loss=2.883, ppl=7.38, wps=88939.2, ups=3.04, wpb=29223.4, bsz=960.5, num_updates=396600, lr=5.02139e-05, gnorm=0.501, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 16:42:16 | INFO | train_inner | epoch 084:   2514 / 4751 loss=4.428, nll_loss=2.814, ppl=7.03, wps=88817.2, ups=3.03, wpb=29298.8, bsz=964.5, num_updates=396700, lr=5.02075e-05, gnorm=0.5, loss_scale=1, train_wall=33, gb_free=6.1, wall=0
2021-04-06 16:42:49 | INFO | train_inner | epoch 084:   2614 / 4751 loss=4.432, nll_loss=2.818, ppl=7.05, wps=88071, ups=3.03, wpb=29069.5, bsz=942.2, num_updates=396800, lr=5.02012e-05, gnorm=0.504, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 16:43:22 | INFO | train_inner | epoch 084:   2714 / 4751 loss=4.542, nll_loss=2.942, ppl=7.69, wps=87761.5, ups=3.03, wpb=28961.3, bsz=928.1, num_updates=396900, lr=5.01949e-05, gnorm=0.512, loss_scale=1, train_wall=33, gb_free=6.5, wall=0
2021-04-06 16:43:55 | INFO | train_inner | epoch 084:   2814 / 4751 loss=4.46, nll_loss=2.85, ppl=7.21, wps=88186.4, ups=3.03, wpb=29061.8, bsz=938.2, num_updates=397000, lr=5.01886e-05, gnorm=0.498, loss_scale=1, train_wall=33, gb_free=6.2, wall=0
2021-04-06 16:44:28 | INFO | train_inner | epoch 084:   2914 / 4751 loss=4.434, nll_loss=2.82, ppl=7.06, wps=89179.3, ups=3.05, wpb=29281.4, bsz=957.7, num_updates=397100, lr=5.01822e-05, gnorm=0.501, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 16:45:01 | INFO | train_inner | epoch 084:   3014 / 4751 loss=4.488, nll_loss=2.882, ppl=7.37, wps=87603.9, ups=3.03, wpb=28914.8, bsz=956.8, num_updates=397200, lr=5.01759e-05, gnorm=0.511, loss_scale=2, train_wall=33, gb_free=7.1, wall=0
2021-04-06 16:45:34 | INFO | train_inner | epoch 084:   3114 / 4751 loss=4.461, nll_loss=2.852, ppl=7.22, wps=88565.6, ups=3.04, wpb=29098.3, bsz=983.8, num_updates=397300, lr=5.01696e-05, gnorm=0.5, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 16:46:07 | INFO | train_inner | epoch 084:   3214 / 4751 loss=4.469, nll_loss=2.86, ppl=7.26, wps=86613.3, ups=3, wpb=28832.6, bsz=929.6, num_updates=397400, lr=5.01633e-05, gnorm=0.498, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 16:46:40 | INFO | train_inner | epoch 084:   3314 / 4751 loss=4.521, nll_loss=2.919, ppl=7.56, wps=87787.6, ups=3.04, wpb=28846.5, bsz=936.3, num_updates=397500, lr=5.0157e-05, gnorm=0.513, loss_scale=2, train_wall=33, gb_free=6, wall=0
2021-04-06 16:47:13 | INFO | train_inner | epoch 084:   3414 / 4751 loss=4.479, nll_loss=2.871, ppl=7.32, wps=87874.5, ups=3.02, wpb=29061.5, bsz=980.1, num_updates=397600, lr=5.01507e-05, gnorm=0.507, loss_scale=2, train_wall=33, gb_free=6.6, wall=0
2021-04-06 16:47:46 | INFO | train_inner | epoch 084:   3514 / 4751 loss=4.484, nll_loss=2.878, ppl=7.35, wps=88496.6, ups=3.05, wpb=29037.5, bsz=957.4, num_updates=397700, lr=5.01444e-05, gnorm=0.508, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 16:48:19 | INFO | train_inner | epoch 084:   3614 / 4751 loss=4.45, nll_loss=2.838, ppl=7.15, wps=88932.4, ups=3.05, wpb=29186.5, bsz=980.7, num_updates=397800, lr=5.01381e-05, gnorm=0.507, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 16:48:52 | INFO | train_inner | epoch 084:   3714 / 4751 loss=4.477, nll_loss=2.869, ppl=7.31, wps=86533.3, ups=3.04, wpb=28443.8, bsz=949.8, num_updates=397900, lr=5.01318e-05, gnorm=0.511, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 16:49:24 | INFO | train_inner | epoch 084:   3814 / 4751 loss=4.466, nll_loss=2.857, ppl=7.25, wps=88411.3, ups=3.06, wpb=28871, bsz=975.3, num_updates=398000, lr=5.01255e-05, gnorm=0.504, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 16:49:58 | INFO | train_inner | epoch 084:   3914 / 4751 loss=4.465, nll_loss=2.856, ppl=7.24, wps=88332.6, ups=3.03, wpb=29168.5, bsz=971, num_updates=398100, lr=5.01192e-05, gnorm=0.501, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 16:50:31 | INFO | train_inner | epoch 084:   4014 / 4751 loss=4.51, nll_loss=2.907, ppl=7.5, wps=87253.5, ups=3.03, wpb=28811.4, bsz=935.8, num_updates=398200, lr=5.01129e-05, gnorm=0.514, loss_scale=2, train_wall=33, gb_free=6.4, wall=0
2021-04-06 16:51:04 | INFO | train_inner | epoch 084:   4114 / 4751 loss=4.512, nll_loss=2.909, ppl=7.51, wps=86977.3, ups=3.01, wpb=28911.3, bsz=942.8, num_updates=398300, lr=5.01066e-05, gnorm=0.512, loss_scale=2, train_wall=33, gb_free=5.9, wall=0
2021-04-06 16:51:37 | INFO | train_inner | epoch 084:   4214 / 4751 loss=4.458, nll_loss=2.847, ppl=7.2, wps=88394.5, ups=3.05, wpb=29011.3, bsz=959.9, num_updates=398400, lr=5.01003e-05, gnorm=0.499, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 16:52:09 | INFO | train_inner | epoch 084:   4314 / 4751 loss=4.498, nll_loss=2.892, ppl=7.42, wps=88932.3, ups=3.05, wpb=29153.5, bsz=918.7, num_updates=398500, lr=5.0094e-05, gnorm=0.501, loss_scale=2, train_wall=33, gb_free=6.8, wall=0
2021-04-06 16:52:42 | INFO | train_inner | epoch 084:   4414 / 4751 loss=4.473, nll_loss=2.865, ppl=7.28, wps=87430.4, ups=3.03, wpb=28831.2, bsz=912.2, num_updates=398600, lr=5.00877e-05, gnorm=0.508, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 16:53:15 | INFO | train_inner | epoch 084:   4514 / 4751 loss=4.466, nll_loss=2.858, ppl=7.25, wps=88376.8, ups=3.03, wpb=29128, bsz=982.6, num_updates=398700, lr=5.00814e-05, gnorm=0.501, loss_scale=2, train_wall=33, gb_free=6.2, wall=0
2021-04-06 16:53:48 | INFO | train_inner | epoch 084:   4614 / 4751 loss=4.506, nll_loss=2.901, ppl=7.47, wps=87818.7, ups=3.05, wpb=28780.8, bsz=925.1, num_updates=398800, lr=5.00752e-05, gnorm=0.513, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 16:54:21 | INFO | train_inner | epoch 084:   4714 / 4751 loss=4.493, nll_loss=2.887, ppl=7.4, wps=88207.5, ups=3.03, wpb=29118.1, bsz=915.7, num_updates=398900, lr=5.00689e-05, gnorm=0.51, loss_scale=2, train_wall=33, gb_free=6.3, wall=0
2021-04-06 16:54:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-06 16:54:34 | INFO | valid | epoch 084 | valid on 'valid' subset | loss 4.127 | nll_loss 2.355 | ppl 5.11 | wps 208292 | wpb 10489.1 | bsz 375 | num_updates 398937 | best_loss 4.119
2021-04-06 16:54:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 84 @ 398937 updates
2021-04-06 16:54:34 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-06 16:54:41 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-06 16:54:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt (epoch 84 @ 398937 updates, score 4.127) (writing took 6.307346578687429 seconds)
2021-04-06 16:54:41 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)
2021-04-06 16:54:41 | INFO | train | epoch 084 | loss 4.47 | nll_loss 2.861 | ppl 7.27 | wps 87365.7 | ups 3.02 | wpb 28968.5 | bsz 946.7 | num_updates 398937 | lr 5.00666e-05 | gnorm 0.507 | loss_scale 2 | train_wall 1559 | gb_free 6.4 | wall 0
2021-04-06 16:54:41 | INFO | fairseq.trainer | begin training epoch 85
2021-04-06 16:54:41 | INFO | fairseq_cli.train | Start iterating over samples
2021-04-06 16:55:03 | INFO | train_inner | epoch 085:     63 / 4751 loss=4.416, nll_loss=2.8, ppl=6.97, wps=69900.1, ups=2.4, wpb=29096.2, bsz=935.8, num_updates=399000, lr=5.00626e-05, gnorm=0.504, loss_scale=2, train_wall=33, gb_free=5.9, wall=0
2021-04-06 16:55:36 | INFO | train_inner | epoch 085:    163 / 4751 loss=4.499, nll_loss=2.894, ppl=7.43, wps=87125.1, ups=3.04, wpb=28626, bsz=938.4, num_updates=399100, lr=5.00563e-05, gnorm=0.506, loss_scale=2, train_wall=33, gb_free=6.1, wall=0
2021-04-06 16:56:09 | INFO | train_inner | epoch 085:    263 / 4751 loss=4.443, nll_loss=2.831, ppl=7.12, wps=88466.7, ups=3.02, wpb=29263.6, bsz=980.2, num_updates=399200, lr=5.00501e-05, gnorm=0.5, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 16:56:42 | INFO | train_inner | epoch 085:    363 / 4751 loss=4.419, nll_loss=2.803, ppl=6.98, wps=88189.1, ups=3.03, wpb=29086.9, bsz=951.7, num_updates=399300, lr=5.00438e-05, gnorm=0.499, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-06 16:57:14 | INFO | train_inner | epoch 085:    463 / 4751 loss=4.492, nll_loss=2.886, ppl=7.39, wps=87705.5, ups=3.06, wpb=28655.2, bsz=906.3, num_updates=399400, lr=5.00375e-05, gnorm=0.511, loss_scale=4, train_wall=33, gb_free=6.5, wall=0
2021-04-06 16:57:47 | INFO | train_inner | epoch 085:    563 / 4751 loss=4.45, nll_loss=2.838, ppl=7.15, wps=87579.7, ups=3.02, wpb=28971.6, bsz=927.7, num_updates=399500, lr=5.00313e-05, gnorm=0.502, loss_scale=4, train_wall=33, gb_free=6.1, wall=0
2021-04-06 16:58:20 | INFO | train_inner | epoch 085:    663 / 4751 loss=4.496, nll_loss=2.89, ppl=7.41, wps=88158.9, ups=3.05, wpb=28913.2, bsz=934.5, num_updates=399600, lr=5.0025e-05, gnorm=0.508, loss_scale=4, train_wall=33, gb_free=6.4, wall=0
2021-04-06 16:58:53 | INFO | train_inner | epoch 085:    763 / 4751 loss=4.479, nll_loss=2.871, ppl=7.32, wps=88036.3, ups=3.04, wpb=28928.1, bsz=938.2, num_updates=399700, lr=5.00188e-05, gnorm=0.508, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 16:59:26 | INFO | train_inner | epoch 085:    863 / 4751 loss=4.476, nll_loss=2.867, ppl=7.3, wps=87272.6, ups=3.03, wpb=28789.2, bsz=937.5, num_updates=399800, lr=5.00125e-05, gnorm=0.51, loss_scale=4, train_wall=33, gb_free=6.2, wall=0
2021-04-06 16:59:59 | INFO | train_inner | epoch 085:    963 / 4751 loss=4.459, nll_loss=2.849, ppl=7.2, wps=86890.5, ups=3.01, wpb=28884.7, bsz=946.9, num_updates=399900, lr=5.00063e-05, gnorm=0.503, loss_scale=4, train_wall=33, gb_free=6.4, wall=0
2021-04-06 17:00:32 | INFO | train_inner | epoch 085:   1063 / 4751 loss=4.436, nll_loss=2.822, ppl=7.07, wps=88468.5, ups=3.05, wpb=29019.5, bsz=938.4, num_updates=400000, lr=5e-05, gnorm=0.501, loss_scale=4, train_wall=33, gb_free=6.3, wall=0
2021-04-06 17:00:32 | INFO | fairseq_cli.train | Stopping training due to num_updates: 400000 >= max_update: 400000
2021-04-06 17:00:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-04-06 17:00:33 | INFO | valid | epoch 085 | valid on 'valid' subset | loss 4.131 | nll_loss 2.358 | ppl 5.13 | wps 195338 | wpb 10489.1 | bsz 375 | num_updates 400000 | best_loss 4.119
2021-04-06 17:00:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 85 @ 400000 updates
2021-04-06 17:00:33 | INFO | fairseq.trainer | Saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-06 17:00:40 | INFO | fairseq.trainer | Finished saving checkpoint to /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt
2021-04-06 17:00:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /home/amax/Data/flstm/wmt/wslstm_fc4_attnfeat/checkpoint_last.pt (epoch 85 @ 400000 updates, score 4.131) (writing took 6.504380755126476 seconds)
2021-04-06 17:00:40 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)
2021-04-06 17:00:40 | INFO | train | epoch 085 | loss 4.463 | nll_loss 2.853 | ppl 7.22 | wps 85598.3 | ups 2.96 | wpb 28925.1 | bsz 939.2 | num_updates 400000 | lr 5e-05 | gnorm 0.505 | loss_scale 4 | train_wall 349 | gb_free 6.3 | wall 0
2021-04-06 17:00:40 | INFO | fairseq_cli.train | done training in 66391.6 seconds
Traceback (most recent call last):
  File "/home/amax/Codes/flstm-nmt/fairseq_cli/train.py", line 454, in <module>
    cli_main()
  File "/home/amax/Codes/flstm-nmt/fairseq_cli/train.py", line 450, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/home/amax/Codes/flstm-nmt/fairseq/distributed/utils.py", line 342, in call_main
    torch.multiprocessing.spawn(
  File "/home/amax/miniconda3/envs/nmt/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 200, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/home/amax/miniconda3/envs/nmt/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 158, in start_processes
    while not context.join():
  File "/home/amax/miniconda3/envs/nmt/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 106, in join
    raise Exception(
Exception: process 3 terminated with signal SIGSEGV
/home/amax/miniconda3/envs/nmt/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 344 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
